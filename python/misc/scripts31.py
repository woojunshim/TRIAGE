#####################################################
## Functions written for the histone width analysis ##
## Developed and written by Woo Jun Shim. Apr. 2017 ##
######################################################


import statistics as stat
import genomics_tools_v1 as genomics
import numpy as np
import scipy
from scipy import interpolate
import os
import statsmodels.stats.multitest as smm
import matplotlib.pyplot as plt
import random
import numpy.matlib
from numpy import trapz
from scipy.stats import norm

input_pathway = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Analysis_results/Tsankov/'
input_pathway1 = '/Users/woojunshim/Research/Data/'
data_pathway = '/Users/woojunshim/Research/Data/'
data_pathway1 = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/'
output_pathway = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Analysis_results/Tsankov/'
output_pathway1 = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Analysis_results/Test1/'
tissue_groups = {}
tissue_groups['IMR90'] = ['E017']
tissue_groups['ES_cell'] = ['E002', 'E008', 'E001', 'E015', 'E014', 'E016', 'E003', 'E024']
tissue_groups['iPSC'] = ['E020', 'E019', 'E018', 'E021', 'E022']
tissue_groups['ES_deriv.'] = ['E007', 'E009', 'E010', 'E013', 'E012', 'E011', 'E004', 'E005', 'E006']
tissue_groups['Blood&T_cell'] = ['E062', 'E034', 'E045', 'E033', 'E044', 'E043', 'E039', 'E041', 'E042',
                                 'E040', 'E037', 'E048', 'E038', 'E047']
tissue_groups['HSC&B_cell'] = ['E029', 'E031', 'E035', 'E051', 'E050', 'E036', 'E032', 'E046', 'E030']
tissue_groups['Mesench.'] = ['E026', 'E049', 'E025', 'E023']
tissue_groups['Myosat.'] = ['E052']
tissue_groups['Epithelial'] = ['E055', 'E056', 'E059', 'E061', 'E057', 'E058', 'E028', 'E027']
tissue_groups['Neurosph.'] = ['E054', 'E053']
tissue_groups['Thymus'] = ['E112', 'E093']
tissue_groups['Brain'] = ['E071', 'E074', 'E068', 'E069', 'E072', 'E067', 'E073', 'E070', 'E082', 'E081']
tissue_groups['Adipose'] = ['E063']
tissue_groups['Muscle'] = ['E100', 'E108', 'E107', 'E089', 'E090']
tissue_groups['Heart'] = ['E083', 'E104', 'E095', 'E105', 'E065']
tissue_groups['Smooth_muscle'] = ['E078', 'E076', 'E103', 'E111']
tissue_groups['Digestive'] = ['E092', 'E085', 'E084', 'E109', 'E106', 'E075', 'E101', 'E102', 'E110', 'E077',
                              'E079', 'E094']
tissue_groups['Other'] = ['E099', 'E086', 'E088', 'E097', 'E087', 'E080', 'E091', 'E066', 'E098', 'E096','E113']
#tissue_groups['ENCODE2012'] = ['E114', 'E115', 'E116', 'E117', 'E118', 'E119', 'E120', 'E121', 'E122', 'E123','E124', 'E125', 'E126', 'E127', 'E128', 'E129']
tissue_groups_ = {}
epigenomes = []
for group in tissue_groups:
    temp = tissue_groups[group]
    for epi in temp:
        tissue_groups_[epi] = group
        epigenomes.append(epi)
mrna_ = genomics.read_file1('mRNA_genes.txt')
mrna = set()
for item in mrna_:
    if item[0] not in mrna:
        mrna.add(item[0])
tf_ = genomics.read_file1('TF_combined.txt')
tf_list = []
znf_list = []
for line in tf_:
    tf_list.append(line[0])  
    if 'ZNF' in line[0]:
        znf_list.append(line[0])
znf_list = set(znf_list)
tf_list = set(tf_list)


def main(file_, output_, max_width__, tss__, dominant_=True, convert_DS=False, centre_=False, remove_ncrna_=True, only_width=True):
    ### Assigned genes to peaks
    ### only_include = a filename with gene IDs that are to be kept
    ### max_width__ = a max distance allowed (e.g. 2500)
    ### dominant_ = a boolean to indicate whether only broadest peaks are to be included (True)
    ### convert_DS = a boolean to indicate whether the width value is to be converted to width/SD (i.e. DS)
    ### centre_ = a boolean to indicate whether the centre location of the peak is used to calculate the distance to TSS

    h3k4me3_ = open(file_,'r')
    h3k4me3 = []
    h3k4me3__ = {}
    cnt = 0
    for line in h3k4me3_:
        cnt += 1
        line = line.strip().split()
        if not line[0].startswith('#'):
            if len(line) > 3:
                if not line[0].startswith('chr'):
                    line[0] = 'chr'+str(line[0])
                if str(line[3]) == '.' or str(line[3]).isdigit():
                    line[3] = 'ID_'+str(cnt)
            else:
                line.append('Peak_'+str(cnt))
            h3k4me3.append([line[0], line[1], line[2], line[3]])
 
            if str(line[3]) not in h3k4me3__:
                h3k4me3__[line[3]] = [[line[0], line[1], line[2], line[3]]]    

    # Assign genes to histone domains
    result_ = genomics.width_analysis3(bed_file=h3k4me3, tss_=tss__, remove_ncrna=remove_ncrna_, dominant=dominant_, list_all_genes=True, max_width_=max_width__, centre_=centre_, only_width=only_width)
    
    if output_ != None:
        genomics.write_file(result_, output_)
    else:
        return result_

def main1(input_file, chip_files, labels):
    ### TF ChIP-seq overlap analysis, writes out an updated file
    ### input_file = a filename with assigned genes (e.g. Assigned_genes_dMS.txt)
    ### chip_files = a list of TF ChIP-seq filename(s)
    ### labels = a list of labels for each ChIP-seq dataset
    domains = {}
    domains_ = open(input_pathway+input_file, 'r')
    for line in domains_:
        line = line.strip().split()
        if not line[0].startswith('#'):
            if len(line) > 5:
                if line[3] not in domains:
                    domains[line[3]] = []  # sort by chr
                domains[line[3]].append([line[0], line[1], line[2], line[4], line[5]])
        else:
            labels_ = []

    for no_ in range(len(chip_files)):
        chip = chip_files[no_]
        label = labels[no_]
        labels_.extend([label])
        data_ = open(input_pathway+chip, 'r')
        print chip
        chip_data = {}
        for line in data_:
            line = line.strip().split()
            if not line[0].startswith('#'):
                if not line[0].startswith('chr'):
                    line[0] = 'chr'+str(line[0])
                if line[0] not in chip_data:
                    chip_data[line[0]] = []
                chip_data[line[0]].append([line[1], line[2]])
        for chr_ in domains:
            for no in range(len(domains[chr_])):
                item = domains[chr_][no]
                cnt = 0
                for chip_ in chip_data[chr_]:
                    if int(chip_[0]) >= int(item[3]) and int(chip_[1]) <= int(item[4]):
                        cnt += 1
                domains[chr_][no].extend([cnt])

    domains__ = []
    domains__.append(['#Peak_ID','Assigned_gene','Width','Chr','Start','End'])
    for l in labels_:
        domains__[0].extend([l])

    for chr_ in domains:
        for item in domains[chr_]:
            domains__.append([item[0], item[1], item[2], chr_, item[3], item[4], item[5]])
            for m in range(6, len(item)):
                domains__[-1].extend([item[m]])



    genomics.write_file(domains__,input_pathway+'results.txt')


def chip_enrichment(input_file, col_no, bin_size, sort_by, binary=False, normalise=True):
    ### input_file (e.g. results.txt)
    ### col_no = a column number where the data is extracted
    ### bin_size = number of the genes in a bin
    ### sort_by = an integer indicating the column with which the data is sorted in a descending order
    ### binary = True (1:TF bound, 0:TF non-bound), False (taking into account the number of TF binding events)
    ### normalise = a boolean to indicate whether the counts are to be normalised for width (only works when binary == False)
    data_ = []
    input_data = open(input_file, 'r')
    for line in input_data:
        line = line.strip().split()
        if not line[0].startswith('#'):
            data_.append(line)
    for no in range(len(data_)):
        data_[no][sort_by] = float(data_[no][sort_by])

    data_ = genomics.sort_(data_, idx=sort_by, reverse_=True)

    results = []
    no_bin = len(data_) / bin_size
    for i in range(0, no_bin):
        numbers = []
        bp = 0.0
        for j in range(0, bin_size):
            idx = (i*bin_size) + j
            if binary==False:
                numbers.append(int(data_[idx][col_no]))
            else:
                if int(data_[idx][col_no]) != 0:
                    numbers.append(1)
                else:
                    numbers.append(0)
            if normalise==True:
                bp += float(data_[idx][5]) - float(data_[idx][4])

        if normalise==False:
            output = genomics.mean_(numbers)
        else:
            if binary==False:
                output = round((np.sum(numbers) / bp) * 1000, 8)  # Normalising counts in 1000 bp
        results.append(output)

    return results


def extract_info(input_file, gene_id_idx, exp_idx, id_separator=','):
    ### extracts gene IDs and corresponding expression data, returns a list
    ### input_file = a source input file (e.g. nature14233-s1.txt)
    ### gene_id_idx = a column index where gene ID(s) are located
    ### exp_idx = a column index where an expression value for a gene is recorded
    ### id_separator = in case of multiple gene IDs, separate entries are created. This separator can't be a part of the gene_id
    results = []
    input_ = open(input_pathway+input_file,'r')
    for line in input_:
        line = line.strip().split()

        if not line[0].startswith('#'):
            gene_ids = line[gene_id_idx]
            gene_ids = gene_ids.strip('"')
            if id_separator in gene_ids:
                ids = gene_ids.split(id_separator)
            else:
                ids = [gene_ids]

            for id in ids:
                results.append([id, float(line[exp_idx])])
    return results

def add_column1(input_file, insert_file, id_idx, insert_head, insert_position):
    ### add a column from insert_file into input_file at column position (insert_position).
    ### id_idx is a column position where gene IDs are located in the input_file
    ### NOTE. the insert_file MUST have two columns (1st column = gene name, 2nd column = relevant data)
    ### returns a list
    input_ = open(input_pathway+input_file, 'r')
    results = []
    for line in input_:
        line = line.strip().split()
        results.append(line)

    input_ = open(input_pathway+insert_file, 'r')
    insert_data = {}
    for line in input_:
        line = line.strip().split()
        if not line[0].startswith('#'):
            insert_data[line[0]] = line[1]

    for no in range(len(results)):
        item = results[no]
        if not item[0].startswith('#'):
            id = str(item[id_idx])
            if id in insert_data:
                results[no].insert(insert_position, insert_data[id])
            else:
                results[no].insert(insert_position, 0.0)   # If no data is available, set the value to 0.0
        else:
            results[0].insert(insert_position, insert_head)

    return results

def num_filter_list(input_list, col_idx, min_, max_=9999999):
    ### extract elements of a list that meets specified numerical conditions (i.e. min_ & max_)
    ### Note. This function ONLY works for a list of lists (nested list). For a single list, see num_filter method.
    ### input_list = a list of lists
    ### col_idx = an index specifying the index number with which the extraction is performed
    ### min_, max_ = floats to define the extraction criterion (i.e. minimum and maximum values)
    results = []
    for item in input_list:
        if float(item[col_idx]) >= float(min_) and float(item[col_idx]) <= float(max_):
            results.append(item)
    return results

def inter_cell_type_analysis(input_file, col_idx1, background_file, col_idx2, output_, convert=True, log_=True):
    ### calculate p-value of a given H3K4me3 width in a population from the background_file
    ### input_file = e.g. Assigned_genes_dMS.txt
    ### col_idx1 = column index number where numerical values for sorting are recorded (input_file)
    ### background_file = e.g. summary_results_pdf_dominant_2.5kb_standard_percentile.txt
    ### col_idx2 = column index number where numercial values for sorting are recorded (background_file)
    ### convert = a boolean to indicate whether the value is to be converted to DS (i.e. width/SD)
    ### log_ = a boolean to indicate whether log-conversion is to be performed
    ### output_ = an output file name

    background = {}
    results = []
    temp_ = []


    # Read in input_file
    temp = open(input_file, 'r')
    for line in temp:
        line = line.strip().split()
        if not line[0].startswith('#'):
            if len(line) > 5:
                if line[1] not in results:
                    if convert==True:
                        temp_.append(float(line[col_idx1]))
                    results.append(line)
                    results[-1].extend([float(line[col_idx1])])
        else:
            header= line

    if convert==True:
        sd = np.std(temp_)
        for no in range(len(results)):
            results[no][-1] = float(results[no][col_idx1]) / sd

    # Read in background file
    temp = open(background_file, 'r')
    for line in temp:
        line = line.strip().split()
        if not line[0].startswith('#'):
            if line[0] not in background:
                background[line[0]] = []
            background[line[0]].extend([float(line[col_idx2])])

    # Calculate the DS
    for no in range(len(results)):
        gene = results[no][1]
        if gene in background:
            if log_ == False:
                mean_ = np.mean(background[gene])
                sd_ = np.std(background[gene])
                input_value = float(results[no][-1])
            else:
                mean_ = np.mean(np.log10(background[gene]))
                sd_ = np.std(np.log10(background[gene]))
                input_value = float(np.log10(results[no][-1]))
            if sd_ != float(0):
                z_ = stat.z_score(input_value, mean_, sd_)
                p_ = stat.p_value(z_)
                results[no].extend([z_, p_])
            else:
                results[no].extend(['NA', 1.0])  # If SD ==0, give p-value of 1.0
        else:
            results[no].extend(['NA','NA'])

    header.extend(['value','z-score','p-value'])
    results.insert(0, header)
    genomics.write_file(results, output_)

def check_dynamic_ranges(input_file, output_file, cut_off_file, col_idx, gene_idx, convert=True, as_value=True):
    ### Check the DS cutoff
    ### input_file = e.g. Assigned_genes_dMS_.txt OR summary_results_pdf_dominant_2.5kb_standard.txt
    ### gene_idx = a column index where the gene name is recorded
    ### cut_off_file = e.g. tf_cut_off_list.txt
    ### col_idx = a column index where the DS (or width) values are recorded in the input file
    ### convert = a boolean to indicate whether conversion to DS (width/SD) is required.
    ### as_value = a boolean to indicate whether the outcome is to be recorded as a difference from the threshold (True) or binary (False)
    gene_idx = int(gene_idx)
    input__ = open(input_file, 'r')
    results = []
    for line in input__:
        line = line.strip().split()
        if not line[0].startswith('#'):
            results.append(line)
        else:
            header = line
    input__ = open(cut_off_file, 'r')
    cut_off = {}
    for line in input__:
        line = line.strip().split()
        if not line[0].startswith('#'):
            cut_off[line[0]] = float(line[1])
    if convert==True:
        temp = []
        for item in results:
            temp.append(float(item[col_idx]))
        sd_ = np.std(temp)
        for no in range(len(results)):
            converted = float(results[no][col_idx]) / sd_
            results[no][col_idx] = converted
    for no in range(len(results)):
        gene = results[no][gene_idx]
        if gene in cut_off:
            if as_value == False:
                if float(results[no][col_idx]) >= float(cut_off[gene]):
                    results[no].extend(['True'])
                else:
                    results[no].extend(['False'])
            else:
                if float(cut_off[gene]) == float(999999):
                    results[no].extend(['NA'])
                else:
                    diff_ = float(results[no][col_idx]) - float(cut_off[gene])
                    results[no].extend([diff_])
        else:
            results[no].extend(['Not_observed'])
    header.extend(['Dynamic_range'])
    results.insert(0, header)
    genomics.write_file(results, output_file)



def calculate_slope(point1, point2, abs_=True):
    ### Calculate a slope given two points
    ### point1, point2 = a list of x,y coordinates (e.g. [1,2])
    ### abs_ = a boolean to indicate whether the calculated slope should be shown as an absolute value (True)
    x_diff = float(point2[0])-float(point1[0])
    y_diff = float(point2[1])-float(point1[1])
    slope = y_diff / x_diff
    if abs_ == True:
        slope = np.abs(slope)
    return slope

def find_dynamic_range(input_data, threshold, interpolate_, range_mark, output_cutoff):
    ### Calculate a slope at each data point and identify data points on the x-axis (or y-axis) whether the slope exceeds the threshold
    ### input_data = a list of lists (data points) E.g. [[1,3],[2,10],...]
    ### threshold = a numerical value as the threshold (e.g. slope of 2 etc)
    ### interpolate_ = a boolean to indicate whether the interpolation of the input data is to be pre-computed. Slope is a tangent of the interpolated curve.
    ### range_mark = a number to define the floor of the high dynamic range (e.g. 0.5 = top 50% as the floor limitation)
    ### output_cutoff = a boolean to indicate whether the cut-off value should be output as well
    ### Note. If number of data points <3, it returns None. Otherwise, a list of x-axis (or y-axis) points is returned.
    ### NOTE. the coordinates must be in the ascending order (i.e. y-axis value from lowest to the highest, while x-axis is just a count)
    results = []
    if len(input_data) < 4:
        return None
    else:
        total_ = float(len(input_data))

        if interpolate_==False:
            cut_off_ = 999999
            for no in range(len(input_data)-1):
                item1 = input_data[no]
                item2 = input_data[no+1]
                slope = calculate_slope(item1, item2, abs_=True)
                if slope >= threshold:
                    if 1-(float(no+1) / total_) <= range_mark:
                        results.append(item1)
                        cut_off_ = item1[1]
                        break

        else:
            x=[]
            y=[]
            h=0.01
            cut_off_ = 999999
            for item in input_data:
                x.append(float(item[0]))
                y.append(float(item[1]))
            f = interpolate.splrep(x, y, k=3, s=1)  # k = spline fit (3= cubic), s = smoothing fit
            for no in range(len(input_data)-1):
                item = input_data[no]
                slope = (interpolate.splev(item[0]+h, f, der=0) - interpolate.splev(item[0], f, der=0)) / h  # derivative

                if abs(float(slope)) >= threshold:
                    if 1-(float(no+1) / total_) <= range_mark:
                        results.append(item)

            if output_cutoff == True and results != []:
                point2 = results[0][0] - 1
                x1 = []
                for i in range(int(1/h)):
                    x1.append(point2+i*h)
                for no in range(len(x1)):
                    slope = (interpolate.splev(x1[no]+h, f, der=0) - interpolate.splev(x1[no], f, der=0)) / h
                    if abs(float(slope)) >= threshold:
                        cut_off_ = interpolate.splev(x1[no]+h, f, der=0)
        if output_cutoff == False:
            return results
        else:
            return results, cut_off_


def define(threshold_, file_, output_):
    ### DEFINE A HIGH DYNAMIC RANGE FOR EACH GENE
    ### threshold = a float that is a multiplier of the overall slope (e.g. 2 meaning the threshold is the overall slope * 2)
    ### file = e.g. summary_results_dominant_1.0.txt
    ### output_ = output file prefix
    results = {}  # results[gene_name] = a set of epigenome IDs
    input_ = {}
    input_tf = {}
    input_non_tf = {}
    epigenome = []
    data_file = open(file_, 'r')
    for line in data_file:
        line = line.strip().split()
        if not line[0].startswith('#'):
            if line[0] not in input_:
                input_[line[0]] = []
            input_[line[0]].append([line[1], float(line[4])])
            if line[-2]=='True':
                if line[0] not in input_tf:
                    input_tf[line[0]] = []
                input_tf[line[0]].append([line[1], float(line[4])])
            else:
                if line[0] not in input_non_tf:
                    input_non_tf[line[0]] = []
                input_non_tf[line[0]].append([line[1], float(line[4])])
            if not line[1] in epigenome:
                epigenome.append(line[1])

    # TF GROUP
    cut_off_list = []
    for tf in input_tf:
        temp = genomics.sort_(input_tf[tf], idx=1, reverse_=False)
        coordinates = []
        for i in range(len(temp)):
            coordinates.append([float(i+1), temp[i][1]])
        if len(coordinates) < 4:
            continue
        else:
            slope_1 = calculate_slope(coordinates[0], coordinates[-1], abs_=True)
            dynamics,cut_off_ = find_dynamic_range(coordinates, threshold=slope_1*threshold_, interpolate_=True, range_mark=0.5, output_cutoff=True)
            cut_off_list.append([tf, cut_off_])
            if len(dynamics) > 0:
                cut_off = float(dynamics[0][1])
            else:
                cut_off = 9999999  # No dynamics range defined
            results[tf] = set()
            for no in range(len(temp)):
                item = temp[no]
                if float(item[1]) >= cut_off:
                    results[tf].add(item[0])
    tf_table = {}
    tf_table['colnames'] = epigenome
    for tf in results:
        if tf not in tf_table:
            tf_table[tf] = []
        for epi in epigenome:
            if epi in results[tf]:
                tf_table[tf].append('1')
            else:
                tf_table[tf].append('0')
    genomics.write_table(tf_table, output_+'tf_background.txt')
    genomics.write_file(cut_off_list, output_+'tf_cut_off_list.txt')


    # NON-TF GROUP
    results = {}
    cut_off_list = []
    for non_tf in input_non_tf:
        temp = genomics.sort_(input_non_tf[non_tf], idx=1, reverse_=False)
        coordinates = []
        for i in range(len(temp)):
            coordinates.append([float(i+1), temp[i][1]])
        if len(coordinates) < 4:
            continue
        else:
            slope_1 = calculate_slope(coordinates[0], coordinates[-1], abs_=True)
            dynamics,cut_off_ = find_dynamic_range(coordinates, threshold=slope_1*threshold_, interpolate_=True, range_mark=0.5, output_cutoff=True)
            cut_off_list.append([non_tf, cut_off_])
            if len(dynamics) > 0:
                cut_off = float(dynamics[0][1])
            else:
                cut_off = 9999999  # No dynamics range defined
            results[non_tf] = set()
            for no in range(len(temp)):
                item = temp[no]
                if float(item[1]) >= cut_off:
                    results[non_tf].add(item[0])
    non_tf_table = {}
    non_tf_table['colnames'] = epigenome
    for non_tf in results:
        if non_tf not in non_tf_table:
            non_tf_table[non_tf] = []
        for epi in epigenome:
            if epi in results[non_tf]:
                non_tf_table[non_tf].append('1')
            else:
                non_tf_table[non_tf].append('0')
    genomics.write_table(non_tf_table, output_+'nontf_background.txt')
    genomics.write_file(cut_off_list, output_+'nontf_cut_off_list.txt')


def group_counting(input_, ref_, output_, proportion=True):
    ### merge counts from individual cell types into a tissue group defined by ref_. Writes out a text file (table)
    ### input_ = an input data in the form of a dictionary (e.g. input_[gene1] = ['E095','E083'])
    ### ref_ = an group reference (e.g. tissue_groups) in the form of a set (e.g. ref_['E095'] = 'Heart')
    ### proportion = a boolean to indicate whether the counts should be converted to proportions (i.e. count / number of cell types of the group)
    results = {}
    epigenomes = []
    for epi in ref_:
        if ref_[epi] not in epigenomes:
            epigenomes.append(ref_[epi])
    for gene in input_:
        results[gene] = []
        for no in range(len(epigenomes)):
            results[gene].extend([0])
        for epi in input_[gene]:
            if epi in ref_:

                idx = epigenomes.index(ref_[epi])
                results[gene][idx] += 1
        if proportion == True:
            for no in range(len(results[gene])):
                group = epigenomes[no]
                results[gene][no] = float(results[gene][no]) / len(tissue_groups[group])
    results['colnames'] = epigenomes
    genomics.write_table(results, data_pathway1+output_)

def read_table1(input_file, numerical=True, as_list=False, include_sum = False, threshold_=None, del_colnames=True):
    ### reads in a table file and returns a dictionary
    ### Note. the number of colnames must be always n-1 where n is the total number of columns (including rownames)
    ### numerical = a boolean to indicate whether the data should be read as numbers (True) or string (False)
    ### as_list = a boolean to indicate whether the data is to be stored in the form of dictionary of lists, rather than dictionary of dictionaries
    ### include_sum = a boolean to indicate whether total counts for each row is to be recorded (only works for numerical data)
    ### threshold = a numerical value to set a threshold value entries with values below which are not included (if threshold_= None --> no threshold)
    ### del_colnames = a boolean to indicate whether to remove 'colnames' in the table
    ### e.g. output[row][col] = xx (when as_list=False) OR output[row] = [xx, xx, ..] (when as_list=True)
    ###      output[row]['total'] = sum of total for the row
    ###      output['colnames'] = [a list of column names]

    results = {}
    results['colnames'] = []
    input_ = open(input_file, 'r')
    cnt= 0
    for line in input_:
        line = line.replace(' ','_')
        line = line.strip().split()
        sum_ = 0.0
        if cnt == 0:
            for item in line:
                results['colnames'].append(item)
            cnt = 1
        else:
            if line[0] not in results:
                if as_list == False:
                    results[line[0]] = {}
                else:
                    results[line[0]] = []
            for no in range(len(results['colnames'])):
                group_name = results['colnames'][no]                
                if numerical == True:
                    if as_list == False:
                        if threshold_!= None:
                            if float(line[no+1]) >= float(threshold_):
                                results[line[0]][group_name] = float(line[no+1])
                        else:
                            results[line[0]][group_name] = float(line[no + 1])
                    else:
                        if threshold_!= None:
                            if float(line[no + 1]) >= float(threshold_):
                                results[line[0]].append(float(line[no + 1]))
                        else:
                            results[line[0]].append([group_name, float(line[no+1])])
                    if include_sum == True:
                        sum_ += float(line[no+1])
                else:
                    if as_list == False:
                        results[line[0]][group_name] = line[no+1]
                    else:
                        results[line[0]].append(line[no+1])
            if include_sum == True:
                results[line[0]]['sum'] = sum_
    if del_colnames==True:
        del results['colnames']
    return results


def extract_rows(input_table, members):
    ### takes a table instance and only takes lines with rawnames as specified by members 
    if type(input_table)==str:
        input_table = read_table1(input_table)
    members = set(members)
    gg = get_rownames(input_table)
    for gene in gg:
        if gene not in members:
            del input_table[gene]
    return input_table




def enrichment_analysis(input_file, background_file, output_ = 'p-value', binary_output=False, threshold=0.05, multiple_correction=False):
    ### takes table files (both input & background) with rows indicating items (e.g. genes) and columns indicating groups (e.g. tissue types)
    ### performs the enrichment analysis using Fisher's exact test and returns a table instance
    ### input_file & background_files = input table files (e.g. tf_dynamics_range_table_GROUP_counts.txt)
    ### binary_output = a boolean to indicate whether the output is a binary outcome based on the threshold as the p-value (only works when binary_output=True)
    ### output_ = 'p-value' or 'odd'
    ### threshold = a statistical threshold to be applied
    ### multiple_correction = a boolean to indicate whether the p-values should be corrected (only works when output_='p-value', FDR_Benjamini-Hochberg method)

    input_data = read_table1(input_file, numerical=True, as_list=False, include_sum=False)
    background_data = read_table1(background_file, numerical=True, as_list=False, include_sum=False)
    results = {}
    results['colnames'] = input_data['colnames']
    for gene in input_data:
        if gene != 'colnames':
            if gene not in results:
                results[gene] = []
                for no in range(len(input_data['colnames'])):
                    results[gene].append(0)
            for no in range(len(input_data['colnames'])):
                group_name = input_data['colnames'][no]
                a = input_data[gene][group_name]
                b = background_data[gene][group_name] - input_data[gene][group_name]
                c = 0.0
                for background_group in input_data['colnames']:
                    if background_group != group_name:
                        c += input_data[gene][background_group]
                d = 0.0
                for background_group in background_data['colnames']:
                    if background_group != group_name:
                        d += background_data[gene][background_group]
                d = d - c
                odd, p = stat.fisher(a, b, c, d)
                if output_ == 'p-value':
                    output = p
                elif output_ == 'odd':
                    output = odd

                if binary_output == True:
                    if output <= threshold:
                        output = 1
                    else:
                        output = 0
                results[gene][no] = output
            if multiple_correction==True:
                temp = smm.multipletests(results[gene], method='fdr_bh')
                results[gene] = list(temp[1])

    return results

def get_DEG(table_file, threshold_=0.05, by_column=True, convert_file='/Users/woojunshim/Research/Data/Ensembl_gene_symbols_conversion.txt'):
    ### reads in an expression table file (e.g. 56_epigenomes_empirical.txt) and outputs a dictionary of DEG (differentially expressed genes)
    ### threshold_ = a float anything below which are considered to be DEGs
    ### by_column = a boolean to indicate whether the output is to be sorted by column names of the input table
    ### convert_file = a text input file for the ID conversion. If '', this step is skipped.
    if convert_file != '':
        conversion_table = {}
        temp = open(convert_file, 'r')
        for line in temp:
            line = line.strip().split()

            if not line[0].startswith('#'):
                if len(line) > 1:
                    conversion_table[line[0]] = line[1]

    results = {}

    input_table = read_table1(table_file, numerical=True, as_list=False, include_sum=False)
    for gene in input_table:
        if gene != 'colnames':
            for group in input_table[gene]:
                if input_table[gene][group] <= threshold_:
                    if by_column==True:
                        if group not in results:
                            results[group] = []
                        if convert_file != '':
                            if gene in conversion_table:
                                gene_ = conversion_table[gene]
                        else:
                            gene_ = gene
                        results[group].append(gene_)
                    else:
                        if convert_file != '':
                            if gene in conversion_table:
                                gene_ = conversion_table[gene]
                        else:
                            gene_ = gene
                        if gene not in results:
                            results[gene_] = []
                        results[gene_].append(group)
    return results

def convert_file(input_file, output_file, from_='summary', to_='assigned'):
    ### REWRITE THIS!
    ### convert files
    ### from_ = 'summary' (e.g. summary_results_pdf_dominant_2.5kb_standard.txt)
    ### to_ = 'assigned' (e.g. Assigned_genes_dMS.txt)
    input__ = open(input_file, 'r')
    input_ = []
    results = []
    if from_== 'summary':
        for line in input__:
            line = line.strip().split()
            if not line[0].startswith('#'):
                input_.append(line)
            else:
                header=line
    if to_ == 'assigned':
        for item in input_:
            results.append([item[2], item[0], item[3]])

def get_intersection(input_data, input_deg, no_genes=100, dynamic_filter=True):
    ### check intersections between DEGs and genes with high h3k4me3 widths
    ### input_data = a dictionary of the input file (e.g. input_data['E095'] = [['HAND2', 12.0453, True], ['ISL1', 3.123, False], ...]). can be multiple cell types
    ### input_deg = an output from 'get_DEG' function
    ### no_genes = total number of top genes to be included
    ### dynamic_file = a boolean to indicate whether filtering using the dynamic range is to be performed
    ### Note. input_file['E095'] = [gene, DS, dynamic range(T/F)]
    results = {}
    intersection_ = {}
    for epi in input_data:
        if epi in input_deg:
            results[epi] = []
            temp = input_data[epi]
            temp = genomics.sort_(temp, idx=1, reverse_=True)
            cnt = 0
            for no in range(len(temp)):
                if cnt == no_genes:
                    break
                item = temp[no]
                if dynamic_filter == True and item[2] == 'True':
                    results[epi].append(item[0])
                    cnt += 1
                elif dynamic_filter == True and item[2] == 'False':
                    continue
                else:
                    results[epi].append(item[0])
                    cnt += 1

            intersection_[epi] = float(len(genomics.intersection(input_deg[epi], results[epi]))) / len(input_deg[epi])
    return intersection_

def overlap_fantom(input_file, input_fantom, gene_idx=1, coordinates=[3,4,5], fantom_type='promoter', distance=2500, gene_match=True):
    ### Check overlap with FANTOM5 CAGE-peak dataset (either 'promoter' or 'enhancer') and returns a list
    ### It scans all entries and records numbers of overlaps with CAGE peak dataset
    ### input_file = e.g. CVP_K4.bed___.txt (i.e files with assigned genes)
    ### input_fantom = e.g. CAGE_human_promoters_FANTOM5.txt (i.e. FANTOM5 CAGE peak annotated file)
    ### gene_idx = a column index in the input_file where the gene symbol is recorded
    ### coordinates = a list of 3 column indexes with genomic coordinates for the entry (representing chr, start and end in order)
    ### fantom_type = either 'promoter' (FANTOM5 CAGE promoter) or 'enhancer' (CAGE enhancer)
    ### gene_match = a boolean to indicate whether only matched FANTOM5 CAGE peaks are to be counted (e.g. HAND2 only to p1/2/3..@HAND2)
    ### distance = an integer that specifies boundaries where the overlap is counted from a TSS (e.g. 2500 = +- 2.5kb of TSS)

    if fantom_type == 'promoter':
        fantom = {}  # For promoters (e.g. fantom['chr4']['HAND2'] = [[100002, 100006, p1@HAND2],...])
    else:
        fantom = []  # For enhancers
    input_data= []
    header = []
    input_file_ = open(input_file, 'r')
    for line in input_file_:
        line = line.strip().split()
        if line[0].startswith('#'):
            for m in line:
                header.append(m)
        else:
            input_data.append(line)

    input_ = open(input_fantom, 'r')
    if fantom_type=='promoter':
        for line in input_:
            line = line.strip().split()
            if not line[0].startswith('#'):
                temp = line[0].split(':')
                chr_ = temp[0]
                temp1 = temp[1].split('..')
                start_ = temp1[0]
                temp2 = temp1[1].split(',')
                end_ = temp2[0]
                temp = line[1].split('@')
                gene_ = temp[1]
                if '..' not in gene_:
                    if chr_ not in fantom:
                        fantom[chr_] = {}
                    if gene_ not in fantom[chr_]:
                        fantom[chr_][gene_] = []
                    fantom[chr_][gene_].append([int(start_), int(end_), str(temp[0])])

    for no in range(len(input_data)):
        item = input_data[no]
        cnt = 0
        chr_ = item[coordinates[0]]
        start_ = item[coordinates[1]]
        end_ = item[coordinates[2]]
        width = int(end_) - int(start_)
        gene_ = item[gene_idx]
        ratio_ = 0
        if gene_match == True:
            if gene_ in fantom[chr_]:
                for m in fantom[chr_][gene_]:
                    m_start = m[0] - distance
                    m_end = m[1] + distance
                    if (m_start >= int(start_)) and (m_start <= int(end_)):
                        cnt += 1
                    elif (m_end >= int(start_)) and (m_end <= int(end_)):
                        cnt += 1
        normalised_count = float(cnt) / float(width)
        if gene_ in fantom[chr_]:
            ratio_ = float(cnt) / len(fantom[chr_][gene_])
        input_data[no].extend([cnt, normalised_count, ratio_])

    header.extend(['CAGE_peak_counts','Normalised_CAGE_peak_counts_per_1kbs','CAGE_peak_counts(ratio)'])
    input_data.insert(0, header)
    return input_data


def add_coordinates(input_file, epi_idx):
    ### reads in a file (e.g. summary_results_pdf_dominant_2.5kb_standard_1.5.txt) and add columns for the coordinates
    ### returns a list
    ### input_file = e.g. summary_results_pdf_dominant_2.5kb_standard_1.5.txt
    ### id_idx = a column index where the domain ID (e.g. Rank_27168) is recorded

    input_data = '-H3K4me3.gappedPeak.bed'
    input_pathway_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/'
    input_, header = genomics.read_file(input_file, [0,2,3,4,8,9,10], rowname=str(epi_idx), header_=True)
    epigenomes = []
    for epi in input_:
        epigenomes.append(epi)
    for epi in epigenomes:
        temp = {}
        temp__ = open(input_pathway_+epi+input_data, 'r')
        for line in temp__:
            line = line.strip().split()
            temp[line[3]] = [line[0], line[1], line[2]]

        items = input_[epi]
        for no in range(len(items)):
            id = input_[epi][no][1]  # peak id index = 1
            input_[epi][no].extend([temp[id][0],temp[id][1],temp[id][2]])

    results = []

    for epi in epigenomes:
        for item in input_[epi]:
            results.append([item[0],epi,item[1],item[7],item[8],item[9],item[2],item[3],item[4],item[5],item[6]])
    header = ['#gene','cell_type','domain','chr','start','end','width','width/SD','TF','mRNA','non-linear']
    results.insert(0, header)
    return results

def find_intra_threshold(input_file, col_idx, threshold_):
    ### reads in a gene-assigned file (e.g. CVP_K4_combined.txt) and find an intra-threshold
    ### returns a list
    ### input_file = e.g. CVP_K4_combined.txt
    ### col_idx = a column index number where the value is recorded
    ### threshold_ = a numberical value (k) defining the threshold slope (i.e. threshold = overall slope * k)
    input_ = genomics.read_file1(input_file)
    for no in range(len(input_)):
        input_[no][col_idx] = float(input_[no][col_idx])
    input_ = genomics.sort_(input_, idx=col_idx, reverse_=False)
    coordinates = []
    for no in range(len(input_)):
        coordinates.append([no+1, input_[no][col_idx]])
    overall_slope = calculate_slope(coordinates[0], coordinates[-1], abs_=True)
    results_, cut_off = find_dynamic_range(coordinates, threshold=overall_slope*threshold_, interpolate_=True, range_mark=0.5, output_cutoff=True)
    results = []
    for item in input_:
        if float(item[col_idx]) >= cut_off:
            results.append(item)
    return results

def convert_id(input_file, ref_file, col_idx1, col_idx2):
    ### reads in a single-columned text file which contains a list of gene IDs (e.g. Ensembl or gene symbols)
    ### and convert those IDs based on ref_file which is a two-columned text file. Returns a list of lists
    ### input_file = e.g. TF_combined.txt or a list of lists (e.g. [['gene1'],['gene2']...])
    ### ref_file = e.g. Ensembl_gene_symbols_conversion.txt (downloaded from BioMart)
    ### col_idx1 = an integer indicating which column in the ref_file is to be used as keys (i.e. from which IDs)
    ### col_idx2 = an integer indicating which column in the ref_file is to be used as values (ie. to which IDs)
    results = []
    if type(input_file) != list:
        input_ = genomics.read_file1(input_file)
    else:
        input_ = []
        for item in input_file:
            input_.append(item)
    if type(ref_file) != dict:
        ref_ = {}
        ref__ = open(ref_file, 'r')
    for line in ref__:
        line = line.strip().split()
        if not line[0].startswith('#'):
            if len(line)> col_idx1 and len(line)> col_idx2:
                if not line[col_idx1] in ref_:
                    ref_[line[col_idx1]] = line[col_idx2]
    for item in input_:
        if item[0] in ref_:
            results.append(ref_[item[0]])
        else:
            results.append('NA')
    return results

def filtering_ratios(input_list, gene_list, gene_idx, dynamic_idx, value_='False'):
    ### calculates filtering metrics (a,b,c, see below) & intersections after filtering (d) & simple-bottom-up trimming (e)
    ### input_list = a list of lists of assigned entries from e.g. E095-H3K4me3.gappedPeak.bed__.txt or summary-***.txt
    ###              Note. This MUST be pre-sorted.
    ### gene_list = a list (or set) of gene members (e.g. highly expressed TFs/genes)
    ### gene_idx = a column number where the genes are recorded in the input_file
    ### dynamic_idx = a column number where the filtering value is recorded
    ### value_ = a string used for filtering (e.g. 'FALSE' = filtered as it's not within the non-linear section)
    ### a = (no. non-members with value_ / total no. with value_) / (no. non-members / total no.)
    ### b = (no. members with value_ / total no. with value_) / (no. members / total no.)
    ### c = a/b  (i.e. c > 1.0 (more specific filtering for non-members and vice versa)
    ### d = a list of intersect genes after the filtering
    ### e = a list of intersect genes after simple bottom-up removal (with the same number of filtered genes removed from the bottom)
    total_before = len(input_list)
    no_members = 0
    no_non_members = 0
    no_members_value = 0
    no_non_members_value = 0
    total_value = 0
    after_filtering = []
    all = []
    for item in input_list:
        all.append(item[gene_idx])
        if str(item[dynamic_idx]) == value_:
            total_value += 1
        else:
            after_filtering.append(item[gene_idx])
        if str(item[gene_idx]) in gene_list:
            no_members += 1

            if str(item[dynamic_idx]) == value_:
                no_members_value += 1
        else:
            no_non_members += 1
            if str(item[dynamic_idx]) == value_:
                no_non_members_value += 1
    a = (float(no_non_members_value) / float(total_value)) / (float(no_non_members) / float(total_before))
    b = (float(no_members_value) / float(total_value)) / (float(no_members) / float(total_before))
    c = 0
    if float(b)!=float(0):
        c = a/b
    bottom_up = []
    for no in range(total_before - total_value):
        bottom_up.append(input_list[no][gene_idx])
    d = genomics.intersection(after_filtering, gene_list)
    e = genomics.intersection(bottom_up, gene_list)
    f = [after_filtering, bottom_up]
    return a,b,c,d,e,f

def transpose(input_):
    ### TRANSPOSE A TABLE INSTANCE
    input_ = check_table(input_)
    results = {}
    rows = get_rownames(input_)
    cols = get_colnames(input_)
    for c in cols:
        results[c] = {}
        for r in rows:
            results[c][r] = input_[r][c]
    return results

def transpose_table(input_file):
    ### transpose a table file (i.e. row -> column, column -> row)
    ### takes a dictionary of dictionary (i.e. from read_table1)
    ### returns a list
    results = {}
    results['colnames'] = []
    input_ = read_table1(input_file, del_colnames=False)
    for i in input_:
        if i == 'colnames':
            rows = input_[i]
        elif i not in results['colnames']:
            results['colnames'].append(i)
    for i in input_:
        if i != 'colnames':
            for j in rows:
                if j not in results:
                    results[j] = []
                results[j].append([i, input_[i][j]])
    return results

def sliding_fet(input_list, ref_list, output_='p-value', convert_to_percentile=True, percentile_bin = 0.01):
    ### calculate Fisher's exact test statistics (output_ = 'p-value' or 'odds')
    ### it's based on membership check at a sliding point starting from index number 0
    ### input_list = a list of input members
    ### ref_list = a list (or set) of reference items the FET is checked against
    ### convert_to_percentile = a boolean to indicate whether the rank position should be converted to a percentile (100~1th%)
    results = []
    a,b,c,d = 0,0,0,0
    if percentile_bin < 1:
        bin_size = int(float(len(input_list)) * float(percentile_bin))
        max_no = int(1 / percentile_bin)
    else:
        bin_size = percentile_bin
        max_no = len(input_list) / percentile_bin
    no = 0
    cnt = 1
    for item in input_list:  # background scanning
        if item in ref_list:
            c += 1
        else:
            d += 1
    qq = 0
    for item in input_list:
        qq += 1
        if item in ref_list:
            a += 1
            c -= 1
        else:
            b += 1
            d -= 1
        if convert_to_percentile==False:            
            odd_, p_ = stat.fisher(a,b,c,d)

            if output_ == 'p-value':
                results.append(p_)
            elif output_ == 'odds':
                results.append(odd_)

        else:
            if (cnt % bin_size == 0) and (no < max_no):
                odd_, p_ = stat.fisher(a, b, c, d)
                no += 1
                if output_ == 'p-value':
                    results.append(p_)
                elif output_== 'odd':
                    results.append(odd_)
        cnt += 1    
    if convert_to_percentile==True:
        results[-1] = 1.0

    return results

def filtering(input_file, table_file, conversion_file, output_file, top_no, sorting='increasing', simple_removal='False', fet_=True, indexs=[0,2,4,-1]):
    ### calculate filtering specificity metrics
    ### input_file = e.g. summary_results_pdf_dominant_2.5kb_standard.txt_1.0 or Assigned_genes_MS__.txt
    ### table_file = e.g. Highly_expressed_TFs.txt (i.e. a table file of highly(differentially) expressed genes by p-value)
    ### conversion_file = e.g. Ensembl_gene_symbols_conversion.txt
    ### output_file = a name of output file prefix (including pathway)
    ### top_no = number of top genes to be selected from the table_file (0 == all in the list)
    ### fet_ = a boolean to indicate whether the Fisher's exact test for our filtering method vs. simple bottom-up method should be outputted
    ### sorting_ = a boolean to indicate whether the table_file is to be sorted in an 'increasing' (e.g. for p-value) or 'descreasing' (e.g. for FPKM) order
    ### simple_revoval = a boolean to indicate whether the outcome is the simple bottol-up removal
    ### indexs = a list of column indexes [gene_ID, domain_ID, SD, dynamic(T/F)]
    if type(table_file) != list:
        table = transpose_table(table_file)
    results = {}
    results['colnames'] = ['non-member-ratio(a)','member-ratio(b)','a/b']
    input_data = {}
    fet = {}
    temp = open(input_file, 'r')
    if top_no==0:
        for m in table:
            top_no = len(m)-1
    for line in temp:
        line = line.strip().split()
        if not line[0].startswith('#'):
            if line[epi_idx] not in input_data:
                input_data[line[epi_idx]] = []
            input_data[line[epi_idx]].append([line[0],line[2],line[4],line[-1]])
            input_data[line[epi_idx]][-1][2] = float(line[2])
    for epi in table:
        if epi != 'colnames':
            input_list = table[epi]
            if sorting == 'increasing':
                sorting_ = False
            else:
                sorting_ = True
            input_list = genomics.sort_(input_list, idx=1, reverse_=sorting_)
            input_list_ = []
            for i in range(top_no):
                input_list_.append(input_list[i][0])
            genomics.write_file(input_list_, 'temp.txt')
            input_list__ = convert_id('temp.txt', conversion_file, col_idx1=0, col_idx2=1)
            temp = input_data[epi]
            temp = genomics.sort_(temp, idx=2, reverse_=True)
            a, b, c, d, e, f = filtering_ratios(temp, input_list__, gene_idx=0, dynamic_idx=-1)

            if simple_removal == True:
                cnt = 0
                for no in range(len(temp)):
                    item = temp[no]
                    if item[-1] == 'True':
                        cnt += 1
                for no in range(cnt):
                    temp[no].extend(['True'])  # 'True' meaning it's within the list (after simple bottom-up removal)
                for no in range(cnt, len(temp)):
                    temp[no].extend(['False'])
                a, b, c, d, e, f = filtering_ratios(temp, input_list__, gene_idx=0, dynamic_idx=-1)
            results[epi] = [a,b,c]

        if fet_==True:
            fet[epi] = [[], []]
            fet[epi][0] = sliding_fet(f[0], set(input_list__))
            fet[epi][1] = sliding_fet(f[1], set(input_list__))
    genomics.write_table(results,output_file + '_specificity_'+ str(top_no) + '.txt')
    if fet_==True:
        for epi in fet:
            genomics.write_file(fet[epi],output_file + '_' + epi + '_sliding_fet.txt')

def density_analysis(input_list, ref_list, bin_size_=0.05, odd_ratio_=True, background_ratio_=None, accumulative_=False):
    ### takes a list of genes (input_list) and calculate distribution of the reference genes in the input across bins with defined size
    ### returns a list
    ### ref_list = a list or set of reference genes (e.g. top differentially expressed genes)
    ### bin_size = a float that defines the size of bins (e.g. 0.05 = 5% of the total size)
    ### odd_ratio = a boolean that indicates whether the outcome are odd-ratios (i.e. density in a bin / overall density) or not (i.e. density in a bin)
    ### background_ratio = either None or a float as the background ratio. If None, the background is calculated based on the input data    
    ### acumulative_ = boolean to indicate whether the ratio is accumulative

    total_no = len(input_list)
    results = []
    ref_list = set(ref_list)
    bin_size = int(round(total_no * bin_size_))
    bin_number = int(1/bin_size_)
    if background_ratio_ == None:
        if odd_ratio_ == True:
            cnt = 0
            for item in input_list:
                if item in ref_list:
                    cnt += 1
            background_ratio = float(cnt) / float(total_no)
        else:
            background_ratio = 1.0
    else:
        background_ratio = float(background_ratio_)
    cnt = 0
    mm= 0 
    for no1 in range(bin_number-1):
        if accumulative_==False:
            cnt = 0
        for no2 in range(bin_size):
            mm += 1
            item = input_list[no1*bin_size + no2]
            if item in ref_list:
                cnt += 1
        if accumulative_==False:
            results.append((float(cnt) / bin_size) / background_ratio)
        else:
            results.append((float(cnt) / mm) / background_ratio)
    if accumulative_==False:
        cnt = 0
    for no2 in range((bin_number-1)*bin_size, total_no):        
        item = input_list[no2]
        if item in ref_list:
            cnt += 1
    if accumulative_==False:
        results.append((float(cnt)/bin_size) / background_ratio)
    else:
        results.append(1.0)
    return results, background_ratio


def density_analysis1(input_list, ref_list, odd_ratio_=True, background_ratio_=None, accumulative_=False):
    ### takes a list of genes (input_list) and calculate distribution of the reference genes in the input across bins with defined size
    ### returns a list
    ### ref_list = a list or set of reference genes (e.g. top differentially expressed genes)
    ### bin_size = a float that defines the size of bins (e.g. 0.05 = 5% of the total size)
    ### odd_ratio = a boolean that indicates whether the outcome are odd-ratios (i.e. density in a bin / overall density) or not (i.e. density in a bin)
    ### background_ratio = either None or a float as the background ratio. If None, the background is calculated based on the input data    
    ### acumulative_ = boolean to indicate whether the ratio is accumulative
    ### bin_size is determined 

    total_no = len(input_list)
    results = []
    ref_list = set(ref_list)
    bin_size = int(round(total_no * bin_size_))
    bin_number = int(1/bin_size_)
    if background_ratio_ == None:
        if odd_ratio_ == True:
            cnt = 0
            for item in input_list:
                if item in ref_list:
                    cnt += 1
            background_ratio = float(cnt) / float(total_no)
        else:
            background_ratio = 1.0
    else:
        background_ratio = float(background_ratio_)
    cnt = 0
    mm= 0 
    for no1 in range(bin_number-1):
        if accumulative_==False:
            cnt = 0
        for no2 in range(bin_size):
            mm += 1
            item = input_list[no1*bin_size + no2]
            if item in ref_list:
                cnt += 1
        if accumulative_==False:
            results.append((float(cnt) / bin_size) / background_ratio)
        else:
            results.append((float(cnt) / mm) / background_ratio)
    if accumulative_==False:
        cnt = 0
    for no2 in range((bin_number-1)*bin_size, total_no):        
        item = input_list[no2]
        if item in ref_list:
            cnt += 1
    if accumulative_==False:
        results.append((float(cnt)/bin_size) / background_ratio)
    else:
        results.append(1.0)
    return results, background_ratio


def point_fet(input_list, ref_list, cut_off_, output_='p-value', alternative_='greater'):
    ### Fisher's exact test at a specified cut-off point (defined as a top x percent, e.g. 0.05 = 95th percentile or index number)
    a,b,c,d = 0,0,0,0    
    if cut_off_ < 1.0:
        cut_off_no = int(round(len(input_list)*cut_off_))
    else:
        cut_off_no = int(cut_off_)
    for no in range(len(input_list)):
        item = input_list[no]
        if no > cut_off_no:
            if item in ref_list:
                c += 1
            else:
                d += 1
        else:
            if item in ref_list:
                a += 1
            else:
                b += 1
    print a,b,c,d
    print
    odd_, p_ = stat.fisher(a, b, c, d, alternative_=alternative_)
    if output_ == 'p-value':
        result = p_
    elif output_ == 'odd':
        result = odd_
    return result

def point_fet1(input_list, ref_list, cut_off, alternative_='greater'):
    ### FET at a defined rank position (as the number of genes)
    a,b,c,d = 0,0,0,0
    temp = input_list[0:cut_off-1]
    ref_list = set(ref_list)
    for i in temp:
        if i in ref_list:
            a += 1
        else:
            b += 1
    for i in range(cut_off-1,len(input_list)):
        if input_list[i] in ref_list:
            c += 1
        else:
            d += 1
    o, p = stat.fisher(a,b,c,d, alternative_=alternative_)
    return p


def point_fet_(input_list, labels, ref_, cut_off):
    results = [['p-value','method','colname']]
    for n in range(len(inputs)):
        input_ = check_table(inputs[n])
        label_ = labels[n]
        cols = get_colnames(input_)
        for col in cols:            
            #positive = get_positive_genes(input_, col, threshold=0)
            positive = ref_
            a = get_rownames_by_sorting_table1(input_, col, threshold=0)            
            aa = point_fet1(a, positive, cut_off)
            results.append([aa, label_, col])
    return results

def create_rank_table(input_data, gene_idx, value_idx, decreasing_=True, rank_position=True, numerical_=True):
    ### reads in a input_data (dictionary, e.g. input_data['E095'] = [[gene1, value1], [gene2, value2], ...] and
    ### sort them in an order, returns a table instance with rank order
    ### gene_idx = a column index where names for row identifications are recorded (e.g. gene symbols)
    ### value_idx = a column index where numerical values for sorting are recorded.
    ### decreasing_ = a boolean to indicate how the items are to be ordered.
    ### rank_position = a boolean to indicate whether the rank positon (True) or value(False) is to be recorded.
    results = {}
    epigenomes = []
    all_genes = set()
    sorted_list = {}
    for epi in input_data:
        if (epi not in epigenomes) and (epi != 'colnames'):
            epigenomes.append(epi)
            sorted_list[epi] = {}
        for item in input_data[epi]:
            gene = item[gene_idx]
            if gene not in all_genes:
                all_genes.add(gene)
                results[gene] = []
    results['colnames'] = epigenomes
    for epi in epigenomes:
        if epi != 'colnames':
            input_data[epi] = genomics.sort_(input_data[epi], idx=value_idx, reverse_=decreasing_, numerical=numerical_)
            for no in range(len(input_data[epi])):
                item = input_data[epi][no]
                if rank_position == True:
                    sorted_list[epi][item[gene_idx]] = no+1
                else:
                    sorted_list[epi][item[gene_idx]] = input_data[epi][no][value_idx]
    for gene in all_genes:
        for epi in epigenomes:
            if epi != 'colnames':
                if gene in sorted_list[epi]:
                    results[gene].append(sorted_list[epi][gene])
                else:
                    results[gene].append('NA')
    return results

def transpose_table1(input_table, as_list_=True):
    ### takes a table instance and transpose it.
    ### as_list_ = a boolean to indicate whether the table instance is a dictionary of lists (e.g. output['E001'] = [['ENSG..', xx.xx], ... ]
    ### Note the input data must be in the form of a dictionary of dictionaries (e.g. input_table['ENSG..]['E001'] = xx.xx)
    results = {}
    if as_list_ != True:
        for item1 in input_table:
            for item2 in input_table[item1]:
                if item2 not in results:
                    results[item2] = {}
        for item1 in input_table:
            for item2 in input_table[item1]:
                results[item2][item1] = input_table[item1][item2]
    else:
        results['colnames'] = []
        for item1 in input_table:
            if item1 not in results['colnames']:
                results['colnames'].append(item1)
            for item2 in input_table[item1]:
                if item2 not in results:
                    results[item2] = []
        for col in results['colnames']:
            for item in input_table[col]:
                if col != 'colnames':
                    results[item].append([col, input_table[col][item]])
    return results

def conversion_table(input_file, from_idx, to_idx):
    ### reads in a file (e.g. Ensembl_gene_symbols_conversion_.txt) and creates a conversion dictionary
    results = {}
    data_ = open(input_file, 'r')
    max_idx = max(from_idx, to_idx)
    for line in data_:
        line = line.strip().split()
        if len(line) > max_idx:
            if line[from_idx] not in results:
                results[line[from_idx]] = line[to_idx]
    return results

def group_comparison(data_file, cat_file, grouping='col', group_id='1.0', exclude_='0.0', test_='wilcoxon'):
    ### takes a data_table (e.g. Max.width_table.txt) with numerical values and a catagory_table(e.g. Peak_count_table.txt) to group subsets of data points
    ### returns a list of statistical outputs
    ### into two subgroups (as defined by group_id in cat_table)
    ### grouping = 'col' (for columns group), 'row' (for rows group)
    ### exclude_ = exclude entries with a designated string in cat_file
    ### test_ = a stat test to be used (i.e. 'wilcoxon' = Wilcoxon rank sum test, 't-test' = student t-test)
    results = [['#ID','statistics','p-value']]
    data_table = read_table1(data_file)
    cat_table = read_table1(cat_file)
    del data_table['colnames']
    del cat_table['colnames']
    if grouping=='col':
        genes =  []
        groups = []
        for item in data_table:
            if item not in genes:
                genes.append(item)
                for col_ in data_table[item]:
                    if col_ not in groups:
                        groups.append(col_)

        for group in groups:
            group1 = []  # members that have the group_id
            group2 = []  # members that do not have the group_id
            for gene in genes:
                if gene in cat_table:
                    if group in cat_table[gene]:
                        if str(cat_table[gene][group]) != str(exclude_):
                            if str(cat_table[gene][group]) == str(group_id):
                                group1.append(float(data_table[gene][group]))
                            else:
                                group2.append(float(data_table[gene][group]))
            if group1 != []:
                if test_ == 'wilcoxon':
                    s, p = scipy.stats.ranksums(group1, group2)
                elif test_ =='t-test':
                    s, p = scipy.stats.ttest_ind(group1, group2)
            results.append([group, s, p])
    return results


def check_overlap(input1, input2):
    ### takes two genomic coordinates to check for overlap and returns a boolean value
    if input1[0] == input2[0]:
        if int(input1[1]) >= int(input2[1]) and int(input1[1]) <= int(input2[2]):
            return True
        elif int(input1[2]) >= int(input2[1]) and int(input1[2]) <= int(input2[2]):
            return True
        else:
            return False
    return False


def create_bed(input_file, chr_idx, start_idx, end_idx, id_idx):
    ### creates a basic 4 column BED format, returns a list
    results = []
    if type(input_file) == str:
        input_ = genomics.read_file1(input_file)
    else:
        input_ = input_file
    max_idx = max(chr_idx, start_idx, end_idx, id_idx)
    for item in input_:
        if len(item) > max_idx:
            results.append([item[chr_idx], item[start_idx], item[end_idx], item[id_idx]])
    return results

def select_lines(input_file, ref_file, id_idx):
    ### scans all lines in the input and takes only ones with reference IDs
    ### id_idx = a column index in the input_file where the IDs are recorded
    results = []
    if type(input_file) == str:
        input_ = genomics.read_file1(input_file)
    else:
        input_ = input_file
    if type(ref_file) == str:
        ref_ = genomics.read_file1(ref_file)
    else:
        ref_ = ref_file
    ref = set()
    for item in ref_:
        ref.add(item[0])    
    for item in input_:        
        if (item[id_idx] in ref) or (list(ref)[0] in item[id_idx]):
            results.append(item)
    return results

def trim_txt(input_file, cols, col_names):
    ### takes an input text file and extract only defined columns
    ### cols = a list of column indexes (input_file)
    ### col_names = a list of column names (i.e. header)
    input_ = genomics.read_file1(input_file)
    results = []
    for item in input_:
        results.append([])
        for idx in cols:
            results[-1].extend([item[idx]])
    if col_names != None:
        results.insert(0, col_names)
    return results

def simple_trim(input_list, cols):
    ### takes a list and extract elements specified by cols (i.e. a list of columm indexes)
    results = []
    for col in cols:
        results.append(input_list[col])
    return results


def identify_ref_peaks(input_file, gene_idx, epi_idx, value_idx, id_idx, category='max'):
    ### identifies the reference peaks from a list of item lists & returns a list
    ### gene_idx = a column index where the gene ID is recorded (as a string, e.g. '1' for the column number 1)
    ### epi_idx = a column index where the cell type (or epi) ID is recorded
    ### value_idx = a column index where the value is recorded
    ### id_idx = a column index where the domain ID is recorded
    ### category = 'max' (highest value) or 'min' (lowest value)
    results = []
    if type(input_file) == str:
        input_ = genomics.read_file(input_file, [epi_idx, value_idx, id_idx], rowname=gene_idx)
    else:
        input_ = {}
        for item in input_:
            if item not in input_:
                input_[item] = []
            input_[item].append([item[epi_idx], float(item[value_idx])])
    for gene in input_:
        current_value = None
        for item in input_[gene]:
            if current_value == None:
                current_value = float(item[1])
                epi = item[0]
                id = item[2]
            else:
                if category=='max':
                    if float(item[1]) > current_value:
                        current_value = float(item[1])
                        id = item[2]
                        epi = item[0]
                elif category=='min':
                    if float(item[1]) < current_value:
                        current_value = float(item[1])
                        id = item[2]
                        epi = item[0]
        results.append([gene, epi, id, current_value])
    results.insert(0, ['#gene','cell_type','domain_id','DS'])
    return results

def extract_cols(input_file, prefix_idx, id_idx, filename, id_idx_, cols, col_names):
    ### streamlines extraction of column information from file(s) defined by prefix_idx (e.g. index where E003 is recorded) and filename (e.g. /Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/E001-H3K4me3.gappedPeak.bed)
    ### input_file = e.g. 'Ref_peaks.txt'
    ### prefix_idx = a column index where prefix of the filename is recorded (e.g. E068)
    ### id_idx = a column index where the domain ID is recorded in the input file(e.g. Rank_xxxx)
    ### filename = e.g. '-H3K4me3.gappedPeak.bed'
    ### id_idx_ = a column index where the domain ID is recorded in the file(s)
    ### cols = a list of column indexes to extract from the file(s) (e.g. [0,1,2])
    ### col_names = a list of column names (i.e. header)
    pathway='/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/'
    input_ = genomics.read_file1(input_file)
    prefix_list = []
    for item in input_:
        if item[prefix_idx] not in prefix_list:
            prefix_list.append(item[prefix_idx])
    data = {}
    for prefix in prefix_list:
        data[prefix] = {}
        temp = open(pathway+prefix+filename, 'r')
        for line in temp:
            line = line.strip().split()
            data[prefix][line[id_idx_]] = []
            for col in cols:
                data[prefix][line[id_idx_]].append(line[col])
    for no in range(len(input_)):
        epi = input_[no][prefix_idx]
        id = input_[no][id_idx]
        if epi in data:
            if id in data[epi]:
                for m in data[epi][id]:
                    input_[no].extend([m])
    input_.insert(0, col_names)
    return input_

def calculate_distances(input_file, ref_file, input_id_idx, input_coord, ref_id_idx, ref_coord, method='centre'):
    ### calculate genomic distances between a reference point and a given peak
    ### input_file = e.g. /Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/summary_results_pdf_dominant_2.5kb_standard.txt_1.0
    ### ref_file = e.g. /Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/Ref_peaks.txt
    ### input_id_idx = a column index where the gene ID (or symbol) is recorded
    ### input_coord = [chr_idx, start_idx, end_idx] in the input_file
    ### method = 'centre' for the centre point, 'min' for the minimum distance
    ### ref_id_idx = where the gene ID is recorded in the ref_file (MUST be a string)
    input_ = genomics.read_file1(input_file)
    ref_ = {}
    ref__ = open(ref_file, 'r')
    for line in ref__:
        line = line.strip().split()
        if not line[0].startswith('#'):
            if line[ref_id_idx] not in ref_:
                ref_[line[ref_id_idx]] = []
                for m in ref_coord:
                    ref_[line[ref_id_idx]].append(line[m])
    for no in range(len(input_)):
        gene_name = input_[no][input_id_idx]
        item = input_[no]
        distance = calculate_distance([item[input_coord[0]],item[input_coord[1]],item[input_coord[2]]], [ref_[gene_name][0],ref_[gene_name][1],ref_[gene_name][2]], method)
        input_[no].extend([distance])
    return input_

def calculate_distance(coord1, coord2, method):
    if coord1[0] == coord2[0]:
        if method=='centre':
            point1 = (int(coord1[1])+int(coord1[2])) / 2
            point2 = (int(coord2[1])+int(coord2[2])) / 2
            distance = np.abs(point1-point2)
        elif method=='min':
            option1 = np.abs(int(coord1[1])-int(coord2[1]))
            option2 = np.abs(int(coord1[1])-int(coord2[2]))
            option3 = np.abs(int(coord1[2])-int(coord2[1]))
            option4 = np.abs(int(coord1[2])-int(coord2[2]))
            distance = np.min([option1,option2,option3,option4])
    else:
        distance = None
    return distance

def rank_product(input_list, id_idx, indexs, order_='ascending'):
    ### calculate rank product (https://en.wikipedia.org/wiki/Rank_product) of variables and returns a list of lists (e.g. [[gene1, rank product],...,])
    ### input_list = a list of items
    ### id_idx = a column index of the input_list where the gene ID is recorded
    ### indexs = a list of column indexes where the rank variables are recorded
    if order_=='descending':
        reverse__ = True
    elif order_ =='ascending':
        reverse__ = False
    ranks = {}
    final_list = []
    for item in input_list:
        if item[id_idx] not in ranks:
            ranks[item[id_idx]] = []
    for idx_ in indexs:
        temp = genomics.sort_(input_list, idx=idx_, reverse_=reverse__)
        for no in range(len(temp)):
            name = temp[no][id_idx]
            ranks[name].append(no+1)
    for name in ranks:
        rp = calculate_rp(ranks[name])
        final_list.append([name, rp])
    return final_list

def calculate_rp(input_list, root_=True):
    ### calculate rank product and returns a float
    product = 1
    for item in input_list:
        product *= item
    if root_==True:
        a = pow(product, 1/float(len(input_list)))
    else:
        a = product    
    return a

def add_column(input_list, add_list, input_idx, add_idx, value_idx):
    ### adds a new column into the input_list
    ### input_idx = a column index where the ID is recorded in input_list
    ### add_idx = a column index where the ID is recorded in the add_list
    ### value_idx = a column index where the value is recorded in the add_list
    add_list_ = {}
    if type(add_list) != dict:
        for item in add_list:
            if item[add_idx] not in add_list_:
                add_list_[item[add_idx]] = ''
            add_list_[item[add_idx]] = item[value_idx]
    else:
        add_list_ = add_list
    for no in range(len(input_list)):
        item = input_list[no]
        name = item[input_idx]
        if name in add_list_:
            input_list[no].extend([add_list_[name]])
        else:
            input_list[no].extend(['NA'])
    return input_list

def compare_two_states(input1, input2, value_idx1, value_idx2, gene_idx1, gene_idx2, output_, write_extra=False):
    ### takes two time-points or cell states and compare values of a given variable
    ### inputs_ = a list of filenames (e.g. Paige_K4me3_day5_assigned_.txt) or a list of dictionaries of item lists (e.g. input[gene1] = [2.22])
    ### value_idx1, value_idx2 = column indexes where values are recorded
    ### gene_idx1, gene_idx2 = column indexes where gene IDs are recorded
    ### output_ = an output filename
    ### write_extra = a boolean to indicate whether appeared and disappeared gene are to be written out
    ### Note1. the output includes a summary statistics and clusters of genes
    ### Note2. the change is ALWAYS assumes to be from input1 to input2
    if type(input1) == str:
        input1_ = genomics.read_file(input1, [value_idx1], rowname=str(gene_idx1))
    else:
        input1_ = input1
    if type(input2) == str:
        input2_ = genomics.read_file(input2, [value_idx2], rowname=str(gene_idx2))
    else:
        input2_ = input2

    # Work out the overall change between the two points (i.e. input2 - input1 for all genes)
    # Only takes into account those present in the both states
    all_changes = []
    appear = []
    disappear = []
    valid_genes = set()
    results = []
    for gene in input1_:
        if gene in input2_:
            change = float(input2_[gene][0][0]) - float(input1_[gene][0][0])
            all_changes.append(change)
            results.append([gene, change])
            valid_genes.add(gene)
        else:
            all_changes.append(float(input1_[gene][0][0]))
            disappear.append([gene, -float(input1_[gene][0][0])])

    for gene in input2_:
        if gene not in input1_:
            all_changes.append(float(input2_[gene][0][0]))
            appear.append([gene, float(input2_[gene][0][0])])

    mean__ = np.mean(all_changes)
    sd__ = np.std(all_changes)
    for no in range(len(results)):
        item = results[no]
        if not item[0].startswith('#'):
            z_ = stat.z_score(input_=item[1], mean_=mean__, sd_=sd__)
            p_ = stat.p_value(z_)
            results[no].extend([z_, p_])

    for no in range(len(appear)):
        item = appear[no]
        if not item[0].startswith('#'):
            z_ = stat.z_score(input_=item[1], mean_=mean__, sd_=sd__)
            p_ = stat.p_value(z_)
            appear[no].extend([z_, p_])

    for no in range(len(disappear)):
        item = disappear[no]
        if not item[0].startswith('#'):
            z_ = stat.z_score(input_=item[1], mean_=mean__, sd_=sd__)
            p_ = stat.p_value(z_)
            disappear[no].extend([z_, p_])


    if write_extra==True:
        for item in appear:
            results.append(item)
        for item in disappear:
            results.append(item)
    results = genomics.sort_(results, idx=1, reverse_=True)
    ps = []
    for item in results:
        ps.append(float(item[-1]))
    fdr = smm.multipletests(ps, method='fdr_bh')
    for no in range(len(results)):
        results[no].extend([fdr[1][no]])
    results.insert(0, ['#gene', 'change', 'z-score', 'p-value','FDR(BH)'])
    genomics.write_file(results, output_)



def get_coordinate(input_file, id_idx, ref_name, cols):
    ### takes an input file (e.g. h3k4me3_day14_assigned.txt) and returns genomic coordinates
    ### id_idx = a column index where the gene ID is recorded in the input_file
    ### ref_name = a string for scanning
    ### cols = a list of column indexes to be returned
    if type(input_file) == str:
        input_ = genomics.read_file1(input_file)
    else:
        input_ = input_file
    results = []
    for item in input_:
        if str(item[id_idx]) == str(ref_name):
            results.append([])
            for col in cols:
                results[-1].extend([item[col]])
    return results

def el_points(input_file, chr_idx, start_idx, end_idx):
    ### takes a input_file (e.g. collapsed_dominant_sorted.bed) or a dictionary of lists (e.g. [[10,20],[15,30],..])
    ### and returns a list of elementary points (with an overlap count) in the form of list
    ### Note. this overlap count indicates a number starting from the point to the next one
    ### e.g. [[1,1],[10,2],..] --> There is one overlap between 1 and 10 positions.
    if type(input_file)==str:
        input_ = genomics.read_file(input_file, [start_idx, end_idx], rowname=str(chr_idx))
    else:
        input_ = input_file
    results = {}
    chrom_list = []
    for item in input_:
        if item not in chrom_list:
            chrom_list.append(item)
    for chr in chrom_list:
        temp = []
        for no in range(len(input_[chr])):
            temp.append(int(input_[chr][no][0]))
            temp.append(int(input_[chr][no][1]))
        temp = list(set(temp))
        temp.sort()
        results[chr] = temp
    return results

def replace(input_file, from_, to_='_'):
    ### reads in a text file and replaces any characters with a defined character (i.e. character)
    input__ = open(input_file, 'r')
    input_ = []
    for line in input__:
        line = line.replace(from_, to_)
        line = line.strip().split()
        input_.append(line)
    return input_


def create_intervals(input_file, col_idx, range_, interval_size):
    ### reads in an input file and creates intervals & assign each entry into the interval
    ### Note. the intervals are numbered from 1 (i.e. lowest in the value). All entries outside the range_ will be excluded
    ### col_idx = a column index where the value is recorded
    ### range_ = a list of minimum and maximum values (e.g. [-1000000, 1000000])
    ### interval_size = size of the interval (e.g. 100, for 100 bps)
    if type(input_file)==str:
        input_ = genomics.read_file1(input_file)
    else:
        input_ = input_file
    for no in range(len(input_)):
        input_[no][col_idx] = float(input_[no][col_idx])
    input_ = genomics.sort_(input_, idx=col_idx, reverse_=False)
    bin=1
    cutoff_ = range_[0] + (bin * interval_size)
    for no in range(len(input_)):
        item = input_[no]
        current_ = float(item[col_idx])
        if (current_ >= range_[0]) and (current_ <= range_[1]):
            while current_ > cutoff_:
                bin += 1
                cutoff_ = range_[0] + (bin * interval_size)
            if current_ < cutoff_:
                input_[no].extend([bin])
        else:
            input_[no].extend(['NA'])
    return input_

def population_analysis(input_list, pseudo_count= 0.0001, set_zero=True, log_ = True, output_='empirical', multiple_correction=False):
    ### takes a list of float values (e.g. DS changes) and work out the statistics
    ### input_list = a list of values (e.g. [1.22, 3.44, xxx, ]
    ### set_zero = a boolean value to indicate whether the values should be shifted to 0 (minimal value) + pseudo_count
    ### pseudo_count = a float to be added to echo value after the resetting the zero reference
    ### log_ = a boolean to indicate whether the input values should be log10 converted
    ### output_ = a boolean to indicate whether the output is 'p-value' or 'z-score' or 'empirical'
    ### multiple_corection = a boolean to indicate whether the p-value should be corrected for multiple testing
    ### To calculate empirical p-values the values must be pre-sorted
    results = []
    if set_zero == True:
        min_abs = np.abs(min(input_list))
        for no in range(len(input_list)):
            input_list[no] = input_list[no] + min_abs + pseudo_count
    if log_ == True:
        temp = stat.log_conversion(input_list)
        input_list = temp
    pvalues = []
    if output_!='empirical':
        mean_ = np.mean(input_list)
        sd_ = np.std(input_list)
        for no in range(len(input_list)):
            item = input_list[no]
            z_score_ = stat.z_score(item, mean_, sd_)
            p_value_ = stat.p_value(z_score_)
            pvalues.append(p_value_)
            if output_ == 'z-score':
                results.append(z_score_)
            elif output_=='p-value':
                results.append(p_value_)
    elif output_ == 'empirical':
        total_ = len(input_list)
        for no in range(len(input_list)):
            results.append(float(no+1)/float(total_+1))
            pvalues.append(float(no+1)/float(total_+1))
    if multiple_correction==True:
        temp = smm.multipletests(pvalues, method='fdr_bh')
        results = temp[1]
    return results

def composition_analysis(input_file, ref_file, gene_idx, difference_idx, value_idx, theta_, threshold=0.05):
    ### performs tissue compositional analysis on input_file (e.g. E066_new_ds.txt)
    ### ref_file = e.g. broadpeak_tissue_enrichment_pvalues_sig.txt (i.e. table text file)
    ### gene_idx = a column index of the input_file where the gene symbol is recorded
    ### difference_idx = a column index of the input_file where the difference_from_threshold is recorded (so that we know they are above the threshold)
    ### Note. difference_idx can be simply the width/sd value as well
    ### value_idx = a column index of the input_file where the DS is recorded
    ### threshold = a threshold below which is considered as significant (usef for ref_file) or if None, it used values in ref_file (e.g. -log10(pvalue))
    ### theta_ = a numerical value indicating the difference from the threshold
    ### Returns a list of tissue-type compositional score
    input_ = []
    if type(input_file) == str:
        input_ = genomics.read_file1(input_file)
    else:
        input_ = input_file
    ref_ = read_table1(ref_file, del_colnames=True)
    ref_list = {}
    if threshold!=None:
        for gene in ref_:
            ref_list[gene] =set()
            for tissue in ref_[gene]:
                if float(ref_[gene][tissue]) < threshold:
                    ref_list[gene].add(tissue)
    else:
        ref_list = ref_

    results = []
    tissue_scores = {}
    sum_score = 0.0
    total_cnt = 0
    input_ = genomics.sort_(input_, idx=difference_idx, reverse_=True)

    if threshold!=None:  # Binary count (i.e. whether above the threshold 1 or not 0)
        for item in input_:
            gene = item[gene_idx]
            if float(item[difference_idx]) < float(theta_):
                break
            else:
                if (gene in mrna) and (gene in ref_list):
                    if len(ref_list[gene]) != 0:
                        for t in ref_list[gene]:
                            if t not in tissue_scores:
                                tissue_scores[t] = 0.0
                            tissue_scores[t] += 1
                            total_cnt += 1
                        sum_score += float(item[value_idx])
        for t in tissue_scores:
            tissue_scores[t] = float(tissue_scores[t]) / total_cnt
            results.append([t, tissue_scores[t], sum_score*tissue_scores[t]])
    else:  # Continuous variable (e.g. -log10(p-value))
        for item in input_:
            gene = item[gene_idx]
            if float(item[difference_idx]) < float(theta_):
                break
            else:
                if (gene in mrna) and (gene in ref_list):
                    if len(ref_list[gene]) != 0:
                        for t in ref_list[gene]:
                            if t not in tissue_scores:
                                tissue_scores[t] = 0.0
                            tissue_scores[t] += float(ref_list[gene][t])
                            sum_score += float(ref_list[gene][t])
        for t in tissue_scores:
            tissue_scores[t] = float(tissue_scores[t]) / sum_score
            results.append([t, tissue_scores[t]])
    return results

def composition_analysis1(input_file, ref_file, gene_idx, difference_idx, value_idx, cutoff_, threshold=0.05):
    ### performs tissue compositional analysis on input_file (e.g. E066_new_ds.txt)
    ### ref_file = e.g. broadpeak_tissue_enrichment_pvalues_sig.txt (i.e. table text file)
    ### gene_idx = a column index of the input_file where the gene symbol is recorded
    ### difference_idx = a column index of the input_file where the difference_from_threshold is recorded (so that we know they are above the threshold)
    ### Note. difference_idx can be simply the width/sd value as well
    ### value_idx = a column index of the input_file where the DS is recorded
    ### threshold = a threshold below which is considered as significant (usef for ref_file) or if None, it used values in ref_file (e.g. -log10(pvalue))
    ### cutoff_ = the cut-off position by DS
    ### Returns a list of tissue-type compositional score
    input_ = []
    if type(input_file) == str:
        input_ = genomics.read_file1(input_file)
    else:
        input_ = input_file
    ref_ = read_table1(ref_file, del_colnames=True)
    ref_list = {}
    if threshold!=None:
        for gene in ref_:
            ref_list[gene] =set()
            for tissue in ref_[gene]:
                if float(ref_[gene][tissue]) > threshold:
                    ref_list[gene].add(tissue)
    else:
        ref_list = ref_

    results = []
    tissue_scores = {}
    sum_score = 0.0
    total_cnt = 0
    input_ = genomics.sort_(input_, idx=difference_idx, reverse_=True)

    if threshold!=None:  # Binary count (i.e. whether above the threshold 1 or not 0)
        for no in range(cutoff_):
            item = input_[no]
            gene = item[gene_idx]
            if (gene in mrna) and (gene in ref_list):
                if len(ref_list[gene]) != 0:
                    for t in ref_list[gene]:
                        if t not in tissue_scores:
                            tissue_scores[t] = 0.0
                        tissue_scores[t] += 1
                    sum_score += float(item[value_idx])
                total_cnt += 1
        for t in tissue_scores:
            tissue_scores[t] = float(tissue_scores[t]) / total_cnt
            results.append([t, tissue_scores[t], sum_score*tissue_scores[t]])
    else:  # Continuous variable (e.g. -log10(p-value))
        for item in input_:
            gene = item[gene_idx]
            if float(item[difference_idx]) < float(theta_):
                break
            else:
                if (gene in mrna) and (gene in ref_list):
                    if len(ref_list[gene]) != 0:
                        for t in ref_list[gene]:
                            if t not in tissue_scores:
                                tissue_scores[t] = 0.0
                            tissue_scores[t] += float(ref_list[gene][t])
                            sum_score += float(ref_list[gene][t])
        for t in tissue_scores:
            tissue_scores[t] = float(tissue_scores[t]) / sum_score
            results.append([t, tissue_scores[t]])
    results = genomics.sort_(results, idx=1, reverse_=True)
    return results


def mle(input_files, ref_file, gene_idx, difference_idx, value_idx, tissue_group_, theta=[0,7.1,0.1], threshold=0.05):
    ### performs maximum likelihood estimation to find the parameter (DS) that maximises likelihood of
    ### being the given tissue group (e.g. Heart)
    ### tissue_group_ = a tissue group of interst(e.g. 'Heart')
    ### theta = [start, end, interval] for the parameter
    ### for other parameters, see 'composition_analysis'
    ### USE THIS FOR A GROUP OF CELL TYPES BELONGING TO A TISSUE GROUP
    results = []
    output_ = []
    print '***'+tissue_group_+'***'
    max_ = -99999
    theta_choice = ''
    bin_size = int((theta[1] - theta[0]) / theta[2])
    for theta__ in range(bin_size+1):
        theta_ = theta[0] + theta[2] * theta__
        results.append([])
        for file_ in input_files:
            temp = composition_analysis(file_, ref_file, gene_idx, difference_idx, value_idx, theta_, threshold)
            for m in temp:
                if m[0] == tissue_group_:
                    results[-1].append(np.log(float(m[1])))
        sum_likelihood = sum(results[-1])
        ave_likelihood = sum_likelihood / len(results[-1])
        print
        print 'Parameter =', theta_
        print 'Sum of log-likelihood =', sum_likelihood
        print 'Ave of log-likelihhod =', ave_likelihood
        output_.append([theta_, sum_likelihood, ave_likelihood])
        if ave_likelihood > max_:
            max_ = ave_likelihood
            theta_choice = theta_
    print
    print 'The best theta for '+tissue_group_+' is ', theta_choice
    print 'Max. average loh-likelihood =', max_
    return output_, theta_choice, max_

def scan(input_file, ref_file, gene_idx, difference_idx, value_idx, theta='restricted', threshold=0.05, relaxed_threshold=None, restricted_range=[500,50]):
    ### scans to find the parameter (DS) for a cell type
    ### that maximises likelihood of being any a tissue group
    ### theta = [start, end, interval] for the parameter or 'auto' (auto scanning, from 0 to the highest) or 'restricted' (scanning from top x position to y position)
    ### restricted_range = only valid for 'restricted' scanning option ([start position, end position], [lower position to higher position])
    ### relaxed_threshold = a numerical value allowed to replace the best theta (mainly used to relax the threshold)
    ### E.g. 0.01 (to allow 1% of the best proportion value as a gap to define the threshold). It finds the closest DS value.
    ### for other parameters, see 'composition_analysis'
    ### USE THIS FOR A CELL TYPE (UNKNOWN) (I.E. TESTING)
    results = []
    current_tissue = ''
    current_value = 0.0
    current_theta = ''
    p = genomics.read_file1(input_file)
    pp = []
    for no in range(len(p)):
        item = p[no]
        p[no][value_idx] = float(p[no][value_idx])
        pp.append(float(item[value_idx]))
    max_ = max(pp)
    records = []
    if theta=='auto':
        bin_size = int(int(max_) / 0.1)
        for theta__ in range(bin_size):
            theta_ = 0.1 * theta__
            results.append([])
            temp = composition_analysis(input_file, ref_file, gene_idx, difference_idx, value_idx, theta_, threshold)
            values = []
            for m in temp:
                values.append(float(m[1]))
            idx = values.index(max(values))
            records.append([theta_, temp])
            if current_value < max(values):
                current_value = max(values)
                current_tissue = temp[idx][0]
                current_theta = theta_
    elif theta=='restricted':
        p = genomics.sort_(p, idx=value_idx, reverse_=True)
        start_ = p[restricted_range[0]][value_idx]
        end_ = p[restricted_range[1]][value_idx]
        start = round(start_, 1)
        end = round(end_, 1)
        bin_size = int((end-start)/0.1)
        for theta__ in range(bin_size):
            theta_ = start + 0.1 * theta__
            results.append([])
            temp = composition_analysis(input_file, ref_file, gene_idx, difference_idx, value_idx, theta_, threshold)
            values = []
            for m in temp:
                values.append(float(m[1]))
            idx = values.index(max(values))
            records.append([theta_, temp])
            if current_value < max(values):
                current_value = max(values)
                current_tissue = temp[idx][0]
                current_theta = theta_


    else:
        bin_size = int((theta[1] - theta[0]) / theta[2])
        for theta__ in range(bin_size):
            theta_ = theta[0] + theta[2] * theta__
            results.append([])
            temp = composition_analysis(input_file, ref_file, gene_idx, difference_idx, value_idx, theta_, threshold)
            values = []
            for m in temp:
                values.append(float(m[1]))
            idx = values.index(max(values))
            records.append([theta_, temp])
            if current_value < max(values):
                current_value = max(values)
                current_tissue = temp[idx][0]
                current_theta = theta_
    if relaxed_threshold != None:
        gap_allowed = np.abs(float(current_value) * relaxed_threshold)
        done_ = False
        for no in range(len(records)):
            item = records[no][1]
            for m in item:
                if (np.abs(current_value - float(m[1])) < gap_allowed) and (m[0]==current_tissue):
                    current_value = float(m[1])
                    current_tissue = m[0]
                    current_theta = float(records[no][0])
                    done_ = True
                    break
            if done_ == True:
                break
    temp = composition_analysis(input_file, ref_file, gene_idx, difference_idx, value_idx, current_theta, threshold)
    return temp, current_tissue, current_theta

def contribution_scores(input_file, ref_file, gene_idx, value_idx, proportions, theta_, output_file, threshold=0.05, test=None, test_type='permutation'):
    ### calculates contribution scores for genes for tissue type
    ### contribution score of a gene for a tissue = DS of the gene / (sum of DSs of all genes above the theta * tissue proportion)
    ### Basically 1. sum all DS above the theta, 2. Divide the score into each tissue group (based on the proportion), 3. Calculate contribution of each gene (by DS) to each tissue type
    ### It aims to find genes that contribute most to the dominant tissue group in the cell context
    ### proportions = a list of tissue group proportions (e.g. output of the mle1, temp)
    ### theta_ = a DS threshold cut-off, as defined by MLE (e.g. output of the mle1, current_theta that maximises proportion of a tissue type)
    ### output_file = a output filename
    ### test = a filename to be used for statistical test (based on the 111 background cell types) (e.g. summary_results_dominant_1.0_broadpeak_mrna_.txt)
    ### test_type = 'permutation' for permutation test, 'empirical' for empirical test
    ### Note. The statistical test takes population scores for the genes within the threshold
    input_ = []
    pvalues = []
    if type(input_file) == str:
        input_ = genomics.read_file1(input_file)
    else:
        input_ = input_file
    ref_ = read_table1(ref_file, del_colnames=True)
    ref_list = {}
    if threshold!=None:
        for gene in ref_:
            ref_list[gene] =set()
            for tissue in ref_[gene]:
                if float(ref_[gene][tissue]) < threshold:
                    ref_list[gene].add(tissue)
    else:
        ref_list = ref_
    all_genes_ = []
    for gene in ref_list:
        all_genes_.append(gene)

    results = []
    sum_ds = 0.0
    cnt = 0
    input_ = genomics.sort_(input_, idx=value_idx, reverse_=True)
    for item in input_:
        if float(item[value_idx]) < float(theta_):
            break
        else:
            cnt += 1  # No. genes
    tissue_scores = {}
    sum_scores = {}

    if threshold != None:
        for no in range(cnt):
            item = input_[no]
            gene_name = item[gene_idx]
            if gene_name in ref_list:
                if len(ref_list[gene_name]) != 0:
                    sum_ds += float(item[value_idx])
        for m in proportions:
            if m[0] not in tissue_scores:
                tissue_scores[m[0]] = 0.0
                sum_scores[m[0]] = 0.0
            tissue_scores[m[0]] = sum_ds * float(m[1])

        for no in range(cnt):
            item = input_[no]
            gene_name = item[gene_idx]
            if gene_name in ref_list:
                if len(ref_list[gene_name]) != 0:
                    for m_ in proportions:
                        m = m_[0]
                        if m in ref_list[gene_name]:
                            sum_scores[m] += float(item[value_idx])
        cnt1 = 0
        for no in range(cnt):
            item = input_[no]
            gene_name = item[gene_idx]
            results.append([gene_name])
            if gene_name in ref_list:
                if len(ref_list[gene_name]) != 0:
                    cnt1 += 1  # No. of valid genes
                    for m_ in proportions:
                        m = m_[0]
                        if m in ref_list[gene_name]:
                            pp = float(item[value_idx]) / sum_scores[m]  # contribution rate of a gene (by DS) to a tissue type
                            results[-1].extend([tissue_scores[m] * pp])
                        else:
                            results[-1].extend([0.0])
                else:
                    for m in tissue_scores:
                        results[-1].extend([0.0])
            else:
                for m in tissue_scores:
                    results[-1].extend([0.0])
        ll = 0
        for n in range(len(proportions)):
            m = proportions[n]
            if float(m[1]) > float(ll):
                tissue___ = m[0]
                ll = float(m[1])

        output_ = open(output_file+'_summary.txt', 'w')
        output_.write('#'+input_file+'\n')
        output_.write('# theta used ='+str(theta_)+'\n')
        output_.write('# observed dominant tissue nature = '+tissue___+'\n')
        output_.write('# details of tissue nature (proportion, p-value)'+'\n')
        if test!=None:
            if test_type=='empirical':
                data_ = genomics.read_file(test, [0,4], rowname='1')
                pvalues = {}
                all_ds_sums = {}
                for m in proportions:
                    all_ds_sums[m[0]] = []
                for epi in epigenomes:
                    sum_ds_ = 0.0
                    counts = {}
                    total_count = 0
                    for m in proportions:
                        counts[m[0]] = 0
                        all_ds_sums[m[0]].append(0.0)
                    temp = data_[epi]
                    for no in range(len(temp)):
                        temp[no][1] = float(temp[no][1])
                    temp = genomics.sort_(temp, idx=1, reverse_=True)
                    epi_data = temp[:cnt]
                    for item in epi_data:
                        gene = item[0]
                        if gene in ref_list:
                            if len(ref_list[gene]) != 0:
                                sum_ds_ += float(item[1])
                                for n in ref_list[gene]:
                                    if n in counts:
                                        counts[n] += 1
                                        total_count += 1
                    for n in counts:
                        counts[n] = float(counts[n]) / total_count  # tissue proportions
                        all_ds_sums[n][-1] = sum_ds_ * counts[n]
                        all_ds_sums[n][-1] = counts[n]  # For proportion p-value
            if test_type=='permutation':
                no_permutation = 1000
                all_ds_sums = {}
                total_count = 0
                pvalues = {}
                for m in proportions:
                    all_ds_sums[m[0]] = []
                for no in range(no_permutation):
                    counts = {}
                    indexs = []
                    selected = []
                    used = set()

                    for m in proportions:
                        counts[m[0]] = 0
                        all_ds_sums[m[0]].append(0.0)
                    for n in range(cnt):
                        idx_ = random.randint(0, len(all_genes_)-1)
                        indexs.append(idx_)
                        if all_genes_[idx_] not in used:
                            used.add(all_genes_[idx_])
                            selected.append(all_genes_[idx_])
                    for gene in selected:
                        if gene in ref_list:
                            if len(ref_list[gene]) != 0:
                                for n1 in ref_list[gene]:
                                    if n1 in counts:
                                        counts[n1] += 1
                                        total_count += 1
                    for n in counts:
                        counts[n] = float(counts[n]) / total_count
                        all_ds_sums[n][-1] = counts[n]


            for m in proportions:
                mean_ = np.mean(all_ds_sums[m[0]])
                sd_ = np.std(all_ds_sums[m[0]])
                z_ = stat.z_score(float(m[1]), mean_=mean_, sd_ = sd_)  # Change to tissue_scores[m[0]] for sum of DSs, float(m[1]) for proportion
                p_ = stat.p_value(z_)
                pvalues[m[0]] = p_
        else:
            pvalues = {}
            for m in proportions:
                pvalues[m[0]] = ''

        for m_ in proportions:
            m = m_[0]
            output_.write(str(m)+'\t'+str(m_[1])+'\t'+str(pvalues[m])+'\n')
        output_.close()
        new_results = []
        for no in range(len(results)):
            sum_ = 0.0
            for m in range(1, len(results[no])):
                sum_ += float(results[no][m])
            results[no].insert(1, sum_)
        new_results.append(['\t','sum'])
        for m in proportions:
            new_results[0].extend([m[0]])
        for item in results:
            if float(item[1])!=float(0):
                new_results.append(item)
        genomics.write_file(new_results, output_file+'_contribution_scores.txt')

    else:
        for no in range(cnt):
            item = input_[no]
            gene_name = item[gene_idx]
            if gene_name in ref_list:
                if len(ref_list[gene_name]) != 0:
                    for m in ref_list[gene_name]:
                        sum_ds += float(ref_list[gene_name][m]) * float(item[value_idx])
        for m in proportions:
            if m[0] not in tissue_scores:
                tissue_scores[m[0]] = 0.0
                sum_scores[m[0]] = 0.0
            tissue_scores[m[0]] = sum_ds * float(m[1])

        for no in range(cnt):
            item = input_[no]
            gene_name = item[gene_idx]
            if gene_name in ref_list:
                if len(ref_list[gene_name]) != 0:
                    for m_ in proportions:
                        m = m_[0]
                        if m in ref_list[gene_name]:
                            sum_scores[m] += float(ref_list[gene_name][m]) * float(item[value_idx])

        for no in range(cnt):
            item = input_[no]
            gene_name = item[gene_idx]
            results.append([gene_name])
            if gene_name in ref_list:
                if len(ref_list[gene_name]) != 0:
                    for m_ in proportions:
                        m = m_[0]
                        if m in ref_list[gene_name]:
                            #pp = float(ref_list[gene_name][m]) * float(item[value_idx]) / sum_scores[m]  # contribution rate of a gene (by DS) to a tissue type
                            results[-1].extend([float(ref_list[gene_name][m]) * float(item[value_idx])])
                        else:
                            results[-1].extend([0.0])
                else:
                    for m in tissue_scores:
                        results[-1].extend([0.0])
            else:
                for m in tissue_scores:
                    results[-1].extend([0.0])
        ll = 0
        for n in range(len(proportions)):
            m = proportions[n]
            if float(m[1]) > float(ll):
                tissue___ = m[0]
                ll = float(m[1])

        output_ = open(output_file + '_summary.txt', 'w')
        output_.write('#' + input_file + '\n')
        output_.write('# theta used =' + str(theta_) + '\n')
        output_.write('# observed dominant tissue nature = ' + tissue___ + '\n')
        output_.write('# details of tissue nature (proportion, p-value)' + '\n')
        if test != None:
            data_ = genomics.read_file(test, [0, 4], rowname='1')
            pvalues = {}
            all_ds_sums = {}
            for m in proportions:
                all_ds_sums[m[0]] = []
            for epi in epigenomes:
                sum_ds_ = 0.0
                counts = {}
                for m in proportions:
                    counts[m[0]] = 0
                    all_ds_sums[m[0]].append(0.0)
                temp = data_[epi]
                for no in range(len(temp)):
                    temp[no][1] = float(temp[no][1])
                temp = genomics.sort_(temp, idx=1, reverse_=True)
                epi_data = temp[:cnt]
                for item in epi_data:
                    gene = item[0]
                    if gene in ref_list:
                        if len(ref_list[gene]) != 0:
                            for n in ref_list[gene]:
                                if n in counts:
                                    counts[n] += float(ref_list[gene][n]) * float(item[1])
                                    sum_ds_ += float(ref_list[gene][n]) * float(item[1])
                for n in counts:
                    all_ds_sums[n][-1] = counts[n] / sum_ds_  # For proportion

            for m in proportions:
                mean_ = np.mean(all_ds_sums[m[0]])
                sd_ = np.std(all_ds_sums[m[0]])
                z_ = stat.z_score(float(m[1]), mean_=mean_,sd_=sd_)  # Change to tissue_scores[m[0]] for sum of DSs, float(m[1]) for proportion
                p_ = stat.p_value(z_)
                pvalues[m[0]] = p_
        else:
            pvalues = {}
            for m in proportions:
                pvalues[m[0]] = ''

        for m_ in proportions:
            m = m_[0]
            output_.write(str(m) + '\t' + str(m_[1]) + '\t' + str(pvalues[m]) + '\n')
        output_.close()
        new_results = []
        for no in range(len(results)):
            sum_ = 0.0
            for m in range(1, len(results[no])):
                sum_ += float(results[no][m])
            results[no].insert(1, sum_)
        new_results.append(['\t', 'sum'])
        for m in proportions:
            new_results[0].extend([m[0]])
        for item in results:
            if float(item[1]) != float(0):
                new_results.append(item)
        genomics.write_file(new_results, output_file + '_contribution_scores.txt')

def contribution_scores1(input_file, ref_file, gene_idx, value_idx, proportions, cutoff_, output_file, threshold=0.05, test=None, test_type='permutation'):
    ### calculates contribution scores for genes for tissue type
    ### contribution score of a gene for a tissue = DS of the gene / (sum of DSs of all genes above the theta * tissue proportion)
    ### Basically 1. sum all DS above the theta, 2. Divide the score into each tissue group (based on the proportion), 3. Calculate contribution of each gene (by DS) to each tissue type
    ### It aims to find genes that contribute most to the dominant tissue group in the cell context
    ### proportions = a list of tissue group proportions (e.g. output of the mle1, temp)
    ### cutoff_= a rank position cutoff by DS
    ### output_file = a output filename
    ### test = a filename to be used for statistical test (based on the 111 background cell types) (e.g. summary_results_dominant_1.0_broadpeak_mrna_.txt)
    ### test_type = 'permutation' for permutation test, 'empirical' for empirical test
    ### Note. The statistical test takes population scores for the genes within the threshold
    input_ = []
    pvalues = []
    if type(input_file) == str:
        input_ = genomics.read_file1(input_file)
    else:
        input_ = input_file
    ref_ = read_table1(ref_file, del_colnames=True)
    ref_list = {}
    if threshold!=None:
        for gene in ref_:
            ref_list[gene] =set()
            for tissue in ref_[gene]:
                if float(ref_[gene][tissue]) > threshold:
                    ref_list[gene].add(tissue)
    else:
        ref_list = ref_
    all_genes_ = []
    for gene in ref_list:
        all_genes_.append(gene)

    results = []
    sum_ds = 0.0
    cnt = 0
    input_ = genomics.sort_(input_, idx=value_idx, reverse_=True)
    cnt = cutoff_
    tissue_scores = {}
    sum_scores = {}

    if threshold != None:
        for no in range(cnt):
            item = input_[no]
            gene_name = item[gene_idx]
            if gene_name in ref_list:
                if len(ref_list[gene_name]) != 0:
                    sum_ds += float(item[value_idx])
        for m in proportions:
            if m[0] not in tissue_scores:
                tissue_scores[m[0]] = 0.0
                sum_scores[m[0]] = 0.0
            tissue_scores[m[0]] = sum_ds * float(m[1])

        for no in range(cnt):
            item = input_[no]
            gene_name = item[gene_idx]
            if gene_name in ref_list:
                if len(ref_list[gene_name]) != 0:
                    for m_ in proportions:
                        m = m_[0]
                        if m in ref_list[gene_name]:
                            sum_scores[m] += float(item[value_idx])
        cnt1 = 0
        for no in range(cnt):
            item = input_[no]
            gene_name = item[gene_idx]
            results.append([gene_name])
            if gene_name in ref_list:
                pp = len(ref_list[gene_name])


                if len(ref_list[gene_name]) != 0:
                    cnt1 += 1  # No. of valid genes
                    for m_ in proportions:
                        m = m_[0]
                        if m in ref_list[gene_name]:
                            results[-1].extend([item[value_idx]*(float(1)/pp)])

                        else:
                            results[-1].extend([0.0])
                else:
                    for m in tissue_scores:
                        results[-1].extend([0.0])
            else:
                for m in tissue_scores:
                    results[-1].extend([0.0])
        ll = 0
        for n in range(len(proportions)):
            m = proportions[n]
            if float(m[1]) > float(ll):
                tissue___ = m[0]
                ll = float(m[1])


        output_ = open(output_file+'_summary.txt', 'w')
        output_.write('#'+input_file+'\n')
        output_.write('# cut-off used ='+str(cutoff_)+'\n')
        output_.write('# observed dominant tissue nature = '+tissue___+'\n')
        output_.write('# details of tissue nature (proportion, p-value)'+'\n')
        if test!=None:
            if test_type=='empirical':
                data_ = genomics.read_file(test, [0,4], rowname='1')
                pvalues = {}
                all_ds_sums = {}
                for m in proportions:
                    all_ds_sums[m[0]] = []
                for epi in epigenomes:
                    sum_ds_ = 0.0
                    counts = {}
                    total_count = 0
                    for m in proportions:
                        counts[m[0]] = 0
                        all_ds_sums[m[0]].append(0.0)
                    temp = data_[epi]
                    for no in range(len(temp)):
                        temp[no][1] = float(temp[no][1])
                    temp = genomics.sort_(temp, idx=1, reverse_=True)
                    epi_data = temp[:cnt]
                    for item in epi_data:
                        gene = item[0]
                        if gene in ref_list:
                            if len(ref_list[gene]) != 0:
                                sum_ds_ += float(item[1])
                                for n in ref_list[gene]:
                                    if n in counts:
                                        counts[n] += 1
                                        total_count += 1
                    for n in counts:
                        counts[n] = float(counts[n]) / total_count  # tissue proportions
                        all_ds_sums[n][-1] = sum_ds_ * counts[n]
                        all_ds_sums[n][-1] = counts[n]  # For proportion p-value
            if test_type=='permutation':
                no_permutation = 1000
                all_ds_sums = {}
                total_count = 0
                pvalues = {}
                for m in proportions:
                    all_ds_sums[m[0]] = []
                for no in range(no_permutation):
                    counts = {}
                    indexs = []
                    selected = []
                    used = set()

                    for m in proportions:
                        counts[m[0]] = 0
                        all_ds_sums[m[0]].append(0.0)
                    for n in range(cnt):
                        idx_ = random.randint(0, len(all_genes_)-1)
                        indexs.append(idx_)
                        if all_genes_[idx_] not in used:
                            used.add(all_genes_[idx_])
                            selected.append(all_genes_[idx_])
                    for gene in selected:
                        if gene in ref_list:
                            if len(ref_list[gene]) != 0:
                                for n1 in ref_list[gene]:
                                    if n1 in counts:
                                        counts[n1] += 1
                                        total_count += 1
                    for n in counts:
                        counts[n] = float(counts[n]) / total_count
                        all_ds_sums[n][-1] = counts[n]


            for m in proportions:
                mean_ = np.mean(all_ds_sums[m[0]])
                sd_ = np.std(all_ds_sums[m[0]])
                z_ = stat.z_score(float(m[1]), mean_=mean_, sd_ = sd_)  # Change to tissue_scores[m[0]] for sum of DSs, float(m[1]) for proportion
                p_ = stat.p_value(z_)
                pvalues[m[0]] = p_
        else:
            pvalues = {}
            for m in proportions:
                pvalues[m[0]] = ''

        for m_ in proportions:
            m = m_[0]
            output_.write(str(m)+'\t'+str(m_[1])+'\t'+str(pvalues[m])+'\n')
        output_.close()


        new_results = [[]]
        for m_ in proportions:
            m = m_[0]
            new_results[-1].extend([m])

        for no in range(len(results)):
            item = input_[no]
            new_results.append([item[gene_idx]])
            for m in range(1, len(results[no])):
                new_results[-1].extend([results[no][m]])
        print results



        genomics.write_file(new_results, output_file+'_contribution_scores.txt')

    else:
        for no in range(cnt):
            item = input_[no]
            gene_name = item[gene_idx]
            if gene_name in ref_list:
                if len(ref_list[gene_name]) != 0:
                    for m in ref_list[gene_name]:
                        sum_ds += float(ref_list[gene_name][m]) * float(item[value_idx])
        for m in proportions:
            if m[0] not in tissue_scores:
                tissue_scores[m[0]] = 0.0
                sum_scores[m[0]] = 0.0
            tissue_scores[m[0]] = sum_ds * float(m[1])

        for no in range(cnt):
            item = input_[no]
            gene_name = item[gene_idx]
            if gene_name in ref_list:
                if len(ref_list[gene_name]) != 0:
                    for m_ in proportions:
                        m = m_[0]
                        if m in ref_list[gene_name]:
                            sum_scores[m] += float(ref_list[gene_name][m]) * float(item[value_idx])

        for no in range(cnt):
            item = input_[no]
            gene_name = item[gene_idx]
            results.append([gene_name])
            if gene_name in ref_list:
                if len(ref_list[gene_name]) != 0:
                    for m_ in proportions:
                        m = m_[0]
                        if m in ref_list[gene_name]:
                            #pp = float(ref_list[gene_name][m]) * float(item[value_idx]) / sum_scores[m]  # contribution rate of a gene (by DS) to a tissue type
                            results[-1].extend([float(ref_list[gene_name][m]) * float(item[value_idx])])
                        else:
                            results[-1].extend([0.0])
                else:
                    for m in tissue_scores:
                        results[-1].extend([0.0])
            else:
                for m in tissue_scores:
                    results[-1].extend([0.0])
        ll = 0
        for n in range(len(proportions)):
            m = proportions[n]
            if float(m[1]) > float(ll):
                tissue___ = m[0]
                ll = float(m[1])

        output_ = open(output_file + '_summary.txt', 'w')
        output_.write('#' + input_file + '\n')
        output_.write('# theta used =' + str(theta_) + '\n')
        output_.write('# observed dominant tissue nature = ' + tissue___ + '\n')
        output_.write('# details of tissue nature (proportion, p-value)' + '\n')
        if test != None:
            data_ = genomics.read_file(test, [0, 4], rowname='1')
            pvalues = {}
            all_ds_sums = {}
            for m in proportions:
                all_ds_sums[m[0]] = []
            for epi in epigenomes:
                sum_ds_ = 0.0
                counts = {}
                for m in proportions:
                    counts[m[0]] = 0
                    all_ds_sums[m[0]].append(0.0)
                temp = data_[epi]
                for no in range(len(temp)):
                    temp[no][1] = float(temp[no][1])
                temp = genomics.sort_(temp, idx=1, reverse_=True)
                epi_data = temp[:cnt]
                for item in epi_data:
                    gene = item[0]
                    if gene in ref_list:
                        if len(ref_list[gene]) != 0:
                            for n in ref_list[gene]:
                                if n in counts:
                                    counts[n] += float(ref_list[gene][n]) * float(item[1])
                                    sum_ds_ += float(ref_list[gene][n]) * float(item[1])
                for n in counts:
                    all_ds_sums[n][-1] = counts[n] / sum_ds_  # For proportion

            for m in proportions:
                mean_ = np.mean(all_ds_sums[m[0]])
                sd_ = np.std(all_ds_sums[m[0]])
                z_ = stat.z_score(float(m[1]), mean_=mean_,sd_=sd_)  # Change to tissue_scores[m[0]] for sum of DSs, float(m[1]) for proportion
                p_ = stat.p_value(z_)
                pvalues[m[0]] = p_
        else:
            pvalues = {}
            for m in proportions:
                pvalues[m[0]] = ''

        for m_ in proportions:
            m = m_[0]
            output_.write(str(m) + '\t' + str(m_[1]) + '\t' + str(pvalues[m]) + '\n')
        output_.close()
        new_results = []
        for no in range(len(results)):
            sum_ = 0.0
            for m in range(1, len(results[no])):
                sum_ += float(results[no][m])
            results[no].insert(1, sum_)
        new_results.append(['\t', 'sum'])
        for m in proportions:
            new_results[0].extend([m[0]])
        for item in results:
            if float(item[1]) != float(0):
                new_results.append(item)
        genomics.write_file(new_results, output_file + '_contribution_scores.txt')



def contribution_analysis(input_file, ref_file, summary_file, contribution_file, gene_idx, value_idx, threshold, output_):
    ### Once contribution scores and composition summary files are generated (using scan & contribution_scores methods),
    ### this allows user-interaction where the user can view bar graphs and statistics.
    ### The user can selected number of tissue groups of interest to finally identify key regulatory genes, relevant to selected tissue groups.
    ### input_file = e.g. E100_new_ds.txt
    ### ref_file = significance table (e.g. broadpeak_tissue_enrichment_pvalues__.txt)
    ### summary_file = e.g. E100_results_summary.txt
    ### contribution_file = e.g. E100_results_contribution_scores.txt
    ### gene_idx, value_idx = column indexes in the input_file
    ### threshold = a numerical value to draw the threshold for the ref_file (as significant genes)
    os.system('clear')
    if type(input_file) == str:
        input_ = genomics.read_file1(input_file)
    else:
        input_ = input_file
    ref_ = read_table1(ref_file, del_colnames=True)
    ref_list = {}
    for gene in ref_:
        ref_list[gene] =set()
        for tissue in ref_[gene]:
            if float(ref_[gene][tissue]) < threshold:
                ref_list[gene].add(tissue)
    contri_input = read_table1(contribution_file, del_colnames=True)
    genes = set()
    for gene in contri_input:
        if gene not in genes:
            genes.add(gene)
    temp = genomics.read_file1(summary_file)
    heights = []
    labels = []
    ticks = []
    no_tissues = 0
    for no in range(len(temp)):
        temp[no][1] = float(temp[no][1])
        temp[no][2] = float(temp[no][2])
    temp = genomics.sort_(temp, idx=1, reverse_=True)
    for no in range(len(temp)):
        heights.append(temp[no][1])
        labels.append(temp[no][0])
        ticks.append(str(no+1))
        no_tissues += 1
    print 'Input data =', input_file
    print 'Reference  =', ref_file
    print 'Number of selected genes =', len(genes)
    print
    print '{:10}'.format('Rank')+'{:25}'.format('Tissue')+'{:25}'.format('p-value')+'{:25}'.format('Contribution')+'{:25}'.format('AccumulativeContribution')
    ac = 0.0
    for no in range(len(temp)):
        item = temp[no]
        ac += float(item[1])
        print '{:10}'.format(str(no+1))+'{:25}'.format(str(item[0]))+'{:25}'.format(str(item[2]))+'{:25}'.format(str(item[1]))+'{:25}'.format(str(ac))
    ind = np.arange(no_tissues)
    width = 0.35
    fig, ax = plt.subplots()
    rect = ax.bar(ind, heights, width, color='y')
    ax.set_ylabel('Contribution rate')
    ax.set_xlabel('Rank')
    ax.set_xticks(ind+width/2)
    ax.set_xticklabels(ticks)
    plt.show()
    print
    no_groups = input('Enter rank position(s) of tissue groups for analysis: ')
    group_list = []
    if type(no_groups)==int:
        group_list.append(no_groups)
    else:
        for m in no_groups:
            group_list.append(m)
    groups = {}
    for no in group_list:
        group = temp[no-1][0]
        groups[group] = temp[no-1][1]
    for no in range(len(input_)):
        input_[no][value_idx] = float(input_[no][value_idx])
    input_ = genomics.sort_(input_, idx=value_idx, reverse_=True)
    theta_ = round(input_[-1][value_idx], 1) - 0.1
    background = composition_analysis(input_file, ref_file, gene_idx, value_idx, value_idx, theta_, threshold=0.05)  # Use this if want to use background rate
    backgrounds = []
    background_rate = {}
    for item in background:  # Change temp to background if want to use background rate
        background_rate[item[0]] = float(item[1])
    for item in input_:
        gene = item[gene_idx]
        sum_ = 0.0
        if gene in ref_:
            for group in groups:
                if (group in ref_[gene]) and (group in background_rate):
                    sum_ += float(item[value_idx]) * background_rate[group]
            backgrounds.append(sum_)

    mean_ = np.mean(backgrounds)
    sd_ = np.std(backgrounds)
    results=[]
    for gene in contri_input:
        value_ = 0.0
        for group in groups:
            value_ += float(contri_input[gene][group]) * groups[group]
        z_ = stat.z_score(value_, mean_=mean_, sd_=sd_)
        p_ = stat.p_value(z_)
        results.append([gene, p_])
    results = genomics.sort_(results, idx=1, reverse_=False)
    results.insert(0, ['#gene', 'p-value'])
    genomics.write_file(results, output_)


def cluster_analysis(input_file, ref_file, output_file, threshold_, input_gene_idx, input_value_idx, ref_gene_idx, ref_cluster_idx, plot_=True, independence_table='/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/hclust/FET/clusters/cluster_independence_table.txt', include_network=True, cond_output_=None, threshold__=0.05, autoselection=False):
    ### Performs the analysis based on gene set clustering from Roadmap dataset
    ### 1. Idenify the intra-threshold as defined at tangent of overall slope * threshold_
    ### 2. FET on each cluster group
    ### 3. Print outcomes with graph
    ### 4. User input to indicate which groups are of interest (This can be automated if necessary, based on pre-defined threshold (i.e. >conditional probability)
    ### 5. Print a list of ranked genes
    ### Note. To selected clusters of interest, you can refer to conditional probability table generated from Roadmap data
    ### input_file = e.g. h3k4me3_day14_assigned_.txt
    ### ref_file = e.g gene_clusters.txt
    ### output_file = an output filename
    ### threshold_ = a slope factor
    ### input_gene_idx = a column index in the input file where gene names are recorded
    ### ref_gene_idx = a column index in the ref_file where gene names are recorded
    ### ref_cluster_idx = a column index in the ref_file where cluster names are recorded
    ### plot_ = a boolean to indicate whether the plotting is to be shown
    ### independece_table = a filename (e.g. cluster_independence_table.txt) to help automatic selection of clusters when the user enters 0
    ### include_network = a boolean to indicate whether dependent genes associated with the selected gene cluster(s) are to be included
    ### autoselection = a boolean to automate the selection of the cluster (if on, it only selects the most significant cluster as the centre)
    if type(input_file)==str:
        input_ = genomics.read_file1(input_file)
    else:
        input_ = input_file
    ref_ = genomics.read_file(ref_file, [ref_cluster_idx], rowname=str(ref_gene_idx))
    for no in range(len(input_)):
        input_[no][input_value_idx] = float(input_[no][input_value_idx])
    input_ = genomics.sort_(input_, idx=input_value_idx, reverse_=False)
    input_list = []
    for no in range(len(input_)):
        input_list.append([no+1, input_[no][input_value_idx]])

    overall_threshold = calculate_slope(input_list[0], input_list[-1], abs_=True)
    a,b = find_dynamic_range(input_list, threshold=threshold_*overall_threshold, interpolate_=True, range_mark=0.99, output_cutoff=True)
    cutoff = len(input_list) - int(a[0][0])
    input_ = genomics.sort_(input_, idx=input_value_idx, reverse_=True)

    groups = []
    for gene in ref_:
        if ref_[gene][0][0] not in groups:
            groups.append(ref_[gene][0][0])
    fet=[]

    for group in groups:
        a,b,c,d = 0,0,0,0
        for no in range(cutoff):
            gene_ = input_[no][input_gene_idx]
            if gene_ in ref_:
                if ref_[gene_][0][0] == group:
                    a += 1
                else:
                    b += 1
        for no in range(cutoff, len(input_)):
            gene_ = input_[no][input_gene_idx]
            if gene_ in ref_:
                if ref_[gene_][0][0] == group:
                    c += 1
                else:
                    d += 1
        s_, p_ = stat.fisher(a,b,c,d)
        fet.append([group, p_, a, a+c, s_])  #[cluster, p-value, number of genes for the cluster above the threshold]


    print 'Input data =', input_file
    print 'Reference  =', ref_file
    print 'Overall slope =', str(overall_threshold)
    print 'Threshold applied =', threshold_*overall_threshold
    print 'Total number of genes in the data =', len(input_)
    print 'Number of genes extracted =', cutoff
    print
    print '{:10}'.format('Rank')+'{:25}'.format('Cluster')+'{:25}'.format('No.genes(selected)')+'{:25}'.format('Total.genes')+'{:25}'.format('Proportion')+'{:25}'.format('Accum.Proportion')+'{:25}'.format('odds.ratio')+'{:25}'.format('p-value(FET)')
    fet = genomics.sort_(fet, idx=-1, reverse_=True)
    ac = 0.0
    no_cluster = len(fet)
    all_genes = set()
    for no in range(cutoff):
        all_genes.add(input_[no][input_gene_idx])
    for no in range(len(fet)):
        item = fet[no]
        prop = float(item[2]) / cutoff
        ac += prop
        print '{:10}'.format(str(no+1))+'{:25}'.format(str(item[0]))+'{:25}'.format(str(item[2]))+'{:25}'.format(str(item[3]))+'{:25}'.format(str(prop))+'{:25}'.format(str(ac))+'{:25}'.format(str(item[4]))+'{:25}'.format(str(item[1]))
    if plot_==True:
        ind = np.arange(no_cluster)
        positive = 0
        negative = 0
        heights1 = []
        heights2 = []
        for item in fet:
            if float(item[4]) >= 1.0:
                positive += 1
                heights1.append(-np.log10(float(item[1])))
            else:
                negative += 1
                heights2.append(-np.log10(float(item[1])))
        ind1 = np.arange(positive)
        ind2 = np.arange(positive, positive+negative)
        width = 0.35
        labels = []
        ticks = []
        for no in range(len(fet)):
            item =fet[no]
            labels.append(item[0])
            ticks.append(str(no+1))
        fig, ax = plt.subplots()
        plt.bar(ind1, heights1, width, color='y')
        plt.bar(ind2, heights2, width, color='r')
        plt.ylabel('-log10(p-value)')
        plt.xlabel('Rank')
        plt.xticks(ind, ticks)
        plt.show()

    if autoselection==False:
        no_groups = input('Enter rank position(s) of tissue groups for analysis (0 for auto-selection): ')
    else:
        no_groups = 1
    group_list = []
    if no_groups == 0:
        data_u = {}
        data__ = open(independence_table, 'r')
        for line in data__:
            line = line.strip().split()
            if not line[0].startswith('#'):
                data_u[line[0]] = line[2]  # up-regulated-by
        ll = 1.0
        idx = 1
        for no in range(len(fet)):
            item = fet[no]
            if float(item[4]) > 1.0:
                if float(item[1]) < ll:
                    idx = no+1
                    ll = float(item[1])
        group_list.append(idx)
        for no in range(0, len(fet)):
            group__ = fet[idx-1][0]
            mm = fet[no][0]
            if mm in data_u[group__]:
                group_list.append(no+1)
    elif type(no_groups) == int:
        group_list.append(no_groups)
    else:
        for m in no_groups:
            group_list.append(m)
    groups = set()
    for m in group_list:
        groups.add(fet[m-1][0])
    results = []
    selected_genes = set()
    for no in range(cutoff):
        item = input_[no]
        if item[input_gene_idx] in ref_:
            gene_group = ref_[item[input_gene_idx]][0][0]
            if gene_group in groups:
                results.append([item[input_gene_idx], gene_group])
                if item[input_gene_idx] not in selected_genes:
                    selected_genes.add(item[input_gene_idx])
    initial_no = len(selected_genes)
    if include_network==True:
        path_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/dependence/'
        connected_genes = dependence(all_genes, path_+'genes_conditional_prob_short_.txt', path_+'genes_marginal_prob.txt')
        no_regulated_genes = {}
        network_table = {}
        for gene in all_genes:
            network_table[gene] = dependent_genes(gene, connected_genes, threshold_=threshold__)
            no_regulated_genes[gene] = len(network_table[gene])
        no_being_regulated = being_regulated(network_table)
        for no in range(len(results)):
            gene = results[no][0]
            for g2 in network_table[gene]:
                if g2 not in selected_genes:
                    selected_genes.add(g2)
                    gene_group = ref_[g2][0][0]
                    results.append([g2, gene_group])

        if cond_output_ != None:
            genomics.write_table1(connected_genes, cond_output_)
            genomics.write_file(no_being_regulated, cond_output_+'_being_regulated_counts.txt')
            genomics.write_file(no_regulated_genes, cond_output_+'_regulating_genes_counts.txt')

        for no in range(len(results)):
            gene=results[no][0]
            results[no].extend([no_regulated_genes[gene], no_being_regulated[gene]])

    #results.insert(0, ['# Size of gene set extracted ='+str(len(selected_genes))])
    #results.insert(1, ['# Number of dependent genes added ='+str(len(selected_genes)-initial_no)])

    genomics.write_file(results, output_file)


def analysis(input_file, threshold_, input_gene_idx, input_value_idx, threshold__ = 0.05, cond_output_=None):
    ### threshold_ = to identify intra-threshold
    ### threshold__ = to define significantly dependent gene pairs

    if type(input_file) == str:
        input_ = genomics.read_file1(input_file)
    else:
        input_ = input_file
    for no in range(len(input_)):
        input_[no][input_value_idx] = float(input_[no][input_value_idx])
    input_ = genomics.sort_(input_, idx=input_value_idx, reverse_=False)
    input_list = []
    for no in range(len(input_)):
        input_list.append([no + 1, input_[no][input_value_idx]])

    overall_threshold = calculate_slope(input_list[0], input_list[-1], abs_=True)
    a, b = find_dynamic_range(input_list, threshold=threshold_ * overall_threshold, interpolate_=True, range_mark=0.99,
                              output_cutoff=True)
    cutoff = len(input_list) - int(a[0][0])
    input_ = genomics.sort_(input_, idx=input_value_idx, reverse_=True)
    print 'Number of genes extracted =', cutoff

    selected_genes = set()
    for no in range(cutoff):
        item = input_[no]
        selected_genes.add(item[input_gene_idx])

    path_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/dependence/'
    connected_genes = dependence(selected_genes, path_ + 'genes_conditional_prob_short.txt',
                                     path_ + 'genes_marginal_prob.txt')
    no_regulated_genes = {}
    network_table = {}

    for gene in connected_genes:
        network_table[gene] = dependent_genes(gene, connected_genes, threshold_=threshold__)
        no_regulated_genes[gene] = len(network_table[gene])
    no_being_regulated = being_regulated(network_table)
    reg_scores = {}
    for gene in connected_genes:
        no_regulated = float(no_regulated_genes[gene])
        no_being = float(no_being_regulated[gene])
        reg_scores[gene] = no_regulated / (no_regulated + no_being)
    results = []
    for gene in connected_genes:
    #    sum_ = 0.0
    #    cnt = 1
    #    for g2 in connected_genes[gene]:
    #        if gene != g2:
    #            if float(connected_genes[gene][g2]) < threshold__:
    #                sum_ += reg_scores[g2]
    #                cnt += 1
        results.append([gene, reg_scores[gene]])
    results = genomics.sort_(results, idx=1, reverse_=True)
    saturation = []
    accu_genes = set()
    for no in range(len(results)):
        gene = input_[no][input_gene_idx]
        for g2 in connected_genes[gene]:
            if gene != g2:
                if float(connected_genes[gene][g2]) < threshold__:
                    accu_genes.add(g2)
        saturation.append(float(len(accu_genes)))
    print saturation
    for no in range(len(saturation)):
        saturation[no] = saturation[no] / len(selected_genes)
    print saturation




    if cond_output_ != None:
        genomics.write_table1(connected_genes, cond_output_)
        genomics.write_file(no_being_regulated, cond_output_ + '_being_regulated_counts.txt')
        genomics.write_file(no_regulated_genes, cond_output_ + '_regulating_genes_counts.txt')


def new_analysis(input_file, ref_file, threshold_, input_gene_idx, input_value_idx):

    if type(input_file)==str:
        input_ = genomics.read_file1(input_file)
    else:
        input_ = input_file
    ref_ = read_table1(ref_file, del_colnames=True)
    for no in range(len(input_)):
        input_[no][input_value_idx] = float(input_[no][input_value_idx])
    input_ = genomics.sort_(input_, idx=input_value_idx, reverse_=False)
    input_list = []
    for no in range(len(input_)):
        input_list.append([no+1, input_[no][input_value_idx]])

    overall_threshold = calculate_slope(input_list[0], input_list[-1], abs_=True)
    a,b = find_dynamic_range(input_list, threshold=threshold_*overall_threshold, interpolate_=True, range_mark=0.99, output_cutoff=True)
    cutoff = len(input_list) - int(a[0][0])
    input_ = genomics.sort_(input_, idx=input_value_idx, reverse_=True)
    groups = epigenomes
    fet=[]
    for group in groups:
        a,b,c,d = 0,0,0,0
        for no in range(cutoff):
            gene_ = input_[no][input_gene_idx]
            if gene_ in ref_:
                if ref_[gene_][group] == 1.0:
                    a += 1
                else:
                    b += 1
        for no in range(cutoff, len(input_)):
            gene_ = input_[no][input_gene_idx]
            if gene_ in ref_:
                if ref_[gene_][group] == 1.0:
                    c += 1
                else:
                    d += 1
        s_, p_ = stat.fisher(a,b,c,d)
        fet.append([group, p_, a, a+c, s_])  #[cluster, p-value, number of genes for the cluster above the threshold]

    fet = genomics.sort_(fet, idx=1, reverse_=False)







def being_regulated(network_table):
    ### count numbers of being regulated by other genes for all genes in the network
    ### network = dictionary of sets (from dependent_genes method)
    ### returns a dictionary of counts
    results = {}
    for item in network_table:
        results[item] = 0
    for item in network_table:
        if len(network_table[item]) != 0:
            for m in network_table[item]:
                if m not in results:
                    results[m] = 0
                results[m] += 1
    return results







def dependent_genes(gene, connected_genes, threshold_=0.05):
    ### finds all significantly dependent genes
    results = set()
    for item in connected_genes[gene]:
        if gene != item:
            if float(connected_genes[gene][item]) < threshold_:
                results.add(item)
    return results



def network(gene, network_table, we_have, count):
    ### recursively finds all genes regulated by a gene given the network_table (i.e. dictionary of sets)
    ### continues until no more new items are added to we_have
    if gene in we_have:
        return we_have, count
    else:
        we_have.add(gene)
        yy=list(network_table[gene])
        for no in range(len(yy)):
            item = yy[no]
            if no+1 == len(network_table[gene]):
                network(item, network_table, we_have, count+1)
            else:
                network(item, network_table, we_have, count)
        return we_have, count








def dependence(gene_set, cond_file, marg_file, output_='p-value'):
    ### Identifies dependent genes associated with the gene set(gene_list) based on conditional and marginal probabilities tables
    ### Significance is calculated for each gene
    ### output_ = 'p-value', 'z-score' or None (for p(A|B) - p(A))
    cond__ = open(cond_file, 'r')
    marg__ = genomics.read_file(marg_file, [1], rowname='0')
    gene_list = []
    gene_idx = []
    cond_ = {}
    no_genes = len(gene_set)
    cnt = 0
    results = {}
    mean_ = {}
    sd_ = {}
    for line in cond__:
        if len(gene_list) == 0:
            line = line.strip().split()
            for m in line:
                gene_list.append(m)
                if m in gene_set:
                    idx = line.index(m)
                    gene_idx.append(idx)
        else:
            if no_genes == cnt:
                break
            else:
                pop_ = []
                line = line.strip().split()
                if line[0] in gene_set:
                    cnt += 1
                    cond_[line[0]] = {}
                    results[line[0]] = {}
                    idx = gene_list.index(line[0])+1
                    for l in range(1, len(line)):
                        if l == idx:
                            continue
                        else:
                            g_ = gene_list[l-1]
                            diff_ = float(line[l]) - float(marg__[line[0]][0][0])
                            cond_[line[0]][g_] = diff_
                            pop_.append(diff_)
                    mean_[line[0]] = np.mean(pop_)
                    sd_[line[0]] = np.std(pop_)

    for g1 in gene_set:
        raw_p = []
        for g2 in gene_set:
            if g1!=g2:
                z_ = stat.z_score(float(cond_[g1][g2]), mean_=mean_[g1], sd_=sd_[g1])
                if output_=='z-score':
                    results[g1][g2] = round(z_,4)
                elif output_=='p-value':
                    p_ = stat.p_value(z_)
                    results[g1][g2] = round(p_,4)
                    raw_p.append([g1,g2,p_])
                else:
                    results[g1][g2] = float(cond_[g1][g2])
        raw_p_ = []

        for item in raw_p:
            raw_p_.append(item[-1])
        temp = smm.multipletests(raw_p_, method='fdr_bh')
        temp_ = temp[1]
        for no in range(len(temp)):
            g1 = raw_p[no][0]
            g2 = raw_p[no][1]
            results[g1][g2] = temp_[no]
    for g1 in results:
        results[g1][g1] = 'NA'


    return results



def independence_test(cond_table, marg_file, cluster_idx, value_idx, threshold_, gene_list=None):
    ### Takes a table format (cond_table, e.g. cluster_conditional_probabilities_odds_ratio.txt) and calculate difference
    ### from the marginal probability of each cluster (i.e. conditional probability - marginal probability)
    ### If > +threshold_ --> the given cluster is positively regulated
    ### If < -threshold_ --> the given cluster is negatively regulated
    ### marg_file = e.g. cluster_probability.txt
    ### cluster_idx = a column index in marg_fie where the cluster ID is recorded
    ### value_idx = a column index in marg_file where the marginal probability is recorded
    ### threshold_ = a threshold numerical value (i.e. the difference)
    ### gene_list = a set (or list) of genes of interest
    ### It also calculates independence score (i.e. number of times the given cluster is within the threshold range / total number of clusters)
    ### Note. the table must have row elements (A) and col elements (B) such that p(A|B)
    if type(cond_table) == str:
        cond_ = read_table1(cond_table, del_colnames=True)
    else:
        cond_ = cond_table
    marg_ = genomics.read_file(marg_file, [value_idx], rowname=str(cluster_idx))
    results = {}
    if gene_list==None:
        gene_list = set()
        for c in cond_:
            gene_list.add(c)
    else:
        gene_list = set(gene_list)
    for c in gene_list:
        results[c] = {}
        results[c]['is'] = 0.0
        results[c]['up'] = []
        results[c]['down'] = []
        results[c]['nc'] = []
        marg_p = marg_[c][0][0]
        for m in cond_[c]:
            if c!=m:
                diff_ = float(cond_[c][m]) - float(marg_p)
                if diff_ > +threshold_:
                    results[c]['up'].append(m)
                elif diff_ < -threshold_:
                    results[c]['down'].append(m)
                else:
                    results[c]['nc'].append(m)
            results[c]['is'] = float(len(results[c]['nc'])) / len(cond_[c])
    final = []
    for c in results:
        final.append([c, results[c]['is']])
        line = ''
        for m in results[c]['up']:
            line += m+','
        final[-1].extend([line])
        line = ''
        for m in results[c]['down']:
            line += m+','
        final[-1].extend([line])
        line = ''
        for m in results[c]['nc']:
            line += m+','
        final[-1].extend([line])
    return final

def marginal_prob(input_file):
    ### takes a table instance (Note. probabilities are calculated for rows) and returns a list of probabilities
    ### It only works for binary (1 or 0) table
    if type(input_file)==str:
        input_= read_table1(input_file, del_colnames=True)
    else:
        input_ = input_file
    results = []
    for item in input_:
        total = 0
        cnt = 0
        for m in input_[item]:
            total += 1
            if float(input_[item][m]) == float(1):
                cnt += 1
        prob = float(cnt) / total
        results.append([item, prob])
    return results

def conditional_prob(input_file, genes=None):
    ### takes a table instance (or file, e.g. broadpeak_combined_foreground_counts_all.txt) and calculates conditional probabilities for all pairs
    ### genes = a list of gene symbols that are of interest
    ### Note. the table must be transposed beforehand (so that genes are columns and epigenomes are rows).
    if type(input_file)==str:
        input_ = read_table1(input_file, del_colnames=True)
    else:
        input_ = input_file
    if genes==None:
        genes = []
        for item in input_['E065']:
            if item not in genes:
                genes.append(item)
    input__ = {}
    for item in input_:
        input__[item] = []
        for gene in genes:
            input__[item].append(float(input_[item][gene]))
    results = {}
    for gene in genes:
        results[gene] = {}
        for g in genes:
            results[gene][g] = 0.0
    for n1 in range(len(genes)):
        print n1
        g1 = genes[n1]
        for n2 in range(len(genes)):
            g2 = genes[n2]
            if n1==n2:
                results[g1][g2] = 1.0
            else:
                cnt1 = 0
                cnt2 = 0
                for epi in input__:
                    if float(input__[epi][n2]) == float(1):
                        cnt2 += 1
                        if float(input__[epi][n1]) == float(1):
                            cnt1 += 1
                prob = float(cnt1) / cnt2
                results[g1][g2] = round(prob, 4)
    return results

def conditional_prob1(input_file, genes=None):
    ### takes a table instance (or file, e.g. broadpeak_combined_foreground_counts_all.txt) and calculates conditional probabilities for all pairs
    ### genes = a list of gene symbols that are of interest
    ### Note. the table must be transposed beforehand (so that genes are columns and epigenomes are rows).
    if type(input_file)==str:
        input_ = read_table1(input_file, del_colnames=True)
    else:
        input_ = input_file
    if genes==None:
        genes = []
        for item in input_['E065']:
            if item not in genes:
                genes.append(item)
    input__ = {}
    for item in input_:
        input__[item] = []
        for gene in genes:
            input__[item].append(float(input_[item][gene]))
    results = {}
    for gene in genes:
        results[gene] = {}
        for g in genes:
            results[gene][g] = 0.0
    for n1 in range(len(genes)):
        print n1
        g1 = genes[n1]
        for n2 in range(len(genes)):
            g2 = genes[n2]
            if n1==n2:
                results[g1][g2] = 1.0
            else:
                joint = 0
                marginal = 0
                for epi in input__:
                    if (float(input__[epi][n2]) == float(1)) and (float(input__[epi][n1]) == float(1)):
                        joint += 1
                    if float(input__[epi][n2]) == float(1):
                        marginal += 1
                joint = float(joint) / len(input__)
                marginal = float(marginal) / len(input__)

                prob = joint / marginal
                results[g1][g2] = round(prob, 4)
    return results

def find_significant_pairs(table_file, threshold_):
    ### identifies significant pairs and results two list of pairs (one positive, the other negative)
    results_p = []
    results_n = []
    table_ = read_table1(table_file, del_colnames=True)
    for item1 in table_:
        for item2 in table_[item1]:
            if item1 != item2:
                if abs(float(table_[item1][item2])) > threshold_:
                    if float(table_[item1][item2]) < 0.0:
                        results_n.append([item2, item1])
                    if float(table_[item1][item2]) > 0.0:
                        results_p.append([item2, item1])
    return results_p, results_n

def entropy(input_list):
    ### takes a list of numerical values (e.g. widths of H3K4me3 for a gene) and calculate entropy (i.e. -sigma{(a value/sum of values) * log2(a value/sum of values)})
    ### See 'Promoter features related to tissue specificity as measured by Shannon entropy' - Schug et al, Genome biology (2005)
    sum_ = np.sum(input_list)
    ratios = [float(num)/sum_ for num in input_list]
    results = [-float(i)*np.log2(i) for i in ratios]
    return sum(results)

def entropy_for_gene_list(input_, ref_, cutoff):
    ### ONLY SUITABLE FOR BINARY CLASSES
    print len(input_)
    value1 = len(genomics.intersection(input_[0:cutoff], ref_))    
    value2 = len(genomics.intersection(input_[cutoff:len(input_)], ref_))
    print len(input_)
    total = len(genomics.intersection(input_, ref_))
    print value1, value2, total
    a = float(value1) / total   
    b = float(value2) / total
    results = -(a*np.log2(a))-(b*np.log2(b))
    return results



def specificity(input_list, entropy_):
    ### calculate cell type specificity for input_list with entropy of the gene (entropy_)
    ### specificity = entropy - log2(a value/sum of values for the gene)
    sum_ = np.sum(input_list)
    ratios = [float(num)/sum_ for num in input_list]
    results = [entropy_-np.log2(i) for i in ratios]
    return results


def find_elbow(input_list):
    ### takes a lit of values and find the elbow point (as index)    
    curve=input_list
    nPoints = len(curve)
    allCoord = np.vstack((range(nPoints), curve)).T
    np.array([range(nPoints), curve])
    firstPoint = allCoord[0]
    lineVec = allCoord[-1] - allCoord[0]
    lineVecNorm = lineVec / np.sqrt(np.sum(lineVec ** 2))
    vecFromFirst = allCoord - firstPoint
    scalarProduct = np.sum(vecFromFirst * np.matlib.repmat(lineVecNorm, nPoints, 1), axis=1)
    vecFromFirstParallel = np.outer(scalarProduct, lineVecNorm)
    vecToLine = vecFromFirst - vecFromFirstParallel
    distToLine = np.sqrt(np.sum(vecToLine ** 2, axis=1))
    idxOfBestPoint = np.argmax(distToLine)
    return idxOfBestPoint

def identify_threshold(input_list, point_):
    ### takes a list of numerical inputs and calculate mean and standard deviation 
    ### then identify the threshold as specified (point_ as the z-score, e.g. 1.65 = top 5% of the population)
    mean_ = np.mean(input_list)
    sd_ = np.std(input_list)
    return (point_)*sd_ + mean_


def identify_rep(input_genes, cor_file, threshold_=None):
    ### takes a list of ranked genes and identify a set of genes with the highest correlation
    ### threshold_ = a numerical value to call the pair as significant
    ### Note. While this can be run with unsorted list of genes, it's better to sort them first so that meaningful extraction of reference genes is possible.
    input_genes = list(input_genes)        
    cor_ = subset_table(cor_file, input_genes, input_genes)
    pp = []
    for item in input_genes:
        if item in cor_:
            pp.append(item)
    input_genes = pp    
    current_cor = 0.000001
    prev_cor = 0.0       
    while current_cor > prev_cor:
        print
        print current_cor
        print prev_cor        
        no_genes2 = len(cor_[input_genes[0]])-1   
        print no_genes2     
        sum_ = []
        for gene1 in input_genes:
            sum_.append([gene1, 0.0]) 
            for gene2 in input_genes:
                if gene1 != gene2:
                    sum_[-1][1] += cor_[gene1][gene2] / no_genes2    
            if gene1 == 'MYH6':
                print sum_[-1][1]                
        sum_ = genomics.sort_(sum_, idx=1, reverse_=True)
        print sum_[0:10]
        idx = int(len(sum_)/2)
        print idx
        prev_cor = current_cor
        current_cor = 0.0
        input_genes = []
        for i in range(idx):
            current_cor += sum_[i][1]
            input_genes.append(sum_[i][0])
        current_cor = current_cor / idx
    return input_genes

def identify_rep1(input_genes, cor_file, threshold_=None):
    ### takes a list of ranked genes and identify a set of genes with the highest correlation
    ### threshold_ = a numerical value to call the pair as significant
    ### Note. While this can be run with unsorted list of genes, it's better to sort them first so that meaningful extraction of reference genes is possible.
    input_genes = list(input_genes)        
    cor_ = subset_table(cor_file, input_genes, input_genes)
    pp = []
    for item in input_genes:
        if item in cor_:
            pp.append(item)
    input_genes = pp    
    results = {}
    scores = {}
    set_no = 1 
    temp = []
    scores_ = {}
    for item in input_genes:
        scores_[item] = input_genes.index(item)
    print len(input_genes)
    if threshold_==None:
        for gene1 in input_genes:
            for gene2 in input_genes:
                if gene1 != gene2:
                    temp.append(cor_[gene1][gene2])
        threshold_ = identify_threshold(temp, point_=1.65)

    print threshold_    

    for gene1 in input_genes:
        for gene2 in cor_[gene1]:
            if gene1 != gene2:
                if float(cor_[gene1][gene2]) > threshold_:
                    added = 0
                    if len(results) == 0:
                        results[str(set_no)] = set()
                        results[str(set_no)].add(gene1)
                        results[str(set_no)].add(gene2)
                        scores[str(set_no)] = scores_[gene1] + scores_[gene2]
                    else:
                        for item in results:
                            if gene1 in results[item]:
                                results[item].add(gene2)
                                added = 1
                                scores[item] += scores_[gene2]
                            elif gene2 in results[item]:
                                results[item].add(gene1)
                                added = 1
                                scores[item] += scores_[gene1]
                        if added == 0:
                            set_no += 1
                            results[str(set_no)] = set()
                            results[str(set_no)].add(gene1)
                            results[str(set_no)].add(gene2)
                            scores[str(set_no)] = scores_[gene1] + scores_[gene2]
    best_score = 0
    best_set = 0
    for item in scores:
        if scores[item] > best_score:
            best_score = scores[item]
            best_set = item
    return list(results[best_set])


def cor_analysis2(input_genes, cor_file, group_number=5, cor_ave=True, p_threshold_=0.0001):    
    ### groups_numers = a maximum number of groups (genes) allowed (i.e. sub-modules)
    ### it takes an ordered list of genes and forms groups by adding genes progressively to groups with significant correlation compared to the background.
    ### cor_ave = a boolean to indicate whether average value of correlation between members are to be printed.
    input_genes = list(input_genes)        
    cor_ = subset_table(cor_file, input_genes, input_genes)
    pp = []
    for item in input_genes:
        if item in cor_:
            pp.append(item)
    input_genes = pp    
    results = {}
    scores = {}    
    temp = []
    scores_ = {}    
    for item in input_genes:
        scores_[item] = input_genes.index(item)
    for i in range(1,group_number+1):
        results[str(i)] = set()
        scores[str(i)] = 0.0  # Ave. correlation for the group, calculated in the final step  
    cnt = 0       
    for gene in input_genes:           
        added = 0   
        back = []
        cnt += 1
        if cnt % 1000 == 0:
            print cnt
        for gene2 in cor_[gene]:
            if gene != gene2:
                back.append(cor_[gene][gene2]) 
         
        for i in range(1, group_number+1):
            group = str(i)   
                  

            if len(results[group]) > 0:
                fore = []                
                for item in results[group]:
                    fore.append(cor_[gene][item])  
                if len(results[group]) == 1:
                    fore.append(cor_[gene][item])                      
                s, p = stat.t_test(fore, back)                                            

                if (s > 0.0) and (p < p_threshold_):
                    results[group].add(gene)
                    added = 1
            elif len(results[group])==0:
                if added == 0:
                    results[group].add(gene)
                    break
    if cor_ave == False:
       return results
    else:
        cor_stat = cor_statistics(results, cor_)
        return results, cor_stat

def cor_analysis3(input_genes, cor_file, threshold_=None, group_number=5, cor_ave=True):    
    ### groups_numers = a maximum number of groups (genes) allowed (i.e. sub-modules)
    ### it takes an ordered list of genes and forms groups by adding genes progressively to groups with significant correlation compared to the background.
    ### cor_ave = a boolean to indicate whether average value of correlation between members are to be printed.
    input_genes = list(input_genes)        
    cor_ = subset_table(cor_file, input_genes, input_genes)
    pp = []
    for item in input_genes:
        if item in cor_:
            pp.append(item)
    input_genes = pp    
    results = {}
    scores = {}    
    temp = []
    scores_ = {}    
    for item in input_genes:
        scores_[item] = input_genes.index(item)
    for i in range(1,group_number+1):
        results[str(i)] = set()
        scores[str(i)] = 0.0  # Ave. correlation for the group, calculated in the final step  
    cnt = 0       
    for gene in input_genes:           
        added = 0   
        back = []
        cnt += 1
        if cnt % 1000 == 0:
            print cnt
        for gene2 in cor_[gene]:
            if gene != gene2:
                back.append(cor_[gene][gene2]) 
         
        for i in range(1, group_number+1):
            group = str(i)   
                  

            if len(results[group]) > 0:
                fore = []                
                for item in results[group]:
                    fore.append(cor_[gene][item])  
                if len(results[group]) == 1:
                    fore.append(cor_[gene][item])                      
                s, p = stat.t_test(fore, back)                                            

                if (s > 0.0) and (p < 0.0001):
                    results[group].add(gene)
                    added = 1
            elif len(results[group])==0:
                if added == 0:
                    results[group].add(gene)
                    break
    if cor_ave == False:
       return results
    else:
        cor_stat = cor_statistics(results, cor_)
        return results, cor_stat

def cor_statistics(input_, cor_):
    ### takes a dictinonary of gene lists (highly correlated genes, e.g. from cor_analysis2) and calculate statistics
    results = []
    for item in input_:
        results.append([item])
        no_genes = len(input_[item])        
        temp = list(input_[item])
        values = []
        for no1 in range(len(temp)-1):
            for no2 in range(no1+1, len(temp)):                
                g1 = temp[no1]
                g2 = temp[no2]
                values.append(cor_[g1][g2])
        results[-1].extend([no_genes, np.mean(values)])
    return results

 


def cor_analysis(candidate_, background_, cor_file, output_, threshold_=0.05, multiple_correction=True, pair_analysis_=False, one_sided=False):
    ### takes a candidate gene list and background (i.e. all genes in the input dataset) and calculate correlation scores for each gene
    ### cor_file (e.g. gene_pearson_short.txt, a correlation table for all pair-wise genes obtained from all datasets of interest (e.g. Roadmap 111 cell types)
    ### correlation score for gene A = sum of Pearson's correlation for the pair (gene A vs. gene B, where gene B are all other genes in the candidate gene list)
    ### Thus, all genes in the candidate list have the same number of samples that contribute to the final correlation score for that gene
    ### These are compared to the background which is a collection of Pearson's correlations for all possible pairs for that gene (i.e. all genes in the data set), using two-sample t-test.
    ### Also, optionally (if pair_analysis=True) includes most significant pairs for each gene (by threshold_ = p-value, one-sample t-test) and rank genes by the count
    ### one_sided = a boolean to indicate whether the t-test (initially two-sided) is to be converted to one-sided (right-end tail). 
    candidate_ = set(candidate_)
    background_ = set(background_)
    cor__ = open(cor_file, 'r')
    cor_ = {}
    colnames = []
    background_all = []
    candidate_sum = {}
    p_values = {}
    s_values = {}
    for line in cor__:
        if len(cor_) == len(background_):
            break
        else:
            line = line.strip().split()
            if len(colnames) == 0:
                for m in line:
                    colnames.append(m)
            else:
                if line[0] in background_:
                    if line[0] in candidate_:
                        candidate_sum[line[0]] = []
                    cor_[line[0]] = {}
                    for no in range(1, len(colnames)):
                        if line[0] != colnames[no]:
                            if colnames[no-1] in background_:
                                cor_[line[0]][colnames[no-1]] = float(line[no])
                                if line[0] in candidate_:
                                    if colnames[no-1] in candidate_:
                                        candidate_sum[line[0]].append(float(line[no]))
                else:
                    continue

    for gene in candidate_sum:
        temp = []
        for item in cor_[gene]:
            temp.append(float(cor_[gene][item]))
        s_, p_ = stat.t_test(candidate_sum[gene], temp, output_=None)
        if one_sided==False:
            p_values[gene] = p_
        elif one_sided==True:            
            p_values[gene] = p_ / 2
        s_values[gene] = s_

    adjusted_p = {}
    if multiple_correction==True:
        pp_name = []
        pp_value = []
        for gene in p_values:
            pp_name.append(gene)
            pp_value.append(p_values[gene])
        gg = stat.corrected_p(pp_value)
        for no in range(len(pp_name)):
            adjusted_p[pp_name[no]] = gg[no]

    ll = []
    if multiple_correction==True:
        for gene in p_values:
            ll.append([gene, s_values[gene], p_values[gene], adjusted_p[gene]])
        ll.insert(0, ['#gene', 't.statistic', 'p-value', 'FDR(BH)'])
    else:
        for gene in p_values:
            ll.append([gene, p_values[gene], s_values[gene]])
        ll.insert(0, ['#gene','p-value', 't.statistic'])

    genomics.write_file(ll, output_+'_results.txt')
    if pair_analysis_ == True:
        pair_analysis(candidate_sum, background_, p_values, s_values, threshold_, cor_, output_, pair_write)


def rescue_analysis(candidate_, background_, cor_file, output_, threshold_=0.05, multiple_correction=True, pair_analysis_=False):
    ### Same as the cor_analysis, but this one is for finding any genes in the background that have significant positive correlation with the candidates
    candidate_ = set(candidate_)
    background_ = set(background_)
    cor__ = open(cor_file, 'r')
    cor_ = {}
    colnames = []
    background_all = []
    candidate_sum = {}
    p_values = {}
    s_values = {}
    for line in cor__:
        if len(cor_) == len(background_):
            break
        else:
            line = line.strip().split()
            if len(colnames) == 0:
                for m in line:
                    colnames.append(m)
            else:
                if line[0] in background_:
                    if line[0] in background_:
                        candidate_sum[line[0]] = []
                    cor_[line[0]] = {}
                    for no in range(1, len(colnames)):
                        if line[0] != colnames[no]:
                            if colnames[no-1] in background_:
                                cor_[line[0]][colnames[no-1]] = float(line[no])
                                if line[0] in background_:
                                    if colnames[no-1] in candidate_:
                                        candidate_sum[line[0]].append(float(line[no]))
                else:
                    continue

    for gene in candidate_sum:
        temp = []
        for item in cor_[gene]:
            temp.append(float(cor_[gene][item]))
        s_, p_ = stat.t_test(candidate_sum[gene], temp, output_=None)
        p_values[gene] = p_
        s_values[gene] = s_

    adjusted_p1 = {}
    adjusted_p2 = {}
    if multiple_correction==True:
        pp_name = []
        pp_value = []
        for gene in p_values:
            pp_name.append(gene)
            pp_value.append(p_values[gene])
        gg = stat.corrected_p(pp_value)
        for no in range(len(pp_name)):
            adjusted_p1[pp_name[no]] = gg[no]

        gg = stat.corrected_p(pp_value, method_='bonferroni')
        for no in range(len(pp_name)):
            adjusted_p2[pp_name[no]] = gg[no]

    ll = []
    if multiple_correction==True:
        for gene in p_values:
            ll.append([gene, s_values[gene], p_values[gene], adjusted_p1[gene], adjusted_p2[gene]])
        ll.insert(0, ['#gene', 't.statistic', 'p-value', 'FDR(BH)', 'Bonferroni'])
    else:
        for gene in p_values:
            ll.append([gene, p_values[gene], s_values[gene]])
        ll.insert(0, ['#gene','p-value', 't.statistic'])

    genomics.write_file(ll, output_)

    if pair_analysis_ == True:
        pair_analysis(candidate_sum, background_, p_values, s_values, threshold_, cor_, output_, pair_write)


def seed_analysis(candidate_, background_, cor_file, output_, multiple_correction=True):
    ### 
    ### background_ must include candidate_
    candidate_ = set(candidate_)
    background_ = set(background_)
    if type(cor_file)==str:
        cor_ = subset_table(cor_file, rows=background_, cols=background_, numerical=True)    
    else:
        cor_ = cor_file
    p_values = {}
    s_values = {}
    genes = set()

    #for item in background_:  # If don't want to include candidate_ to be assessed
    #    if item not in candidate_:
    #        genes.add(item)
    
    for g in background_:
        if g in cor_:
            genes.add(g)    
    for gene in genes:              
        if gene in cor_:     
            fore = []
            back = []
            for g1 in genes:                
                
                if g1 in candidate_:
                        
                    fore.append(float(cor_[gene][g1]))
                else:

                    back.append(float(cor_[gene][g1]))            
            s_, p_ = stat.t_test(fore, back, output_=None)
            p_values[gene] = p_
            s_values[gene] = s_

    adjusted_p1 = {}
    adjusted_p2 = {}
    if multiple_correction==True:
        pp_name = []
        pp_value = []
        for gene in p_values:
            pp_name.append(gene)
            pp_value.append(p_values[gene])
        gg = stat.corrected_p(pp_value)
        for no in range(len(pp_name)):
            adjusted_p1[pp_name[no]] = gg[no]

        gg = stat.corrected_p(pp_value, method_='bonferroni')
        for no in range(len(pp_name)):
            adjusted_p2[pp_name[no]] = gg[no]

    ll = []
    if multiple_correction==True:
        for gene in p_values:
            ll.append([gene, s_values[gene], p_values[gene], adjusted_p1[gene], adjusted_p2[gene]])
        ll.insert(0, ['#gene', 't.statistic', 'p-value', 'FDR(BH)', 'Bonferroni'])
    else:
        for gene in p_values:
            ll.append([gene, p_values[gene], s_values[gene]])
        ll.insert(0, ['#gene','p-value', 't.statistic'])
    if type(output_)==str:
        genomics.write_file(ll, output_)
    else:
        return ll

    
def seed_analysis1(candidate_, background_, cor_file, output_, multiple_correction=True):
    ### FOR IMPROVED EFFICIENCY
    ### background_ must include candidate_
    candidate_ = set(candidate_)   
    cor_ = cor_file
    
    p_values = {}
    s_values = {}
    genes = set()

    #for item in background_:  # If don't want to include candidate_ to be assessed
    #    if item not in candidate_:
    #        genes.add(item)
  
    for gene in background_:              
           
        fore = []
        back = background_[gene]
        for g1 in candidate_:                  
                                      
            fore.append(float(cor_[gene][g1]))                      
        s_, p_ = stat.t_test(fore, back, output_=None)
        p_values[gene] = p_
        s_values[gene] = s_

    adjusted_p1 = {}
    adjusted_p2 = {}
    if multiple_correction==True:
        pp_name = []
        pp_value = []
        for gene in p_values:
            pp_name.append(gene)
            pp_value.append(p_values[gene])
        gg = stat.corrected_p(pp_value)
        for no in range(len(pp_name)):
            adjusted_p1[pp_name[no]] = gg[no]

        gg = stat.corrected_p(pp_value, method_='bonferroni')
        for no in range(len(pp_name)):
            adjusted_p2[pp_name[no]] = gg[no]

    ll = []
    if multiple_correction==True:
        for gene in p_values:
            ll.append([gene, s_values[gene], p_values[gene], adjusted_p1[gene], adjusted_p2[gene]])
        ll.insert(0, ['#gene', 't.statistic', 'p-value', 'FDR(BH)', 'Bonferroni'])
    else:
        for gene in p_values:
            ll.append([gene, p_values[gene], s_values[gene]])
        ll.insert(0, ['#gene','p-value', 't.statistic'])
    if type(output_)==str:
        genomics.write_file(ll, output_)
    else:
        return ll



def extract_lines_from_files(files, rownames, row_idx, col_idx):
    ### takes a multiple files (all must have the same format) and take lines with rownames 
    results = {}
    for i in range(len(rownames)):
        results[rownames[i]] = []
        for m in range(len(files)):
            results[rownames[i]].append('')
    for no in range(len(files)):
        file = files[no]
        data_ = genomics.read_file(file, [col_idx], rownames=str(row_idx))
        for name in rownames:
            results[name][no] = data_[name][0][0]
    return results





def pair_analysis(candidate_sum, background_, p_values, s_values, threshold_, cor_, output_):
    ### candidate_sum = a dictionary of lists of correlations for all candidates
    results_p = []
    results_n = []
    background_all = []
    g_p = set()
    g_n = set()
    for g1 in candidate_sum:
        if p_values[g1] < threshold_:  # consider only significant genes
            for item in background_:
                if item in cor_[g1]:
                    background_all.append(float(cor_[g1][item]))
            pop_mean = np.mean(background_all)
            pop_sd = np.std(background_all)
            for g2 in candidate_sum:
                if g1 != g2:
                    if g1 in cor_:
                        if g2 in cor_[g1]:
                            z_ = stat.z_score(cor_[g1][g2], mean_=pop_mean, sd_=pop_sd)
                            p_ = stat.p_value(z_)
                            if p_ < threshold_:
                                if s_values[g1] > 0.0:
                                    if g1 not in g_p:
                                        results_p.append([g1])
                                        g_p.add(g1)
                                    results_p[-1].extend([g2])
                                elif s_values[g1] < 0.0:
                                    if g1 not in g_n:
                                        results_n.append([g1])
                                        g_n.add(g1)
                                    results_n[-1].extend([g2])

    results_p.insert(0, ['#gene','Sig_pos_partners'])
    #results_n.insert(0, ['#gene','Sig_neg_partners'])
    genomics.write_file(results_p, output_+'_sig_pos_partners.txt')
    #genomics.write_file(results_n, output_+'_sig_neg_partners.txt')

def identify_correlated_genes1(input_genes, table_, p_threshold_):
    ### takes a gene list and find ones that are correlated using a similarity matrix
    ### returns a dictionary of lists    
    results = {}    
    for g1 in input_genes:
        background_ = []
        results[g1] = []
        for g2 in table_[g1]:            
            background_.append(table_[g1][g2])            
        mean_ = np.mean(background_)
        sd_ = np.std(background_)
        for g2 in table_[g1]:
            if table_[g1][g2] > mean_:
                z_ = stat.z_score(table_[g1][g2], mean_, sd_)
                p_ = stat.p_value(z_)
                if p_ < p_threshold_:
                    results[g1].append(g2)
    return results


def subset_table(input_table, rows, cols=None, numerical=True):
    ### takes a table text file (or instance) and return a subset defined by rows and cols (both are either lists or sets)
    ### if cols==None, it used all cols in the input_table
    input_ = {}
    colnames = []
    selected_cols = []  # index numbers
    rows = set(rows)
    if type(input_table)==str:
        data_ = open(input_table, 'r')
        for line in data_:
            line = line.strip().split()
            if len(colnames) == 0:
                for m in line:
                    colnames.append(m)
                if cols==None:
                    cols = set(colnames)
                else:
                    cols = set(cols)
                for col in cols:
                    if col in colnames:
                        idx = colnames.index(col)
                        selected_cols.append(idx)
            else:
                if len(input_) == len(rows):
                    break
                else:
                    if line[0] in rows:
                        input_[line[0]] = {}
                        if numerical==True:
                            for idx in selected_cols:
                                input_[line[0]][colnames[idx]] = float(line[idx+1])
                        else:
                            for idx in selected_cols:
                                input_[line[0]][colnames[idx]] = line[idx+1]
    else:
        for row in rows:
            if row in input_table:
                input_[row] = {}
                for col in cols:
                    input_[row][col] = input_table[row][col]

    return input_

def gene_cor(gene_, candidate_list, cor_table):
    ### take a single gene and calculate two-sampled t-test based on correlations within the candidate_ compared to the background_
    ### cor_table must be pre-sorted so that it only contains selected columns to represent the background
    ### candidate_list = a list of candidate genes
    ### returns t.statistic and p value
    pf = []
    pb = []
    if gene_ in cor_table:
        for gene in candidate_list:

            if gene_==gene:
                continue
            else:
                if gene in cor_table[gene_]:
                    pf.append(float(cor_table[gene_][gene]))
        for gene in cor_table[gene_]:
            if gene_==gene:
                continue
            else:
                pb.append(float(cor_table[gene_][gene]))
    s_, p_ = stat.t_test(pf, pb, output_=None)
    ave_f = np.mean(pf)
    ave_b = np.mean(pb)
    return s_, p_, ave_f, ave_b

def subsample_epi(input_):
    ### takes a dictionary of data (e.g. tissue_groups[group] = [xx, xx, ...]) and returns a list of lists with an added member from each group
    results = []
    epi_ = set()
    max_itr = 0
    for group in tissue_groups:
        if len(tissue_groups[group]) > max_itr:
            max_itr = len(tissue_groups[group])
    for n in range(max_itr):
        for group in tissue_groups:
            for epi in tissue_groups[group]:
                if epi in epi_:
                    continue
                else:
                    epi_.add(epi)
                    break
        results.append(list(epi_))
    return results

def binary_table(input_table, threshold_, na_=0, restricted_list=None, as_list=False):
    ### takes in a table instance and creates a binary table
    ### 'NA' will be regarded as 0 (default) (you can change it by changing na_ parameter)
    ### restricted_list = a list of set to restrict rows to
    ### as_list = indicate whether the output is a dictonary of lists (True) or dictionary of dictionaries (False)
    if type(input_table)==str:
        table_ = read_table1(input_table, del_colnames=True, numerical=False)
    gene_ = set()
    restricted_list = set(restricted_list)
    for item in table_:
        if restricted_list==None:
            gene_.add(item)
        else:
            if item in restricted_list:
                gene_.add(item)
    if as_list==False:
        results = {}
        for gene in gene_:
            results[gene] = {}
            for col in table_[gene]:
                results[gene][col] = 0
        for gene in gene_:
            for col in table_[gene]:
                if table_[gene][col] != 'NA':
                    if float(table_[gene][col]) < threshold_:
                        results[gene][col] = 1
                else:
                    results[gene][col] = na_
    elif as_list==True:
        results = {}
        colnames = []
        for gene in gene_:
            results[gene] = []
            if len(colnames)==0:
                for col in table_[gene]:
                    colnames.append(col)
            for no in range(len(colnames)):

                results[gene].append(0)
        for gene in gene_:
            for col in colnames:
                if table_[gene][col] != 'NA':
                    if float(table_[gene][col]) < threshold_:
                        results[gene].append(1)
                    else:
                        results[gene].append(0)
                else:
                    results[gene].append(na_)
    return results


def subsample_epi2(epigenomes, initial_size, bin_size, randomize_=True):
    ### epigenomes = a list of all 111 epigenomes
    ### initial_set = a list of set of the starting set
    ### it adds (bin_size) members from epigenomes until all filled
    if randomize_==True:
        epigenomes = list(np.random.choice(epigenomes, len(epigenomes), replace=False))
    initial_set = epigenomes[:initial_size]
    results = [initial_set]
    itr_no = (len(epigenomes)-initial_size) / bin_size
    for i in range(itr_no):
        start = (i * bin_size) + initial_size
        end = start + bin_size
        results.append(initial_set+epigenomes[start:end])
        initial_set = initial_set + epigenomes[start:end]
    return results

def subsample_epi3(groups_, initial_set, bin_size):
    initial_set = set(initial_set)
    cnt = 0
    results = [list(initial_set)]
    while len(initial_set) != len(epigenomes):
        for group in groups_:
            for epi_ in groups_[group]:
                if epi_ not in initial_set:
                    initial_set.add(epi_)
                    cnt += 1
                    break
            if cnt % bin_size == 0:
                if len(initial_set)!= len(results[-1]):
                    results.append(list(initial_set))
    return results

def plot_dist(y):
    ### takes a list of numerical values (as y-axis values) and plot the distribution chart
    ticks = []
    for no in range(len(y)):
        ticks.append(str(no+1))
    ind = np.arange(len(y))
    width = 0.35
    fig, ax = plt.subplots()
    rect = ax.bar(ind, y, width, color='y')
    ax.set_ylabel('value')
    ax.set_xlabel('position')
    ax.set_xticks(ind+width/2)
    ax.set_xticklabels(ticks)
    plt.show()

def extract_lines(table_file, rownames, na_ignore=False):
    ### takes a table file (or instance) and extract values in lines specified by rownames
    if type(table_file)==str:
        table_file = read_table1(table_file, del_colnames=True, numerical=False)
    results = []
    for row in rownames:
        line = []
        for col in table_file[row]:
            if na_ignore==True:
                if table_file[row][col] != 'NA':
                    line.append(table_file[row][col])
            else:
                line.append(table_file[row][col])
        results.append(line)
    return results

def sort_elements(input_, order_='ascending', na_value = 0.0):
    ### takes a list of lists (numerical values and 'NA') and sort them in order
    ### 'NA' will be replaced by 0.0 (by default)
    #print input_[0]
    for no in range(len(input_)):
        item = input_[no]
        for m in range(len(item)):
            if input_[no][m] =='NA':
                input_[no][m] = na_value
            else:
                input_[no][m] = float(input_[no][m])
        if order_=='ascending':
            input_[no].sort()
        elif order_=='descending':
            input_[no].sort(reverse=True)
        #input_[no] = input_[no]
    #print input_[0:2]
    #print np.mean(input_[0])
    #print np.mean(input_[1])
    #print len(input_[0])
    return input_

def sort_by_position(input_):
    ### takes a list of lists and creates a dictionary of lists sorted by index positions of the elements
    ### e.g. [[1,2,3],[2,3,4],[3,4,5]] --> dict['0'] = [1,2,3], dict['1'] = [2,3,4], dict['2'] = [3,4,5]
    ### here the keys are the index positions
    results = {}
    total = len(input_[0])
    for no in range(total):
        results[str(no)] = []
    for item in input_:
        for no in range(len(item)):
            results[str(no)].append(item[no])
    #print results['1']
    #print results['2']
    return results

def remove_zeros(input_list):
    results = []
    for item in input_list:
        line = []
        results.append([])
        for m in item:
            if m != float(0.0):
                results[-1].extend([m])
    return results

def specificity_p(input_list, background_file, background_specificity_, order_='ascending'):
    ### takes in a list of numerical values (e.g. specificity scores for a gene) and calculate p-values based on background population
    ### background_file = a table file (e.g. background_specificity.txt)
    ### it works out the number of cell contexts. Depending on this, it extract a suitable background data to calculate p-values
    ### 'NA' will be ignored.
    no_cell_types = 0
    new_list = []
    results_p = []
    results_z = []
    for no in range(len(input_list)):
        if input_list[no] !='NA':
            no_cell_types += 1
            new_list.append(float(input_list[no]))
    if type(background_file)==str:
        counts = genomics.read_file(background_file, [0], rowname='1')
    else:
        counts = background_file
    if order_ == 'ascending':
        new_list.sort()
    elif order_== 'descending':
        new_list.sort(reverse=True)
    new_list = new_list
    list_ = set()
    for item in counts[str(no_cell_types)]:
        list_.add(item[0])
    #print len(new_list)
    background_ = extract_lines(background_specificity_, list_, na_ignore=True)
    #if no_cell_types != 111:
    #    print background_[0:2]
    background_ = sort_elements(background_)
    #if no_cell_types != 111:
    #    background_ = remove_zeros(background_)
    #    print background_[0:2]
    background_ = sort_by_position(background_)
    #if no_cell_types != 111:
    #    print background_['0']
    #    print background_['1']
    for no in range(no_cell_types):
        mean_ = np.mean(background_[str(no)])
        sd_ = np.std(background_[str(no)])
        z_ = stat.z_score(new_list[no], mean_, sd_)
        p_ = stat.p_value(z_, type='z', side='lower')


        results_p.append(p_)
        results_z.append(z_)

    return results_z, results_p



def initiate_table(input_table, initial_value=0):
    ### creates a list of colnames and an empty table instance for the given input_table
    colnames = []
    results = {}
    for gene in input_table:
        if len(colnames)==0:
            for m in input_table[gene]:
                colnames.append(m)
        else:
            break
    for gene in input_table:
        results[gene] = {}
        for col in colnames:
            results[gene][col] = initial_value
    return results

def initiate_table1(rows, cols, initial_value=0):
    results = {}
    for r in rows:
        results[r] = {}
        for c in cols:
            results[r][c] = initial_value
    return results



def identify_cell_types(input_spec, p_table, threshold_):
    ### takes in a table file for specificity scores and p-value tables (based on constant dynamics)
    if type(input_spec)==str:
        input_spec = read_table1(input_spec, del_colnames=True, numerical=False)
    if type(p_table)==str:
        p_table = read_table1(p_table, del_colnames=True, numerical=False)
    results, colnames = initiate_table(input_spec)
    for gene in input_spec:
        items = []
        for col in colnames:
            if input_spec[gene][col] != 'NA':
                value_ = float(input_spec[gene][col])
                items.append([col, value_])
        items = genomics.sort_(items, idx=1, reverse_=False)
        reached = False
        for item in items:
            if reached == True:
                break
            else:
                if p_table[gene][item[0]] !='NA':
                    if float(p_table[gene][item[0]]) < threshold_:
                        results[gene][item[0]] = 1
                    else:
                        reached = True
    return results

def add_pseudo(input_data, count_='min'):
    ### adds a pseudo-counts for data set
    ### done for each row
    ### input_data = a table text file
    ### count_ = a numerical value to add or 'min' for minimum value (except 0) 'max' for maximum value
    if type(input_data)==str:
        data_ = read_table1(input_data, del_colnames=True)
    else:
        data_ = input_data
    for gene_ in data_:
        if count_=='min':
            p_ = 999999
            for item in data_[gene_]:
                if (data_[gene_][item] < p_) and (data_[gene_][item] != float(0)):
                    p_ = data_[gene_][item]
        else:
            p_ = count_
        for item in data_[gene_]:
            data_[gene_][item] += p_
    return data_

def find_broad_peaks(p_table_file, width_file, threshold_, elbow_point=False):
    ### reads in both specificity_p_table and All_widths text files and output a table instance with significant cell types
    ### elbow_point = a boolean to indicate whether the scan should be done up to the elbow point.
    if type(p_table_file)==str:        
        p_table = read_table1(p_table_file, del_colnames=True, numerical=False)
    else:
        p_table = p_table_file
    if type(width_file)==str:
        w_table = read_table1(width_file, del_colnames=True)
    else:
        w_table = width_file
    colnames = []
    genes = set()    
    for gene in p_table:
        if len(colnames)!=0:
            genes.add(gene)
        else:
            for epi in p_table[gene]:
                colnames.append(epi)
    results = {}    
    for gene in genes:
        results[gene] = {}
        for epi in colnames:
            results[gene][epi] = 0
    for gene in w_table:
        temp = []
        temp1 = []        
        for epi in w_table[gene]:            
            temp.append([w_table[gene][epi], epi])
            if w_table[gene][epi]=='NA':
                temp1.append(0.0)
            else:
                temp1.append(w_table[gene][epi])
        temp = genomics.sort_(temp, idx=0, reverse_=True)
        temp1.sort(reverse=True)
        elbow_point_ = find_elbow(temp1)
        if elbow_point==False:
            for item in temp:
                epi = item[1]         
                if p_table[gene][epi] =='NA':
                    p_table[gene][epi] = 1.0              
                if float(p_table[gene][epi]) < threshold_:
                    results[gene][epi] = 1
                else:
                    break
        else:
            print elbow_point_
            for no in range(elbow_point_):
                item = temp[no]
                epi = item[1]         
                if p_table[gene][epi] =='NA':
                    p_table[gene][epi] = 1.0              
                if float(p_table[gene][epi]) < threshold_:
                    results[gene][epi] = 1
                else:
                    break
    return results



def prepare_fet(foreground, background, ref):
    ### take lists of fore- and back-ground sets and check membership with ref list.
    ### returns a,b,c,d
    foreground = set(foreground)
    background = set(background)
    ref = set(ref)
    a = 0
    b = 0
    for item in foreground:
        if item in ref:
            a += 1
        else:
            b += 1
    c, d = 0, 0
    for item in background:
        if item in ref:
            c += 1
        else:
            d += 1
    return a,b,c,d



def read_line(file_, col_idx, numerical=False):
    ### reads items in col_idx and return a single list
    data_ = open(file_, 'r')
    results = []
    for line in data_:
        line = line.strip().split()
        if not line[0].startswith('#'):
            if numerical==False:
                results.append(line[col_idx])
            elif numerical==True:
                results.append(float(line[col_idx]))
    return results


def mean_idx(input_list):
    ### takes a list of lists (binary) and calculate average ranks for each index.
    ### e.g. input_list = [[1,0,0,0,1],[0,1,1,1,1],[1,0,0,0,0]] --> [2, 2, 2, 2, 1]
    ### if count is 0, it returns the total number of list.
    results = []
    for no in range(len(input_list[0])):
        results.append(0)
    for no in range(len(input_list)):
        for m in range(len(input_list[no])):
            if float(input_list[no][m]) != float(0):
                results[m] += no
    for m in range(len(results)):
        results[m] = float(results[m]) / len(input_list)
    return results

def extract_genes(input_table, col_name, sort_='descending', min_threshold_=None, max_threshold_=None):
    ### takes a TABLE file and extract names of genes as defined by col_names 
    ### sort_ = 'descending' or 'ascending' to order the list by the value 
    ### min_threshold_m max_threshold_ = numerical values to ignore values if outside the range.
    input_ = read_table1(input_table, del_colnames=True, numerical=False)
    colnames = get_colnames(input_)
    results = []
    temp = []    
    if min_threshold_==None:
        min_threshold_ = -9999999999
    if max_threshold_==None:
        max_threshold_ = 9999999999        
    if type(col_name)==int:
        idx = col_name        
        col_name = colnames[idx]
    for gene in input_:        
        if (float(input_[gene][col_name]) > min_threshold_) and (float(input_[gene][col_name]) < max_threshold_):
            temp.append([gene, float(input_[gene][col_name])])
    if sort_=='descending':
        temp = genomics.sort_(temp, idx=1, reverse_=True)
    elif sort=='ascending':
        temp = genomics.sort_(temp, idx=1, referse_=False)
    for item in temp:
        results.append(item[0])
    return results

def extract_values(genes, table_):
    ### returns a list of lists for values of genes
    results = []
    if type(table_)==str:
        table_ = read_table1(table_, del_colnames=True)
    colnames = get_colnames(table_)
    for gene in genes:
        if gene in table_:
            results.append([])
            for col in colnames:
                results[-1].append(table_[gene][col])
    return results


def get_cols(genes, table_, character_='1.0'):
    ### takes a list of genes and a table instance
    ### returns a list of colnames where the value matches the character_
    results = []
    colnames = []
    for gene in table_:
        if len(colnames) == 0:
            for m in table_[gene]:
                colnames.append(m)
        else:
            break
    if type(genes)==str:
        genes = [genes]    
    for gene in genes:
        results.append([])
        if gene in table_:
            for col in colnames:
                if str(table_[gene][col]) == character_:
                    results[-1].append(col)
        else:
            results[-1].append('NA')
    return results

def extract_intersection(input_list, ref_):
    ### takes a list of lists and compare each list with ref_ and returns a list of lists of intersected items.
    results = []
    for item in input_list:        
        if item[0]=='NA':
            results.append([])
            results[-1].append('NA')
        else:
            results.append(stat.intersection(item, ref_))
    return results

def get_colnames(table_):
    results = []
    for gene in table_:
        if len(results)==0:
            for item in table_[gene]:
                results.append(item)
        else:
            break
    return results



def create_background(genes, table_):
    ### creates a list of randomly distributed background 
    results = []
    colnames = get_colnames(table_)    
    new_ = genomics.random_sample(genes)
    input_ = []
    for gene in new_:
        if gene in table_:
            input_.append([])
            for col in colnames:
                input_[-1].append(table_[gene][col])  
    return input_




def perform_analysis(input_genes, sig_table_, cor_table_, output_file, threshold_=0.0001, back_itr=10, high_cor_=None):
    ### 1. FIND CELL TYPES WHERE RANKS ARE SIGNIFICANTLY HIGHER THAN RANDOM 
    ### 2. CALCULATE DEPENDENCY (I.E. CONDITIONAL P - MARGINAL P) AND FIND ONE CELL TYPE WITH HIGHEST DEPENDENCY SCORE (ONLY CONSIDER ONES WITH > 0.1)
    ### 3. CHOOES THIS GROUP AS THE MOST INFLUENTIAL GROUP (REGULATORY) AND USE IT AS THE REFERENCE SET
    ### 4. IDENTIFY GENES WITH SIGNIFICANTLY HIGH CORRELATION WITH THIS SET COMPARED TO BACKGROUND
    ### 4. CREATE A SUMMARY TABLE 

    # 1
    results_final = {}    
    if type(sig_table_)==str:
        sig_ = read_table1(sig_table_, del_colnames=True)        
    else:
        sig_ = sig_table_
    colnames = get_colnames(sig_)    
    input_ = extract_values(input_genes, sig_)
    fore = mean_idx(input_)
    back = []
    for m in colnames:
        back.append([])
    for i in range(back_itr):
        back__ = create_background(input_genes, sig_)
        back_ = mean_idx(back__)
        for m in range(len(back_)):
            back[m].append(back_[m])    
    results = []
    for no in range(len(fore)):
        mean_ = np.mean(back[no])
        sd_ = np.std(back[no])
        z_ = stat.z_score(fore[no], mean_=mean_, sd_=sd_)
        p_ = stat.p_value(z_, side='lower')
        results.append([colnames[no], fore[no], mean_, p_])
    results = genomics.sort_(results, idx=1, reverse_=True)
    sig_groups = []
    ave_ranks = []
    for item in results:        
        if item[3] < threshold_:
            sig_groups.append(item[0])
            ave_ranks.append([item[0], item[1]])
    ave_ranks = genomics.sort_(ave_ranks, idx=1, reverse_=False)

    # 2        
    t1 = get_cols(input_genes, sig_)
    t2 = extract_intersection(t1, sig_groups)    
    cond, dep = cond_probability(t2, sig_groups, dependency_=True)    
    dep_colnames = get_colnames(dep)
    genomics.write_table1(dep, output_file+'_dep.txt')
    current_score = -99999
    current_sum = 0.0
    sig_group = ''
    for col2 in dep_colnames:
        temp = 0.0
        sum_ = 0.0
        for col1 in dep_colnames:
            if col2 != col1:
                if dep[col1][col2] > 0.1:
                    temp += 1
                    sum_ += dep[col1][col2]
        if temp > current_score:
            current_score = temp
            sig_group = col2
            current_sum = sum_
        if temp == current_score:
            if sum_ > current_sum:
                current_sum = sum_
                current_score = temp
                sig_group = col2



    print sig_group

    # 3,4   
    candidate = []    
    for no in range(len(t2)):
        item = t2[no]
        gene = input_genes[no]
        if sig_group in set(item):
            candidate.append(gene)    
    print len(candidate)
    if high_cor_ != None:
        new_candidate_ = extract_cor_genes(candidate, cor_table_, threshold_=high_cor_)
        new_candidate = set()
        for item in new_candidate_:
            for m in item:
                if m not in new_candidate:
                    new_candidate.add(m)
        candidate = list(new_candidate)
    print len(candidate)
    rescue_analysis(candidate, input_genes, cor_file=cor_table_, output_=output_file, pair_analysis_=False)

def extract_cor_genes(input_genes, cor_file, threshold_):
    ### returns pairs of genes that are highly correlated (set by threshold_)    
    cor_ = subset_table(cor_file, input_genes, input_genes)
    results = []
    for g1 in cor_:
        for g2 in cor_[g1]:
            if g1 != g2:
                if cor_[g1][g2] > threshold_:
                    results.append([g1,g2])
    return results





def perform_analysis2(input_genes, sig_table_, cor_table_, output_file, threshold_=0.0001, back_itr=10):
    ### 1. FIND CELL TYPES WHERE RANKS ARE SIGNIFICANTLY HIGHER THAN RANDOM 
    ### 2. CALCULATE DEPENDENCY (I.E. CONDITIONAL P - MARGINAL P) AND CALCULATE REGULATORY SCORE FOR EACH SIGNIFICANT CELL TYPE 

    # 1
    results_final = {}    
    if type(sig_table_)==str:
        sig_ = read_table1(sig_table_, del_colnames=True)        
    else:
        sig_ = sig_table_
    colnames = get_colnames(sig_)    
    input_ = extract_values(input_genes, sig_)
    fore = mean_idx(input_)
    back = []
    for m in colnames:
        back.append([])
    for i in range(back_itr):
        back__ = create_background(input_genes, sig_)
        back_ = mean_idx(back__)
        for m in range(len(back_)):
            back[m].append(back_[m])    
    results = []
    for no in range(len(fore)):
        mean_ = np.mean(back[no])
        sd_ = np.std(back[no])
        z_ = stat.z_score(fore[no], mean_=mean_, sd_=sd_)
        p_ = stat.p_value(z_, side='lower')
        results.append([colnames[no], fore[no], mean_, p_])
    results = genomics.sort_(results, idx=1, reverse_=True)
    sig_groups = []
    ave_ranks = []
    for item in results:        
        if item[3] < threshold_:
            sig_groups.append(item[0])
            ave_ranks.append([item[0], item[1]])
    ave_ranks = genomics.sort_(ave_ranks, idx=1, reverse_=False)
    if len(sig_groups)==0:
        print 'No highly ranked cell types are found.'
        return

    # 2        
    t1 = get_cols(input_genes, sig_)
    t2 = extract_intersection(t1, sig_groups)    
    cond, dep = cond_probability(t2, sig_groups, dependency_=True) 
    genomics.write_table1(dep, output_file+'_dep.txt')   
    dep_colnames = get_colnames(dep)
    group_scores = {}
    for col in dep_colnames:
        group_scores[col] = 0.0          
    for col2 in dep_colnames:       
            regulating = 0
            regulated = 0
            for m in dep_colnames:
                if m!=col2:
                    if dep[m][col2] > 0.1:
                        regulating += 1
            for m in dep_colnames:
                if m!=col2:
                    if dep[col2][m] > 0.1:
                        regulated += 1
            group_scores[col2] = float(regulating - regulated) / len(sig_groups)    
    print group_scores

    # 3
    final = [['#gene', 'score']]
    for no in range(len(input_genes)):
        gene = input_genes[no]
        score = 0.0
        item = t2[no]
        if len(item) != 0:
            if item[0] != 'NA':
                for m in item:
                    if group_scores[m] > 0:
                        score += group_scores[m]
        final.append([gene, score])
    genomics.write_file(final, output_file)
    

def perform_analysis3(input_genes, sig_table_, cor_table_, output_file, threshold_=0.0001, back_itr=10):
    ### 1. FIND CELL TYPES WHERE RANKS ARE SIGNIFICANTLY HIGHER THAN RANDOM 
    ### 2. CALCULATE DEPENDENCY (I.E. CONDITIONAL P - MARGINAL P) AND CALCULATE REGULATORY SCORE FOR EACH SIGNIFICANT CELL TYPE 

    # 1
    results_final = {}    
    if type(sig_table_)==str:
        sig_ = read_table1(sig_table_, del_colnames=True)        
    else:
        sig_ = sig_table_
    colnames = get_colnames(sig_)    
    input_ = extract_values(input_genes, sig_)
    fore = mean_idx(input_)
    back = []
    for m in colnames:
        back.append([])
    for i in range(back_itr):
        back__ = create_background(input_genes, sig_)
        back_ = mean_idx(back__)
        for m in range(len(back_)):
            back[m].append(back_[m])    
    results = []
    for no in range(len(fore)):
        mean_ = np.mean(back[no])
        sd_ = np.std(back[no])
        z_ = stat.z_score(fore[no], mean_=mean_, sd_=sd_)
        p_ = stat.p_value(z_, side='lower')
        results.append([colnames[no], fore[no], mean_, p_])
    results = genomics.sort_(results, idx=1, reverse_=True)
    sig_groups = []
    ave_ranks = []
    for item in results:        
        if item[3] < threshold_:
            sig_groups.append(item[0])
            ave_ranks.append([item[0], item[1]])
    ave_ranks = genomics.sort_(ave_ranks, idx=1, reverse_=False)
    if len(sig_groups)==0:
        print 'No highly ranked cell types are found.'
        return

    # 2        
    t1 = get_cols(input_genes, sig_)
    t2 = extract_intersection(t1, sig_groups)    
    cond, dep = cond_probability(t2, sig_groups, dependency_=True) 
    genomics.write_table1(dep, output_file+'_dep.txt')   
    dep_colnames = get_colnames(dep)


    # 3
    final = [['#gene', 'score']]
    for no in range(len(input_genes)):
        gene = input_genes[no]
        score = 0.0
        item = t2[no]
        if len(item) != 0:
            if item[0] != 'NA':
                for m in item:
                    if group_scores[m] > 0:
                        score += group_scores[m]
        final.append([gene, score])
    genomics.write_file(final, output_file)


def perform_analysis4(input_genes, sig_table_, cor_table_, output_file, threshold_=0.0001, threshold2_=0.1, back_itr=10):
    ### 1. FIND CELL TYPES WHERE RANKS ARE SIGNIFICANTLY HIGHER THAN RANDOM 
    ### 2. CALCULATE DEPENDENCY (I.E. CONDITIONAL P - MARGINAL P) AND FIND ONE CELL TYPE WITH HIGHEST DEPENDENCY SCORE (ONLY CONSIDER ONES WITH > 0.1)
    ### 3. CHOOES THIS GROUP AS THE MOST INFLUENTIAL GROUP (REGULATORY) AND USE IT AS THE REFERENCE SET
    ### 4. IDENTIFY GENES WITH SIGNIFICANTLY HIGH CORRELATION WITH THIS SET COMPARED TO BACKGROUND
    ### 4. CREATE A SUMMARY TABLE 

    # 1
    results_final = {}    
    if type(sig_table_)==str:
        sig_ = read_table1(sig_table_, del_colnames=True)        
    else:
        sig_ = sig_table_
    colnames = get_colnames(sig_)    
    input_ = extract_values(input_genes, sig_)
    fore = mean_idx(input_)
    back = []
    for m in colnames:
        back.append([])
    for i in range(back_itr):
        back__ = create_background(input_genes, sig_)
        back_ = mean_idx(back__)
        for m in range(len(back_)):
            back[m].append(back_[m])    
    results = []
    for no in range(len(fore)):
        mean_ = np.mean(back[no])
        sd_ = np.std(back[no])
        z_ = stat.z_score(fore[no], mean_=mean_, sd_=sd_)
        p_ = stat.p_value(z_, side='lower')
        results.append([colnames[no], fore[no], mean_, p_])
    results = genomics.sort_(results, idx=1, reverse_=True)
    sig_groups = []
    ave_ranks = []
    for item in results:        
        if item[3] < threshold_:
            sig_groups.append(item[0])
            ave_ranks.append([item[0], item[1]])
    

    # 2        
    t1 = get_cols(input_genes, sig_)
    t2 = extract_intersection(t1, sig_groups)    
    cond, dep = cond_probability(t2, sig_groups, dependency_=True)    
    dep_colnames = get_colnames(dep)
    genomics.write_table1(dep, output_file+'_dep.txt')
    current_score = 0
    sig_group = ''
    results_ = []
    for col2 in dep_colnames:
        temp = 0
        for col1 in dep_colnames:
            if col2 != col1:
                if dep[col1][col2] > threshold2_:
                    temp += 1
        idx_ = sig_groups.index(col2)
        results_.append([col2, temp, ave_ranks[idx_][1], float(temp) / ave_ranks[idx_][1]])

        temp = float(temp) / ave_ranks[idx_][1]

        if temp > current_score:
            current_score = temp
            sig_group = col2

    results_ = genomics.sort_(results_, idx=3, reverse_=True)
    print results_

    # 3,4   
    candidate = []    
    for no in range(len(t2)):
        item = t2[no]
        gene = input_genes[no]
        if sig_group in set(item):
            candidate.append(gene)    
    print len(candidate)
    rescue_analysis(candidate, input_genes, cor_file=cor_table_, output_=output_file, pair_analysis_=False)

def perform_analysis_(input_genes, h3k4me3_rank_, h3k27me3_rank_, output_file, threshold_=0.0001, threshold2_=0.1, back_itr=10):
    ### 1. FIND CELL TYPES WHERE RANKS ARE SIGNIFICANTLY HIGHER THAN RANDOM 
    ### 2. CALCULATE DEPENDENCY (I.E. CONDITIONAL P - MARGINAL P) AND FIND ONE CELL TYPE WITH HIGHEST DEPENDENCY SCORE (ONLY CONSIDER ONES WITH > 0.1)
    ### 3. CHOOES THIS GROUP AS THE MOST INFLUENTIAL GROUP (REGULATORY) AND USE IT AS THE REFERENCE SET
    ### 4. IDENTIFY GENES WITH SIGNIFICANTLY HIGH CORRELATION WITH THIS SET COMPARED TO BACKGROUND
    ### 4. CREATE A SUMMARY TABLE 

    # 1
    
    h3k4me3_rank = read_table1(h3k4me3_rank_)
    h3k27me3_rank = read_table1(h3k27me3_rank_)
    genes = input_genes
    
    
    results_final = {}    
    sig_table_ = h3k4me3_rank_
    if type(sig_table_)==str:
        sig_ = read_table1(sig_table_, del_colnames=True)        
    else:
        sig_ = sig_table_
    colnames = get_colnames(sig_)    
    input_ = extract_values(genes, sig_)
    
    fore = mean_idx(input_)
    print genes[0:10]
    print fore    
    back = []
    for m in colnames:
        back.append([])
    for i in range(back_itr):
        back__ = create_background(genes, sig_)
        back_ = mean_idx(back__)
        for m in range(len(back_)):
            back[m].append(back_[m])    
    results = []
    for no in range(len(fore)):
        mean_ = np.mean(back[no])
        sd_ = np.std(back[no])
        z_ = stat.z_score(fore[no], mean_=mean_, sd_=sd_)
        p_ = stat.p_value(z_, side='lower')
        results.append([colnames[no], fore[no], mean_, p_])
    results = genomics.sort_(results, idx=1, reverse_=True)
    sig_groups = []
    ave_ranks = []
    for item in results:        
        if item[3] < threshold_:
            sig_groups.append(item[0])
            ave_ranks.append([item[0], item[1]])
    

    # 2   
    print sig_groups     
    

    
def cond_probability(input_list, ref_, dependency_=False):
    ### takes a list of lists and calculates conditional probabilities for each of item in ref_
    ### at present, it only considers 2 variables.
    ### returns a table instance
    ### and if dependency == True, output table for dependency is output[g1][g2] --> p(g1 | g2) - p(g1)
    results = {}
    dependency = {}
    for ref in ref_:
        results[ref] = {}
        dependency[ref] = {}
        for ref1 in ref_:
            results[ref][ref1] = 1.0
            dependency[ref][ref1] = 0.0
    for ref2 in ref_:
        marg = probability(input_list, [ref2])
        for ref1 in ref_:
            if ref1 != ref2:
                joint = probability(input_list, [ref1, ref2])
                cond = joint / marg
                results[ref1][ref2] = cond
                dependency[ref1][ref2] = cond - marg
            else:
                dependency[ref1][ref2] = 1.0 - marg
    if dependency_==False:
        return results
    else:
        return results, dependency


def probability(input_list, ref_):
    ### calculates probability of having ref_ (which is a list of items)
    ### when multiple items are provided, it calculates joint probability
    total = len(input_list)
    cnt = 0
    for item in input_list:
        absence = 0
        for m in ref_:            
            if m not in set(item):
                absence = 1
        if absence == 0:
            cnt += 1
    return float(cnt) / total


def find_genes_in_cluster(input_table_, colnames, threshold_='higher', sort_='descending', ignore_zero=True):
    ### takes a table instance and identify genes in clusters that are over-(or under-) expressed.
    ### threshold_ = 'higher' (over-expressed), 'lower' (under-expressed)
    ### sort_ = 'descending' (sort them in descending order by the expression value), 'ascending'
    ### returns a list of lists
    file_ = read_table1(input_table_, del_colnames=True)
    results = []
    for no in range(len(colnames)):
        results.append([])
    for gene in file_:
        sum_ = 0.0
        for col in colnames:
            sum_ += file_[gene][col]
        ave_ = sum_ / len(colnames)
        for no in range(len(colnames)):
            if ignore_zero==True:
                if file_[gene][colnames[no]] == float(0):
                    continue
                else:
                    if threshold_=='higher':
                        if file_[gene][colnames[no]] >= ave_:
                            results[no].append([gene, float(file_[gene][colnames[no]])])
                    elif threshold_=='lower':
                        if file_[gene][colnames[no]] <= ave_:
                            results[no].append([gene, float(file_[gene][colnames[no]])])
            else:
                if threshold_=='higher':
                    if file_[gene][colnames[no]] >= ave_:
                        results[no].append([gene, float(file_[gene][colnames[no]])])
                elif threshold_=='lower':
                    if file_[gene][colnames[no]] <= ave_:
                        results[no].append([gene, float(file_[gene][colnames[no]])])
    if sort_=='descending':
        for no in range(len(results)):
            results[no] = genomics.sort_(results[no], idx=1, reverse_=True)
    elif sort_=='ascending':
        for no in range(len(results)):
            results[no] = genomics.sort_(results[no], idx=1, reverse_=False)
    return results

def get_rownames(table_):
    results = set()
    for item in table_:
        if item not in results:
            results.add(item)
    return list(results)





def calculate_rank_ratios(table1, table2, normalise_=True, use_value_=True):
    ### takes in two table files and calculate rank ratios (for gene i, (rank1/total_rank_positions1) / (rank2/total_rank_positions2))
    ### rows are genes and columns are cell types.
    ### returns a table instance.
    ### normalise_ = a boolean to indicate whether the value should be normalised by total rank position in the table.
    ### use_value_ = a boolean to indicate whether the actual value should be used, not rank positions.

    if type(table1)==str:
        table1 = read_table1(table1, del_colnames=True)
    if type(table2)==str:
        table2 = read_table1(table2, del_colnames=True)        
    colnames = get_colnames(table1)
    genes1 = get_rownames(table1)
    genes2 = get_rownames(table2)
    genes = set(genomics.intersection(genes1, genes2))
    results = {}
    for gene in genes:
        results[gene] = {}
        for col in colnames:
            results[gene][col] = 0.0
    for col in colnames:
        total1 = 0.0
        total2 = 0.0
        list1 = []
        list2 = []
        current_genes = {}
        for gene in genes:
            if (table1[gene][col] != float(0)) and (table2[gene][col] != float(0)):
                current_genes[gene] = [0, 0]
            if table1[gene][col] != float(0):
                total1 += table1[gene][col]
                list1.append([gene, table1[gene][col]])
            if table2[gene][col] != float(0):
                total2 += table2[gene][col]
                list2.append([gene, table2[gene][col]])
        list1 = genomics.sort_(list1, idx=1, reverse_=True)
        list2 = genomics.sort_(list2, idx=1, reverse_=True)
        for no in range(len(list1)):
            item = list1[no]
            gene = item[0]
            if use_value_==False:
                value1 = no+1
                if normalise_==True:
                    value1 = float(value1) / len(list1)
            elif use_value_==True:
                value1 = item[1]
                if normalise_==True:
                    value1 = float(value1) / total1
            if gene in current_genes:                
                current_genes[gene][0] = value1
        for no in range(len(list2)):
            item = list2[no]
            gene = item[0]
            if use_value_==False:
                value2 = no+1
                if normalise_==True:
                    value2 = float(value2) / len(list2)
            elif use_value_==True:
                value2 = item[1]
                if normalise_==True:
                    value2 = float(value2) / total2              
            if gene in current_genes:
                current_genes[gene][1] = value2
        for gene in current_genes:
            value = current_genes[gene][0] / current_genes[gene][1]
            results[gene][col] = value
    return results


def rank_genes(input_table_, order_='descending', null_value=0.0):
    ### rank items by values for each column 
    ### order_ = 'descending' or 'ascending'
    if type(input_table_)==str:
        table_ = read_table1(input_table_, del_colnames=True)
    else:
        table_ = input_table_
    colnames = get_colnames(table_)
    genes = get_rownames(table_)        
    results = {}
    for gene in genes:
        results[gene] = {}
        for col in colnames:
            results[gene][col] = null_value
    for col in colnames:
        temp = []
        for gene in genes:
            temp.append([gene, float(table_[gene][col])])
        if order_=='descending':
            temp = genomics.sort_(temp, idx=1, reverse_=True)
        elif order_=='ascending':
            temp = genomics.sort_(temp, idx=1, reverse_=False)        
        for no in range(len(temp)):
            item = temp[no]
            results[item[0]][col] = no+1
    return results

def rank_product_tables(table1, table2, null_value_=0.0):
    ### takes two table text files and calculate rank product for each column 
    ### only considers genes (rownames) present in the both tables
    if type(table1)==str:
        table1 = read_table1(table1, del_colnames=True)
    if type(table2)==str:
        table2 = read_table1(table2, del_colnames=True)    
    gene1 = get_rownames(table1)
    gene2 = get_rownames(table2)
    genes = stat.intersection(gene1, gene2)
    colnames = get_colnames(table1)
    results = {}
    for gene in genes:
        results[gene] = {}
        for col in colnames:
            results[gene][col] = null_value_
    for col in colnames:
        temp = []
        for gene in genes:
            temp.append([gene, table1[gene][col], table2[gene][col]])
        rp_ = rank_product(temp, id_idx=0, indexs=[1,2], order_='ascending')
        for item in rp_:
            results[item[0]][col] = item[1]
    return results


def table_operation(table1, table2, operator_='divide', null_value_=0.0, round_=4):
    ### takes two table instances and perform math operations
    ### round_ = the number of digits
    if type(table1)==str:
        table1 = read_table1(table1, del_colnames=True)
    if type(table2)==str:
        table2 = read_table1(table2, del_colnames=True)
    gene1 = get_rownames(table1)
    gene2 = get_rownames(table2)
    genes = stat.intersection(gene1, gene2)
    colnames = get_colnames(table1)
    results = {}    
    for gene in genes:
        results[gene] = {}
        for col in colnames:
            results[gene][col] = null_value_
    if operator_=='divide':
        for gene in genes:
            for col in colnames:
                results[gene][col] = round(float(table1[gene][col]) / float(table2[gene][col]), round_)
    elif operator_=='add':
        for gene in genes:
            for col in colnames:
                results[gene][col] = round(float(table1[gene][col]) + float(table2[gene][col]), round_)
    elif operator_=='subtract':
        for gene in genes:
            for col in colnames:
                results[gene][col] = round(float(table1[gene][col]) - float(table2[gene][col]), round_)
    elif operator_=='multiply':
        for gene in genes:
            for col in colnames:
                results[gene][col] = round(float(table1[gene][col]) * float(table2[gene][col]), round_) 
    return results

def single_table_operation(table1, operator_='log2', null_value_=0.0, round_=4):
    if type(table1)==str:
        table1 = read_table1(table1, del_colnames=True)
    genes = get_rownames(table1)
    colnames = get_colnames(table1)
    results = {}
    for gene in genes:
        results[gene] = {}
        for col in colnames:
            results[gene][col] = null_value_
    if operator_=='log2':
        for gene in genes:
            for col in colnames:
                results[gene][col] = round(np.log2(float(table1[gene][col])), round_)
    if operator_=='abs':
        for gene in genes:
            for col in colnames:
                results[gene][col] = np.abs((table1[gene][col]))
    if operator_=='log10':
        for gene in genes:
            for col in colnames:
                results[gene][col] = round(np.log10(float(table1[gene][col])), round_)

    return results

def convert_to_proportion(input_list):
    ### takes a list (or dictionary) of numerical values and convert them into proportions.
    if type(input_list)==list:
        sum_ = np.sum(input_list)
        for no in range(len(input_list)):
            input_list[no] = float(input_list[no]) / sum_
        
    elif type(input_list)==dict:
        sum_ = 0
        for i in input_list:
            sum_ += input_list[i]
        for i in input_list:
            input_list[i] = float(input_list[i]) / sum_
    return input_list


def sum_column(input_table, col_):
    ### takes a table instance and calculate sum of items in a designated column
    if type(input_table)==str:
        input_table = read_table1(input_table)
    sum_ = 0.0
    colnames = get_colnames(input_table)
    if type(col_)==int:
        col_ = colnames[col_]    
    for row in input_table:
        sum_ += input_table[row][col_]
    return sum_


def multiply_elements(input_list, table_):
    ### takes a list of inputs (e.g. [['gene1', value1], ['gene2',value2]...]) and a table instance
    ### it matches the gene name with rowname of the table_ and multiplies values in all columns of the gene.
    colnames = get_colnames(table_)
    for item in input_list:
        gene = item[0]
        value = float(item[1])
        if gene in table_:
            for col in colnames:
                table_[gene][col] = table_[gene][col] * value
    return table_

def convert_to_proportion_t(input_table):
    ### same as 'convert_to_proportion' except it takes a table instance
    ### it converts values for each column
    if type(input_table)==str:
        input_table = read_table1(input_table, del_colnames=True)
    colnames = get_colnames(input_table)
    rownames = get_rownames(input_table)
    for col in colnames:
        temp = []
        for row in rownames:
            temp.append(input_table[row][col])
        results = convert_to_proportion(temp)
        for no in range(len(rownames)):
            row = rownames[no]
            input_table[row][col] = results[no]
    return input_table


def row_operation(input_table, fun_='variance'):
    ### takes a table instance and perform a math operation. Returns a dictionary.
    ### It does for each row. 
    if type(input_table)==str:
        input_table = read_table1(input_table, del_colnames=True)
    results = {}
    rownames = get_rownames(input_table)
    if fun_=='variance':
        for row in rownames:        
            temp = []
            for col in input_table[row]:
                temp.append(float(input_table[row][col]))
            results[row] = np.var(temp)
    return results


def dic_to_list(input_dic, list_=False):
    ### converts a dictionary of items into a list
    results = []
    tt = input_dic.items()
    for item in tt:
        if list_==False:
            results.append([item[0], item[1]])
        else:
            results.append([item[0]])
            for m in item[1]:
                results[-1].extend([m])
    return results

    

def saturation_analysis(input_table, ref_table, random_=False):
    ### takes a rank table instance (e.g. combined_rank.txt) and a ref_table (e.g. DE_TF_table.txt)
    ### and calculate saturation for each column 
    ### For ref_table, any non-zero rownames are regarded as positive
    ### random_ = a boolean to indicate whether the random distribution should override
    ### returns a dictionary of list
    results = {}
    if type(input_table)==str:
        input_table = read_table1(input_table, del_colnames=True)
    if type(ref_table)==str:
        ref_table = read_table1(ref_table, del_colnames=True)
    rownames1 = get_rownames(input_table)
    rownames2 = get_rownames(ref_table)
    rownames = stat.intersection(rownames1, rownames2)
    colnames1 = get_colnames(input_table)
    colnames2 = get_colnames(ref_table)
    colnames = stat.intersection(colnames1, colnames2)
    total_no = len(rownames)
    for col in colnames:
        results[col] = [[]]
    for col in colnames:
        interval = total_no / 100
        ref_ = set()
        temp = []
        for gene in rownames:
            if ref_table[gene][col] != float(0):
                ref_.add(gene)
            temp.append([gene, input_table[gene][col]])
        temp = genomics.sort_(temp, idx=1, reverse_=False)
        total_ref = len(ref_)
        cnt = 0
        ll = []
        mm = 0
        for i in range(99):
            for j in range(interval):
                mm += 1
                idx = interval * i + j
                item = temp[idx]
                if item[0] in ref_:
                    cnt += 1
            if random_==False:
                ll.append(float(cnt)/total_ref)
            else:                
                ll.append((i+1)*0.01)
        ll.append(1.0)
        for i in range(len(ll)):
            results[col][0].extend([ll[i]])
    return results


def get_clusters(input_table_, low_threshold_=0.8, top_=0.05):
    ### takes a table instance and identify a set of partners with a value above the low_threshold_ and within the top proportion (top_) of the given population
    ### calculation is done for each row and generates a binary table instance
    ### It's normally useful for a correlation matrix
    if type(input_table_)==str:
        input_table_ = read_table1(input_table_, del_colnames=True)
    results = {}
    genes = get_rownames(input_table_)
    for gene in genes:
        results[gene] = {}
        for g in genes:
            results[gene][g] = 0
    for gene in genes:
        temp = []
        for item in input_table_[gene]:
            temp.append([item, input_table_[gene][item]])
        temp = genomics.sort_(temp, idx=1, reverse_=True)
        idx = int(len(temp) * top_)        
        for no in range(idx):
            if temp[no][0] != gene:
                if temp[no][1] >= low_threshold_:
                    results[gene][temp[no][0]] = 1
    return results


def sum_widths(input_file_, id_idx, value_idx):
    ### sums numerical values of designated colume sorted by ID designated by id_idx
    if type(input_file_)==str:
        input_file = genomics.read_file1(input_file_)
    results = {}
    for item in input_file_:
        gene = item[id_idx]
        if gene not in results:
            results[gene] = 0
        results[gene] += float(item[value_idx])
    outcome = []
    for gene in results:
        outcome.append([gene, results[gene]])
    return outcome

def calculate_(input_table_, operator_='median'):
    ### takes a table instance and calculates for each row
    if type(input_table_)==str:
        input_table_ = read_table1(input_table_)
    results = {}
    genes = get_rownames(input_table_)
    for gene in genes:
        temp = []
        for col in input_table_[gene]:
            temp.append(input_table_[gene][col])
        temp.sort(reverse=True)
        if operator_=='median':
            idx = len(temp) / 2
            results[gene] = temp[idx]
    return results

def mean_values(input_table_, colname, order_list, operator_='mean', cumulative_=False):
    ### takes a table instance with numerical values (e.g. rpkm values) and calculate mean values set by the order_list
    ### it calculates at every percentile 
    ### cumulative_ = a boolean to indicate whether cumulative values are to be used (True)
    if type(input_table_)==str:
        input_table_ = read_table1(input_table_)
    results = []
    rownames = get_rownames(input_table_)    
    combined_list = []    
    for item in order_list:
        if item in input_table_:
            combined_list.append(item)
    total = len(combined_list)
    interval = total / 100

    if cumulative_==False:
        for i in range(100):
            temp = []
            cnt = 0        
            for j in range(interval):
                cnt += 1
                idx = (i * interval) + j
                if idx+1 == total:
                    break
                name_ = combined_list[idx]          

                temp.append(input_table_[name_][colname])
            results.append(np.sum(temp) / cnt)
    else:
        temp = []
        cnt = 0
        for i in range(100):                 
            for j in range(interval):
                cnt += 1
                idx = (i * interval) + j
                if idx+1 == total:
                    break
                name_ = combined_list[idx]          

                temp.append(input_table_[name_][colname])
            results.append(np.sum(temp) / cnt)     


    return results


    #cnt = 0
    #for i in range(99*interval, total):
    #    cnt += 1
    #    temp = []
    #    name_ = combined_list[i]
    #    temp.append(input_table_[name_][colname])    
    #results.append(np.sum(temp) / cnt)

def identify_knn(input_table_, k_):
    ### takes a table instance (e.g. dist_eg_g.txt) representing distances between pairs of genes
    ### and identify k-nearest neighbours (Xu et al. 2015)
    ### returns a table instance with ranks of the similarity up to k_
    if type(input_table_)==str:
        input_table_ = read_table1(input_table_)
    rownames = get_rownames(input_table_)
    colnames = get_colnames(input_table_)
    results = {}
    for row in rownames:
        results[row] = {}
        for col in colnames:
            results[row][col] = len(colnames)
    for row in rownames:
        temp = []
        for col in colnames:
            temp.append([col, input_table_[row][col]])
        temp = genomics,sort_(temp, idx=1, reverse_=False)
        for i in range(k_):
            col = temp[i][0]
            results[row][col] = i+1
    return results



def construct_snn(table_input_, k_):
    ### Construct shared nearest neighbour (SNN) (Xu et al. 2015)
    if type(input_table_)==str:
        input_table_ = read_table1(input_table_)
    input_table_ = identify_knn(input_table_, k_)
    rownames = get_rownames(input_table_)
    colnames = get_colnames(input_table_)
    results = {}
    for row in rownames:
        results[row] = {}
        for col in colnames:
            results[row][col] = 0
    data_ = {}
    for row in rownames:
        data_[row] = set()
        temp = []
        for col in colnames:
            temp.append([col, input_table_[row][col]])
        temp = genomics.sort_(temp, idx=1, reverse_=False)
        for i in range(k_):
            data_[row].add(temp[i][0])
    #for row in rownames:
    #    for col in colnames:
    #        inter_ = genomics.intersection(list(data_[row], list(data_[col])))
    #        temp = []
    #        if len(inter_) != 0:
                

def identify_correlated_genes(input_table_, order_list, threshold_, no_):
    ### takes a table instance (e.g. corelation table subsetted) and creates a list of genes that are highly correlated between each other 
    results = []
    cnt = 1
    for item in order_list:
        if item in input_table_:
            no_tag=0
            if cnt==no_:
                break
            else:
                if len(results)==0:
                    results.append(item)
                else:
                    for m in results:
                        pp = input_table_[item][m]
                        if pp < threshold_:
                            no_tag=1
                    if no_tag==0:
                        results.append(item)
                        cnt += 1
    return results


def find_common_genes(input1, input2):
    ### takes outputs of rescue_analysis and find genes that are significantly highly associated in both sets
    if type(input1)==str:
        input1 = genomics.read_file1(input1)
    if type(input2)==str:
        input2 = genomics.read_file1(input2)
    results = []
    data1 = set()
    data2 = set()
    for item in input1:
        if float(item[1]) > float(0):
            if float(item[3]) < float(0.05):
                data1.add(item[0])
    for item in input2:
        if float(item[1]) > float(0):
            if float(item[3]) < float(0.05):
                data2.add(item[0])
    results = genomics.intersection(list(data1), list(data2))
    return results


def max_likelihood(input_list, ref_):
    ### take a list of lists (i.e. [[gene1, value1],[gene2,value2]...]) and reference set to identify value that can maximise the proportion of the reference set
    ### it assumes the list was pre-sorted in a ascending order
    if type(input_list)==str:
        input_list = genomics.read_file1(input_list)
    input_list = genomics.sort_(input_list, idx=1, reverse_=False)
    ref_ = set(ref_)
    total_fore = 0
    total_back = 0    
    idx = 0
    total = len(input_list)
    for item in input_list:
        if item[0] in ref_:
            total_fore += 1
        else:
            total_back += 1
    current_fore = total_fore
    current_back = total_back
    current = 0
    idx = 0
    for i in range(len(input_list)-1):
        total -= 1
        if total == 1:
            break
        else:
            gene = input_list[i][0]
            if gene in ref_:
                current_fore -= 1
            else:
                current_back -= 1
            if current_back == 0:
                break
            else:
                ratio = (float(current_fore) / total_fore) / (float(current_back) / total_back)
                ratio = float(current_fore)  / float(current_back) 
                ratio = (float(current_fore) / total_fore) - (float(current_back) / total_back)
                if ratio > current:
                    current = ratio
                    idx = i
    print len(input_list)-idx
    print input_list[idx]
    print ratio


def analysis_(input_list, ref_, ref_idx, ref_threshold, output_file, include_tf=False, type_='H3K27me3', no_seed=30):
    ### 1. GIVEN A GENE LIST RANKED BY RAW EXPRESSION VALUE
    ### 2. SELECTED TOP 30 GENES FROM THE TOP OF THE LIST (IF WITHIN THE LIST BY MEAN H3K27ME3 WIDTH, set by ref_threshold)    
    ### 3. USE THIS AS A MAGNET GENE SET AND IDENTIFY GENES THAT ARE HIGHLY CORRELATED
    ### 4. GO BACK TO THE ORIGINAL LIST AND REMOVE ONES THAT ARE NOT HIGHLY CORRELATED TO THE REFERERENCE GENE SET
    ### 5. CALCULATE (EXPRESSION / P-VALUE) FOR EACH GENE & RANK 
    if type_=='H3K4me3':
        cor_ = '/Users/woojunshim/Research/Data/broadPeaks/svd/H3K4me3_cor.txt'  
    elif type_=='H3K27me3':
        cor_ = '/Users/woojunshim/Research/Data/broadPeaks/svd/H3K27me3_cor.txt'  
    if already_input==False:
        input_list = genomics.sort_(input_list, idx=1, reverse_=True)
        ref_ = genomics.read_file1(ref_)
        ref_genes = set()
        ref_ = genomics.sort_(ref_, idx=ref_idx, reverse_=True)
        for i in range(ref_threshold):
            ref_genes.add(ref_[i][0])
        
        fore = []
        back = []
        cnt = 0           
        for line in input_list:
            if cnt < no_seed:
                if include_tf==False:
                    if line[0] in ref_genes:
                        fore.append(line[0])
                        cnt += 1
                else:
                    if (line[0] in ref_genes) or (line[0] in tf_list):
                        fore.append(line[0])
                        cnt +=1

            back.append(line[0])


    print len(fore)
    print len(back)
    genomics.write_file(fore, output_file+'_seed.txt')
    rescue_analysis(candidate_=fore, background_=back, cor_file=cor_, output_=output_file, threshold_=0.05, multiple_correction=True, pair_analysis_=False)   
    temp = genomics.read_file1(output_file)
    genes = {}
    for item in temp:
        if float(item[1]) > float(0):
            if float(item[3]) < 0.05:
                genes[item[0]] = float(item[3])
    results = []
    for item in input_list:
        gene = item[0]
        if gene in genes:
            value = item[1] / genes[gene]
            results.append([gene, value])
        else:
            results.append([gene, 0.0])
    results = genomics.sort_(results, idx=1, reverse_=True)
    genomics.write_file(results, output_file+'_.txt')


def simple_analysis(input_list, ref_list, threshold_):
    ### takes a list of genes (e.g. ordered by the expression value) and extract ones that are within the threshold_ of ref_list:
    ### threshold_ = as a numerical value (mim allowed)
    ref = set()
    for item in ref_list:
        if float(item[1]) > threshold_:
            ref.add(item[0])
    results = []
    input_list = genomics.sort_(input_list, idx=1, reverse_=True)
    for item in input_list:
        if item[0] in ref:
            results.append(item)
    return results


def add_id_col(input_, col_idx):
    ### takes a text file and add a column (ID)
    if type(input_)==str:
        input_ = genomics.read_file1(input_)
    for no in range(len(input_)):
        input_[no].insert(col_idx, 'ID_'+str(no+1))
    return input_

def extract_bed_entry(input_, coordinate):
    ### extract entries that are within the coordinate
    if type(input_)==str:
        input__ = []
        temp_ = open(input_, 'r')
        for line in temp_:   
            line = line.strip().split()         
            if line[0]==coordinate[0]:
                if (float(line[1]) > float(coordinate[1])) and (float(line[1]) < float(coordinate[2])):
                    input__.append([line[0], line[1], line[2], line[3], line[4]])
                elif (float(line[2]) > float(coordinate[1])) and (float(line[2]) < float(coordinate[2])):
                    input__.append([line[0], line[1], line[2], line[3], line[4]])
                elif (float(line[1]) < float(coordinate[1])) and (float(line[2]) > float(coordinate[2])):
                    input__.append([line[0], line[1], line[2], line[3], line[4]])
                elif (float(line[1]) > float(coordinate[1])) and (float(line[2]) < float(coordinate[2])):
                    input__.append([line[0], line[1], line[2], line[3], line[4]])
    return input__


def convert_to_bins(input_data, bins_=10, genes_=None):
    ### takes a table of widths and discretise them 
    ### ones with zero are specifally binned into 0
    if type(input_data)==str:
        input_data=read_table1(input_data)
    epis = get_colnames(input_data)
    if genes_==None:
        genes = get_rownames(input_data)
    else:
        genes = genes_
    results = {}
    for gene in genes:
        results[gene] = {}
        for col in epis:
            results[gene][col] = 0
    for col in epis:
        temp = []
        for gene in genes:
            if input_data[gene][col] != float(0):
                temp.append([gene, input_data[gene][col]])
        temp = genomics.sort_(temp,idx=1, reverse_=True)
        cutoff = len(temp)/bins_
        for i in range(bins_-1):
            for j in range(cutoff):
                idx = (i*cutoff) + j
                gene = temp[idx][0]
                value = temp[idx][1]
                results[gene][col] = bins_ - i
        for i in range((bins_-1)*cutoff, len(temp)):
            gene = temp[i][0]
            value = temp[i][1]
            results[gene][col] = 1
    return results


def tag_genes(input_, ref_, remove_=True):
    ### compared genes between input_ and ref_ and tag (or remove) ones not in the ref_file
    ref_ = set(ref_)
    results = []
    for item in input_:
        if item in ref_:
            if remove_==True:
                results.append(item)
            else:
                results.append([item, 'True'])
        else:
            if remove_==False:
                results.append([item, 'False'])
    return results

def extract_features(files, gene, colnames, normalise_=True):
    ### takes a list of strings as file names and creates a new table for a given gene
    ### only genes with features that are present in all files are considered
    ### normalise_ = a boolean to indicate whether values are to be converted to z-score
    results = [[]]
    for col in colnames:
        results[-1].extend([col])       
    for file in files:
        name_ = file.split('/')[-1]
        name = name_.split('_')[0]

        results.append([name])
        temp = read_table1(file)
        for col in colnames:
            if normalise_==True:
                pp = []
                for g in temp:
                    pp.append(float(temp[g][col]))
                    if g == gene:
                        value = float(temp[g][col])
                mean_ = np.mean(pp)
                sd_ = np.std(pp)
                z_ = stat.z_score(value, mean_, sd_)
                results[-1].extend([round(z_,4)])
            else:
                results[-1].extend([temp[gene][col]])
    return results

def convert_to_z(input_file, pc_=True):
    ### takes a table instance and convert to z-score for each gene (row) within each population group (column)
    ### pc_ = pseudo count
    if type(input_file)==str:
        input_file = read_table1(input_file)
    genes = get_rownames(input_file)
    colnames = get_colnames(input_file)
    for col in colnames:
        temp = []
        yy = []
        for gene in genes:
            if pc_==False:
                if input_file[gene][col]!= float(0):
                    temp.append([gene, input_file[gene][col]])
                    yy.append(input_file[gene][col])
            else:
                temp.append([gene, input_file[gene][col]+1])
                yy.append(input_file[gene][col])
        temp = genomics.sort_(temp, idx=1, reverse_=True)
        mean_ = np.mean(yy)
        sd_ = np.std(yy)
        for no in range(len(temp)):
            g = temp[no][0]            
            input_file[g][col] = stat.z_score(temp[no][1], mean_=mean_, sd_=sd_)
    return input_file

def get_common_genes(input_files):
    ### takes a list of files (tables) and find common genes (rows)    
    input1 = read_table1(input_files[0])
    g1 = get_rownames(input1)
    results = set(g1)
    for no in range(len(input_files)-1):        
        input1 = read_table1(input_files[no])
        input2 = read_table1(input_files[no+1])
        g1 = get_rownames(input1)
        g2 = get_rownames(input2)
        temp = genomics.intersection(g1, g2)
        results = genomics.intersection(results, temp)
    return results


def get_correlated_genes(input_genes, background_genes, cor_, r_, com_='higher'):
    ### takes a list of genes and using correlation table, identify genes that are correlated to the given gene
    ### r_ = a float to define correlation threshold (r)
    ### com_ = 'higher' or 'lower'
    ### returns a list of lists
    cor_table = subset_table(cor_, rows=background_genes, cols=background_genes)
    genes__ = get_rownames(cor_table)
    genes_ = genomics.intersection(genes__, input_genes)
    print len(genes_)
    results = []
    for g in genes_:
        results.append([g])
        for h in genes_:
            if g != h:
                if com_=='higher':
                    if cor_table[g][h] >= r_:
                        results[-1].extend([h])
                else:
                    if cor_table[g][h] <= r_:
                        results[-1].extend([h])
    print len(results)
    return results

def count_genes(input_list):
    ### takes a list of lists (or list) and counts numbers of occurrences
    ### returns a dictionary
    results = {}
    for item in input_list:
        if type(item)==list:
            for m in item:
                if m not in results:
                    results[m] = 0
                results[m] += 1
        else:
            if item not in results:
                results[item] = 0
            results[item] += 1
    return results

def cul_mad(input_genes, mad_file):
    ### takes a list of genes (e.g. all genes in input) and rank them in the order of MAD
    ### calculate cumulative proportions (i.e. MAD for a gene / sum of MADs) 
    mad_ = genomics.read_file(mad_file, [1], rowname='0')
    results = []
    total = 0.0
    for item in input_genes:
        if item in mad_:
            results.append([item, float(mad_[item][0][0])])
            total += float(mad_[item][0][0])
    for no in range(len(results)):
        results[no][1] = results[no][1] / total
    results = genomics.sort_(results, idx=1, reverse_=True)
    return results

def filtering_analysis(exp_table, feature_table, cor_table, no_seed, output_file, combine_result=False, output_seed_set=False, exp_filter=1.0, skip_seed_analysis=False):
    ### perform filtering analysis using H3K27me3 dynamics
    ### exp_table = a text file for expression table (e.g. TPM_ave.txt) 
    ### feature_table = a text file for feature table (e.g. H3K27me3_mad_table.txt)
    ### cor_table = a text file for the similarity table (e.g. H3K27me3_cor.txt)
    ### no_seed = the number of seed set genes (e.g. 20), None = all TFs with the feature, 'filter' = all TFs but unassociated ones (p<0.0001)
    ### output_file = output filename
    ### if combine_result==False, output is a table text (rows=genes, cols=cells) with binary outcomes (i.e. 1=included, 0=excluded) by the filtering
    ### if combine_result==True, output is a table text (rows=genes, cols=cells) with gene pexression values (Note. filtered out genes are converted to 0)
    ### output_seed_set = whether to write out a text file (binary table) to show seed set genes for each cell (types)
    ### exp_filter = a numerical value to define a threshold to define whether a given gene is expressed (hence kept for analysis)
    ### skip_seed_analysis = a boolean to indicate whether to skip the seed set analysis. If so, genes that have positive features are selected
    exp_ = read_table1(exp_table)
    colnames = get_colnames(exp_)  # cells (or samples)
    rownames = get_rownames(exp_)  # genes
    if skip_seed_analysis==False:
        cor_ = subset_table(cor_table, rows=rownames, cols=rownames, numerical=True)      
    result_table = {}  
    seed_table = {}
    for row in rownames:  # initiate output table
        result_table[row] = {}
        seed_table[row] = {}
        for col in colnames:
            result_table[row][col] = 0
            seed_table[row][col] = 0
    print len(result_table)

    # PERFORM ANALYSIS FOR EACH CELL (OR SAMPLE)
    for col in colnames:  
        input_genes = []  # only gene symbols
        input_ = []  # a list of gene symbols and exp values i.e. [[gene1, exp1], ..., ]
        for gene in rownames:
            if exp_[gene][col] > exp_filter:  # choose genes (expressed)
                input_genes.append(gene)
                input_.append([gene, exp_[gene][col]])            
        print 'Cell ID =', col
        print 'No. expressed genes =', len(input_genes)

        # CALCULATE CUMULATIVE MAD / SUM OF MADS FOR GENES 
        mad_list = cul_mad(input_genes, feature_table)

        # FIND INFLECTION POINT
        data_points = []
        for item in mad_list:
            data_points.append(item[1])      
        elbow_point = find_elbow(data_points)
        print 'Elbow point =', elbow_point

        if skip_seed_analysis==True:
            for i in range(elbow_point):
                gene = mad_list[i][0]                
                result_table[gene][col] = 1
            print
        else:
            # EXTRACT GENES WITH ABOVE THE ELBOW POINT    
            genes_above_elbow = []  # Genes that are above the elbow point
            tfs = []  # TFs that are above the elbow point
            for no in range(elbow_point):
                gene = mad_list[no][0]
                genes_above_elbow.append(gene)
                if gene in tf_list:            
                    tfs.append(gene)
            print 'No. TFs above the elbow point =', len(tfs)

            # INTEGRATE WITH INPUT DATA AND FIND SEED SET GENE  

            input_ = genomics.sort_(input_, idx=1, reverse_=True)
            seed_set = []  # Seed set gene
            cnt = 0
            for no in range(len(input_)):
                gene = input_[no][0]
                if gene in tfs:
                    seed_set.append(gene)
                    cnt += 1
                if no_seed != None:
                    if cnt == no_seed:
                        break
                else:
                    continue
            if no_seed == 'filter':
                back = []
                fore = {}
                for g1 in seed_set:
                    fore[g1] = []                
                    for g2 in seed_set:
                        fore[g1].append(cor_[g1][g2])
                        back.append(cor_[g1][g2])
                filtered_set = []
                for gene in fore:
                    s, p = stat.t_test(fore[gene], back)
                    if (s < 0) and (p < 0.0001):  # If the TF is significantly unassociated with other members
                        filtered_set.append(gene)
                for g in filtered_set:
                    seed_set.remove(g)
            print 'No. seed set gene =', len(seed_set)
            if output_seed_set==True:
                for s in seed_set:
                    seed_table[s][col] = 1
            
            
            # CALCULATE SIMILARITY FOR ALL GENES WITH THE SEED SET    
            # IDENTIFY GENES THAT ARE SIGNIFICANTLY POSITIVELY (BH-ADJUSTED P<0.05) TO THE SEED SET        
            results = seed_analysis(candidate_=seed_set, background_=input_genes, cor_file=cor_, output_=None, multiple_correction=True)  
            cnt = 0      
            for no in range(1, len(results)):
                if (results[no][1] > 0) and (results[no][3] < 0.05):   
                    gene = results[no][0]
                    result_table[gene][col] = 1
                    cnt += 1
            print 'No. genes that are sig. pos. to the seed set =', cnt
            print
    if combine_result==False:
        genomics.write_table1(result_table, output_file)  # Write the output table
    else:
        new_ = combine_filtering_analysis(exp_, result_table)        
        genomics.write_table1(new_, output_file)
    if output_seed_set==True:
        genomics.write_table1(seed_table, output_file+'_seed_genes.txt')


def ranking_analysis(exp_table, feature_table, cor_table, no_seed, output_file, output_seed_set=False, exp_filter=1.0):
    ### perform ranking analysis using H3K27me3 dynamics
    ### same as the filtering_analysis, except this calculate scores (i.e. log10(BH-pvalue)/exp.value) for all genes
    ### exp_table = a text file for expression table (e.g. TPM_ave.txt) 
    ### feature_table = a text file for feature table (e.g. H3K27me3_mad_table.txt)
    ### cor_table = a text file for the similarity table (e.g. H3K27me3_cor.txt)
    ### no_seed = the number of seed set genes (e.g. 20), None = all TFs with the feature, 'filter' = all TFs but unassociated ones (p<0.0001)
    ### output_file = output filename
    ### if combine_result==False, output is a table text (rows=genes, cols=cells) with binary outcomes (i.e. 1=included, 0=excluded) by the filtering
    ### if combine_result==True, output is a table text (rows=genes, cols=cells) with gene pexression values (Note. filtered out genes are converted to 0)
    ### output_seed_set = whether to write out a text file (binary table) to show seed set genes for each cell (types)
    ### exp_filter = a numerical value to define a threshold to define whether a given gene is expressed (hence kept for analysis)
    ### skip_seed_analysis = a boolean to indicate whether to skip the seed set analysis. If so, genes that have positive features are selected
    exp_ = read_table1(exp_table)
    colnames = get_colnames(exp_)  # cells (or samples)
    rownames = get_rownames(exp_)  # genes
    cor_ = subset_table(cor_table, rows=rownames, cols=rownames, numerical=True)  
    result_table = {}  
    seed_table = {}
    for row in rownames:  # initiate output table
        result_table[row] = {}
        seed_table[row] = {}
        for col in colnames:
            result_table[row][col] = 0
            seed_table[row][col] = 0

    # PERFORM ANALYSIS FOR EACH CELL (OR SAMPLE)
    for col in colnames:  
        input_genes = []  # only gene symbols
        input_ = []  # a list of gene symbols and exp values i.e. [[gene1, exp1], ..., ]
        for gene in rownames:
            if exp_[gene][col] > exp_filter:  # choose genes (expressed)
                input_genes.append(gene)
                input_.append([gene, exp_[gene][col]])            
        print 'Cell ID =', col
        print 'No. expressed genes =', len(input_genes)

        # CALCULATE CUMULATIVE MAD / SUM OF MADS FOR GENES 
        mad_list = cul_mad(input_genes, feature_table)

        # FIND INFLECTION POINT
        data_points = []
        for item in mad_list:
            data_points.append(item[1])      
        elbow_point = find_elbow(data_points)
        print 'Elbow point =', elbow_point


       
        # EXTRACT GENES WITH ABOVE THE ELBOW POINT    
        genes_above_elbow = []  # Genes that are above the elbow point
        tfs = []  # TFs that are above the elbow point
        for no in range(elbow_point):
            gene = mad_list[no][0]
            genes_above_elbow.append(gene)
            if gene in tf_list:            
                tfs.append(gene)
        print 'No. TFs above the elbow point =', len(tfs)

        # INTEGRATE WITH INPUT DATA AND FIND SEED SET GENE  

        input_ = genomics.sort_(input_, idx=1, reverse_=True)
        seed_set = []  # Seed set gene
        cnt = 0
        for no in range(len(input_)):
            gene = input_[no][0]
            if gene in tfs:
                seed_set.append(gene)
                cnt += 1
            if no_seed != None:
                if cnt == no_seed:
                    break
            else:
                continue
        if no_seed == 'filter':
            back = []
            fore = {}
            for g1 in seed_set:
                fore[g1] = []                
                for g2 in seed_set:
                    fore[g1].append(cor_[g1][g2])
                    back.append(cor_[g1][g2])
            filtered_set = []
            for gene in fore:
                s, p = stat.t_test(fore[gene], back)
                if (s < 0) and (p < 0.0001):  # If the TF is significantly unassociated with other members
                    filtered_set.append(gene)
            for g in filtered_set:
                seed_set.remove(g)
        print 'No. seed set gene =', len(seed_set)
        if output_seed_set==True:
            for s in seed_set:
                seed_table[s][col] = 1
            
            
        # CALCULATE SIMILARITY FOR ALL GENES WITH THE SEED SET    
        # IDENTIFY GENES THAT ARE SIGNIFICANTLY POSITIVELY (BH-ADJUSTED P<0.05) TO THE SEED SET        
        results = seed_analysis(candidate_=seed_set, background_=input_genes, cor_file=cor_, output_=None, multiple_correction=True)  
        cnt = 0      
        for no in range(1, len(results)):                  
            gene = results[no][0]
            value = exp_[gene][col] / results[no][3]
            result_table[gene][col] = value

    new_ = combine_filtering_analysis(exp_, result_table)
    genomics.write_table1(new_, output_file)
    if output_seed_set==True:
        genomics.write_table1(seed_table, output_file+'_seed_genes.txt')

def filtering_analysis2(exp_table, feature_table, cor_table, no_seed, output_file):
    ### IT IDENTIFIES HIGHLY CORRELATED GENES FOR EACH TF AND CALCULATE JACCARD INDEX BETWEEN TFS  
    ### perform filtering analysis using H3K27me3 dynamics
    ### exp_table = a text file for expression table (e.g. TPM_ave.txt) 
    ### feature_table = a text file for feature table (e.g. H3K27me3_mad_table.txt)
    ### cor_table = a text file for the similarity table (e.g. H3K27me3_cor.txt)
    ### no_seed = the number of seed set genes (e.g. 20)
    ### output_file = output filename
    ### output is a table text (rows=genes, cols=cells) with binary outcomes (i.e. 1=included, 0=excluded) by the filtering
    exp_ = read_table1(exp_table)
    colnames = get_colnames(exp_)  # cells (or samples)
    rownames = get_rownames(exp_)  # genes       
    result_table = {}  
    background = {}
    for row in rownames:  # initiate output table
        result_table[row] = {}             
        for col in colnames:
            result_table[row][col] = 0

    # PERFORM ANALYSIS FOR EACH CELL (OR SAMPLE)
    for col in colnames:  
        input_genes = []  # only gene symbols
        input_ = []  # a list of gene symbols and exp values i.e. [[gene1, exp1], ..., ]
        for gene in rownames:
            if exp_[gene][col] > 1.0:  # choose genes (expressed)
                input_genes.append(gene)
                input_.append([gene, exp_[gene][col]])            
        print 'Cell ID =', col
        print 'No. expressed genes =', len(input_genes)

        # CALCULATE CUMULATIVE MAD / SUM OF MADS FOR GENES 
        mad_list = cul_mad(input_genes, feature_table)

        # FIND INFLECTION POINT
        data_points = []
        for item in mad_list:
            data_points.append(item[1])      
        elbow_point = find_elbow(data_points)
        print 'Elbow point =', elbow_point

        # EXTRACT GENES WITH ABOVE THE ELBOW POINT    
        genes_above_elbow = []  # Genes that are above the elbow point
        tfs = []  # TFs that are above the elbow point
        for no in range(elbow_point):
            gene = mad_list[no][0]
            genes_above_elbow.append(gene)
            if gene in tf_list:            
                tfs.append(gene)
        print 'No. TFs above the elbow point =', len(tfs)

        # INTEGRATE WITH INPUT DATA AND FIND SEED SET GENE
        input_ = genomics.sort_(input_, idx=1, reverse_=True)
        seed_set = []  # Seed set gene
        cnt = 0
        for no in range(len(input_)):
            gene = input_[no][0]
            if gene in tfs:
                seed_set.append(gene)
                cnt += 1
            if no_seed != None:
                if cnt == no_seed:
                    break
            else:
                continue
        print 'No. seed set gene =', len(seed_set)
        print
        print '... Reading correlation matrix ...'

        # OPTION 1
        # IDENTIFY HIGHLY CORRELATED GENES FOR EACH OF SEED SET GENE, BASED ON GENES THEY REGULATE
        #cor_ = subset_table(cor_table, rows=input_genes, cols=input_genes, numerical=True)   
        #cor_genes = identify_correlated_genes1(input_genes=seed_set, table_=cor_, p_threshold_=0.01)
        #jc = {}
        #for g1 in seed_set:
        #    jc[g1] = {}
        #    for g2 in seed_set:
        #        jc[g1][g2] = jaccard_index(cor_genes[g1], cor_genes[g2])
        #genomics.write_table1(jc, output_file+'_'+col+'.txt')

        # OPTION 2
        # COLLECT SIMILARITY MEASURES DIRECTLY FROM THE SIMILIARITY MATRIX
        # AND REMOVE TFS THAT ARE UNASSOCIATED WITH OTHER MEMBERS (P<0.05, LOWER-TAIL)
        cor_ = subset_table(cor_table, rows=seed_set, cols=seed_set, numerical=True)
        genomics.write_table1(cor_, output_file+'_'+col+'.txt')


        
def jaccard_index(input1, input2):
    ### takes two lists and compute a jaccard index
    total = set()
    for item in input1:
        total.add(item)
    for item in input2:
        total.add(item)
    intersect_ = len(genomics.intersection(input1, input2))
    return float(intersect_) / len(total)


def combine_into_table(input_lists, output_file, default_value=0):
    ### takes a list of lists each of which represents a single column 
    ### e.g. [['colname1',[[g1,value1],[g2,value2],...,[g_n,value_n]]],['colname2',...],...
    ### then combine into a single table (rows = genes, columns = colnames)
    results = {}
    genes = set()
    colnames = set()
    for item in input_lists:
        colnames.add(item[0])
        for m in item[1]:
            gene = m[0]
            if gene not in genes:
                genes.add(gene)                
    for gene in genes:
        results[gene] = {}
        for col in colnames:
            results[gene][col] = default_value
    for item in input_lists:
        colname = item[0]
        for m in item[1]:
            gene = m[0]
            results[gene][colname] = m[1]
    return results


def overlap_coefficient(input1, input2):
    ### takes two sets of lists and calculate overlap coefficient (https://en.wikipedia.org/wiki/Overlap_coefficient)
    min_ = min(len(input1), len(input2))
    overlap_ = len(genomics.intersection(input1, input2))
    return float(overlap_) / min_

def combine_filtering_analysis(exp_table, filtered_table):
    ### once run the filtering analysis, we need to combine the outcome with inital expression data set
    ### output is a text file for gene table with their expression values
    ### Note. if gene names can't be found, it will regard them as discarded
    ### Note. make sure that colnames between tables do match. 
    ### For genes discarded, expression values are assigned 0
    if type(exp_table)==str:
        exp_table = read_table1(exp_table)
    if type(filtered_table)==str:
        filtered_table = read_table1(filtered_table)
    genes = get_rownames(exp_table)
    for gene in genes:
        for col in filtered_table[gene]:
            if filtered_table[gene][col] == 0:
                exp_table[gene][col] = 0.0
    return exp_table

def empirical_p(input_data, p_=0.05):
    ### takes a list of numerical values and returns a list of binary outcomes to indicate whether satisfies the threshold using (r+1)/(n+1)
    total = len(input_data)    
    r = p_ * (total+1) - 1
    results = []
    for i in input_data:
        cnt = 0
        for j in input_data:
            if j >= i:
                cnt += 1



    

def add_tissue_groups(input_table):
    ### reads in a table instance and add a column representing tissue groups (Roadmap)
    ### cell types must be rownames
    if type(input_table)==str:
        input_table = read_table1(input_table)
    for c in input_table:
        input_table[c]['group'] = tissue_groups_[c]
    return input_table


def roc_stat(input_, positives, order_='descending'):
    ### takes a list of lists (i.e. ID and score, as input_) and calculate TPR and FPR for ROC curve.
    ### positives = a list of positive IDs
    ### order_ = 'descending' to order the items in input_ in decreasing order, 'ascending' in ascending order
    ### output is a list of lists (i.e. TPR and FPR)    
    positives = set(positives)
    if order_=='descending':
        input_ = genomics.sort_(input_, idx=1, reverse_=True)
    elif order_ =='ascending':
        input_ = genomics.sort_(input_, idx=1, reverse_=False)
    total_p = len(positives)
    total_n = len(input_) - total_p
    results = []
    right = 0
    wrong = 0
    for item in input_:
        gene = item[0]
        if gene in positives:
            right += 1
        else:
            wrong += 1
        tpr = float(right) / total_p
        fpr = float(wrong) / total_n
        results.append([tpr,fpr])    
    return results

def prc_stat(input_, positives, order_='descending'):
    ### NEED NEGATIVE?
    ### takes a list of lists (i.e. ID and score, as input_) and calculate precision (TP/(TP+FP)) and recall (TP/(TP+FN)) for PRC curve.
    ### positives = a list of positive IDs
    ### order_ = 'descending' to order the items in input_ in decreasing order, 'ascending' in ascending order
    ### output is a list of lists and baseline
    positives = set(positives)
    if order_=='descending':
        input_ = genomics.sort_(input_, idx=1, reverse_=True)
    elif order_ =='ascending':
        input_ = genomics.sort_(input_, idx=1, reverse_=False)
    total_p = len(positives)
    total_n = len(input_) - total_p
    results = []
    right = 0
    wrong = 0
    fp = 0
    for item in input_:
        gene = item[0]
        if gene in positives:
            right += 1
        else:
            wrong += 1

        precision = float(right) 
        recall = float(right) / total_p
        results.append([precision, recall])
    baseline = float(total_p) / (total_p + total_n)
    return results, baseline

def extract_values(input_table, colname, members=None):
    ### extracts values of a given column in input_table
    ### if members != False, only rownames that are members (list) are extracted
    ### output is a list of lists
    if type(input_table)==str:
        input_table = read_table1(input_table)
    results = []
    for gene in input_table:
        if members==None:
            results.append([gene, float(input_table[gene][colname])])
        else:
            if gene in members:
                results.append([gene, float(input_table[gene][colname])])
    return results


def calculate_auc(y_coords):
    ### takes a list of y-coordinates and calculate AUC using trapzoidal rule
    y_ = np.array(y_coords)
    interval = 1.0 / len(y_coords)
    area = trapz(y_, dx=interval)
    return area

def count_filtered_genes(exp_table, binary_table, exp_threshold=1.0):
    ### takes expression table (original data) and count numbers of filtered genes across cells (or cell types)
    ### by comparing with a binary table (e.g. output of filtering_analysis)
    ### exp_threshold = a numerical value as threshold to define 'expressed' genes
    ### output is a list of counts
    if type(exp_table)==str:
        exp_table = read_table1(exp_table)
    if type(binary_table)==str:
        binary_table = read_table1(binary_table)
    results = []
    colnames = get_colnames(exp_table)
    genes = get_rownames(exp_table)
    for col in colnames:
        cnt = 0
        for gene in genes:
            if exp_table[gene][col] > exp_threshold:
                if binary_table[gene][col] == 0:
                    cnt += 1
        results.append(cnt)
    return results


def transform_to_croc(input_coord, mag_par=7):
    ### takes a list of lists (ROC coordinates) and transform them into coordinates for concentrated ROC
    ### mag_par = magnification parameter    
    ### https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2865862/pdf/btq140.pdf
    for no in range(len(input_coord)):
        value = float(input_coord[no][1])
        input_coord[no][1] = (1-2.71828**(-mag_par*value)) / (1-2.71828**(-mag_par))
    return input_coord

def background_roc_curve(no_item):
    ### generate a list of coordinate lists given a number of coordinate items
    results = []
    interval = float(1) / (no_item-1)
    for no in range(no_item):
        value = no * interval
        results.append([value, value])
    return results

def convert_to_rank(input_table_, rank_limit, order_='descending'):
    ### takes a table instance and convert values to ranks
    ### rank_limit = an integer where anything below that rank are kept to that limit
    ### returns a table instance
    if type(input_table_)==str:
        input_table_ = read_table1(input_table_)
    colnames = get_colnames(input_table_)
    for col in colnames:
        temp = []
        for gene in input_table_:
            temp.append([gene, input_table_[gene][col]])
        if order_=='descending':
            temp = genomics.sort_(temp, idx=1, reverse_=True)
        else:
            temp = genomics.sort_(temp, idx=1, reverse_=False)
        cnt = 1
        for item in temp:
            gene = item[0]
            if cnt > rank_limit:
                input_table_[gene][col] = rank_limit
            else:
                input_table_[gene][col] = cnt
            cnt += 1
    return input_table_

def find_potential_genes(input_list, mad_file_, members=None):
    ### takes a list of genes and exp values and extract only members
    ### then identifies elbow point and returns gene list
    ### converts values for genes below elbow to 0
    if members != None:
        members = set(members)
    input_ = []
    tfs = []
    for item in input_list:
        gene = item[0]
        if members!=None:
            if gene in members:
                input_.append(item)
                tfs.append(gene)
        else:
            input_.append(item)
            tfs.append(gene)
    input_ = genomics.sort_(input_, idx=1, reverse_=True)
    values = cul_mad(tfs, mad_file_)
    pp = []
    for item in values:
        pp.append(item[1])    
    elbow = find_elbow(pp)
    selected_ = values[:elbow]
    selected = set()
    for i in selected_:
        selected.add(i[0])
    for no in range(len(input_)):
        gene = input_[no][0]
        if gene not in selected:
            input_[no][1] = 0
    return input_

def count_positives(input_file, positives, cut_off=None, idx=1):
    ### count positives 
    if type(input_file)==str:
        input_file = genomics.read_file1(input_file)
    if type(positives)==str:
        positives = genomics.read_file_items(positives)
    positives = set(positives)
    cnt = 0
    for no in range(len(input_file)):
        item = input_file[no]
        if cut_off == None:
            if float(item[idx]) != float(0):
                if item[0] in positives:
                    cnt += 1
        else:
            if no == cut_off:
                break
            else:
                if float(item[idx]) != float(0):
                    if item[0] in positives:
                        cnt += 1
    return cnt, float(cnt)/len(positives)


def extract_go_genes(term, output_file, taxa=9606, annotation_file='gene_association_goa_ref_human'):
    import godata    
    go = godata.GO(annotation_file, 'go-basic.obo')
    t_ = go.getGenes(terms_or_term=term, evid = None, taxa = taxa, rel = None, include_more_specific = True)    
    results = []
    for item in t_:
        results.append(item)
    genomics.write_file_items(results, output_file)

def combine_into_table(files, labels):
    ### takes multiple files and create a combined table
    genes = set()
    results = {}
    temp = read_table1(files[0])
    for item in temp:
        genes.add(item)
    for gene in genes:
        results[gene] = {}
        for no in range(len(labels)):
            label = labels[no]
            results[gene][label] = 0
    for no in range(len(files)):
        file = files[no]
        label = labels[no]
        temp = read_table1(file)
        col = get_colnames(temp)[0]
        for gene in temp:    
            if gene in results:        
                results[gene][label] = temp[gene][col]
    return results

def restrict_elements(input_file, idx, cutoff, only_names=True):
    ### reads in a file and subset elements 
    ### only_names = whether only the first elements are to be returned
    if type(input_file)==str:
        input_file = genomics.read_file1(input_file)
    results = []
    for item in input_file:
        value = float(item[idx])
        if value >= cutoff:
            if only_names==True:
                results.append(item[0])
            else:
                results.append(item)
    return results

def extract_lines(input_table, prefix):
    ### takes a list of lists and extract only elements with first item starting with prefix 
    ### return a list of lists
    if type(input_table)==str:
        input_table = genomics.read_file1(input_table)
    results = []
    for item in input_table:
        if prefix in item[0]:
            results.append(item)
    return results

def combine_lists(list1, list2, idx, method='average'):
    ### takes two separate lists of lists and combine into one
    ### idx = an index number for target elements
    ### only items present in both lists are combined (item is defined by item[0])
    l1 = {}
    l2 = {}
    results = []
    for item in list1:
        if item[0] not in l1:
            l1[item[0]] = float(item[idx])
    for item in list2:
        if item[0] not in l2:
            l2[item[0]] = float(item[idx])
    g1 = get_rownames(l1)
    g2 = get_rownames(l2)
    genes = genomics.intersection(g1, g2)
    for gene in genes:
        if method=='average':
            value = (l1[gene] + l2[gene]) / 2
            results.append([gene, value])
        if method=='list':
            results.append([gene, l1[gene], l2[gene]])
    return results

def performance_analysis(file, positives, output, all_genes, order_='descending',write_file=True):
    ### takes an ranked list (e.g. [[g1, exp1],[g2,exp2]...]) and generate data for ROC curve
    temp = check_table(file, numerical=False) 
    temp = extract_rows(temp, all_genes)    
    cols = get_colnames(temp)
    col = cols[0]
    input_ = []    
    for gene in temp:
        input_.append([gene, float(temp[gene][col])])
    if order_=='descending':
        input_ = genomics.sort_(input_, idx=1, reverse_=True)
    else:
        input_ = genomics.sort_(input_, idx=1, reverse_=False)
    positives = genomics.read_file_items(positives)
    results = roc_stat(input_, positives)
    results.insert(0, ['#TPR','FPR'])
    if write_file==True:
        genomics.write_file(results, output)
    else:       
        return results



def performance_analysis1(files, positives, output, labels, all_genes, order_='descending', calculate_auc_=False):
    ### takes ranked lists (e.g. [[g1, exp1],[g2,exp2]...]) and generate data for ROC curve
    ### for multiple files
    ### it creates a table instance
    tpr = []
    fpr = []
    auc = []
    for no in range(len(files)):
        file = files[no]
        p = performance_analysis(file, positives, output, all_genes, order_=order_, write_file=False)
        tpr.append([labels[no]])
        fpr.append([labels[no]])        
        for i in range(1, len(p)):
            item = p[i][0]
            tpr[-1].extend([item])
            item = p[i][1]
            fpr[-1].extend([item])
        if calculate_auc_==True:
            y_ = calculate_auc(tpr[-1][1:])
        auc.append(y_)
    genomics.write_file(tpr, output+'_tpr.txt')
    genomics.write_file(fpr, output+'_fpr.txt')
    if calculate_auc_==True:
        genomics.write_file_items(auc, output+'_auc.txt')

def _performance_analysis(file, positives, order_='descending'):
    ### takes an ranked list (e.g. [[g1, exp1],[g2,exp2]...]) and generate data for ROC curve
    temp = check_table(file)        
    cols = get_colnames(temp)
    col = cols[0]
    input_ = []    
    for gene in temp:
        input_.append([gene, float(temp[gene][col])])
    if order_=='descending':
        input_ = genomics.sort_(input_, idx=1, reverse_=True)
    else:
        input_ = genomics.sort_(input_, idx=1, reverse_=False)    
    results = roc_stat(input_, positives)    
    return results


def performance_analysis2(input_table, positives, order_='descending', calculate_auc_=False):
    ### takes ranked lists (e.g. [[g1, exp1],[g2,exp2]...]) and generate data for ROC curve
    ### for multiple files
    ### it creates table instances and AUC
    tpr = [[]]
    fpr = [[]]   
    auc = [] 
    input_table = check_table(input_table)
    genes = get_rownames(input_table)
    cols = get_colnames(input_table)     
    for c in cols:
        tpr[-1].extend([c])
        fpr[-1].extend([c])
    for i in range(len(genes)):
        tpr.append([])
        fpr.append([])
        for n in range(len(cols)):
            tpr[-1].extend([0])
            fpr[-1].extend([0])
    for no in range(len(cols)):
        col = cols[no]
        file = {}
        for g in genes:
            file[g] = {}
            file[g]['value'] = input_table[g][col]
        p = _performance_analysis(file, positives, order_=order_)             
        for i in range(len(p)):
            item = p[i]
            tpr[i+1][no] = item[0]
            fpr[i+1][no] = item[1]            
        if calculate_auc_==True:
            temp = []
            for i in range(len(genes)):
                temp.append(tpr[i+1][no])
            y_ = calculate_auc(temp)
        auc.append([col, y_])    
    return tpr, fpr, auc


def sort_table(input_table, order_='descending'):
    ### takes a table instance and sort them in order
    ### table must be 1 column
    ### output is a list of lists
    results = []
    if type(input_table)==str:
        input_table = read_table1(input_table)
    col = get_colnames(input_table)[0]
    for gene in input_table:
        results.append([gene, input_table[gene][col]])
    if order_=='descending':
        results = genomics.sort_(results, idx=1, reverse_=True)
    else:
        results = genomics.sort_(results, idx=1, reverse_=False)
    return results

def check_table(input_table, numerical=False):
    if type(input_table)==str:
        input_table = read_table1(input_table, numerical=numerical)
    return input_table

def check_file(potential):
    if type(potential)==str:
        potential = genomics.read_file1(potential)
    return potential

def check_items(potential):
    if type(potential)==str:
        potential = genomics.read_file_items(potential)
    return potential


def remove_ff_element(input_list):
    input_list = check_file(input_list)
    input_list[0] = input_list[0][1::]
    return input_list

def identify_positive_genes(input_table, potential_members, idx=0, threshold_=1.0, qualifiers=None):
    ### to identify positive gene set
    ### input_table = exp. table
    ### potential_members = a list of potential genes
    ### threshold_ = a threshold to define expressed genes
    input_table = check_table(input_table)
    genes = get_rownames(input_table)
    results = []
    potential_members = check_items(potential_members)
    potential_members = set(potential_members)
    colnames = get_colnames(input_table)
    col = colnames[idx]
    for gene in genes:
        if gene in potential_members:
            if qualifiers==None:
                if input_table[gene][col] > threshold_:
                    results.append(gene)
            else:
                if gene in qualifiers:
                    if input_table[gene][col] > threshold_:
                        results.append(gene)
    return results

def cor_btw_tables(table1, table2, method_='spearman'):
    ### takes two table instances and calculate correlation between two tables
    ### returns a list of statistical output (i.e. rho(or r) and p-value)
    ### method_ = 'pearson' or 'spearman'
    ### Note. only colnames that match between tables are considered
    ### only genes that are present in both tables are used for calculation
    table1 = check_table(table1)
    table2 = check_table(table2)
    g1 = get_rownames(table1)
    g2 = get_rownames(table2)
    genes = genomics.intersection(g1, g2)
    c1 = get_colnames(table1)
    c2 = get_colnames(table2)
    colnames = genomics.intersection(c1, c2)
    results = [['#name','r','p-value']]
    for col in colnames:
        l1 = []
        l2 = []
        for gene in genes:
            l1.append(table1[gene][col])
            l2.append(table2[gene][col])
        if method_=='spearman':
            r, p = stat.spearman(l1, l2)
        else:
            r, p = stat.pearson(l1, l2)
        results.append([col, r, p])
    return results

def cor_btw_lists(list1, list2, method_='spearman'):
    ### takes two list instances and calculate correlation between two 
    ### returns statistical outputs (i.e. rho(or r) and p-value)
    ### method_ = 'pearson' or 'spearman'
    ### e.g. list1 = [[g1,value1],[g2,value2],...]
    ### only items that are present in both lists are considered
    result = []
    g1 = []
    g2 = []
    g1_ = {}
    g2_ = {}
    for item in list1:
        g1.append(item[0])
        g1_[item[0]] = item[1]
    for item in list2:
        g2.append(item[0])
        g2_[item[0]] = item[1]
    genes = genomics.intersection(g1, g2)    
    l1 = []
    l2 = []
    for gene in genes:        
        l1.append(g1_[gene])
        l2.append(g2_[gene])
    if method_=='spearman':
        r, p = stat.spearman(l1, l2)
    else:
        r, p = stat.pearson(l1, l2)        
    return r, p



def check_membership(input_list, members):
    ### takes a list of items and check if present in members 
    ### returns a list of binary output (0: absent, 1: present)
    members = set(members)
    results = []    
    for item in input_list:
        if item in members:
            results.append(1)            
        else:
            results.append(0)
    
    return results


def calculate_product(dic1, dic2, exp_filter=1.0, fill_missing=False):
    ### takes two dictionaries (or lists) and calculate products of those two 
    ### if lists are input, it has to [[g1, value1],[g2,value2],...] format
    ### output is a list of lists
    ### NOTE. did1 must be expression table
    all_genes = []
    min_ = 1.0
    if type(dic1)==list:
        temp = {}
        for item in dic1:
            temp[item[0]] = float(item[1])
            all_genes.append(item[0])
    dic1 = temp
    if type(dic2)==list:
        temp={}
        for item in dic2:
            temp[item[0]] = float(item[1])
            if float(item[1]) < min_:
                min_ = float(item[1])
    dic2 = temp
    if fill_missing==True:
        for g in all_genes:
            if g not in dic2:
                dic2[g] = min_
    results = []    
    for gene in all_genes:
        if dic1[gene] < exp_filter:
            value = 0.0
        else:
            if gene in dic2:
                value = dic1[gene] * dic2[gene]
            else:
                value = 0.0
        results.append([gene, value])
    return results

def product_analysis(exp_data, exp_col, ref_file, ref_col, header=True):
    ### calculate products of two inputs
    prop_ = genomics.read_file1(ref_file, cols=[0, int(ref_col)])
    exp__ = genomics.read_file1(exp_data)    
    exp_ = []
    for item in exp__:
        if len(item) > exp_col:
            exp_.append([item[0], float(item[exp_col])])    
    results = calculate_product(exp_, prop_)
    results = genomics.sort_(results, idx=1, reverse_=True)    
    if header==True:
        results.insert(0, ['\t','score'])    
    return results

def product_analysis1(exp_data, exp_col, ref_file, ref_col, pseudo_=None, header=True, exp_filter=1.0, fill_missing=False, log_conversion=False):
    ### calculate products of two inputs
    prop_ = genomics.read_file1(ref_file, cols=[0, int(ref_col)])
    exp__ = check_table(exp_data)    
    if pseudo_!=None:
        exp__ = add_pseudo(exp__, count_=pseudo_)
    exp_ = []
    for item in exp__:        
        if log_conversion==False:
            exp_.append([item, float(exp__[item][exp_col])])    
        else:
            exp_.append([item, np.log10(float(exp__[item][exp_col]))])
    results = calculate_product(exp_, prop_, exp_filter=exp_filter, fill_missing=fill_missing)
    results = genomics.sort_(results, idx=1, reverse_=True)    
    if header==True:
        results.insert(0, ['\t','score'])    
    return results

def product_analysis2(exp_data, ref_file, ref_col, pseudo_=None):
    ### TAKES A TABLE AND CALCULATE PRODUCT SCORE FOR EACH COLUMN
    ### RETURNS A TABLE
    prop_ = genomics.read_file1(ref_file, cols=[0, int(ref_col)])
    genes = {}
    results = {}
    for i in prop_:
        genes[i[0]] = float(i[1])
    exp__ = check_table(exp_data)    
    if pseudo_!=None:
        exp__ = add_pseudo(exp__, count_=pseudo_)
    for g in exp__:
        if g in genes:
            results[g] = {}
            for c in exp__[g]:                
                results[g][c] = float(exp__[g][c]) * genes[g]    
    return results

def rank_table(input_table, order_='descending', all_genes=None):
    ### TAKES A TABLE AND PUT A RANK FOR EACH GENE WITHIN A CELL TYPE (IE. COLUMN)
    input_table = check_table(input_table)
    if all_genes==None:
        genes = get_rownames(input_table)
    else:
        genes = genomics.intersect(all_genes, get_rownames(input_table))
    cols = get_colnames(input_table)
    results = {}
    for g in genes:
        results[g] = {}
        for c in cols:
            results[g][c] = 0.0
    for c in cols:
        temp = []
        cnt = 1
        for g in genes:
            temp.append([g, input_table[g][c]])
        if order_=='descending':
            temp = genomics.sort_(temp, idx=1, reverse_=True)
        else:
            temp = genomics.sort_(temp, idx=1, reverse_=False)
        for i in range(len(temp)):
            name = temp[i][0]            
            results[name][c] = cnt
            cnt += 1
    return results

def count_occurrence_table(input_table, rank_threshold=100, convert_to_proportion=True, operator_='less'):
    ### COUNT NUMBERS OF OCCURRENCE A GIVEN GENE IS WITHIN A RANK
    input_table = check_table(input_table)
    results = []    
    genes = get_rownames(input_table)
    cols = get_colnames(input_table)
    for g in genes:
        cnt = 0
        for c in cols:
            if operator_ =='less':
                if input_table[g][c] < rank_threshold:
                    cnt += 1
            elif operator_=='greater':
                if input_table[g][c] > rank_threshold:
                    cnt += 1
        if convert_to_proportion == False:
            results.append([g, cnt])
        else:            
            results.append([g, float(cnt)/len(cols)])
    return results

def rank_product_table(input_table, root_=True):
    input_table = check_table(input_table)
    results = []
    genes = get_rownames(input_table)
    cols = get_colnames(input_table)
    for g in genes:
        temp = []
        for c in cols:
            temp.append(input_table[g][c])
        value = calculate_rp(temp, root_, ave_=True)
        results.append([g, value])        
    return results

def average_rank_table(input_table):
    input_table = check_table(input_table)
    results = []
    genes = get_rownames(input_table)
    cols = get_colnames(input_table)
    for g in genes:
        temp = []
        for c in cols:
            temp.append(input_table[g][c])
        value = np.mean(temp)
        results.append([g, value])        
    return results 

def find_colnames(table_, id_, value_):
    ### finds a colname (or colnames) that a given gene (id_) has a particular value_
    ### returns a list of colname(s)
    if type(table_)==str:
        table_ = read_table1(table_)
    results = []
    if id_ in table_:
        for col in table_[id_]:
            if table_[id_][col] == value_:
                results.append(col)
    return results

def find_colnames_summary(table_, ids, value_, prop_=True):
    ### summarises counts (or proportions) of counts given a list of genes 
    ### returns a dictionary of dic[colname] = count(or prop)
    table_ = check_table(table_)
    results = {}
    for id_ in ids:
        temp = find_colnames(table_, id_, value_=value_)
        for item in temp:
            if item not in results:
                results[item] = 1
            else:
                results[item] += 1
    total = len(ids)
    if prop_==True:
        for item in results:
            results[item] = float(results[item]) / total
    return results


def cell_type_scores(input_data, ref_table, obtain_rank=False):
    ### takes a result of product analysis (input_data) and multiply with inverse width table (ref_table)
    ### returns a list of lists (e.g. [[cell_type1, sum_of_value1],...,])
    ### IT CAN ALSO GENERATE RANKED GENE LIST BY SETTING obtain_rank=True
    input_data = check_table(input_data)
    ref_table = check_table(ref_table)
    results = []
    rank = {}
    colnames = get_colnames(ref_table)
    aa = get_colnames(input_data)[0]
    for col in colnames:
        rank[col] = []
        sum_ = 0.0
        for gene in input_data:
            if gene in ref_table:
                value = input_data[gene][aa] * ref_table[gene][col]
                rank[col].append([gene, value])
                sum_ += value
        rank[col] = genomics.sort_(rank[col], idx=1, reverse_=True)
        results.append([col, sum_])
    results = genomics.sort_(results, idx=1, reverse_=True)
    if obtain_rank==False:
        return results
    else:
        return results, rank

def convert_to_num(input_list, idx):
    ### convert a variable to a corresponding numerical value
    for no in range(len(input_list)):
        input_list[no][idx] = float(input_list[no][idx])
    return input_list

def fill_gaps(input_table, ref_list, value_=0.0):
    ### takes a table instance (must be 1 column with 1 rownames) and check if all members of ref_list are present
    ### if not add these members with the designated value
    ref_list = check_items(ref_list)
    ref_list = set(ref_list)
    input_table = check_table(input_table)
    col = get_colnames(input_table)[0]
    for gene in ref_list:
        if gene not in input_table:
            input_table[gene] = {}
            input_table[gene][col] = value_
    return input_table

def is_within(point, coordinate):
    if (float(point) >= float(coordinate[0])) and (float(point) <= float(coordinate[1])):
        return True
    else:
        return False

def gene_body_size(input_data, id_idx, start, end):
    ### calculate size of the gene body given an input data (in the form in a list of lists or a text file)
    ### returns a dictionary
    if type(input_data)==str:
        input_data = genomics.read_file1(input_data)
    results = {}    
    for item in input_data:
        gene = item[id_idx]
        if gene not in results:
            results[gene] = []
        s_ = float(item[start])
        e_ = float(item[end])
        if len(results[gene])!=0:
            if s_ < results[gene][0]:
                results[gene][0] = s_
            if e_ > results[gene][1]:
                results[gene][1] = e_
        else:
            results[gene] = [s_, e_]
    for gene in results:
        size = results[gene][1] - results[gene][0]
        results[gene].extend([size])
    return results


def extract_elements(input_files, names, ids, id_idx, value_idx, log_convert=True, default_value=0.0):
    ### USEFUL FOR processing GO OUTPUTS (generated by R scirpt)
    ### extract specified elements from input files
    ### names = a list to specify colnames of the output table
    ### ids = a list of GO term ids to extract
    ### log_convert = a boolean to indicate whether the value is to be log-converted (i.e. -log10)
    ### output is a table instance
    results = {}    
    for id_ in ids:
        results[id_] = {}
        for name in names:
            results[id_][name] = default_value    
    for i in range(len(input_files)):
        input_ = genomics.read_file1(input_files[i])
        name_ = names[i]        
        for j in range(len(ids)):
            id_ = ids[j]
            for item in input_:                
                if item[id_idx] == id_:
                    if log_convert==True:
                        value_ = -np.log10(float(item[value_idx]))
                    else:
                        value_ = float(item[value_idx])             
                    results[id_][name_] = value_
    return results

def extract_coordinate(input_coor, bin_size):
    ### takes a list of start & end coordinate and convert them into the unit of the bin_size
    if (input_coor[0]=='NA') or (input_coor[1]=='NA'):
        return None
    else:
        input_coor = [int(float(input_coor[0]))/bin_size, int(float(input_coor[1]))/bin_size]
        return input_coor


def pileup1(min_table, max_table, genes, colnames, bin_size=100, range_=[-10000, 10000], normalise_=True):
    ### reads in both min & max distance tables and generate pileups for a selected set of genes (genes) within a sample or samples (colname)
    ### bin_size in bp, range_ is a list of genomic region to analyse where 0 is the TSS (in bp)
    ### output is a list. Note unit of the distance is defined by bin_size
    ### normalise_ = a boolean to indiate whether the count is normalised for the number of total peaks    
    ### Note. To represent the pile-up correctly at the centre position, each position should be added by +0.5
    ### FOR GENES
    min_ = subset_table(min_table, rows=genes, cols=colnames, numerical=False)
    max_ = subset_table(max_table, rows=genes, cols=colnames, numerical=False)
    results = {}        
    range_ = [int(range_[0])/bin_size, int(range_[1])/bin_size]
    genes = genomics.intersect(get_rownames(min_), get_rownames(max_))      
    gg = 0
    cnt = 0    
    for col in colnames: 
           
        gg += 1
        print gg
        coordinates = []
        for gene in genes:
            temp = extract_coordinate([min_[gene][col], max_[gene][col]], bin_size=bin_size)
            if temp != None:
                coordinates.append([gene, int(temp[0]), int(temp[1])])
              
        for p in range(range_[0], range_[1]+1, 1):
            if str(p) not in results:
                results[str(p)] = 0
            for item in coordinates:
                gene = coordinates[0]                
                if is_within(p, [item[1],item[2]]):
                    results[str(p)] += 1
        cnt += len(coordinates) 
        print results['0']                
    if normalise_==True:
        for item in results:
            results[item] = float(results[item]) / cnt  

    return results

def pileup2(min_table, max_table, binary_table, genes, colnames, binary_value=1, bin_size=100, range_=[-10000, 10000], normalise_=True):
    ### reads in both min & max distance tables and generate pileups for peaks (separated by binary_table)
    ### bin_size in bp, range_ is a list of genomic region to analyse where 0 is the TSS (in bp)
    ### output is a list. Note unit of the distance is defined by bin_size
    ### normalise_ = a boolean to indiate whether the count is normalised for the number of total peaks    
    ### Note. To represent the pile-up correctly at the centre position, each position should be added by +0.5
    ### FOR PEAKS
    min_ = subset_table(min_table, rows=genes, cols=colnames, numerical=False)
    max_ = subset_table(max_table, rows=genes, cols=colnames, numerical=False)
    bin_ = subset_table(binary_table, rows=genes, cols=colnames, numerical=False)
    results = {}        
    range_ = [int(range_[0])/bin_size, int(range_[1])/bin_size]
    genes = genomics.intersect(get_rownames(min_), get_rownames(max_))
    genes = genomics.intersect(genes, get_rownames(bin_))     
    ll = 0     
    for col in colnames:     
        cnt = 0  
        coordinates = []
        ll += 1
        print ll
        for gene in genes:
            temp = extract_coordinate([min_[gene][col], max_[gene][col]], bin_size=bin_size)
            if temp != None:
                if bin_[gene][col]==str(binary_value):
                    coordinates.append([gene, int(temp[0]), int(temp[1])])

        for p in range(range_[0], range_[1]+1, 1): 
            if str(p) not in results:
                results[str(p)] = 0           
            for item in coordinates:
                gene = coordinates[0]                
                if is_within(p, [item[1],item[2]]):
                    results[str(p)] += 1
        cnt += len(coordinates)       
    if normalise_==True:
        for item in results:
            results[item] = float(results[item]) / cnt  

    return results



def create_binary_table(input_table, cutoff=1.0):
    ### reads in a input table and creates a binary table (1= above the cutoff, 0= below)
    input_table = check_table(input_table)
    for gene in input_table:
        for col in input_table[gene]:
            value = input_table[gene][col]
            if value >= cutoff:
                input_table[gene][col] = 1
            else:
                input_table[gene][col] = 0
    return input_table


def combine_tables(input_tables, labels, default_value=0):
    ### reads in multiple tables and combine into a single table
    ### Note. tablets must be n * 1 (i.e. n rows but only 1 column)
    results = {}
    genes = []
    for input_ in input_tables:
        temp = check_table(input_)
        genes = genomics.union(genes, get_rownames(temp))
    for gene in genes:
        results[gene] = {}
        for label in labels:
            results[gene][label] = default_value
    for no in range(len(input_tables)):
        temp = check_table(input_tables[no])
        col = get_colnames(temp)[0]
        label = labels[no]
        for gene in genes:
            results[gene][label] = temp[gene][col]
    return results


def get_median(input_list):
    ### takes a list of numerical values and find a median value
    input_list.sort()
    return input_list[len(input_list)/2] 

def merge_files(files, labels, default_value=0):
    ### takes a simple text file (n * 2) but the first column must be common between files and merge them into a single table
    results = {}
    m = genomics.read_file1(files[0])
    for i in m:
        results[str(i[0])] = {}
        for l in labels:
            results[str(i[0])][l] = default_value
    for no in range(len(files)):
        l = labels[no]
        file_ = files[no]
        temp_ = genomics.read_file1(file_)
        temp = {}
        for i in temp_:
            temp[str(i[0])] = i[1]
        for n in temp:
            results[n][l] = temp[n]
    return results

def common_names(tables, only_intersection=True, target_='row'):
    ### get multiple tables and find common names
    ### returns a list
    if target_=='row':
        results = get_rownames(read_table1(tables[0]))    
        for n in tables:
            temp = read_table1(n)
            rows = get_rownames(temp)
            if only_intersection==False:
                results = genomics.union(results, rows)
            else:
                results = genomics.intersect(results, rows)
    elif target_=='col':
        results = get_colnames(read_table1(tables[0]))    
        for n in tables:
            temp = read_table1(n)
            cols = get_colnames(temp)
            if only_intersection==False:
                results = genomics.union(results, cols)
            else:
                results = genomics.intersect(results, cols)
    return results

def proportion_in_columns(input_table, colnames, genes, ref_value):
    ### takes a single input_table and calculate proportion of genes in each colname that have the ref_value
    ### returns a list
    iput_table = check_table(input_table)
    results = []
    for col in colnames:
        temp = []
        for g in genes:
            temp.append(input_table[g][col])
        cnt = temp.count(ref_value)
        results.append(float(cnt)/len(temp))
    return results

def read_bed(input_file):
    ### reads a text BED file and sort them by chromosome and return a dictionary of lists
    input_ = open(input_file, 'r')
    results = {}
    for line in input_:
        line = line.strip().split()
        if not line[0].startswith('#'):
            if line[0] not in results:
                results[line[0]] = []
            results[line[0]].append([int(line[1]), int(line[2]), line[3]])
    for m in results:
        results[m] = genomics.sort_(results[m], idx=0)
    return results

def check_point_overlaps(inputs, ref_dic):
    ### inputs = a list of coordinates (i.e. [chr, start, end])
    ### ref_dic = an output from read_bed function
    ### returns a list of booleans
    results = []
    for i in inputs:
        temp = check_overlap(i, ref_dic[i[0]])
        results.append(temp)
    return results

def check_point_overlap(input_, ref_):
    result = False
    point_ = int(input_[1])    
    for r in ref_:
        if result == True:
            break
        if point_ > r[2]:
            continue
        else:
            result = is_within(point_, [r[0], r[1]])
    return result

def mutual_information(input_list):
    ### takes a list of lists (e.g. [[X1, Y1],[X2, Y2] ...])
    ### X and Y classes should be numbers
    ### calculate mutual information (https://en.wikipedia.org/wiki/Mutual_information)
    result = 0
    group1 = []
    group2 = []    
    for i in input_list:
        group1.append(i[0])
        group2.append(i[1])
    g1 = set(group1)
    g2 = set(group2)
    total = len(input_list)     
    for n in g2:
        c2 = group2.count(n)
        for m in g1:
            together = 0
            c1 = group1.count(m)
            for i in input_list:
                if (i[0] == m) and (i[1] == n):
                    together += 1
            p_together = float(together) / total
            p_c1 = float(c1) / total
            p_c2 = float(c2) / total
            result += p_together * np.log10((p_together) / (p_c1 * p_c2))                       
    return result

def entropy(input_list):
    classes = set()
    for i in input_list:
        classes.add(i)
    result = 0
    total_ = len(input_list)
    for m in classes:
        cnt = 0
        for i in input_list:
            if i==m:
                cnt += 1
        p = float(cnt) / total_
        result += p * np.log10(p)
    return -result


def assign_and_check_overlaps(input_beds, labels, tss__):
    ### takes multiple input bed files to assign genes and find if the peak overlaps the TSS 
    ### creates two tables (width & TSS overlap tables)
    results_w, results_o = {}, {}
    for no in range(len(input_beds)):
        input_bed = input_beds[no]
        label = labels[no]        
        if no % 10 == 0:
            print no
        temp = main(input_bed, output_=None, tss__=tss__, max_width__=2500, dominant_=True, convert_DS=False, centre_=True, remove_ncrna_=True, only_width=False)
        for i in temp:
            if len(i) == 5:
                g = i[1]
                if np.abs(float(i[2])) < float(i[-1])/2:
                    tag = 2
                else:
                    tag = 1
                if g not in results_w:
                    results_w[g] = {}
                    for l in labels:
                        results_w[g][l] = 0.0
                results_w[g][label] = float(i[-1])
                if g not in results_o:
                    results_o[g] = {}
                    for l in labels:
                        results_o[g][l] = 0
                results_o[g][label] = tag
    return results_w, results_o

def signal_saturation(input_table, iter=100, bin_size=3):
    ### signal saturation analysis by correlation measure
    ### input_table = e.g. broad_peak counts
    results = []
    input_table = check_table(input_table)
    cols = get_colnames(input_table)
    genes = get_rownames(input_table)
    no_bin = len(cols) / bin_size
    print len(cols)
    for i in range(no_bin-1):
        results.append([])
        for m in range(iter):
            results[-1].extend([0])
    for i in range(iter):
        print i
        current, previous = [], []
        record = {}
        for g in genes:
            record[g] = 0
        order = genomics.random_sample(cols)
        for c in order[:bin_size]:
            for g in genes:
                record[g] += int(input_table[g][c])
        for g in genes:
            previous.append(record[g])
        cnt = 0
        ll = 0
        for no in range(bin_size,len(cols)):  
            name = order[no]          
            if ((no % bin_size == 0) and (no != bin_size)) or (no==len(cols)-1):
                for g in genes:
                    current.append(record[g])                              
                s, p = stat.spearman(previous, current)
                results[ll][i] = s
                ll += 1                
                previous = current
                current = []            
            for g in genes:
                record[g] += int(input_table[g][name])
            cnt += 1
    return results


def signal_saturation1(input_table, iter=100, bin_size=3, threshold=0.01):
    ### signal saturation analysis by change of the rank position
    ### input_table = e.g. broad_peak counts
    ### threshold as the percent of the whole population
    results = []
    input_table = check_table(input_table)
    cols = get_colnames(input_table)
    genes = get_rownames(input_table)
    no_bin = len(cols) / bin_size
    print len(cols)
    thre = int(len(genes) * threshold)
    for i in range(no_bin-1):
        results.append([])
        for m in range(iter):
            results[-1].extend([0])
    for i in range(iter):
        print i
        current, previous = {}, {}
        current_, previous_ = [], []
        record = {}
        for g in genes:
            record[g] = 0
        order = genomics.random_sample(cols)
        for c in order[:bin_size]:
            for g in genes:
                record[g] += int(input_table[g][c])
        for g in genes:
            previous_.append([g, record[g]])
        previous_ = genomics.sort_(previous_, idx=1, reverse_=True)
        for m in range(len(previous_)):
            g = previous_[m][0]
            previous[g] = m+1
        cnt = 0
        ll = 0
        for no in range(bin_size,len(cols)):  
            name = order[no]          
            if ((no % bin_size == 0) and (no != bin_size)) or (no==len(cols)-1):
                yy = 0
                for g in genes:
                    current_.append([g, record[g]])
                current_ = genomics.sort_(current_, idx=1, reverse_=True)
                for pp in range(len(current_)):
                    g = current_[pp][0]
                    current[g] = pp+1                
                for g in genes:
                    diff = np.abs(previous[g] - current[g])
                    if diff > thre:
                        yy += 1
                prop = float(yy) / len(genes)                
                results[ll][i] = prop
                ll += 1                
                previous = current
                current_ = [] 
                current = {}           
            for g in genes:
                record[g] += int(input_table[g][name])
            cnt += 1
    return results

def convert_cell_to_tissue(input_table, cols, ref):
    ### takes a table instance and convert designated cols (must be specified by characters) to as defined by ref (dictionary)
    ### it adds all values into the tissue group
    input_table = check_table(input_table)
    genes = get_rownames(input_table)    
    results = {}
    tissues = []
    for c in cols:
        t = ref[c]
        if t not in tissues:
            tissues.append(t)
    for g in genes:
        results[g] = {}
        for t in tissues:
            results[g][t] = 0
    for g in genes:
        for c in cols:
            t = ref[c]
            results[g][t] += input_table[g][c]
    return results

def fet_by_tissue_group(input_table, ref, p_threshold):
    ### takes an input table and calculate FET for each tissue group
    ### ref is a dictionary to link each cell name to tissue name
    ### p_threshold is p-value of FET used as a threshold of the significance
    ### output is a binary table 
    input_table = check_table(input_table)
    genes = get_rownames(input_table)
    cols = get_colnames(input_table)
    results = {}
    tissues = []
    for c in cols:
        t = ref[c]
        if t not in tissues:
            tissues.append(t)
    for g in genes:
        results[g] = {}
        for t in tissues:
            results[g][t] = 0
    for g in genes:
        for t in tissues:
            a,b,c,d = 0,0,0,0
            for c_ in cols:
                if ref[c_] == t:
                    if input_table[g][c_] == float(1):
                        a += 1
                    else:
                        b += 1
                else:
                    if input_table[g][c_] == float(1):
                        c += 1
                    else:
                        d += 1
            s, p = stat.fisher(a,b,c,d)
            if p < p_threshold:
                results[g][t] = 1
    return results

def generate_scores(exp_file, exp_c, h3k4me3_file, h3k4me3_c, ref_, ref_c, positive_file, roc_=False, order_='descending', positive_only_tf=True, write_positives=None):
    ### run analysis for (Exp, H3K4me3, Corrected)
    ### roc_ = False. Give the score table
    ### roc_ = True. give ROC table 
    groups=['Exp','H3K4me3','Corrected']
    exp_ = read_table1(exp_file)    
    h3k4me3_ = read_table1(h3k4me3_file)
    tt = genomics.read_file1(ref_)  
    g_ref = []
    for i in tt:
        g_ref.append(i[0])    
    a = []
    for g in exp_:
        if exp_[g][exp_c] > float(1):
            a.append(g)    
    genes = genomics.intersect(a, g_ref)
    genes = genomics.intersect(genes, get_rownames(h3k4me3_))
    print 'genes =', len(genes)
    if type(positive_file)==str:
        positives__ = set(genomics.read_file_items(positive_file))
        positives_ = []
        if positive_only_tf == True:
            for i in positives__:
                if i in tf_list:
                    positives_.append(i)
        else:
            positives_ = positives__
    else:
        positives_ = positive_file
    positives = extract_expressed_genes(exp_, exp_c, positives_)
    positives = genomics.intersect(positives, genes)
    print 'positives =', len(positives)
    corrected = product_analysis1(exp_, exp_c, ref_, ref_c, pseudo_=None, header=False, exp_filter=1.0)    
    ### CREATE A COMBINED TABLE FOR EXP, H3K4ME3 AND PRODUCT
    results = {}
    for g in genes:
        results[g] = {}
        for group in groups:
            results[g][group] = 0.0
        results[g]['Exp'] = exp_[g][exp_c]
        results[g]['H3K4me3'] = h3k4me3_[g][h3k4me3_c]
    for i in corrected:
        g = i[0]
        value = i[1]
        if g in genes:
            results[g]['Corrected'] = value
    if write_positives != None:
        genomics.write_file_items(positives, write_positives)
    if roc_==False:
        return results
    else:
        tpr, fpr, auc = performance_analysis2(results, positives, order_=order_, calculate_auc_=True)
        return tpr, fpr, auc, results


def generate_scores1(exp_file, exp_c, h3k4me3_file, h3k4me3_c, ref_, ref_c, positive_file, roc_=False, order_='descending', positive_only_tf=True, write_positives=None, log_conversion=False, exp_filter=1.0):
    ### run analysis for (Exp, H3K4me3, Corrected)
    ### roc_ = False. Give the score table
    ### roc_ = True. give ROC table 
    ### MODIFICATION TO ADDRESS MISSING POSITIVE GENES 
    groups=['Exp','H3K4me3','Corrected']
    exp_ = read_table1(exp_file)    
    h3k4me3_ = read_table1(h3k4me3_file)
    tt = genomics.read_file1(ref_)  
    g_ref = []
    for i in tt:
        g_ref.append(i[0])    
    a = []
    for g in exp_:
        if exp_[g][exp_c] > float(1):
            a.append(g)    
    genes = a
    for g in genes:
        if g not in h3k4me3_:
            h3k4me3_[g] = {}
            h3k4me3_[g][h3k4me3_c] = 0.0
    print 'genes =', len(genes)
    if type(positive_file)==str:
        positives__ = set(genomics.read_file_items(positive_file))
        positives_ = []
        if positive_only_tf == True:
            for i in positives__:
                if i in tf_list:
                    positives_.append(i)
        else:
            positives_ = positives__
    else:
        positives_ = positive_file
    print len(positives_)
    positives = extract_expressed_genes(exp_, exp_c, positives_)
    positives = genomics.intersect(positives, genes)
    print 'positives =', len(positives)
    corrected = product_analysis1(exp_, exp_c, ref_, ref_c, pseudo_=None, header=False, exp_filter=exp_filter, fill_missing=True, log_conversion=log_conversion)    
    ### CREATE A COMBINED TABLE FOR EXP, H3K4ME3 AND PRODUCT
    results = {}
    for g in genes:
        results[g] = {}
        for group in groups:
            results[g][group] = 0.0
        results[g]['Exp'] = exp_[g][exp_c]
        results[g]['H3K4me3'] = h3k4me3_[g][h3k4me3_c]
    for i in corrected:
        g = i[0]
        value = i[1]
        if g in genes:
            results[g]['Corrected'] = value
    if write_positives != None:
        genomics.write_file_items(positives, write_positives)
    if roc_==False:
        return results
    else:
        tpr, fpr, auc = performance_analysis2(results, positives, order_=order_, calculate_auc_=True)
        return tpr, fpr, auc, results


def extract_expressed_genes(input_table, col, ref, threshold_=1.0):
    ### extract a list of expressed genes
    input_table = check_table(input_table)
    results = []
    for g in ref:
        if g in input_table:
            if input_table[g][col] > threshold_:
                results.append(g)
    return results

def extract_samples(exp_file, anno_file, name):
    ### TO EXTRACT ONLY DESIGNATED SAMPLES
    ### USEFUL FOR A BIG DATA FILE
    temp = genomics.read_file1(anno_file)    
    id_ = []
    if type(name)==str:
        for i in temp:
            if len(i) > 2:
                if name in i[2]:
                    id_.append(i[0])
    else:
        id_ = name
    aa = open(exp_file, 'r')
    first = aa.readline()
    first = first.replace(' ', '_')
    first = first.strip().split()
    idx = []
    for i in id_:
        try:
            n = first.index(i)
            idx.append(n)
        except ValueError:
            continue
    results = []
    print 'extracting...'
    aa = open(exp_file, 'r')
    for line in aa:
        line = line.replace(' ','_')
        line = line.strip().split()        
        results.append([line[1]])
        for m in idx:
            results[-1].extend([line[m]])
    results[0].pop(0)
    results = convert_to_table(results)
    return results

def convert_to_table(input_list, remove_first_col=True):
    ### CONVERT A LIST OF LISTS TO TABLE INSTANCE
    cols = []
    rows = []
    for m in input_list[0]:
        cols.append(m)
    if remove_first_col==True:
        cols = cols[1:]
    for m in input_list[1:]:
        rows.append(m[0])
    results = {}
    for m in range(len(rows)):
        r = rows[m]
        results[r] = {}
        for n in range(len(cols)):
            c = cols[n]            
            results[r][c] = input_list[m+1][n+1]
    return results

def check_file(input_file):
    if type(input_file) == str:
        input_file = genomics.read_file1(input_file)
    return input_file


def create_go_table(input1, input2, terms, file_labels, term_col, value_col, default_value=1):
    ### TAKES OUTPUT OF GO ANALYSIS FROM THE R SCRIPT (E.G. _BP.TXT) AND CREATES A COMBINED TABLE FOR SELECTED TERMS 
    results = {}
    for i in terms:
        results[i] = {}
        for l in file_labels:
            results[i][l] = default_value
    file1 = genomics.read_file(input1, [value_col], rowname=str(term_col))
    file2 = genomics.read_file(input2, [value_col], rowname=str(term_col))
    for i in terms:
        if i in file1:
            results[i][file_labels[0]] = file1[i][0][0]
        if i in file2:
            results[i][file_labels[1]] = file2[i][0][0]
    return results

def create_table_from_lists(input_lists, labels, col_idx, default_value=0, cut_off=100):
    ### TAKES A MULTIPLE LISTS AND COMBINE INTO A TABLE INSTANCE
    ### LABELS ARE COLNAMES
    ### FIRST ELEMENT OF LIST IS ROWNAMES, THE VALUE IS SPECIFIED BY COL_IDX
    ### CUT_OFF IS THE NUMBER OF ITEMS 
    results = {}
    for q in range(len(input_lists)):
        i = input_lists[q]        
        i = check_file(i)
        col = labels[q]
        for m in range(len(i)):
            i[m][col_idx] = float(i[m][col_idx])
        i = genomics.sort_(i, idx=col_idx, reverse_=True)
        for n in range(cut_off):
            gene = i[n][0]
            value = i[n][col_idx]
            if gene not in results:
                results[gene] = {}
                for l in labels:
                    results[gene][l] = default_value
            results[gene][col] = value
    return results


def binarise_table(input_table, threshold_=1):
    input_table = check_table(input_table)
    for g in input_table:
        for c in input_table[g]:
            if input_table[g][c] > threshold_:
                input_table[g][c] = 1
            else:
                input_table[g][c] = 0
    return input_table

def discretise_table(input_table, value_ranges):
    input_table = check_table(input_table)
    results = initiate_table(input_table)
    total = len(value_ranges) 
    values = {}
    for i in range(total):
        values[i+1] = [value_ranges[i][0], value_ranges[i][1]]      
    print values

    for g in input_table:
        for c in input_table[g]:
            for m in values:
                start, end = values[m][0], values[m][1]
                if (input_table[g][c] > start) and (input_table[g][c] <= end):
                    results[g][c] = m               
    return results

def check_values_in_table(input_table, cols, value=1):
    ### IDENTIFY GENES (I.E. ROWNAMES) THAT HAVE THE SPECIFIED VALUE IN THE COLS
    results = []
    input_table = check_table(input_table)
    for g in input_table:
        tag = 0
        for c in cols:
            if input_table[g][c] != value:
                tag = 1
        if tag == 0:
            results.append(g)
    return results

def check_values_in_table1(input_table, cols, value=1):
    ### IDENTIFY GENES (I.E. ROWNAMES) THAT HAVE THE SPECIFIED VALUE IN THE COLS
    results = []
    input_table = check_table(input_table)
    colnames = get_colnames(input_table)
    for g in input_table:
        tag = 0
        for c in colnames:
            if c in cols:
                if input_table[g][c] != value:
                    tag = 1
            else:
                if input_table[g][c] == value:
                    tag = 1
        if tag == 0:
            results.append(g)
    return results

def get_counts(input_genes, ref_file, col_idx):
    results = []
    if type(input_genes)==str:
        input_genes = genomics.read_file_items(input_genes)
    ref_file = genomics.read_file(ref_file, [col_idx], rowname='0')
    for no in range(len(input_genes)):
        g = input_genes[no]
        if g in ref_file:
            value = ref_file[g][0][0]
        else:
            value = 'NA'
        results.append([g, value])
    return results


def remove_as(input_table):
    ### table as n * 2
    input_table = check_table(input_table)
    col = get_colnames(input_table)[0]
    results = {}    
    for g in input_table:
        value = input_table[g][col]
        name = g.split('-')[0]
        if name not in results:
            results[name] = {}
            results[name][col] = 0        
        if results[name][col] < value:
            results[name][col] = value
    return results


def find_significant_genes(table1, table2, threshold_=0.05, method_='mann'):
    ### TAKES TWO TABLES AND CALCULATE STATISTICS TO FIND SIGNIFICANTLY DIFFERENT GENE SETS
    results = []
    table1 = check_table(table1)
    table2 = check_table(table2)
    genes = genomics.intersect(get_rownames(table1), get_rownames(table2))
    for g in genes:
        try:
            l1, l2 =[], []
            for c1 in table1[g]:
                l1.append(table1[g][c1])
            for c2 in table2[g]:
                l2.append(table2[g][c2])
            if method_=='mann':
                s, p = stat.mann(l1, l2, alternative_='two-sided')
            if p<threshold_:
                results.append([g, p])
        except:
            continue
    return results

def convert_to_z(input_table, rows, cols, pseudo_=0):
    input_table = check_table(input_table)
    genes = get_rownames(input_table)
    colnames = get_colnames(input_table)
    for c in colnames:
        temp = []
        for g in genes:
            temp.append(input_table[g][c]+pseudo_)
        ave_ = np.mean(temp)
        sd_ = np.std(temp)
        for n in range(len(temp)):
            value = stat.z_score(temp[n], ave_, sd_)
            temp[n] = value
        for n in range(len(genes)):
            gene = genes[n]
            input_table[gene][c] = temp[n]
    if rows != None:
        input_table = subset_table(input_table, rows, cols)
    return input_table

def log_convert_table(input_table, pseudo_=0):
    input_table = check_table(input_table)
    genes = get_rownames(input_table)
    colnames = get_colnames(input_table)
    for g in genes:
        for c in colnames:
            value = np.log10(input_table[g][c]+pseudo_)
        input_table[g][c] = value
    return input_table


def find_deg_from_table(input_table, threshold_=0.05):
    input_table = check_table(input_table)
    genes = get_rownames(input_table)
    colnames = get_colnames(input_table)
    results = initiate_table(input_table)
    for g in genes:
        temp = []
        for c in colnames:
            temp.append(input_table[g][c])
        mean_ = np.mean(temp)
        print mean_
        for c in colnames:
            s,p = stat.one_t_test(input_table[g][c], mean_)
            if p < threshold_:
                results[g][c] = 1
    return results

def get_range_values_table(input_table):
    min_, max_ = 9999999, -9999999
    for g in input_table:
        for c in input_table[g]:
            if input_table[g][c] < min_:
                min_ = input_table[g][c]
            if input_table[g][c] > max_:
                max_ = input_table[g][c]
    return min_, max_

def permutation_test(input_list, no_sampling, step_by):
    ### It first needs to be sorted in an order
    ### input_list = a list of tags for genes (e.g. [T,T,F,T,T,T,..])
    ### step_by = rank positions where the test is performed
    ### no_sampling = a number of resampling to generate the distribution
    ### output is a dictioanry of proportions of positive genes in treatment and p-value (one-tailed)
    total = len(input_list)
    to_do = []
    cnt = 1
    while cnt*step_by < total:
        to_do.append(cnt*step_by)
        cnt += 1
    results = {}    
    for no in to_do:
        fore = []
        b = []
        
        for i in range(no):
            fore.append(input_list[i])
        
        f = float(fore.count('T')) / no
        for i in range(no_sampling):
            back_ = genomics.random_sample(input_list)            
            back = []
            for j in range(no):
                back.append(back_[j])       
               
            temp = float(back.count('T')) / no
            b.append(temp)        
        t = 0
        for i in b:
            if i >= f:
                t += 1
        p_ = float((t+1)) / (no_sampling+1)
        results[str(no)] = [f, p_]       
    return results


def permutation_dist(input_list, ref_, no_sampling, by_sample=True):
    ### permutation test specifically designed for finding a threshold using the discordant score
    ### input_list = a list of sorted genes (e.g. [[g1, exp1],[g2,exp2],...,])
    ### ref_ = a dictionary of latency score for genes. If a genes is not found, the lowest score will be given. 
    ### output is two lists (one for foregroup and the other for background)
    genes = []  # all genes in the order (by expression value)
    min_score = 1
    exp_ = {}  # expression value (from the observed data) for all genes
    exp__ = []  # expression value in the order (from the observed data), corresponding to the ranked genes
    temp = []
    fore, back = [], []  
    for g in ref_:        
        if ref_[g] < min_score:
            min_score = ref_[g]    
    for g in input_list:
        exp_[g[0]] = g[1]
        exp__.append(g[1])
        if g[0] not in ref_:
            la = min_score
        else:
            la = ref_[g[0]]        
        temp.append([g[0], g[1]*la])
    temp = genomics.sort_(temp, idx=1, reverse_=True)
    if by_sample==False:
        for i in temp:
            genes.append(i[0])
            fore.append(i[1])
            back.append([])    
        for n in range(no_sampling):
            temp = genomics.random_sample(exp__)        
            for i in range(len(genes)):
                g = genes[i]
                if g not in ref_:
                    la = min_score
                else:
                    la = ref_[g]
                value = temp[i] * la
                back[i].extend([value])
    else:
        for i in temp:
            genes.append(i[0])
            fore.append(i[1])
        for i in range(no_sampling):
            back.append([])   
        for n in range(no_sampling):
            temp = genomics.random_sample(exp__)        
            for i in range(len(genes)):
                g = genes[i]
                if g not in ref_:
                    la = min_score
                else:
                    la = ref_[g]
                value = temp[i] * la
                back[n].extend([value])       
    return fore, back

def permutation_test_sliding_window_percentile(f, b):
    ### perform permutation t-test at each percentile of the input_data
    ### b is a list of lists 
    total_no = len(f)
    interval = int(total_no * 0.01)
    bin_no = 0
    results = []
    while bin_no != 99:
        start = bin_no * interval
        end = (bin_no + 1) * interval
        fore = fore + f[start:end]
        back = []
        for i in range(start, end):
            back = back + b[i]
        s, p = stat.t_test(fore, back)
        results.append([s, p])
        bin_no += 1
    fore = f[bin_no * interval:]
    back = []
    for i in range(bin_no * interval, total_no):
        back = back + b[i]
    s, p = stat.t_test(fore, back)
    results.append([s, p])
    return results


def permutation_test_sliding_window(f, b, down_to=3000, find_lowest=False):
    ### perform permutation t-test at each percentile of the input_data
    ### b is a list of lists 
    ### down_to = number of gene positions to which the calculation is performed
    total_no = len(f)
    interval = 1
    bin_no = 0
    results = []
    fore, back = [f[0]], b[0]
    idx, p_ = 0, 1
    for i in range(1,down_to):
        if i%100 == 0:
            print i
        fore = fore + [f[i]]
        back = back + b[i]    
        s, p = stat.t_test(fore, back)
        results.append([s, p])
        if p < p_:
            p_ = p
            idx = i
    if find_lowest==False:
        return results
    else:
        return results, idx, p_


def threshold_using_permutation(input_, ref_, no_sampling=100, down_to=3000, threshold_=0.05):    
    ### FDR corrected p-value
    print len(input_)
    f, b = permutation_dist(input_, ref_, no_sampling=no_sampling)
    print len(f)
    results = permutation_test_sliding_window(f, b, down_to=down_to)    
    aa = []
    for m in results:
        aa.append(m[1])
    yy = stat.corrected_p(aa)    
    cnt = 0
    for i in yy:
        if i > threshold_:
            break
        else:
            cnt += 1
    return yy, cnt, i


def calculate_difference_between(f, b, sum_=True):
    ### calculate difference between f and b at each position
    ### returns a list of the differences
    results = []
    if sum_ == True:
        for i in range(len(f)):
            results.append(0)
            input_ = f[i]        
            if type(b[i])==list:
                for m in b[i]:
                    diff = input_ - m
                    results[-1] += diff
            else:
                diff = input_ = b[i]
                results[-1] += diff
    else:
        for i in range(len(f)):
            results.append([])
            input_ = f[i]        
            if type(b[i])==list:
                for m in b[i]:
                    diff = input_ - m
                    results[-1].extend([diff])
            else:
                diff = input_ = b[i]
                results[-1].extend([diff])      
    return results


def calculate_difference_between1(f, b):
    ### calculate difference between f and b at each position
    ### returns a list of the differences
    results = []
    for i in range(len(f)):
        input_ = f[i]
        results.append(0)
        if type(b[i])==list:
            for m in b[i]:
                v = input_ - m
                results[-1] += v
    return results





def calculate_permutation_stat(f, b, point_idx):
    back = []
    for i in range(point_idx):
        back = back + b[i]
    s, p = stat.t_test(f[0:point_idx], back)
    return s, p


def t_or_f(input_table, col_name, ref):
    ### convert a column of table to T or F list
    temp = chekc_table(input_table)
    input_ = []
    for g in temp:
        input_.append([g, temp[g][colnames]])
    input_ = genomics.sort_(input_, idx=1, reverse_=True)
    ref_ = genomics.read_file1(ref)
    ref_genes = set()
    for i in ref_:
        if i[1] != '0':
            ref_genes.add(i[0])
    input__ = []
    for i in input_:
        if i[0] in ref_genes:
            input__.append('T')
        else:
            input__.append('F')
    return input__

def poisson(input_, mean_):
    from scipy.stats import poisson
    return poisson.pmf(input_, mean_)

def extract_lines1(input_file, cols, values):
    ### returns a list of lists specified by cols and values
    ### cols, values are lists
    input_file = check_file(input_file)
    results = []
    for i in input_file:
        tag = 0
        for n in range(len(cols)):
            c = int(cols[n])
            v = values[n]
            if i[c] != v:
                tag = 1
        if tag == 0:
            results.append(i)
    return results

def calculate_event_rates(input_list, cell_id, overall_bp, start_=1, end_=2):
    ### calcualte cosntant rate for Poisson distribution given input data
    ### cell_id = an index where the cell names are recorded
    ### overall_bp = a bp of the total base pairs
    ### returns a dictionary
    input_list = check_file(input_list)
    results = {}
    if cell_id != None:
        for i in input_list:
            cell_ = i[cell_id]
            cells = cell_.split(',')
            for cell in cells:
                if cell not in results:
                    results[cell] = 0                
                width = int(i[end_]) - int(i[start_])
                results[cell] += width
        for m in results:
            results[cell] =  float(results[cell]) / overall_bp * 1000  # no. events in 1000 bp 
    else:
        results = 0
        for i in input_list:
            width = int(i[end_]) - int(i[start_])
            results += width
        results = float(results) / overall_bp * 1000
    return results

def hypergeom(a,b,c):
    ### calculate pmf for hypergenomic distribution
    ### a = total number of genes
    ### b = number of positive genes (e.g. H3K27me3 positive genes)
    ### c = number of extracted genes 
    ### returns a list of p-values 
    from scipy.stats import hypergeom
    t = hypergeom(a,b,c)  
    x = np.arange(0, b+1)
    return t.pmf(x)

def calculate_hypergeom(input_list, ref_, bottom_no=1000, coverage=False):
    ### takes a list of genes already sored in a descending order 
    ### ref_ = a positive gene set (e.g. H3K27me3 positive genes)
    ### bottom_no = the calculation will continue to this point, if None, will continue for all data points
    ### coverage = whether to show coverage rate of the positive genes throughout the analysis
    ### returns a list of p-values for each data point (e.g. [p-value when the first top 1 gene is extracted, ....])
    ### Note. At each point, we calculate with different number of extracted genes (c). But the p-value is taken at (b).     
    ref_ = set(ref_)
    results = []
    cnt = 0  # no. of positive genes at the current data point
    a = len(input_list)
    cov = []
    if bottom_no==None:
        bottom_no = a
    b = 0    
    for i in input_list:
        if i in ref_:
            b += 1    
    for i in range(bottom_no):
        gene = input_list[i]
        if gene in ref_:
            cnt += 1
        if coverage==True:
            cov.append(float(cnt) / b)
        hyp = hypergeom(a, b, i+1)           
        results.append(hyp[cnt])
    if coverage==False:
        return results
    else:
        return results, cov


def find_threshold(input_list, method='lowest'):
    ### returns an index of element (highest or lowest value)
    if method=='lowest':
        t = input_list.index(np.min(input_list))
    elif method=='highest':
        t = input_list.index(np.max(input_list))
    return t


def run_permutation_test(input_, ref_, no_sampling=1000, find_lowest=False, down_to=3000):
    f, b = permutation_dist(input_, ref_, no_sampling=no_sampling)
    results = calculate_difference_between(f, b)    
    results_ = []
    current = 0
    for i in results:
        results_.append(current+i)
        current = results_[-1]    
    thre = find_threshold(results_, method='highest')    
    s, p = calculate_permutation_stat(f, b, thre)
    if find_lowest==False:
        return s, p, thre
    else:
        r, idx, p_ = permutation_test_sliding_window(f, b, down_to=down_to, find_lowest=True)
        return s, p, thre, idx, p_


def run_permutation_test1(f, b, down_to=3000, log_=True):
    ### calculate p-value at each point    
    results = []
    if down_to==None:
        down_to = len(f)
    for i in range(down_to):
        temp = []
        item = b[i]
        for m in item:
            if log_==False:
                temp.append(m)
            else:
                temp.append(np.log10(m))
        mean_ = np.mean(temp)
        sd_ = np.std(temp)
        if log_==True:
            v = np.log10(f[i])
        else:
            v = f[i]
        z_ = stat.z_score(v, mean_=mean_, sd_=sd_)
        p_ = stat.p_value(z_)
        results.append(p_)
    return results

def sum_list_elements(input_list):
    ### take a list of elements and add them up
    results = 0
    for i in input_list:
        results += i
    return results

def cumsum(input_list):
    ### calculate cumulative summations of elements in the list
    current = input_list[0]
    results = [current]
    for i in range(1,len(input_list)):
        current += input_list[i]
        results.append(current)
    return results


def merge_go_results(inputs, labels):
    ### merge GO result tables 
    ### creates a table instance
    results = {}
    for n in range(len(inputs)):
        i = inputs[n]
        label = labels[n]
        temp = genomics.read_file1(i)
        for m in temp:
            t = m[2]
            if t not in results:
                results[t] = {}
                for l in labels:
                    results[t][l] = 1.0
            results[t][label] = m[3]
    return results


def normalise_counts(genes, total_samples, normalise_factor):
    ### normalise counts 
    ### returns a list of genes and values
    results = []
    for i in genes:        
        value = float(i[1]) * normalise_factor / total_samples
        results.append([i[0], value])
    return results

def calculate_entropy_table(input_table, count_table=True, relative_expression=True):
    ### input_table = count table
    input_table = check_table(input_table)
    results = []
    cols = get_colnames(input_table)
    genes_ = get_rownames(input_table)
    genes = []
    for g in genes_:
        cnt = 0
        for c in cols:
            if input_table[g][c] > 1:
                cnt += 1
        if cnt >= 3:
            genes.append(g)
    print 'Number of genes =', len(genes)

    if count_table==True:
        for g in genes:
            total = 0
            for c in cols:
                total += input_table[g][c]
            for c in cols:
                input_table[g][c] = float(input_table[g][c]) / total
    if relative_expression==True:  # Convert to relative expression
        for g in genes:
            sum_ = 0
            for c in cols:
                sum_ += input_table[g][c]
            for c in cols:
                input_table[g][c] = float(input_table[g][c]) / sum_


    for g in genes:
        temp = []
        for c in cols:
            temp.append(input_table[g][c])
        value = calculate_entropy(temp)
        results.append([g, value])
    return results


def calculate_entropy(input_list):
    result = 0
    for i in input_list:
        if i == float(0):
            value = 0
        else:
            value = i * np.log2(i)
        result += value
    if result == float(0):
        result = -result
    return -result

def grid_probabilities(x_file, y_file, genes, grids=[10,10]):
    x_file = check_table(x_file)
    y_file = check_table(y_file)
    cols = get_colnames(x_file)    
    results = {}
    for g in genes:
        results[g] = {}
        for c in cols:
            results[g][c] = 0
    x_range, y_range = [], []
    min_, max_ = 100, -1
    for g in genes:
        for c in cols:
            if x_file[g][c] < min_:
                min_ = x_file[g][c]
            if x_file[g][c] > max_:
                max_ = x_file[g][c]
    interval_ = (max_ - min_) / grids[0]
    x_range.append([min_, min_+interval_])
    for i in range(1, grids[0]):
        start_ = min_ * i
        end_ = start_ + interval_
        x_range.append([start_, end_])
    min_, max_ = 100, -1
    for g in genes:
        for c in cols:
            if y_file[g][c] < min_:
                min_ = y_file[g][c]
            if y_file[g][c] > max_:
                max_ = y_file[g][c]
    interval_ = (max_ - min_) / grids[1]
    x_range.append([min_, min_+interval_])
    for i in range(1, grids[1]):
        start_ = min_ * i
        end_ = start_ + interval_
        y_range.append([start_, end_])
    total_grids = len(x_range) * len(y_range)
    

def calculate_correlation(table1, table2, method='spearman'):
    ### takes a pair of table instances and calculate correlations between genes
    ### method = 'spearman', 'pearson'
    table1 = check_table(table1)
    table2 = check_table(table2)
    genes = genomics.intersection(get_rownames(table1), get_rownames(table2))
    cols = genomics.intersection(get_colnames(table1), get_colnames(table2))
    results = []
    for g in genes:
        t1, t2 = [], []
        for c in cols:
            t1.append(table1[g][c])
            t2.append(table2[g][c])
        if method=='spearman':
            s, p = stat.spearman(t1, t2)
        elif method=='pearson':
            s, p = stat.pearson(t1, t2)
        results.append([g, s, p])
    return results


def extend_domains(input_, unit=1000):
    ### takes a bed file and extend to the nearest unit point
    ### need to run before the analysis
    input_ = check_file(input_)
    results = []
    for i in input_:
        start = (int(i[1]) / unit) + 1
        while start + unit < int(i[2]):
            results.append([i[0], start, start+unit])
            if len(i) > 3:
                for m in range(3, len(i)):
                    results[-1].extend([i[m]])
            start = start + unit
        end = (int(i[2]) / unit) + unit
        results.append([i[0], start, end])
    return results

def bin_bed_file(input_file, bin_size=100, value=None):
    ### takes an input bed file and segment them into bed intervals defined by bin_size
    ### values for the given interval is the maximum value
    ### intervals with value of 0 is ignored
    input_ = open(input_file, 'r')
    print 'read done...'
    results = {}
    for i in input_:
        i = i.strip().split()
        if value==None:
            value = int(i[3])
        else:
            value = 1
        chr_ = i[0]
        if value == 0:
            continue
        else:
            if chr_ not in results:
                results[chr_] = {}
            start = ((int(i[1]) / bin_size) * bin_size) + 1
            end = (int(i[2]) / bin_size) * bin_size
            if start not in results[chr_]:
                results[chr_][start] = value
            for m in range(start, end+bin_size, bin_size):
                if m not in results[chr_]:
                    results[chr_][m] = value
                else:
                    if value > results[chr_][m]:
                        results[chr_][m] = value
    output_ = []
    print 'writing..'
    for i in results:
        for j in results[i]:
            output_.append([i, j, results[i][j]])
    return output_


def bin_bed(input_file, bin_size=100):
    ### SIMPLY SEGREGATE GIVEN BED FILES INTO DESIGNATED BINS 
    input_ = open(input_file, 'r')    
    results = {}
    for i in input_:
        i = i.strip().split()
        chr_ = i[0]
        if chr_ not in results:
            results[chr_] = []
        start = ((int(i[1]) / bin_size) * bin_size) + 1
        end = (int(i[2]) / bin_size) * bin_size
        for m in range(start, end+bin_size, bin_size):
            results[chr_].append(m)
    return results


def generate_binary_bootstrapping(n, p, iter_=1000):
    ### generates probability of observing a binary outcome with n observations and p sample probability
    results = []
    for m in range(iter_):
        cnt = 0
        for i in range(n):            
            number = random.uniform(0, 1)
            if number <= p:
                cnt += 1
        results.append(float(cnt)/n)
    return results

def calculate_overall_specificity(positives, ref_table, expected=0.12096884274):
    ### (OVERALL) CELL-TYPE SPECIFICITY = OBSERVED DISSIMILARITY / EXPECTED BACKGROUND DISSIMILARITY
    ### LOWER THE OUTCOME, MORE SPECIFIC
    ref_table = check_table(ref_table)
    f_count, f_sum = 0, 0.0
    for i in range(len(positives)):
        for j in range(len(positives)):
            if i == j:
                continue
            else:
                a = positives[i]
                b = positives[j]                
                f_sum += float(ref_table[a][b])
                f_count += 1
    return (f_sum / f_count) / expected

def create_latency_table(filenames):
    ### STREAMLINING 1. ASSIGN PEAKS TO THE CLOEST TSS, 2. IDENTIFY THE ELBOW POINT, 3. IDENTIFY GENES WITH THE BROAD DOMAIN 
    ### 4. ITERATE ACROSS ALL FILES, 5. FINALLY CREATE A LATENCY SCORE TABLE 
    results = {}
    for file in filenames:
        try:
            temp = main(file, output_=None, max_width__=2500, tss__='/Users/woojunshim/Research/Data/hg19_TSS_.txt', dominant_=True, convert_DS=False, centre_=True, remove_ncrna_=True, only_width=True)
            print temp
        except:
            continue

def create_flat_bed(files, names, bin_size=100):
    ### READS IN MULTIPLE BED FILES AND CREATES A FLAT BED FILE WITH A DESIGNATED BIN SIZES
    ### files and names are lists of strings
    results = {}
    cnt = 0
    print 'Total number of files =', len(files)
    for i in range(len(files)):
        cnt += 1
        file = files[i]
        name = names[i]
        print cnt, name
        temp = bin_bed(file, bin_size)
        for chr_ in temp:
            if chr_ not in results:
                results[chr_] = {}
            for m in temp[chr_]:
                if m not in results[chr_]:
                    results[chr_][m] = []
                results[chr_][m].append(name)
    output_ = []
    print 'merging...'
    for chr_ in results:
        for m in results[chr_]:
            output_.append([chr_, m, int(m)+bin_size-1])
            conca = ''
            for l in results[chr_][m]:
                conca += l+';'
            output_[-1].extend([conca])
    return output_


def calculate_cell_type_correlation(filename, method='spearman'):
    ### READS IN A BED FILE (WITH THE FOURTH COLUMN CELL-TYPES SEPARATED BY ';') - FLAT BED FILE (CAN BE GENERATED BY 'create_flat_bed' METHOD) 
    ### AND CALCULATE GENOME-WIDE CORRELATION BETWEEN PAIRS OF CELL-TYPES 
    ### CURRENTLY ONLY DEALS WITH BINARY VALUES 
    ### RETURNS A TABLE INSTANCE
    ref = {}
    whole_list, whole_cells = [], []
    results = {}
    p_values = {}
    temp = open(filename, 'r')
    for i in temp:
        i = i.strip().split()
        chr_, start = i[0], i[1]
        id_ = chr_+'_'+start
        cells = i[3].split(';')[:-1]
        for c in cells:
            if c not in ref:
                ref[c] = set()
                whole_cells.append(c)
            if id_ not in ref[c]:
                ref[c].add(id_)            
        whole_list.append(id_)
    print 'finished reading file.'
    binary = {}
    for c in whole_cells:
        binary[c] = []
        for m in whole_list:
            if m in ref[c]:
                binary[c].append(1)
            else:
                binary[c].append(0)
    for c1 in whole_cells:
        results[c1], p_values[c1] = {}, {}
        for c2 in whole_cells:
            if method == 'spearman':
                r, p = stat.spearman(binary[c1], binary[c2])
                results[c1][c2] = r
                p_values[c1][c2] = p
    return results, p_values

def calculate_cell_type_correlation1(filename, cells, method='spearman'):
    ### READS IN A BED FILE (WITH THE FOURTH COLUMN CELL-TYPES SEPARATED BY ';') - FLAT BED FILE (CAN BE GENERATED BY 'create_flat_bed' METHOD) 
    ### AND CALCULATE GENOME-WIDE CORRELATION BETWEEN PAIRS OF CELL-TYPES 
    ### CURRENTLY ONLY DEALS WITH BINARY VALUES 
    ### RETURNS A TABLE INSTANCE
    ### CELLS = A SET OF ALL CELL-TYPES
    binary = {}    
    results = {}
    p_values = {}
    for c in cells:
        binary[c] = []
    temp = open(filename, 'r')
    for i in temp:
        i = i.strip().split()        
        cs = set(i[3].split(';')[:-1])
        for c in cells:
            if c in cs:
                binary[c].append(1)
            else:
                binary[c].append(0)
    print 'finished reading file.'
    total = len(cells) * len(cells)
    cnt = 0
    for c1 in cells:
        results[c1], p_values[c1] = {}, {}
        for c2 in cells:
            cnt += 1
            if method == 'spearman':
                r, p = stat.spearman(binary[c1], binary[c2])
                results[c1][c2] = r
                p_values[c1][c2] = p
            if cnt % 10 == 0:
                print '.'
    return results, p_values

def calculate_cell_type_correlation2(filename, cells):
    ### READS IN A BED FILE (WITH THE FOURTH COLUMN CELL-TYPES SEPARATED BY ';') - FLAT BED FILE (CAN BE GENERATED BY 'create_flat_bed' METHOD) 
    ### AND CALCULATE GENOME-WIDE CORRELATION BETWEEN PAIRS OF CELL-TYPES 
    ### CURRENTLY ONLY DEALS WITH BINARY VALUES 
    ### RETURNS A TABLE INSTANCE
    ### CELLS = A SET OF ALL CELL-TYPES
    binary = {}    
    results = {}    
    for c in cells:
        binary[c] = []
    temp = open(filename, 'r')
    for i in temp:
        i = i.strip().split()        
        cs = set(i[3].split(';')[:-1])
        for c in cells:
            if c in cs:
                binary[c].append(1)
            else:
                binary[c].append(0)
    print 'finished reading file.'
    total = len(binary[cells[0]])    
    for c1 in cells:
        results[c1] = {}
        for c2 in cells:
            cnt = 0            
            for i in range(total):
                if binary[c1][i] == binary[c2][i]:
                    cnt += 1
            results[c1][c2] = float(cnt) / total          
            if cnt % 10 == 0:
                print '.'
    return results

def average_tsv(files, value_idx, prefix='ENSG'):
    ### READS IN MULTIPLE TSV FILES AND AVERAGE VALUES 
    ### RETURNS A LIST OF LISTS
    results = {}
    no_files = len(files)
    for file in files:
        temp = genomics.read_file1(file)
        for i in temp:
            if prefix not in i[0]:
                continue
            else:
                id_ = i[0].split('.')[0]
                if id_ not in results:
                    results[id_] = 0
                results[id_] += float(i[value_idx])
    for m in results:
        results[m] = results[m] / no_files
    return results

def calculate_dissimilarity_background1(filename, ref_, background_value, col_idx=3, separator=';', calculate_negative=False):
    ### READS IN A BED FILE AND CREATES A LIST OF NUMBERS, WHICH REPRESENTS OBSERVED DISSIMILARITY 
    ### USEFUL TO CREATE A BACKGROUND FOR POSITIVE AND NEGATIVE DISSIMILARITIES
    ### DISSIMILARITY = SUM OF ALL OBSERVED (POSITIVE & NEGATIVE) PAIRWISE DISSIMILARITIES / EXPECTED DISSIMILARITY (I.E. AVERAGE OF DISSIMILARITY)
    ### ref_ = a table instance to define dissimilarity between cell-types
    ### col_idx = column index where positive cell-types are included, separated by a separator
    ### FOR BINARY INPUT (E.G. H3K27ME3)
    ref_ = check_table(ref_)
    cells = get_colnames(ref_)
    results = []
    if type(filename)==str:
        temp = open(filename, 'r')   
    else:
        temp = filename 
    for i in temp:
        if type(filename)==str:
            i = i.strip().split()
        cs = set(i[col_idx].split(separator)[:-1])        
        sum_p = 0
        cnt = 0
        for c1 in cs:
            for c2 in cs:
                cnt += 1
                sum_p += float(ref_[c1][c2])
        results.append([(sum_p/cnt)/background_value])        
        if (calculate_negative==True) and (len(cs)!=len(cells)):
            ns = []
            for c in cells:
                if c not in cs:
                    ns.append(c)
            sum_n, cnt = 0, 0             
            for c1 in ns:
                for c2 in ns:
                    cnt += 1
                    sum_n += float(ref_[c1][c2])
            results[-1].extend([(sum_n/cnt)/background_value])        
    return results

    
def calculate_dissimilarity_background2(filename, ref_, background_value, col_idx=3, separator=';', calculate_negative=True):
    ### READS IN A TABLE FILE AND CREATES A LIST OF NUMBERS, WHICH REPRESENTS OBSERVED DISSIMILARITY 
    ### USEFUL TO CREATE A BACKGROUND FOR POSITIVE AND NEGATIVE DISSIMILARITIES
    ### DISSIMILARITY = SUM OF ALL OBSERVED (POSITIVE & NEGATIVE) PAIRWISE DISSIMILARITIES / EXPECTED DISSIMILARITY (I.E. AVERAGE OF DISSIMILARITY)
    ### ref_ = a table instance to define dissimilarity between cell-types
    ### col_idx = column index where positive cell-types are included, separated by a separator
    ### FOR CONTINUOUS INPUT (E.G. RNA-SEQ)
    ref_ = check_table(ref_)
    cells = get_colnames(ref_)
    results = []
    temp = open(filename, 'r')    
    for i in temp:
        i = i.strip().split()
        cs = set(i[col_idx].split(separator)[:-1])        
        sum_p = 0
        cnt = 0
        for c1 in cs:
            for c2 in cs:
                cnt += 1
                sum_p += float(ref_[c1][c2])
        results.append([(sum_p/cnt)/background_value])        
        if (calculate_negative==True) and (len(cs)!=len(cells)):
            ns = []
            for c in cells:
                if c not in cs:
                    ns.append(c)
            sum_n, cnt = 0, 0             
            for c1 in ns:
                for c2 in ns:
                    cnt += 1
                    sum_n += float(ref_[c1][c2])
            results[-1].extend([(sum_n/cnt)/background_value])        
    return results


def find_complements(filename, col_idx, ref, separator=';'):
    ### READS IN A TEXT FILE (E.G. H3K27me3_100bp_annotated.txt) AND OUTPUTS COMPLEMENTS OF THE ELEMENTS 
    ### ref = a list of all elements
    ### RETURNS A LIST of LISTS. ORDER FOLLOWS THAT OF FILENAME
    temp = open(filename, 'r')
    results = []    
    cnt = 0
    for i in temp:
        cnt += 1
        if cnt % 10000 == 0:
            print cnt
        i = i.strip().split()
        names = set(i[col_idx].split(separator)[:-1])        
        negatives = ''
        for c in ref:
            if c not in names:
                negatives += c+separator
        results.append([negatives]) 
        if cnt == 1000:
            break
    return results

def histogram(input_, density_=True):
    ### PLOT A HISTOGRAM 
    ### INPUT IS A LIST OF NUMBERS 
    plt.hist(input_, density=density_)


#def random_select(input_, no_samples):
    ### READS IN A TEXT FILE (OR EQUIVALENT) AND RETURN A LIST OF RANDOMLY SELECTED ROWS
#    input_ = check_file(input_)

#def get_element(input_, idx):


#def convert_list_to_table(input_):
    

def create_overlap_table(files, names, threshold):
    ### READS IN MULTIPLE TABLE FILES, PRESORTED BY A VALUE, AND CREATE A OVERLAP SUMMARY TABLE (BINARY) 
    results = {}
    for m in range(len(files)):        
        file = files[m]
        name = names[m]
        temp = genomics.read_file1(file)        
        for i in range(1, threshold):
            g = temp[i][0]            
            if g not in results:
                results[g] = {}
                for n in names:
                    results[g][n] = 0
            results[g][name] = 1
    return results


def aggregate_regions(input_file, step=10, value_idx=3, threshold=None):
    ### READS IN A TEXT FILE AND CREATE AGGREGATED BED FILE 
    ### IGNORES ITEMS WITH A VALUE OF 0
    temp = open(input_file, 'r')
    results = []    
    previous_v = 0
    current_c = [0, 0]
    coordinate = [0, 0]
    cnt = 0    
    for i in temp:
        i = i.strip().split()
        current_c = [int(i[1]), int(i[2])]
        if coordinate[1] == 0:
            coordinate = current_c
        if threshold == None:
            if int(i[value_idx]) != 0:
                value = ((int(i[value_idx])-1) / step) + 1
            else:
                value = 0
            if value != previous_v:
                results.append([i[0], coordinate[0], coordinate[1], previous_v])
                coordinate = current_c            
            else:
                coordinate[1] = i[2]
        else:
            if int(i[value_idx]) > threshold:
                value = 1
            else:
                value = 0
            if value != previous_v:
                results.append([i[0], coordinate[0], coordinate[1], previous_v])
                coordinate = current_c            
            else:
                coordinate[1] = i[2]            
        previous_v = value
        cnt += 1
        if cnt % 10000 == 0:
            print cnt
    return results

def create_cell_type_array(input_file, start, end, cell_idx, cell_list, width=True):
    ### READS IN A TEXT FILE (E.G. H3K27me3_broad_domains_flat_annotated.txt) AND CREATES A DICTIOANRY OF LISTS WHICH COLLECT ALL DOMAINS INFORMATIONS
    ### WIDTH INFORMATION CAN BE INCLUDED (width=True) OR NOT (I.E. BINARY 0 OR 1)
    ### THIS IS REQUIRED BEFORE CALCULATING SPEARMANS CORRELATIONS
    results = {}
    temp = open(input_file, 'r')    
    current = 0
    positives = set()
    cnt = 0
    for c in cell_list:
        results[c] = []
    for i in temp:
        cnt += 1
        if cnt % 10000 == 0:
            print cnt
        i = i.strip().split()
        id_ = i[0]+'_'+i[start]        
        c = i[cell_idx]
        if current==0:
            current = id_
            positives.add(c)  
            value = int(i[end]) - int(i[start])
            continue          
        else:
            if current == id_:
                positives.add(c)
                value = int(i[end]) - int(i[start])
            else: 
                if width==False:
                    value = 1
                for m in cell_list:
                    if m in positives:
                        results[m].append(value)
                    else:
                        results[m].append(0)
                positives = set()
                positives.add(c)
                current = id_
    return results

def calculate_correlation_for_lists(input_, method='spearman'):
    ### TAKES A DICTIONARY OF LISTS AND CALCULATE CORRELATION BETWEEN THEM 
    ### INPUT CAN BE THE RESULT FROOM 'create_cell_type_array'
    ### RETURNS A TABLE INSTANCE
    results = {}
    cells = []
    cnt = 0
    for i in input_:
        cells.append(i)
    for c1 in cells:
        results[c1] = {}
        for c2 in cells:
            if c1 == c2:
                results[c1][c2] = 1
            else:
                r, p =stat.spearman(input_[c1],input_[c2])
                results[c1][c2] = r
                cnt += 1
                if cnt % 100 == 0:
                    print cnt
    return results

def calculate_mean_dissimilarity(ref, cells):
    ### TAKES A TABLE AND CALCULATE A MEAN VALUE FOR ALL PAIR-WISE COMBINATIONS
    ref = check_table(ref, numerical=True)
    cnt = 0
    sum_ = 0
    for c1 in cells:
        for c2 in cells:
            if c1 != c2:
                cnt += 1
                sum_ += ref[c1][c2]
    if cnt == 0:
        value = 0
    else:
        value = float(sum_) / cnt
    return value


                
def merge_into_single_lines(input_, col_idx):
    ### READS IN BED FILES (e.g. H3K27me3_broad_domains_flat_annotated.txt) AND MERGE ITEMS IN COL_IDX INTO THE ENTRY WITH THE SAME GENOMIC POSITION
    ### returns a dictionary
    temp = open(input_, 'r')
    results = {}
    for i in temp:
        i = i.strip().split()
        chr_ = i[0]
        id_ = i[1]+'_'+i[2]
        cell = i[3]
        if chr_ not in results:
            results[chr_] = {}
        if id_ not in results[chr_]:
            results[chr_][id_] = []
        results[chr_][id_].append(cell)
    return results

def calculate_similarity_table(input_, method='spearman'):
    ### TAKES IN A TABLE AND CALCULATE CORRELATION BETWEEN EACH PAIR-WISE SAMPLES (I.E. COLUMNS)
    input_ = check_table(input_)
    cols = get_colnames(input_)
    ref = {}
    for c in cols:
        ref[c] = []
        for g in input_:
            ref[c].append(float(input_[g][c]))
    results = {}
    for c1 in cols:
        results[c1] = {}
        for c2 in cols:
            results[c1][c2] = 0.0
    for i in range(len(cols)-1):
        c1 = cols[i]        
        for j in range(i+1, len(cols)):
            c2 = cols[j]
            if method=='spearman':
                r, p = stat.spearman(ref[c1], ref[c2])
                results[c1][c2] = r
                results[c2][c1] = r
    for c in cols:
        results[c][c] = 1.0
    return results

def convert_to_table2(input_, feature, labels):
    results = {}
    if feature=='row':
        for i in range(len(input_)):
            results['feature_'+str(i+1)] = {}
            for j in range(len(input_[i])):
                results['feature_'+str(i+1)][labels[j]] = input_[i,j]
        return results
    elif feature=='column':
        for i in range(len(input_[0])):
            results['feature_'+str(i+1)] = {}
            for j in range(input_):
                results['feature_'+str(i+1)][labels[j]] = input_[j,i]
        return results


def calculate_dissimilarity(input_, method='spearman', svd=False, threshold=0.8, feature='row'):
    ### READS IN A TABLE INSTANCE OF SIMILARITY AND CALCULATE DISSIMILARITY
    ### svd = A BOOLEAN TO INDICATE WHETHER SVD TO BE PERFORMED TO SELECT FEATURES (IDEAL FOR A LARGE DATA SETS)
    input_ = check_table(input_)
    cells = get_colnames(input_)
    genes = get_rownames(input_)
    if svd==True:
        input_ = perform_svd(input_, rownames=genes, colnames=cells, threshold=threshold)
        print len(input_), len(input_[0])
        temp = convert_to_table2(input_, feature=feature, labels=cells)
        print len(temp), len(temp['feature_1'])
    sim = calculate_similarity_table(temp, method='spearman')   
    return sim

def calculate_dissimilarity1(input_, method='spearman'):
    ### READS IN A TABLE INSTANCE OF SIMILARITY AND CALCULATE DISSIMILARITY
    input_ = check_table(input_)
    cells = get_colnames(input_)
    for c1 in cells:
        for c2 in cells:
            if method=='spearman':
                value = (1 - float(input_[c1][c2])) / 2
            input_[c1][c2] = value
    return input_

def convert_to_z(input_, mean_=None, sd_=None, exclude_values=[]):
    ### ASSUMING NORMAL DISTRIBUTION, CALCULATE Z-SCORE FOR EACH ITEM IN THE INPUT
    ### exclude_values = a list of values to exclude in obtaining the distribution (e.g. 0)
    if type(input_)==str:
        input_ = genomics.read_file_items(input_, numeric=True)
    background = []
    for m in input_:
        if m in exclude_values:
            continue
        else:
            background.append(m)
    if mean_==None:
        mean_ = np.mean(background)
    if sd_==None:
        sd_ = np.std(background)
    for m in range(len(input_)):
        value = (input_[m] - mean_) / sd_
        input_[m] = value
    print 'Mean =', mean_
    print 'S.D. =', sd_
    return input_

def add_labels(input_, col_idx, prefix='item_'):
    ### READS IN A TEXT FILE AND ADDS A LABEL (WHICH IS PREFIX + COUNT)
    ### RETURNS A LIST OF LISTS
    input_ = check_file(input_)
    for i in range(len(input_)):
        label = prefix+str(i+1)
        input_[i].insert(col_idx, label)
    return input_


def assign_genes(input_file, tss_, min_distance=0, max_distance=999999999, centre=False, width=True, gene_include=True):
    ### ASSIGN PEAKS TO THE CLOSEST GENE (OR TSS)
    ### RETURNS A LIST OF LISTS (E.G. [item name, gene name, distance to the gene, gene included, width of the peak])
    temp = genomics.read_file1(input_file)
    cnt = 1
    for i in range(len(temp)):
        if len(temp[i]) < 4:
            temp[i].extend(['item_'+str(cnt)])
            cnt += 1
    data_entry = []
    for i in temp:
        data_entry.append([i[0], i[1], i[2], i[3]])    
    tss_data = genomics.read_file(tss_,[1, 3, 4, 2, 5, 0])   # for hg19
    #tss_data = read_file(tss_,[2, 4, 5, 3, 12, 1])  # for mm 10
    tss = genomics.tss(tss_data, chr_idx=0, position_list=[1, 2], strand_idx=3, id_idx=4)
    results = genomics.assign_gene(data_entry, tss, min_distance, max_distance, centre, width, gene_include)    
    return results


def select_items(input_, keyword, idx):
    ### TAKES A LIST OF LIST AND RETURNS ONES WITH A SPECIFIED KEYWORD IN THE INDEX
    results = []
    for i in input_:
        if keyword in i[idx]:
            results.append(i)
    return results

def get_random_dissimilarity(ref, no_samples, no_permutation=1000):
    ### TAKES IN A DISSIMILARITY MATRIX AND GENERATE A DISTRIBUTION OF RANOM SAMPLING GIVEN no_samples 
    ### samples are randomly choosen and their average dissimilarity is calculated
    ### returns a list of values
    ref = check_table(ref,numerical=True)
    cols = get_colnames(ref)
    results = []
    for i in range(no_permutation):
        cells = genomics.random_sample(cols, n_samples=no_samples)
        value = calculate_mean_dissimilarity(ref, cells)
        results.append(value)
    return results

def identify_hotspots(input_file, ref, id_idx, value_idx, separator=';', no_permutation=1000):
    ### STREAMLINE CALCULATION OF P-VALUE GIVEN INPUT
    ### 1. GENERATE DISTRIBUTION OF RANDOM SAMPLING FOR ALL OBSERVED M (WHERE M=NUMBER OF SAMPLES WHERE A GENETIC ELEMENT IS PRESENT)
    ### 2. CALCULATE P-VALUE USING A PERMUTATION TEST FOR EACH GENETIC ELEMENT
    ### RETURNS A LIST OF P-VALUES
    ### FOR INPUT_FILE, ID_IDX = COLUMN INDEX WHERE THE ITEM NAME IS LOCATED, VALUE_IDX = COLUMN INDEX WHERE THE POSITIVE SAMPLE IDS ARE RECORDED
    input_file = check_file(input_file)
    ref = check_table(ref, numerical=True)
    background = {}
    no_cells = set()
    results = []
    print 'CALCULATING DISSIMILARITY INDEX FOR EACH ELEMENT...'    
    for i in input_file:
        id_ = i[id_idx]
        names = set(i[value_idx].split(separator)[:-1])
        if len(names) not in background:
            background[len(names)] = []
        if len(names) != 1:
            value = calculate_mean_dissimilarity(ref, names)
            results.append([id_, value, len(names), i[value_idx]])
    print 'GENERATING DISTRIBUTIONS OF RANDOM SAMPLING...'
    for m in background:
        background[m] = get_random_dissimilarity(ref, no_samples=m, no_permutation=no_permutation)
        background[m] = [np.mean(background[m]), np.std(background[m])]
    print 'CALCULATING P-VALUE OF EACH ELEMENT...'
    for n in range(len(results)):
        item = results[n]
        m = item[2]
        if m == 1:
            continue
        else:
            z = stat.z_score(item[1], background[m][0], background[m][1])        
            p = stat.p_value(z)
            if z < 0:
                p = 1- p            
            if p > 1:
                p = 1.0
            results[n].extend([round(z, 6), round(p, 6)])
    return results

def identify_hotspots1(input_file, ref, id_idx, value_idx, separator=';'):
    ### STREAMLINE CALCULATION OF P-VALUE GIVEN INPUT
    ### 1. GENERATE DISTRIBUTION OF RANDOM SAMPLING FOR ALL OBSERVED M (WHERE M=NUMBER OF SAMPLES WHERE A GENETIC ELEMENT IS PRESENT)
    ### 2. CALCULATE P-VALUE BASED ON EMPIRICAL DISTRIBUTION OF DISSIMILARITY SCORE IN INPUT (ASSUMES GAUSSIAN DISTRIBUTION)
    ### RETURNS A LIST OF P-VALUES
    ### FOR INPUT_FILE, ID_IDX = COLUMN INDEX WHERE THE ITEM NAME IS LOCATED, VALUE_IDX = COLUMN INDEX WHERE THE POSITIVE SAMPLE IDS ARE RECORDED
    input_file = check_file(input_file)
    ref = check_table(ref, numerical=True)
    background = []
    no_cells = set()
    results = []
    print 'CALCULATING DISSIMILARITY INDEX FOR EACH ELEMENT...'    
    for i in input_file:
        id_ = i[id_idx]
        names = set(i[value_idx].split(separator)[:-1])
        if len(names) not in background:
            background[len(names)] = []
        if len(names) != 1:
            value = calculate_mean_dissimilarity(ref, names)
            results.append([id_, value, len(names), i[value_idx]])
    print 'EXTRACTING EMPIRICAL DISTRIBUTION...'
    for i in results:
        background.append(float(i[1]))
    mean_ = np.mean(background)
    std_ = np.std(background)
    background = [mean_, std_]
    
    print 'CALCULATING P-VALUE OF EACH ELEMENT...'
    for n in range(len(results)):
        item = results[n]
        m = item[2]
        if m == 1:
            continue
        else:
            z = stat.z_score(item[1], background[0], background[1])        
            p = stat.p_value(z)
            if z < 0:
                p = 1- p            
            if p > 1:
                p = 1.0
            results[n].extend([round(z, 6), round(p, 6)])
    return results


def divide_by_prop_samples(input_, no_samples, value_idx, sample_idx, separator=';'):
    ### DIVIDE Z-SCORE BY PROPORTION OF POSITIVE SAMPLES (TO INCORPORATE SPECIFICITY INFORMATION)
    input_ = check_file(input_)
    for i in range(len(input_)):
        item = input_[i]
        no = item[sample_idx].count(separator)
        prop = float(no) / no_samples
        input_[i][value_idx] = float(input_[i][value_idx]) / prop
    return input_


def convert_to_array(input_):
    input_ = check_table(input_)
    results = []
    for g in input_:
        results.append([])
        for c in input_[g]:
            results[-1].extend([float(input_[g][c])])
    return results

def convert_to_table_(input_, rownames, colnames):
    ### TAKES AN 2D-ARRAY AND CONVERT TO A TABLE INSTANCE 
    results = {}
    for i in range(len(rownames)):
        g = rownames[i]
        results[g] = {}
        for j in range(len(colnames)):
            c = colnames[j]
            results[g][c] = input_[i,j]
    return results


def convert_to_table1(input_, colnames, col_no, head='PC_'):
    ### TAKES AN 2D-ARRAY AND CONVERT TO A TABLE INSTANCE 
    ### WHEN ROWNAMES ARE NOT IMPORTANT (I.E. REDUCED FEATURES)
    results = {}
    for i in range(len(input_)):
        g = head+str(i+1)
        results[g] = {}
        for j in range(col_no):
            c = colnames[j]
            results[g][c] = input_[i,j]
    return results


def find_no_eigens(input_, threshold=0.8, square=False):
    ### TAKES A LIST OF EIGENVALUES AND FIND THE NUMBER OF EIGENVALUES TO USE
    if square==False:
        sum_ = np.sum(input_)
    else:
        sum_ = 0
        for m in input_:
            sum_ += float(m)**2
    cum_ = 0    
    for i in range(len(input_)):
        m = input_[i]
        if square==True:
            value = float(m) ** 2
        else:
            value = float(m)
        cum_ += value / sum_        
        if cum_ >= threshold:            
            return i+1

def svd_(input_, full_matrices=False):
    u,s,v = np.linalg.svd(input_, full_matrices=full_matrices) 
    return u,s,v

def create_diag_matrix(input_):
    ### input_ = a list of numerical values (which are diagonal values of the matrix)
    ### USEFUL TO CREATE THE EIGENVALUE MATRIX
    l = len(input_)
    s = np.zeros((l, l),int)
    np.fill_diagonal(s, input_)
    return s

def perform_svd(input_, rownames, colnames, threshold=0.8):
    ### STREAMLINE TO PERFORM SVD ON A GIVEN MATRIX
    ### STANDARDISATION STEP IS MISSING!!! REQUIRES PRE-COMPUTATION!!
    input_ = convert_to_array(input_)    
    u,s,v = svd_(input_)
    no_eigens = find_no_eigens(s, threshold=threshold)
    print 'Number of eigens used =', no_eigens
    s_ = create_diag_matrix(s)
    a = reconstruct_matrix_with_reduced(u,s_,v,no_eigens)    
    return a



def reconstruct_matrix(u,s,v,no_eigens):
    q = np.matmul(u[::,:no_eigens], s[:no_eigens, :no_eigens])
    q = np.matmul(q, v[:no_eigens,::])
    return q

def reconstruct_matrix_with_reduced(u,s,v,no_eigens):   
    q = np.matmul(s[:no_eigens, :no_eigens], v[:no_eigens, ::])
    return q


def scale_table(table_):
    ### EQUIVALENT TO SCALE FUNCTION IN R
    ### CENTERING AND SCALING IS DONE BEFORE SVD
    ### !!CHECK AGAIN!! 
    table_ = check_table(table_)
    for g in table_:
        temp = []
        for c in table_[g]:
            temp.append(float(table_[g][c]))
        mean_ = np.mean(temp)
        std_ = np.std(temp)
        for c in table_[g]:
            value = (float(table_[g][c]) - mean_) / std_
            table_[g][c] = value
    return table_

def is_within(point, item):
    if (float(point) >= float(item[0])) and (float(point) <= float(item[1])):
        return True
    else:
        return False

def union_width(item1, item2):
    ### takes two lists of [start, end] and calcuate the width of the union 
    ### returns 
    start, end = 0, 0
    if is_within(float(item1[0]), item2):
        start = float(item1[0])
        if is_within(float(item1[1]), item2):
            end = float(item1[1])
        else:
            end = float(item2[1])
    elif is_within(float(item1[1]), item2):
        end = float(item1[1])
        if is_within(float(item1[0]), item2):
            start = float(item1[0])
        else:
            start = float(item2[0])
    elif is_within(float(item2[0]), item1):
        start = float(item2[0])
        if is_within(float(item2[1]), item1):
            end = float(item2[1])
        else:
            end = float(item1[1])
    elif is_within(float(item2[1]), item1):
        end = float(item2[1])
        if is_within(float(item2[0]), item1):
            start = float(item2[0])
        else:
            start = float(item1[0])
    return start, end

def saturation(input_, iter_, step_=3, stable_prop=0.02):
    temp = read_table1(input_)
    cols = get_colnames(temp)
    results1, results2, results3 = [], [], []  # mean score, rank and proportion of stably ranked genes 
    genes = get_rownames(temp)
    no_stable = int(len(genes) * stable_prop)    
    print len(genes), no_stable
    for ii in range(iter_):
        print ii
        results1.append([])
        results2.append([])
        results3.append([])
        order = genomics.random_sample(cols)        
        track = {}
        for g in temp:
            track[g] = [0, 0]  # [score, rank]
            for c in order[0:step_]:
                track[g][0] += float(temp[g][c])
        previous1 = track           
        pp = []
        for g in temp:
            pp.append([g, track[g][0]])        
        pp = genomics.sort_(pp, idx=1, reverse_=True)        
        max_ = pp[0][1]
        min_ = pp[-1][1]
        for i in range(len(pp)):
            pp[i][1] = (float(pp[i][1]) - min_) / (max_ - min_)
        track_ = {}
        for n in range(len(pp)):
            m = pp[n]
            track_[m[0]] = [0, 0]
            track_[m[0]][0] = m[1]
            track_[m[0]][1] = n+1
        #print previous1['RNF14']
        previous2 = track_ 
        #print previous2['RNF14']       
        #print order        

        for j in range(step_,len(cols),step_):            
            track = {}
            cnt = 0
            for g in temp:
                track[g] = [previous1[g][0], 0]  # [score, rank]
                for c in order[j:j+step_]:
                    track[g][0] += float(temp[g][c])                
            previous1 = track
            pp = []
            for g in temp:
                pp.append([g, track[g][0]])
            pp = genomics.sort_(pp, idx=1, reverse_=True)        
            max_ = pp[0][1]
            min_ = pp[-1][1]
            for i in range(len(pp)):
                pp[i][1] = (float(pp[i][1]) - min_) / (max_ - min_)   
            track_ = {}         
            for n in range(len(pp)):                
                m = pp[n]
                track_[m[0]] = [0,0]
                track_[m[0]][0] = m[1]
                track_[m[0]][1] = n+1
            tt = [0, 0, 0]  # change in score and rank and prop
            for g in genes:
                diff_s = np.abs(track_[g][0] - previous2[g][0])
                diff_r = np.abs(track_[g][1] - previous2[g][1])
                tt[0] += diff_s
                tt[1] += diff_r
                if diff_r < no_stable:
                    cnt += 1
            tt[0] = float(tt[0]) / len(track_)
            tt[1] = float(tt[1]) / len(track_)
            tt[2] = float(cnt) / len(genes)
            previous2 = track_
            results1[-1].extend([tt[0]])
            results2[-1].extend([tt[1]])   
            results3[-1].extend([tt[2]])                     
        
        
    return results1, results2, results3

def saturation1(input_, iter_, step_=3, stable_prop=0.02):
    temp = read_table1(input_)
    cols = get_colnames(temp)
    results1, results2, results3, results4, results5 = [], [], [], [], []  # mean score, rank and proportion of stably ranked genes 
    genes = get_rownames(temp)
    no_stable3 = int(len(genes) * 0.03)
    no_stable4 = int(len(genes) * 0.04)  
    no_stable5 = int(len(genes) * 0.05)    
    print no_stable3, no_stable4, no_stable5  
    
    for ii in range(iter_):
        print ii
        results1.append([])
        results2.append([])
        results3.append([])
        results4.append([])
        results5.append([])
        order = genomics.random_sample(cols)        
        track = {}
        for g in temp:
            track[g] = [0, 0]  # [score, rank]
            for c in order[0:step_]:
                track[g][0] += float(temp[g][c])
        previous1 = track           
        pp = []
        for g in temp:
            pp.append([g, track[g][0]])        
        pp = genomics.sort_(pp, idx=1, reverse_=True)        
        max_ = pp[0][1]
        min_ = pp[-1][1]
        for i in range(len(pp)):
            pp[i][1] = (float(pp[i][1]) - min_) / (max_ - min_)
        track_ = {}
        for n in range(len(pp)):
            m = pp[n]
            track_[m[0]] = [0, 0]
            track_[m[0]][0] = m[1]
            track_[m[0]][1] = n+1
        #print previous1['RNF14']
        previous2 = track_ 
        #print previous2['RNF14']       
        #print order        

        for j in range(step_,len(cols),step_):            
            track = {}
            cnt3, cnt4, cnt5 = 0,0,0
            for g in temp:
                track[g] = [previous1[g][0], 0]  # [score, rank]
                for c in order[j:j+step_]:
                    track[g][0] += float(temp[g][c])                
            previous1 = track
            pp = []
            for g in temp:
                pp.append([g, track[g][0]])
            pp = genomics.sort_(pp, idx=1, reverse_=True)        
            max_ = pp[0][1]
            min_ = pp[-1][1]
            for i in range(len(pp)):
                pp[i][1] = (float(pp[i][1]) - min_) / (max_ - min_)   
            track_ = {}         
            for n in range(len(pp)):                
                m = pp[n]
                track_[m[0]] = [0,0]
                track_[m[0]][0] = m[1]
                track_[m[0]][1] = n+1
            tt = [0, 0, 0, 0, 0]  # change in score and rank and prop
            for g in genes:
                diff_s = np.abs(track_[g][0] - previous2[g][0])
                diff_r = np.abs(track_[g][1] - previous2[g][1])
                tt[0] += diff_s
                tt[1] += diff_r
                if diff_r < no_stable3:
                    cnt3 += 1
                if diff_r < no_stable4:
                    cnt4 += 1
                if diff_r < no_stable5:
                    cnt5 += 1
            tt[0] = float(tt[0]) / len(track_)
            tt[1] = float(tt[1]) / len(track_)
            tt[2] = float(cnt3) / len(genes)
            tt[3] = float(cnt4) / len(genes)
            tt[4] = float(cnt5) / len(genes)
            previous2 = track_
            results1[-1].extend([tt[0]])
            results2[-1].extend([tt[1]])   
            results3[-1].extend([tt[2]])        
            results4[-1].extend([tt[3]]) 
            results5[-1].extend([tt[4]])              
        
        
    return results1, results2, results3, results4, results5


def calculate_repressive_tendency(input_, cols):
    ### NEW METHOD
    temp = check_table(input_)
    results = {}
    ref = []
    for g in temp:
        results[g] = 0
        for c in cols:
            results[g] += float(temp[g][c])
        ref.append([g, results[g]])
    ref = genomics.sort_(ref, idx=1, reverse_=True)
    max_ = ref[0][1]
    min_ = ref[-1][1]
    output_ = {}    
    for i in range(len(ref)):
        output_[ref[i][0]] = (float(ref[i][1]) - min_) / (max_ - min_)
    return output_

def segment_lists(input_, bin_size):
    ### input_ = list
    ### bin_size = as a percent of the total number of lists
    ### returns a list of lists
    total = len(input_)
    if bin_size < 1:
        bin_ = int(total * bin_size)
        iter_ = int(1 / bin_size)    
    else:
        bin_ = bin_size
        iter_ = total / bin_size
    results = []
    cnt = 0
    for i in range(iter_-1):
        results.append([])
        for m in range(bin_):
            results[-1].extend([input_[cnt]])
            cnt += 1
    if cnt != total:
        results.append([])
        for i in range(cnt, cnt+bin_):
            results[-1].extend([input_[cnt]])
            cnt += 1
    return results

def segment_jaccard(input1, input2, bin_size):
    set1 = segment_lists(input1, bin_size)
    set2 = segment_lists(input2, bin_size)
    results = []
    for i in range(len(set1)):
        t = jaccard_index(set1[i], set2[i])
        results.append(t)
    return results


def get_items(input_, keywords, key_idx, value_idx):
    input_ = check_file(input_)
    results = []
    for i in input_:
        if i[key_idx] in keywords:
            results.append(i[value_idx])
    return results

def get_performance_stats(input_, positives):
    ### TAKES A LIST OF GENES AND POSITIVES AND CALCULATES 4 STATS (I.E. TP, FP, TN, FN)
    ### RETURNS 4 LISTS (TP, FP, TN, FN)
    positives = set(positives)
    tp_fn = len(positives)
    tn_fp = len(input_) - tp_fn
    tp,fn,tn,fp = 0,tp_fn,tn_fp,0
    tp_,fn_,tn_,fp_ = [], [], [], []    
    for i in input_:
        if i in positives:
            tp += 1
            fn -= 1
        else:
            fp += 1
            tn -= 1
        tp_.append(tp)
        fn_.append(fn)
        tn_.append(tn)
        fp_.append(fp)        
    return tp_, fp_, tn_, fn_

def calculate_performance(tp,fp,tn,fn,option='roc'):
    ### CALCULATE STATS FOR PERFORMANCE CURVES AT EACH POSITION AND RETURNS 2 LISTS
    s1, s2 = [], []  
    if option=='roc':
        for i in range(len(tp)):
            a1 = float(tp[i]) / (tp[i]+fn[i])   # sensitivity
            a2 = float(tn[i]) / (fp[i]+tn[i])   # specificity
            s1.append(a1)
            s2.append(1-a2)
        return s1,s2
    elif option=='prc':
        for i in range(len(tp)):
            a1 = float(tp[i]) / (tp[i]+fp[i])   # precision
            a2 = float(tp[i]) / (tp[i]+fn[i])   # recall = sensitivity
            s1.append(a1)
            s2.append(a2)
        # correct for the starting point
        
        for m in s1:
            if float(m) != float(0):
                value = m
                break
        print value
        for i in range(len(s1)):
            if float(s1[i]) == float(0):
                s1[i] = value

        s2.insert(0, 0)
        s1.insert(0, value)

        return s1,s2


def calculate_roc_auc(x,y):
    ### CALCULATE AUC AT EACH POSITION
    import sklearn
    from sklearn import metrics
    return metrics.auc(x,y)  

def _calculate_discordance(dic1, dic2, fill_missing=True, gene_mapping=None):    
    all_genes = []
    min_ = 1.0
    if gene_mapping!=None:
        temp = {}
        for g in dic1:
            if g in gene_mapping:
                temp[gene_mapping[g]] = dic1[g]
            else:
                temp[g] = dic1[g]
        dic1 = temp
    for g in dic1:        
        all_genes.append(g)    
    for g in dic2:
        if float(dic2[g]) < min_:
            min_ = float(dic2[g])   
    if fill_missing==True:
        for g in all_genes:
            if g not in dic2:
                dic2[g] = min_
    results = []    
    for gene in all_genes:         
        value = dic1[gene] * dic2[gene]            
        results.append([gene, value, dic1[gene]])
    return results


def calculate_discordance(exp, ref, pseudo_=1, fill_missing=True, log_conversion=True, gene_mapping=None):     
    ### exp, ref = dictionary
    if pseudo_!=None:
        exp = add_pseudo(exp, count_=pseudo_)
    if log_conversion==True:
        for g in exp:
            exp[g] = np.log(exp[g])
    results = _calculate_discordance(exp, ref, fill_missing=True, gene_mapping=gene_mapping)
    results = genomics.sort_(results, idx=1, reverse_=True)      
    return results

def calculate_discordance_cage(exp, ref, min_, pseudo_=1):     
    ### exp, ref = dictionary
    if pseudo_!=None:
        exp = add_pseudo(exp, count_=pseudo_)    
    results = []
    
    for g in exp:
        id_ = g.split('@')[1]
        if 'chr' not in id_:
            if id_ not in ref:
                value = min_
            else:
                value = ref[id_]
            dis = np.log(exp[g]+1) * value
            results.append([g, dis, exp[g]])
         
    return results

def calculate_discordance_for_table(input_, ref, rows=None, cols=None, log=True, pseudo=1):
    input_ = check_table(input_, numerical=True)
    if rows==None:
        rows = get_rownames(input_)
    if cols==None:
        cols = get_colnames(input_)
    results = initiate_table1(rows, cols)    
    min_ = 1
    cnt = 0    
    for g in ref:
        if float(ref[g]) != float(0):
            if float(ref[g]) < min_:
                min_ = float(ref[g])
    for c in cols:    
        cnt += 1
        print cnt
        if pseudo==-1:
            old = pseudo
            min_value = 9999
            for r in rows:
                if float(input_[r][c]) != 0:
                    if float(input_[r][c]) < min_value:
                        min_value= float(input_[r][c])
            pseudo=min_value
        else:
            old = pseudo
        print pseudo

        for r in rows:      
            if log==True:
                if r in ref: 
                    results[r][c] = np.log(float(input_[r][c])+pseudo) * ref[r]     
                else:
                    results[r][c] = np.log(float(input_[r][c])+pseudo) * min_
            else:
                if r in ref:
                    results[r][c] = float(input_[r][c]+pseudo) * ref[r]
                else:
                    results[r][c] = float(input_[r][c]+pseudo) * min_
        pseudo = old
    return results



def add_pseudo(input_data, count_):
    for gene_ in input_data:        
        input_data[gene_] += float(count_)
    return input_data


def fet_for_matrix(input_table, positives):
    ### PERFORMS A FET AT EACH PERCENTILE RANK ACROSS COLUMNS
    ### RETURNS A LIST OF LISTS 
    input_table = check_table(input_table)
    cols = get_colnames(input_table)
    results = []
    for c in cols:
        temp = []
        for g in input_table:
            if float(input_table[g][c]) > 0:
                temp.append([g, float(input_table[g][c])])        
        temp = genomics.sort_(temp, idx=1, reverse_=True)
        input_ = []
        for i in temp:
            input_.append(i[0])        
        tt = sliding_fet(input_, positives, output_='p-value', convert_to_percentile=True, percentile_bin = 0.01)
        results.append([c])
        for i in tt:
            results[-1].extend([i])
    return results
    

def extract_cols(input_, cols):
	results = []
	temp = open(input_, 'r')
	for i in temp:
		i = i.strip().split()
		results.append([])
		for c in cols:
			results[-1].extend([i[c]])
	return results


def sort_assigned_genes(input_):
	### FIND THE BROADEST PEAK
	### USE OUTPUT FROM 'assign_genes' function
	results = {}
	for i in input_:
		if i[1]!='':
			g = i[1]
			if g not in results:
				results[g] = 0
			if float(i[-1]) > results[g]:
				results[g] = float(i[-1])
	return results

def get_overlap_coordinate(input1, input2):
	results = [0,0]
	a1 = int(input1[0])
	a2 = int(input1[1])
	b1 = int(input2[0])
	b2 = int(input2[1])
	if (a1 <= b1) and (a2 <= b2):
		if (a2>b1) and (a2<b2):
			results = [b1,a2]
	elif (a1 >= b1) and (a2 >= b2):
		if (a1>b1) and (a1<b2):
			results = [a1,b2]
	elif (b1>a1) and (b1<a2):
		if (b2>a1) and (b2<a2):
			results = [b1,b2]
	elif (a1>b1) and (a1<b2):
		if (a2>b1) and (a2<b2):
			results = [a1,a2]
	return results

    #a1 = [172654409,172668022]
    #a2 = [172612315,172664815]


def find_positive_genes(matrix, col, ref1, ref2=None, threshold=0):
	matrix = check_table(matrix)
	if type(ref1) == str:
		ref1 = genomics.read_file_items(ref1)
	ref1 = set(ref1)
	if ref2 != None:
		ref2 = set(ref2)
	results = []
	for g in matrix:
		if g in ref1:
			if float(matrix[g][col]) > threshold:
				if ref2==None:
					results.append(g)
				else:
					if g in ref2:
						results.append(g)
	return results

def calculate_ave_columns(matrix, cols):
	matrix = check_table(matrix)
	results = {}
	no = len(cols)
	for g in matrix:
		sum_ = 0
		for c in cols:
			sum_ += float(matrix[g][c])
		results[g] = sum_ / no
	return results

def extract_dic_column(input_, col, threshold=0):
	input_ = check_table(input_)
	results = {}
	for g in input_:
		if float(input_[g][col]) > threshold:
			results[g] = float(input_[g][col])
	return results

def sort_column(table_, col_name):
    results = []
    for g in table_:
        results.append([g, float(table_[g][col_name])])
    results = genomics.sort_(results, idx=1, reverse_=True)
    return results

def get_rownames_by_sorting_table(input_, col, with_value=False):
    input_ = check_table(input_)
    temp = []
    for g in input_:
        temp.append([g, float(input_[g][col])])
    temp = genomics.sort_(temp, idx=1, reverse_=True)
    if with_value==True:
    	return temp
    else:
    	results = []
    	for i in temp:
    		results.append(i[0])
    	return results



def get_rownames_by_sorting_table1(input_, col, threshold=0):
    input_ = check_table(input_)
    temp = []
    for g in input_:
        temp.append([g, float(input_[g][col])])
    temp = genomics.sort_(temp, idx=1, reverse_=True)
    results = []
    for i in temp:
    	if threshold != None:
    		if i[1] > threshold:
    			results.append(i[0])
    	else:
    		results.append(i[0])
    return results

def get_rownames_by_sorting_table_cage(input_, col, threshold=0):
    input_ = check_table(input_)
    temp = []
    genes = {}
    for g in input_:
    	short = g.split('@')[1]
    	if short not in genes:
    		genes[short] = float(input_[g][col])
    	else:
    		if float(input_[g][col]) >= genes[short]:        		
        		genes[short] = float(input_[g][col])
    for sh in genes:
    	temp.append([sh, genes[sh]])
    temp = genomics.sort_(temp, idx=1, reverse_=True)
    results = []
    for i in temp:
    	if i[1] > threshold:
    		results.append(i[0])
    return results


def get_positive_genes(input_, col, threshold, tf=True):
	input_ = check_table(input_)
	results = []
	for g in input_:		
		if tf==False:
			if float(input_[g][col]) > threshold:
				results.append(g)
		else:
			if (float(input_[g][col]) > threshold) and (g in tf_list):
				results.append(g)
	return results

def convert_genes_for_cage(input_, ref_):
	results = []
	ref_ = set(ref_)
	input_ = check_table(input_)
	for g in input_:
		short = g.split('@')[1]
		if short in ref_:
			results.append(g)
	return results

def best_fet_for_matrix(inputs, labels, ref_):
	### FIND THE BEST P-VALUE AND RANK BIN POSITION FOR A MATRIX 
	### CAN HANDLE MULTIPLE DATASETS WITH DIFFERENT LABELS

	results = [['p-value','rank','method','colname']]
	for n in range(len(inputs)):
		input_ = check_table(inputs[n])
		label_ = labels[n]
		cols = get_colnames(input_)
		for col in cols:
			print col
			#positive = get_positive_genes(input_, col, threshold=0)
			positive = ref_
			a = get_rownames_by_sorting_table1(input_, col, threshold=0)
			
			aa = sliding_fet(a, positive)
			min_ = 1
			pos=0
			for m in range(len(aa)):
				if aa[m] < min_:
					min_ = aa[m]
					pos = m+1
			results.append([min_, pos, label_, col])
	return results


def fixed_fet_for_matrix(inputs, labels, ref_, rank):
    ### FIND THE P-VALUE AND AT A FIXED RANK BIN POSITION FOR A MATRIX 
    ### CAN HANDLE MULTIPLE DATASETS WITH DIFFERENT LABELS

    results = [['p-value','method','colname']]
    for n in range(len(inputs)):
        input_ = check_table(inputs[n])
        label_ = labels[n]
        cols = get_colnames(input_)
        for col in cols:
            print col
            #positive = get_positive_genes(input_, col, threshold=0)
            positive = ref_
            a = get_rownames_by_sorting_table1(input_, col, threshold=0)            
            aa = sliding_fet(a, positive)
            results.append([aa[rank-1], label_, col])
    return results

def best_fet_for_matrix_cage(inputs, labels, ref_):
	### FIND THE BEST P-VALUE AND RANK BIN POSITION FOR A MATRIX 
	### CAN HANDLE MULTIPLE DATASETS WITH DIFFERENT LABELS

	results = [['p-value','rank','method','colname']]
	for n in range(len(inputs)):
		input_ = check_table(inputs[n])
		label_ = labels[n]	
		cols = get_colnames(input_)
		cnt = 0
		for col in cols:
			cnt += 1
			print cnt
			#positive = get_positive_genes(input_, col, threshold=0)
			positive = ref_			
			a = get_rownames_by_sorting_table_cage(input_, col)	

			aa = sliding_fet(a, positive)
			min_ = 1
			pos=0
			for m in range(len(aa)):
				if aa[m] < min_:
					min_ = aa[m]
					pos = m+1
			results.append([min_, pos, label_, col])
	return results

def get_list_from_table(input_, col):
    input_ = check_table(input_)
    results = []
    for i in input_:
    	results.append(input_[i][col])
    return results

def divide_into_bins(input_, bins):
    results = []
    interval = len(input_) / int(bins)
    idx = 0
    for i in range(bins-1):
        temp = []
        for j in range(interval):
            temp.append(input_[idx])
            idx += 1
        results.append(temp)
    results.append([])
    for i in range(idx, len(input_)):
        results[-1].extend([input_[i]])
    return results


def sliding_fet1(input_, ref_, output_='p-value', tail_='greater'):
	### Fisher's exact test performed for each element of input_ with a sliding window method 
	### Background is all items found in input_
	### input_ is a list of lists 
	### ref_ is a reference item list (i.e. positive gene set)
	### Returns a list of outputs (e.g. p-value for each element of the input_)
	results = []
	ref_ = set(ref_)
	a,b,c,d = 0,0,0,0
	pno = 0
	all_ = []
	for i in input_:
		for j in i:
			all_.append(j)
			if j in ref_:
				pno += 1
	allno = len(all_)

	for i in input_:
		for j in i:			
			if j in ref_:
				a += 1
			else:
				b += 1
		c = pno - a
		d = allno - a - b - c
		odd_, p_ = stat.fisher(a,b,c,d, alternative_=tail_)
		if output_=='p-value':
			results.append(p_)
		else:
			results.append(odd_)
	return results

def perform_fet_with_sliding_window(input_list, ref, bin_no, output='p-value', tail='greater'):
	input_ = divide_into_bins(input_list, bins=bin_no)	
	results = sliding_fet1(input_, ref, output, tail)
	return results




def prop_membership_for_matrix(input_, ref, bins):
    input_ = check_table(input_)
    results = []
    cols = get_colnames(input_)
    ref = set(ref)
    for col in cols:
        a = get_rownames_by_sorting_table1(input_, col) 
        b = divide_into_bins(a, bins)

        total = []
        results.append([col])
        for i in a:
            if i in ref:
                total.append(i)
        for i in b:
            qq = stat.intersection(i, total)
            results[-1].extend([float(len(qq))/len(total)])
    return results


def prop_membership_for_list(input_, ref, bins):
	b = divide_into_bins(input_, bins)
	total = []
	results = []
	for i in input_:
		if i in ref:
			total.append(i)
	for i in b:
		qq = stat.intersection(i, total)
		results.append(float(len(qq))/len(total))
	return results

def create_empty_table(rows, cols, value=0):
    results = {}
    for r in rows:
        results[r] = {}
        for c in cols:
            results[r][c] = value
    return results


def calculate_rt(breadth, broad, cols):
    ### NEED Z-SCORE TABLE FOR BREADTH
    breadth = check_table(breadth)
    broad = check_table(broad)
    genes = get_rownames(breadth)
    sb = {}
    prop = {}
    results = []
    for g in genes:
        sb[g] = 0
        prop[g] = 0
        for c in cols:
            sb[g] += float(breadth[g][c])
            if g in broad:
                prop[g] += float(broad[g][c])
            else:
                prop[g] = 0
        prop[g] = float(prop[g]+1) / (len(cols)+1)
    min_, max_ = 99999, 0
    for g in sb:
        if sb[g] < min_:
            min_ = sb[g]
        if sb[g] > max_:
            max_ = sb[g]
    for g in sb:
        sb[g] = float(sb[g]-min_) / (max_ - min_)
    min_, max_ = 99999, 0
    for g in sb:
        value = sb[g] * prop[g]
        results.append([g, value])
        if value < min_:
            min_ = value
        if value > max_:
            max_ = value
    results_ = {}
    for i in range(len(results)):
        item = results[i]
        value = float(item[1]-min_) / (max_ - min_)
        results_[item[0]] = value
    return results_


def count_members(input_, ref_):
    ### input_ and ref_ are lists
    cnt = 0
    ref_ = set(ref_)
    for i in input_:
        if i in ref_:
            cnt += 1
    return cnt



def create_breadth_table(input_, col_id, gene_id, breadth_id, peak_id, id_table=False):
    data_ = genomics.read_file1(input_)
    genes = set()
    cols = set()
    for i in data_:
        genes.add(i[gene_id])
        cols.add(i[col_id])
    results = initiate_table1(rows=list(genes), cols=list(cols))
    if id_table == True:
        idt = initiate_table1(rows=list(genes), cols=list(cols), initial_value='NA')   

    for i in data_:
        if int(i[breadth_id]) > results[i[gene_id]][i[col_id]]:
            results[i[gene_id]][i[col_id]] = int(i[breadth_id])            
            if id_table == True:
                idt[i[gene_id]][i[col_id]] = i[peak_id]
    if id_table==True:
        return results, idt
    else:
        return results


def list_from_table(input_, col):
    input_ = check_table(input_)
    results = []
    for g in input_:
        results.append(input_[g][col])
    return results

def sort_row(input_, col, thre=0):
    aa = []
    for g in input_:
        if float(input_[g][col]) > thre:
            aa.append([g, float(input_[g][col])])
    aa = genomics.sort_(aa, idx=1, reverse_=True)
    output_ = []
    for i in aa:
        output_.append(i[0])
    return output_

def normalise_table(input_):
    ### Take a numeric valued table and normalise [0,1]
    rows = get_rownames(input_)
    cols = get_colnames(input_)
    for c in cols:
        temp = [input_[g][c] for g in rows]
        min_ = np.min(temp)
        max_ = np.max(temp)
        for g in rows:
            input_[g][c] = (input_[g][c] - min_) / (max_ - min_)
    return input_

def fetch_top_go_terms(files, col_idx=2, value_idx=3, no_terms=10):
    results = []
    for file in files:
        temp = genomics.read_file1(file)
        temp = genomics.sort_(temp, idx=value_idx, reverse_=False)
        for i in range(no_terms):
            results.append(temp[i][col_idx])
    #results = list(set(results))
    return results



if __name__ == '__main__':    

    #http://www.uniprot.org/uploadlists/
    ### TOTAL GENOME SIZE (hg19) = 3095677412 bp 
    ### BACKGROUND OCCURRENCE OF TSS = 0.000019 / bp = 19 / 1 Mbp (INCLUDING NR TRANSCRIPT)
    ### IN FLAT FILES, 163518 TSS OCCURRENCES IN BROAD DOMAINS (2315063817 BP)
    ### 836312 OCCURRENCES IN NARROW DOMAINS (4881291100 BP)
    ### BROAD  -> 0.000070 / BP = 70 / 1 Mbp
    ### NARROW -> 0.000171 / BP = 171 / 1 Mbp
    ### COMBINED -> 139 / 1 Mbp

    #tf_list = genomics.read_file_items('/Users/woojunshim/Research/Data/TF_list_mm10_symbol.txt')  # ONLY FOR MM10 DATA

    ### KEEP THESE LINES
    exp_ = read_table1('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.txt', numerical=True)  # For human
    all_exp_genes = get_rownames(exp_)
    non_tf_list = [x for x in all_exp_genes if x not in set(tf_list)]   
    regulated_tf = set(genomics.read_file_items('/Users/woojunshim/Research/Data/regulated_tf.txt'))
    regulated_nontf = set(genomics.read_file_items('/Users/woojunshim/Research/Data/regulated_nontf.txt'))
    stable_tf = set(genomics.read_file_items('/Users/woojunshim/Research/Data/stable_tf.txt'))
    stable_nontf = set(genomics.read_file_items('/Users/woojunshim/Research/Data/stable_nontf.txt'))
    all_ = list(regulated_tf) + list(regulated_nontf) + list(stable_tf) + list(stable_nontf)
    ref = genomics.read_file_dic('/Users/woojunshim/Research/Data/new_assigned/tables/repressive_hg19_cont_prop.txt', id_idx=0, col_idx=1)
    house = set(genomics.read_file_items('/Users/woojunshim/Research/Data/house_keeping_genes.txt', col=0))
    #broad_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_binary.txt')

    ### CREATE AN INPUT EXPRESSION FILE FOR TRIAGE
    cols = ['E104','E038','E070']
    names = ['Heart(Right_Atrium)','Blood(T_helper_naive_cells)','Brain(Germinal_Matrix)']  
    genes = get_rownames(exp_)
    results = initiate_table1(rows=genes, cols=names)
    for i in range(len(cols)):
        name = names[i]
        col = cols[i]
        for g in genes:
            results[g][name] = exp_[g][col]
    genomics.write_table1(results, 'example_input.txt')   

    # temp = genomics.read_file1('/Users/woojunshim/Research/Data/hg19_longest_TSS_size.txt')
    # cnt = 0
    # for i in temp:
    #     cnt += int(i[1])
    # print cnt

    ### EXTRACT CODING GENES 
    # genes = set(get_rownames(exp_))
    # temp = read_table1('/Users/woojunshim/Research/intergenic/data/result/predictive/svd/H3K27me3_svd_u_pre_final.txt')
    # results = {}
    # for g in temp:
    #     if g in genes:
    #         results[g] = {}
    #         for c in temp[g]:                
    #             results[g][c] = float(temp[g][c])
    # genomics.write_table1(results, '/Users/woojunshim/Research/intergenic/data/result/predictive/svd/H3K27me3_svd_u_final.txt')

    ### CALCULATE WILCOXON RANK SUM P FOR EACH EPIGENOME ACROSS GENES
    # temp = genomics.read_table('/Users/woojunshim/Research/intergenic/data/result/tss_quantification/tss_H3K27me3_quantification_table_refseq.txt')
    # cols = get_colnames(temp)
    # genes = get_rownames(temp)


    ### FIND ELBOW POINT
    # temp = genomics.read_file1('/Users/woojunshim/Research/intergenic/data/rts_2.5kb_tss.txt', sort_by=1)
    # idx = find_elbow([x[1] for x in temp])
    # idx = int(len(temp)*0.1)
    # results = temp[:idx]
    # genomics.write_file(results, '/Users/woojunshim/Research/intergenic/data/tss_2.5kb_score_top10.txt')

    ### COUNT REFSEQ CODING GENES WITH DIFFERENT START TSS
    # temp = open('/Users/woojunshim/Research/Data/hg19_TSS.txt', 'r')
    # results = {}
    # for i in temp:
    # 	i = i.strip().split()
    # 	if i[0].startswith('NM'):
    # 		if i[-1] not in results:
    # 			results[i[-1]] = set()
    # 		results[i[-1]].add(i[3])
    # cnt = []
    # for m in results:
    # 	if len(results[m]) > 1:
    # 		cnt.append([m, results[m]])
    # print cnt[0:10]

    ###
    # temp = open('/Users/woojunshim/Research/Data/hg19_tss_50kb.txt', 'r')
    # results = []
    # for i in temp:
    #     i = i.strip().split()
    #     if i[-1] in tf_list:
    #         results.append(i)
    # genomics.write_file(results, '/Users/woojunshim/Research/Data/hg19_tss_50kb_tf.txt')


    ### TOP 50 HIGHLY EXPRESSED VEGS
    #rows = get_rownames(exp_)
    #cols = get_colnames(exp_)
    #results = initiate_table1(rows=regulated_tf, cols=cols)
    #for c in cols:        
    #    temp = sort_row(exp_, c)
    #    print temp[0:10]
    #    cnt = 0
    #    for i in temp:
    #        g = i[0]
    #        if g in regulated_tf:
    #            results[g][c] = 1
    #            cnt += 1
    #            if cnt == 50:
    #                break
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/top_50_highly_expressed_VEG.txt')



    ### MERGE H3K4ME3 FILES
    #results = []
    #pathway = '/Volumes/backup/Research/bigdata/roadmap/broad_peaks/'
    #list_ = []   
    #for epi in epigenomes:  
    #     try:      
    #         temp = open(pathway+epi+'-H3K27ac.broadPeak', 'r')
    #         for i in temp:
    #             i = i.strip().split()
    #             w = int(i[2]) - int(i[1])
    #             results.append([i[0], i[1], i[2], i[3], w, epi])
    #         list_.append(epi)
    #     except:
    #         continue
    # genomics.write_file(results, '/Volumes/backup/Research/bigdata/roadmap/broad_peaks/merged/merged_H3K27ac.bed')

    # ### A LINE FOR H3K4ME3 DATA
    # line = ['']
    # for epi in list_:
    #     line[0] += epi+'-H3K27ac.broadPeak '
    # genomics.write_file_items(line, '/Users/woojunshim/Research/Data/H3K27ac_files.txt')

    ### CREATE A BED FILE (TSS +/- X)
    #genes = set(get_rownames(exp_))
    #dist = 100000
    #results_mrna = []
    #results_non = []
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/hg19_TSS.txt')
    #t = set()
    #for i in temp:        
    #    if i[2] == '+':
    #        start = int(i[3]) - dist
    #        if start < 0:
    #            start = 0
    #        end = int(i[3]) + dist
    #    elif i[2] == '-':
    #        start = int(i[4]) - dist
    #        if start < 0:
    #            start = 0
    #        end = int(i[4]) + dist
    #    if i[-1] in genes:
    #        results_mrna.append([i[1], start, end, i[0], i[2], i[-1]])
    #    else:
    #        results_non.append([i[1], start, end, i[0], i[2], i[-1]])        
    #genomics.write_file(results_mrna, '/Users/woojunshim/Research/Data/coding_tss_100kb.bed')
    #genomics.write_file(results_non, '/Users/woojunshim/Research/Data/non_coding_tss_100kb.bed')

    #genes = set(get_rownames(exp_))

    # dist = 2500  

    # temp = genomics.read_file1('/Users/woojunshim/Research/Data/FANTOM/hg19.cage_peak.txt')
    # t = {}
    # for i in temp: 
    #     name = i[-1]+'_'+i[-2]
    #     if name not in t:
    #         t[name] = 0
    #     if i[3] == '+':
    #         start = int(i[1]) - dist
    #         if start < 0:
    #             start = 0
    #         end = int(i[1]) + dist
    #     elif i[3] == '-':
    #         start = int(i[2]) - dist
    #         if start < 0:
    #             start = 0
    #         end = int(i[2]) + dist
    #     #aa = name.split('_')
    #     #gene = aa[0]
    #     #id_ = aa[1]
    #     #t[name]=[[i[0], start, end, gene, i[3], id_]]   
    #     t[name]=[[i[0], start, end, name, i[3]]] 
    # output = [t[x][0] for x in t]
    # print output[0:10]
    # genomics.write_file(output, '/Users/woojunshim/Research/Data/FANTOM/hg19_cage_2.5kb_name_merged.txt')

    # dist = 2500
    # temp = genomics.read_file1('/Users/woojunshim/Research/Data/hg19_TSS.txt')
    # t = {}
    # for i in temp: 
    #     w = int(i[4]) -int(i[3])
    #     if i[-1] not in t:
    #         t[i[-1]] = 0
    #     if i[2] == '+':
    #         start = int(i[3]) - dist
    #         if start < 0:
    #             start = 0
    #         end = int(i[3]) + dist
    #     elif i[2] == '-':
    #         start = int(i[4]) - dist
    #         if start < 0:
    #             start = 0
    #         end = int(i[4]) + dist
    #     if w > t[i[-1]] :
    #         t[i[-1]]=[[i[1], start, end, i[-1], i[2]]]   
    # output = [t[x][0] for x in t]
    # print output[0:10]
    # genomics.write_file(output, '/Users/woojunshim/Research/Data/hg19_tss_2.5kb_longest.txt')


    
    ### ANALYSIS OF LOCATIONS OF H3K27ME3 PEAKS
    #pathway = '/Volumes/backup/Research/bigdata/roadmap/broad_peaks/'


    ### CREATE BED FILE FOR EXCLUDED BROAD H3K27ME3 DOMAINS
    #pathway='/Users/woojunshim/Research/bigdata/roadmap/broad_peaks/H3K27me3/'
    #ref_ = genomics.read_file1('/Users/woojunshim/Research/Data/H3K27me3_top5_threshold.txt')
    #broad = {}
    #temp = open('/Users/woojunshim/Research/bigdata/roadmap/broad_peaks/H3K27me3/broad_H3K27me3_domains.txt', 'r')
    #for i in temp:
    #    i = i.strip().split()
    #    if i[4] not in broad:
    #        broad[i[4]] = set()
    #    broad[i[4]].add(i[3])
    #all_results = []
    #results = []
    #ref = {}
    #for i in ref_:
    #    ref[i[0]] = float(i[1])
    #for c in ref:
    #    print c
    #    thre = ref[c]
    #    temp = open(pathway+c+'-H3K27me3.broadPeak', 'r')
    #    for i in temp:
    #        i = i.strip().split()
    #        width = int(i[2])-int(i[1])
    #        if width >= thre:
    #            all_results.append([i[0], i[1], i[2], i[3], c])
    #            if i[3] not in broad[c]:
    #                results.append([i[0], i[1], i[2], i[3], c])
    #genomics.write_file(all_results, '/Users/woojunshim/Research/bigdata/roadmap/broad_peaks/merged/H3K27me3_broad_all.bed')
    #genomics.write_file(results, '/Users/woojunshim/Research/bigdata/roadmap/broad_peaks/merged/H3K27me3_broad_intergenic.bed')


    ### EXTRACT TOP 10 GO TERMS 
    #files = ['/Users/woojunshim/Research/BN/clustering/red_go.txt','/Users/woojunshim/Research/BN/clustering/yellow_go.txt','/Users/woojunshim/Research/BN/clustering/green_go.txt','/Users/woojunshim/Research/BN/clustering/blue_go.txt']
    #terms = fetch_top_go_terms(files)
    #genomics.write_file_items(terms, '/Users/woojunshim/Research/BN/clustering/selected_terms.txt')
    #names = ['Category_1','Category_2','Category_3','Category_4']
    #results = extract_elements(files, names, terms, id_idx=2, value_idx=3, log_convert=True, default_value=0.0)
    #genomics.write_table1(results, '/Users/woojunshim/Research/BN/clustering/top10_terms.txt')


    ### CREATE COORDINATES FOR LINEAR REGRESSION LINES
    #temp = read_table1('/Users/woojunshim/Research/BN/features.txt')    
    #genes = get_rownames(temp)
    #cols = [i for i in range(11)]
    #results = initiate_table1(genes, cols)
    #for g in genes:
    #    intercept = temp[g]['intercept']
    #    s = temp[g]['slope']
    #    for i in range(11):
    #        y = intercept + float(i)*s            
    #        results[g][i] = y
    #genomics.write_table1(results, '/Users/woojunshim/Research/BN/coordinates_full.txt')


    ### CREATE ROADMAP EXPRESSION TABLE FOR 45 CELL TYPES
    #cols = get_colnames(exp_)
    #cols.remove('E055')
    #print len(cols)
    #genes = get_rownames(exp_)
    #results = {}
    #for g in genes:
    #    results[g] = {}
    #    for c in cols:
    #        results[g][c] = exp_[g][c]
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/45epigenomes.RPKM.symbols.txt')

    ### NORMALISE EXP AND H3K27ME3 DATA INTO A RANGE OF [0,1]
    #k27_ = read_table1('/Users/woojunshim/Research/Data/new_assigned/H3K27me3_width_table.txt')
    #temp = read_table1('/Users/woojunshim/Research/Data/45epigenomes.RPKM.symbols.txt')   
    #k27_ = normalise_table(k27_)
    #temp = normalise_table(temp)


    ### CREATE A TABLE WITH BINS OF 5 CELL TYPES FOR AVERAGE GENE EXPRESSION VALUES
    #k27_ = read_table1('/Users/woojunshim/Research/Data/new_assigned/H3K27me3_width_table.txt')
    #temp = read_table1('/Users/woojunshim/Research/Data/45epigenomes.RPKM.symbols.txt')
    #genes = get_rownames(temp)
    #genes = genomics.intersection(genes, get_rownames(k27_))
    #cols = get_colnames(temp)
    #results = {}
    #anno = {}
    #for g in genes:
    #    aa = [[g, c, temp[g][c]] for c in cols]
    #    aa = genomics.sort_(aa, idx=2, reverse_=True)
    #    results[g] = {}
    #    anno[g] = {}
    #    for i in range(1,10):
    #        results[g][i] = 0
    #        anno[g][i] = ''
    #    cnt = 1
    #    for i in range(45):
    #        cell = aa[i][1]
    #        if i%5 == 0:
    #            bb = []
    #            cc = ''
    #        bb.append(k27_[g][cell])
            #bb.append(aa[i][2])
    #        cc = cc + (cell) + ';'
    #        if i%5 == 4:
    #            results[g][cnt] = np.mean(bb)
    #            anno[g][cnt] = cc
    #            cnt += 1
    #genomics.write_table1(results, '/Users/woojunshim/Research/BN/data/ave_k27_table_normalised.txt')
    #genomics.write_table1(anno, '/Users/woojunshim/Research/BN/data/anno_table.txt')






    ### TEST SIMILARITY OF EXPRESSED VARIABLY EXPRESSED TFS BETWEEN ROADMAP SAMPLES
    #results = {}
    #cols = get_colnames(exp_)
    #for c in cols:
    #    results[c] = set()
    #    for g in exp_:
    #        if (exp_[g][c] > float(1)) and (g in regulated_tf):
    #            results[c].add(g)
    #    results[c] = list(results[c])
    #output_ = {}
    #for c1 in cols:
    #    output_[c1] = {}
    #    for c2 in cols:
    #        a = jaccard_index(results[c1], results[c2])
    #        output_[c1][c2] = a
    #genomics.write_table1(output_, '/Users/woojunshim/Research/Data/jaccard_variably_expressed_tf')

    ### PROCESS VISTA ENHANCER FA FILE TO MAKE A BED FILE
    #temp = open('/Users/woojunshim/Research/Data/vista_enhancer/vista_enhancer.fa', 'r')
    #results = []
    #for i in temp:
    #    i = i.strip().split()
    #    if len(i) > 1:
    #        if i[0].startswith('>'):
    #            a1 = i[0].split('|')[1]
    #            a2 = a1.split(':')
    #            chr_ = a2[0]
    #            a3 = a2[1].split('-')
    #            start_ = a3[0]
    #            end_ = a3[1]
    #            name = i[2]+'_'+i[3]
    #            results.append([chr_, start_, end_, name])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/vista_enhancer/vista_enhancer_hg19.bed')




    ### CHECK NUMBER OF LINES 
    #temp = open('/Users/woojunshim/Research/bigdata/roadmap/broad_peaks/H3K27me3/merged_H3K27me3_sorted.bed', 'r')
    #results = {}
    #for i in temp:
    #    i = i.strip().split()
    #    if i[-1] not in results:
    #        results[i[-1]] = 0
    #    results[i[-1]] += 1
    #genomics.write_file(results, '/Users/woojunshim/Research/bigdata/roadmap/broad_peaks/H3K27me3/peak_counts.txt')

    ### CHECK THE NUMBER OF CELL TYPES
    #temp = open('/Volumes/backup/Research/bigdata/roadmap/broad_peaks/H3K27me3/merged_H3K27me3.bed', 'r')
    #results = set()
    #for i in temp:
    #    i = i.strip().split()
    #    results.add(i[5])
    #print len(results)


    ### TABLE FOR FINDING K 
    #k27_ = read_table1('/Users/woojunshim/Research/Data/new_assigned/H3K27me3_width_table.txt')
    #cols = get_colnames(exp_)
    #results = []
    #results.append(['#gene','diff','number','group','ave.k27','ave.exp'])
    #for g in house:
    #    if (g in exp_) and (g in k27_):
    #        temp_exp = [[float(exp_[g][c]), c] for c in cols]
    #        temp_exp = genomics.sort_(temp_exp, reverse_=False, idx=0)   
    #        temp_exp_ = [x[0] for x in temp_exp]         
    #        temp_k27_p = [float(k27_[g][x[1]]) for x in temp_exp]
    #        temp_k27_n = temp_k27_p[::-1]
    #        for i in range(0, 46):
    #            pos, neg = float(np.sum(temp_k27_p[0:i+1]))/(i+1), float(np.sum(temp_k27_n[0:i+1]))/(i+1)
    #            results.append([g, pos-neg, i+1, 'House_keeping_genes', pos, np.sum(temp_exp_[0:i+1])/(i+1)])
    #print 'VET'
    #for g in regulated_tf:
    #    if (g in exp_) and (g in k27_):
    #        temp_exp = [[float(exp_[g][c]), c] for c in cols]
    #        temp_exp = genomics.sort_(temp_exp, reverse_=False, idx=0)   
    #        temp_exp_ = [x[0] for x in temp_exp]         
    #        temp_k27_p = [float(k27_[g][x[1]]) for x in temp_exp]
    #        temp_k27_n = temp_k27_p[::-1]
    #        for i in range(0, 46):
    #            pos, neg = float(np.sum(temp_k27_p[0:i+1]))/(i+1), float(np.sum(temp_k27_n[0:i+1]))/(i+1)
    #            results.append([g, pos-neg, i+1, 'Variably_expressed_TF', pos, float(np.sum(temp_exp_[0:i+1]))/(i+1)])
    #genomics.write_file(results, '/Users/woojunshim/Research/BN/knn_table.txt')          


    #
    #k27_ = read_table1('/Users/woojunshim/Research/Data/new_assigned/H3K27me3_width_table.txt')
    #cols = get_colnames(exp_)
    #results = []  
    #results.append(['#gene','Ave_K27','number','group'])  
    #for g in house:
    #    if (g in exp_) and (g in k27_):
    #        temp_exp = [[float(exp_[g][c]), c] for c in cols]
    #        temp_exp = genomics.sort_(temp_exp, reverse_=False, idx=0)   
    #        temp_exp_ = [x[0] for x in temp_exp]         
    #        temp_k27_ = [float(k27_[g][x[1]]) for x in temp_exp]    
    #        mean_, sd_ = np.mean(temp_k27_), np.std(temp_k27_)        
    #        for i in range(0, 46):
    #            pos = float(np.sum(temp_k27_[0:i+1]))/(i+1)
    #            value = (pos - mean_) / sd_
    #            results.append([g, value, i+1, 'House_keeping_genes'])
    #print 'VET'
    #for g in regulated_tf:
    #    if (g in exp_) and (g in k27_):
    #        temp_exp = [[float(exp_[g][c]), c] for c in cols]
    #        temp_exp = genomics.sort_(temp_exp, reverse_=False, idx=0)   
    #        temp_exp_ = [x[0] for x in temp_exp]         
    #        temp_k27_ = [float(k27_[g][x[1]]) for x in temp_exp]    
    #        mean_, sd_ = np.mean(temp_k27_), np.std(temp_k27_)        
    #        for i in range(0, 46):
    #            pos = float(np.sum(temp_k27_[0:i+1]))/(i+1)
    #            value = (pos - mean_) / sd_
    #            results.append([g, value, i+1, 'Variably_expressed_TFs'])
                    
    #genomics.write_file(results, '/Users/woojunshim/Research/BN/k27_sorted_by_exp.txt')  
    

    ### TOP 1% DS GENES FOR ROADMAP SAMPLES
    #pathway = '/Users/woojunshim/Research/Data/roadmap_ds/'
    #cols = ['E087','E038','E070','E095','E096']
    #cols = genomics.read_file_items('/Users/woojunshim/Research/Data/roadmap_ds/order_cols.txt')
    #files = []
    #for c in cols:
    #    files.append(pathway+c+'_top1.txt')
    #names = ['Pancreatic_Islets','Primary_T_helper_naive_cells_from_peripheral_blood','Brain_Germinal_Matrix','Left_Ventricle','Lung']
    #names = genomics.read_file_items('/Users/woojunshim/Research/Data/roadmap_ds/desc_cols.txt')
    #ids = genomics.read_file_items('/Users/woojunshim/Research/Data/roadmap_ds/selected_terms_all.txt')
    #results = extract_elements(files, names, ids, id_idx=2, value_idx=3, log_convert=True, default_value=0.0)
    #genomics.write_table1(results, pathway+'top1_ds_table_all.txt')
    #genomics.write_file_items(names, pathway+'colnames.txt')


    ### CALCULATE DS FOR ROADMAP SAMPLES
    #results = calculate_discordance_for_table('/Users/woojunshim/Research/Data/GTEX/GTEX_tissue_exp_ave_table.txt', ref, rows=None, cols=None, log=True, pseudo=1)
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/GTEX/GTEX_tissue_discordance.txt')

    ### CALCULATE DISTRIBUTIONS (AS PROPORTIONS) OF THE PRIORITY GENES ACROSS ROADMAP SAMPLES
    #ref_ = genomics.read_file1('/Users/woojunshim/Research/Data/new_assigned/tables/repressive_hg19_cont_prop.txt', sort_by=1)
    #ref = []
    #for a in range(1359):
    #    i = ref_[a]
    #    ref.append(i[0])
    #results = prop_membership_for_matrix('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols_discordance.txt', ref, bins=100)
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/priority_gene_dist.txt') 


    ### TESTING TO ENSURE
    #temp = genomics.read_file1('/Users/woojunshim/Research/BN/data/h3k27me3.tsv')
    #tf = set()
    #cnt = 0
    #results = []
    #for i in temp:
    #    tf.add(i[1])
    #    if float(i[2]) != float(0):
    #        cnt += 1
    #        results.append(np.log2(float(i[2])))
    #print len(tf), cnt
    #results.sort(reverse=True)
    #print results[0:10]
    #genomics.write_file(results, '/Users/woojunshim/Research/BN/data/h3k27me3_signal2.tsv')


    ### CREATE A MOCK DATA FOR EM
    #nums = [1,2,3,4,5,100,110,120,130,140]
    #results = []
    #for n in nums:
    #    for i in range(1000):
    #        results.append(n+i*0.001)
    #genomics.write_file(results, '/Users/woojunshim/Research/BN/data/mock.tsv')

    ### CREATE TSC FILES
    #exp_ = read_table1('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols_z.txt', numerical=True)

    #genes = ['PTF1A','GATA4','NEUROD2','TNNI3','GFAP','EEF2','NKX2-5','SIX3','GNAS']
    #genes = ['NFIC','NCKAP1','GPR82','KANSL1','MAGEC1','UBL4B']
    #k27 = read_table1('/Users/woojunshim/Research/Data/new_assigned/H3K27me3_width_table.txt')    
    #for g in k27:
    #    for c in k27[g]:
    #        k27[g][c] = k27[g][c]
    #genomics.write_table1(k27, '/Users/woojunshim/Research/Data/new_assigned/H3K27me3_log2width_table.txt')
    #cols = get_colnames(exp_)    
    #for gene in genes:
    #    results = []
    #    for c in cols:            
    #        results.append([np.log2(exp_[gene][c]+1), k27[gene][c], c])
            #results.append([exp_[gene][c], k27[gene][c], c])
    #    genomics.write_file(results, '/Users/woojunshim/Research/BN/data/'+gene+'.tsv')

    #rows = genomics.intersection(get_rownames(exp_), get_rownames(k27))
    #for r in rows:
    #    for c in cols:
    #        results.append([np.log2(exp_[r][c]+1), k27[r][c], r, c])
    #genomics.write_file(results, '/Users/woojunshim/Research/BN/data/all_data.tsv')

    ### ROADMAP DISCORDANCE SCORE TABLE
    #results=calculate_discordance_for_table(exp_, ref, rows=None, cols=None, log=True, pseudo=1)
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols_ds.txt')


    ### CREATE A BINARY TABLE FOR BROAD H3K27ME3 DOMAINS
    #temp = read_table1('/Users/woojunshim/Research/Data/new_assigned/H3K27me3_width_table.txt')
    #results = initiate_table(temp)
    #genes = get_rownames(temp)
    #cols = get_colnames(temp)
    #for c in cols:
    #    aa = sort_row(temp, c)
    #    idx = len(aa) / 20
    #    for i in range(idx):            
    #        results[aa[i]][c] = 1
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/new_assigned/H3K27me3_broad_table.txt')



    ### SORT CSV TO TXT
    #pathway = '/Users/woojunshim/Research/Data/inter-species/skeletal muscle/'
    #files = ['discordance - Danio rerio','discordance - Drosophila melanogaster','discordance - Gallus Gallus','discordance - Homo sapiens','discordance - Mus musculus','discordance - Cavia porcellus','discordance - Ciona intestinalis','discordance - Sus scrofa','discordance - Anas platyrhynchos','discordance - Bos taurus','discordance - Macaca mulatta']
    
    #for f in files:
    #    try:
    #        temp = genomics.read_csv(pathway+f+'.csv')
    #        results = []
    #        for i in temp:
    #            results.append([i[0],i[1],i[4],i[5]])
    #        genomics.write_file(results, pathway+'/processed/'+f+'.txt')
    #    except:
    #        continue

    #### INTERSPECIES ANALYSIS 

    #files = ['discordance - Danio rerio','discordance - Drosophila melanogaster','discordance - Gallus Gallus','discordance - Homo sapiens','discordance - Mus musculus','discordance - Cavia porcellus','discordance - Ciona intestinalis','discordance - Sus scrofa','discordance - Anas platyrhynchos','discordance - Bos taurus','discordance - Macaca mulatta']
    #pathway = '/Users/woojunshim/Research/Data/inter-species/'
    #organs = ['brain','heart','kidney','liver','lung','skeletal muscle']
    #positives = ['GO.0007420','GO.0003007','GO.0001822','GO.0001889','GO.0030324','GO.0001501']
    #terms = ['Brain development','Heart morphogenesis','Kidney development','Liver development','Lung development','Skeletal system development']
    #species = []
    #thre = 100
    #for f in files:
    #    name = f.split('-')[1]
    #    species.append(name[1:])
    #print species
    #results1 = initiate_table1(rows=terms, cols=species, initial_value='NA')
    #results2 = initiate_table1(rows=terms, cols=species, initial_value='NA')
    #output1, output2 = [], []

    #for no in range(len(organs)):
    #    o = organs[no]
    #    print 
    #    pathway_ = pathway+o+'/processed/'        
    #    temp = read_table1('/Users/woojunshim/Research/Data/genes_with_go_term/'+positives[no]+'.txt', numerical=False)
    #    aa = []
    #    for m in temp:
    #        aa.append(temp[m]['x'])
        #pos = genomics.intersection(aa, tf_list)
    #    pos = aa

    #    for f in files:
    #        try:
    #            name_ = f.split('-')[1]  
    #            name = name_[1:]              
    #            temp = genomics.read_file1(pathway_+f+'.txt')
    #            temp = temp[1:]
    #            aa = []            
    #            for i in temp:
    #                aa.append([i[1], float(i[2]), float(i[3])])                
    #            exp_ = genomics.sort_(aa, idx=1, reverse_=True)
    #            dis_ = genomics.sort_(aa, idx=2, reverse_=True)
    #            exp, dis = [], []
    #            for i in exp_:
    #                exp.append(i[0])
    #            for i in dis_:
    #                dis.append(i[0])
    #            q1 = point_fet1(input_list=exp, ref_list=pos, cut_off=100)
    #            q2 = point_fet1(input_list=dis, ref_list=pos, cut_off=100)
                #output1.append([terms[no],name,q1])
                #output2.append([terms[no],name,q2])
                
    #            results1[terms[no]][name] = q1
    #            results2[terms[no]][name] = q2
    #        except:
    #            continue

    #genomics.write_table1(results1, pathway+'inter-species_fet_exp_all.txt')
    #genomics.write_table1(results2, pathway+'inter-species_fet_dis_all.txt')

    #temp = genomics.read_file1(pathway+'ChickenBrainTimecourse.txt')
    #results = []
    #for i in temp:
    #    results.append([i[0],i[1],i[-2],i[-1]])
    #genomics.write_file(results, pathway+'/processed/discordance - Galus galus.txt')

    ### CREATE RTS TABLE FOR MOUSE (SIMPLY BY MAPPING HUMAND GENES TO MOUSE GENES) 
    #results = []
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/Tabula_Muris/mouse_human_gene_mapping_table.txt')
    #for i in temp:
    #    if len(i) > 1:
    #        if i[1] in ref:
    #            results.append([i[0], ref[i[1]]])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/new_assigned/tables/mapped_rts_mouse.txt')

    ### CREATE MOUSE DATA SET BY MAPPING BETWEEN HUMAN AND MOUSE
    #aa = genomics.read_file1('example_input1.txt')
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/Tabula_Muris/mouse_human_gene_mapping_table.txt')
    #ref = {}
    #results = []
    #for i in temp:
    #    if len(i) > 1:
    #        ref[i[1]] = i[0]
    #for i in range(len(aa)):
    #    item = aa[i]
    #    g = item[0]
    #    if g in ref:
    #        results.append([ref[g], item[1], item[2], item[3]])

    #genomics.write_file(results, 'example_input_mouse.txt')


    ### CREATE TSV FILES FOR H3K27ME3 AND RNA-SEQ 
    #k27 = read_table1('/Users/woojunshim/Research/Data/new_assigned/H3K27me3_width_table.txt')
    #genes = genomics.intersection(get_rownames(k27), get_rownames(exp_))
    #print len(genes)
    #genes = genomics.intersection(genes, tf_list)
    #print len(genes)
    #results = []
    #col1 = get_colnames(k27)
    #col2 = get_colnames(exp_)  
    #print len(col1), len(col2)  
    #for g in genes:
    #    for c in col1:
    #        results.append([c, g, int(k27[g][c])])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/remap/data/h3k27me3.tsv')
    #results = []
    #for g in genes:
    #    for c in col2:
    #        results.append([c, g, exp_[g][c]])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/remap/data/rpkm.tsv')   

    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/new_assigned/tables/repressive_hg19_cont_prop.txt', sort_by=1)
    #cnt = 0
    #for i in range(len(temp)):
    #    if cnt < 1359:
    #        tag = 'Y'
    #    else:
    #        tag = 'N'
    #    cnt += 1
    #    temp[i].extend([tag])
    #genomics.write_file(temp, '/Users/woojunshim/Research/Data/new_assigned/tables/repressive_hg19_cont_prop_new.txt')



    ### ADD HUMAN GENE SYMBOLS
    ### AND CREATE A MOUSE VERSION OF VARIABLY EXPRESSED TF
    #ref = genomics.read_file1('/Users/woojunshim/Research/Data/gene_annotate.txt')
    #m = genomics.read_file_dic('/Users/woojunshim/Research/Data/human_mouse_gene_symbols.txt', col_idx=1, id_idx=0,numerical=False)
    #for i in range(len(ref)):
    #    gene = ref[i][-1]
    #    if gene in m:
    #        label = m[gene]
    #    else:
    #        label = 'NA'
    #    ref[i].extend([label])
    #genomics.write_file(ref, '/Users/woojunshim/Research/Data/human_mouse_gene_annotation.txt')
    #m = genomics.read_file_dic('/Users/woojunshim/Research/Data/human_mouse_gene_symbols.txt', col_idx=0, id_idx=1,numerical=False)
    #results = []
    #for i in m:
    #    if i in regulated_tf:
    #        results.append(m[i])
    #genomics.write_file_items(results, '/Users/woojunshim/Research/Data/variably_expressed_tf_mouse.txt')

    #tt = genomics.read_file_dic('/Users/woojunshim/Research/Data/human_mouse_gene_annotation.txt', id_idx=3, col_idx=0, numerical=False)
    #results = []
    #for i in tt:
    #    if i in regulated_tf:
    #        label = tt[i].split('.')[0]
    #        results.append(label)
    #genomics.write_file_items(results, '/Users/woojunshim/Research/Data/variably_expressed_tf_mouse_ensembl.txt')



    ### CREATE A CONVERSION TABLE BETWEEN MOUSE AND HUMAN GENE SYMBOLS
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/mouse_to_human.txt')
    #results = {}
    #cnt = 0
    #for i in temp:
    #    if int(i[0]) != cnt:
    #        results[i[3]] = 'NA'
    #        gene = i[3]
    #        cnt = int(i[0])
    #    else:
    #        results[gene] = i[3]
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/human_mouse_gene_symbols.txt')

    ### SC CARDIAC DATA FOR DAY 30
    #input_ = read_table1('/Users/woojunshim/Research/cardiac_sc/ds/ds_d30.txt')
    #input_ = read_table1('/Users/woojunshim/Research/cardiac_sc/exp/exp_d30.txt')
    #ref = genomics.read_file_items('/Users/woojunshim/Research/Data/genes_with_go_term/GO.0007507_tf.txt')    
    #ref = list_from_table('/Users/woojunshim/Research/Data/genes_with_go_term/GO.0030017.txt', 'x')
    #ref = genomics.read_file_items('/Users/woojunshim/Research/Data/house_keeping_genes.txt', col=0)
    #ref = genomics.read_file_items('/Users/woojunshim/Research/Data/KEGG/heart_signaling_genes.txt')
    #results = prop_membership_for_matrix(input_, ref, bins=100)
    #results = fet_for_matrix(input_, ref)    
    #output_ = []
    #for i in results:
    #    temp = []
    #    for j in range(1, len(i)):
    #        aa = i[j]
    #        temp.append([aa, j])
    #    temp = genomics.sort_(temp, idx=0, reverse_=False)
    #    output_.append([i[0]])
    #    for m in range(len(temp)):
    #        output_[-1].extend([0])
    #    for p in range(1, 101):
    #        output_[-1][p] = temp[p-1][1]
    #genomics.write_file(output_, '/Users/woojunshim/Research/cardiac_sc/ds/exp_d30_heart_signaling_rank.txt')

    #genomics.write_file(results, '/Users/woojunshim/Research/cardiac_sc/ds/exp_d30_heart_development_tf_fet.txt')


    ### ANALYSIS ON CARDIAC SC DATA FOR DAY 30 
    #input_ = read_table1('/Users/woojunshim/Research/cardiac_sc/ds/ds_d30.txt')
    #input_ = read_table1('/Users/woojunshim/Research/cardiac_sc/exp/exp_d30.txt')
    #ref = genomics.read_file_items('/Users/woojunshim/Research/Data/genes_with_go_term/GO.0007507_tf.txt')
    #ref = regulated_tf
    #ref = list_from_table('/Users/woojunshim/Research/Data/genes_with_go_term/GO.0030017.txt', 'x')
    #ref = genomics.read_file_items('/Users/woojunshim/Research/Data/house_keeping_genes.txt', col=0)
    #ref = genomics.read_file_items('/Users/woojunshim/Research/Data/KEGG/heart_signaling_genes.txt')
    #results = prop_membership_for_matrix(input_, ref, bins=100)
    #genomics.write_file(results, '/Users/woojunshim/Research/cardiac_sc/ds/exp_d30_heart_development_tf.txt')

    ### FIND A GENE SET FOR CARDIAC SIGNALLING 
    #terms = genomics.read_file_items('/Users/woojunshim/Research/Data/KEGG/signaling_terms.txt')
    #table_ = read_table1('/Users/woojunshim/Research/Data/KEGG/gene_kegg_table.txt')
    #genes = []
    #for g in table_:
    #    for t in terms:
    #        if table_[g][t] == float(1):
    #            genes.append(g)
    #genes = list(set(genes))
    #genomics.write_file_items(genes, '/Users/woojunshim/Research/Data/KEGG/signaling_genes.txt')
    #aa = read_table1('/Users/woojunshim/Research/Data/genes_with_go_term/GO.0007507.txt', numerical=False)
    #a = []
    #for c in aa:
    #    a.append(aa[c]['x'])
    #results = genomics.intersection(genes, a)
    #genomics.write_file_items(results, '/Users/woojunshim/Research/Data/KEGG/heart_signaling_genes.txt')

    ### CONVERT REMAP COUNT TABLES TO PROPORTIONS
    #results = convert_to_proportion_t('/Users/woojunshim/Research/Data/remap/overall_counts.txt')
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/remap/non-specific_scores.txt')


    ### CREATE CELL-TYPE SPECIFIC TF REGULATORY TABLE
    #temp = open('/Users/woojunshim/Research/Data/remap/remap_promoter_overlap.txt', 'r')
    #genes, cols = set(), set()
    #collected = {}
    #for i in temp:
    #    i = i.strip().split()
    #    aa = i[3].split('.')
    #    g = aa[1]
    #    c = aa[-1].split('_')[0]
    #    if c not in collected:
    #        collected[c] = []
    #    collected[c].append([aa[0],g,aa[-1],i[-2]])
    #    if g not in genes:
    #        genes.add(g)        
    #    if c not in cols:
    #        cols.add(c)
    #print len(genes), len(cols) 
    #track = set()   
    #for c in cols:
    #    print c        
    #    results = initiate_table1(rows=list(genes), cols=list(genes))     

    #    for i in collected[c]:
    #        if (i[1] in genes) and (i[-1] in genes):
    #            s = i[0]+i[1]+i[2]+i[3]
    #            if s not in track:
    #                results[i[1]][i[3]] += 1
    #                track.add(s)
    #    genomics.write_table1(results, '/Users/woojunshim/Research/Data/remap/specific/counts/'+c+'_counts.txt')
    #track = set()  
    #results = initiate_table1(rows=list(genes), cols=list(genes))   
    #for c in cols:
    #    print c 
    #    for i in collected[c]:
    #        if (i[1] in genes) and (i[-1] in genes):
    #            s = i[0]+i[1]+i[2]+i[3]
    #            if s not in track:
    #                results[i[1]][i[3]] += 1
    #                track.add(s)
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/remap/overall_counts.txt')

    ### IDENTIFY CELL-TYPES WHERE AT LEAST 1 TFBS SAMPLE DATA IS AVAILABLE 
    #temp = read_table1('/Users/woojunshim/Research/Data/remap/sample_counts_matrix.txt')
    #results = []
    #genes = get_rownames(temp)
    #cols = get_colnames(temp)
    #for c in cols:
    #    cnt = 0
    #    for g in genes:
    #        cnt += temp[g][c]
    #    if cnt != float(0):
    #        results.append([c, int(cnt)])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/remap/selected_cell_types.txt')



    ### CREATE COUNT TABLE FOR REMAP 
    #temp = open('/Users/woojunshim/Research/Data/remap/remap_promoter_overlap.txt', 'r')
    #genes, cols = set(), set()
    #for i in temp:
    #    i = i.strip().split()
    #    aa = i[3].split('.')
    #    g = aa[1]
    #    c = aa[-1].split('_')[0]
    #    if g not in genes:
    #        genes.add(g)        
    #    if c not in cols:
    #        cols.add(c)
    #print len(genes), len(cols)
    #results = initiate_table1(rows=list(genes), cols=list(cols))
    #temp = open('/Users/woojunshim/Research/Data/remap/remap_promoter_overlap.txt', 'r')
    #record = set()
    #for i in temp:
    #    i = i.strip().split()
    #    aa = i[3].split('.')
    #    g = aa[1]
    #    c = aa[-1].split('_')[0]
    #    s = i[3]       
    #    if s not in record:            
    #        results[g][c] += 1
    #        record.add(s)
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/remap/sample_counts_matrix.txt')


    ### STATISTICS FOR 1359 GENES
    #ref_ = genomics.read_file1('/Users/woojunshim/Research/Data/new_assigned/tables/repressive_hg19_cont_prop.txt', sort_by=1)
    #cnt = 0
    #positive = set(genomics.read_file_items('/Users/woojunshim/Research/Data/ncRNAs.txt'))
    #pos = read_table1('/Users/woojunshim/Research/Data/KEGG/gene_kegg_table.txt')
    #positive = set()
    #cols = ['hsa04310','hsa04340','hsa04330','hsa04350','hsa04010','hsa04020']
    #for g in pos:
    #    for c in pos[g]:
    #        if pos[g][c] == float(1):
    #            positive.add(g)
    #for i in range(1359):
    #    if ref_[i][0] in positive:
    #        cnt += 1
    #print cnt
    #input_ = []
    #for i in ref_:
    #    input_.append(i[0])
    #a = point_fet1(input_, list(positive), cut_off=1359)
    #print a



    ### FINDING A TF OF HIGH HIERARCHY 
    

    ### COMBINE DE RESULTS INTO ONE
    #a = read_table1('/Users/woojunshim/Research/cardiac_sc/comparison/d30c2_vs_c1_heart_development_fet.txt')
    #b = read_table1('/Users/woojunshim/Research/cardiac_sc/comparison/d30c2_vs_c1_heart_development_fet.txt')
    #genes = genomics.intersection(get_rownames(a), get_rownames(b))
    #results = initiate_table1(rows=genes, cols=['DE_C1','DE_C3','Expression','Discordance'])
    #for g in genes:
    #    results[g]['DE_C1'] = a[g]['DE']
    #    results[g]['DE_C3'] = b[g]['DE']
    #    results[g]['Expression'] = a[g]['Expression']
    #    results[g]['Discordance'] = a[g]['Discordance']
    #genomics.write_table1(results, '/Users/woojunshim/Research/cardiac_sc/comparison/d2c2_table.txt')


    ### EXTRACT TOP 6 GO TERMS FOR EACH GENE SET
    #files = ['/Users/woojunshim/Research/Data/1359/first_1359_bp.txt', '/Users/woojunshim/Research/Data/1359/second_1359_bp.txt', '/Users/woojunshim/Research/Data/1359/bottom_1359_bp.txt']
    #ids = ['multicellular_organism_development','system_development','anatomical_structure_development','developmental_process','pattern_specification_process','multicellular_organismal_process','cell-cell_signaling','cell_communication','nervous_system_development','anatomical_structure_morphogenesis','RNA_processing','posttranscriptional_gene_silencing','gene_silencing_by_RNA','gene_expression','macromolecule_metabolic_process']
    #results = extract_elements(files, names=['Top_1359','Second_1359','Bottom_1359'], ids=ids, id_idx=2, value_idx=3, log_convert=False, default_value=1.0)
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/1359/selected_terms_p.txt')


    ### COMBINE EXPRESSION DATA INTO A TABLE
    #pathway = '/Users/woojunshim/Research/cardiac_sc/exp/'
    #a = genomics.read_csv(pathway+'d30c1_old.csv')
    #b = genomics.read_csv(pathway+'d30c2_old.csv')
    #c = genomics.read_csv(pathway+'d2c3_old.csv')
    #genes = set()
    #print a[0:10]
    #for i in a:
    #    if i[0] != 'gene':
    #        if i[0] not in genes:
    #            genes.add(i[0])
    #for i in b:
    #    if i[0] != 'gene':
    #        if i[0] not in genes:
    #            genes.add(i[0])   
    #for i in c:
    #    if i[0] != 'gene':
    #        if i[0] not in genes:
    #            genes.add(i[0])  
    #print len(genes)
    #results = initiate_table1(rows=genes, cols=['d2c1_old','d2c2_old','d2c3_old'])
    #results = initiate_table1(rows=genes, cols=['d30c1_old','d30c2_old'])
    #for i in a:
    #    if i[0] != 'gene':            
    #        results[i[0]]['d30c1_old'] = i[1]    
    #for i in b:
    #    if i[0] != 'gene':            
    #        results[i[0]]['d30c2_old'] = i[1]  
    #for i in c:
    #    if i[0] != 'gene':            
    #        results[i[0]]['d2c3_old'] = i[1]  
    #genomics.write_table1(results, pathway+'exp_d30_.txt')


    #results = calculate_discordance_for_table('/Users/woojunshim/Research/cardiac_sc/exp/exp_d30.txt', ref, rows=None, cols=None, log=True, pseudo=1)
    #genomics.write_table1(results, '/Users/woojunshim/Research/cardiac_sc/ds/ds_d30.txt')

    ### IDENTIFY TOP 50 VARIABLY EXPRESSED TFS ACROSS CELL-TYPES
    #results = []
    #cols = get_colnames(exp_)
    #genes = get_rownames(exp_)
    #results = initiate_table1(genes, cols)
    #for c in cols:
    #    temp = []
    #    for g in genes:
    #        if g in regulated_tf:
    #            if exp_[g][c] > 1:
    #                temp.append([g, exp_[g][c]])
    #    temp = genomics.sort_(temp, idx=1, reverse_=True)
    #    for i in range(50):
    #        results[temp[i][0]][c] = 1
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/logit_regression/top50_variably_expressed_tfs.txt')



    ### COLLATE ALL DATA FOR HM BREADTHS ACROSS CELL-TYPES
    #ref = read_table1('/Users/woojunshim/Research/Data/logit_regression/top50_variably_expressed_tfs.txt')
    #k27ac = read_table1('/Users/woojunshim/Research/Data/new_assigned/H3K27ac_tss_2.5kb_combined_z.txt')
    #k4me1 = read_table1('/Users/woojunshim/Research/Data/new_assigned/H3K4me1_tss_2.5kb_combined_z.txt')
    #k4me3 = read_table1('/Users/woojunshim/Research/Data/new_assigned/H3K4me3_tss_2.5kb_combined_z.txt')
    #k9me3 = read_table1('/Users/woojunshim/Research/Data/new_assigned/H3K9me3_tss_2.5kb_combined_z.txt')
    #k27me3 = read_table1('/Users/woojunshim/Research/Data/new_assigned/H3K27me3_tss_2.5kb_combined_z.txt')
    #k36me3 = read_table1('/Users/woojunshim/Research/Data/new_assigned/H3K36me3_tss_2.5kb_combined_z.txt')
    #cols = genomics.intersection(get_colnames(k27ac), get_colnames(exp_))
    #genes = genomics.intersection(get_rownames(k4me1), get_rownames(k4me3))
    #genes = genomics.intersection(genes, get_rownames(k9me3))
    #genes = genomics.intersection(genes, get_rownames(k27ac))
    #genes = genomics.intersection(genes, get_rownames(k27me3))
    #genes = genomics.intersection(genes, get_rownames(k36me3))
    #print len(genes)
    #results = [['#gene','h3k4me1','h3k4me3','h3k9me3','h3k27ac','h3k27me3','h3k36me3','cell_type','regulatory']]
    #for g in genes:
    #    for c in cols:
    #        if g in ref:
    #            if ref[g][c] == float(1):
    #                tag = 1
    #            else:
    #                tag = 0
    #        else:
    #            tag = 0
    #        results.append([g, k4me1[g][c], k4me3[g][c], k9me3[g][c], k27ac[g][c], k27me3[g][c], k36me3[g][c], c, tag])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/logit_regression/inputs.txt')


    ### DE ANALYSIS FOR CARDIC SC DATA
    #des = ['/Users/woojunshim/Research/cardiac_sc/exp/d2_c1_vs_c2_de.txt', '/Users/woojunshim/Research/cardiac_sc/exp/d2_c1_vs_c3_de.txt', '/Users/woojunshim/Research/cardiac_sc/exp/d2_c2_vs_c3_de.txt', '/Users/woojunshim/Research/cardiac_sc/exp/d30_de.txt']
    #de = genomics.read_file1('/Users/woojunshim/Research/cardiac_sc/exp/d30_de.txt', cols=[0,11], numerical=False)
    #exp_ = read_table1('/Users/woojunshim/Research/cardiac_sc/exp/exp_d30.txt')
    #exp_genes = []
    #exp_label = 'd30c2_old'
    #label = 'd30c2'
    #for g in exp_:
    #    if exp_[g][exp_label] > 0:
    #        exp_genes.append(g)
    #dis_ = read_table1('/Users/woojunshim/Research/cardiac_sc/ds/ds_d30.txt', numerical=False)
    #dis_genes = []    
    #for g in dis_:
    #    if dis_[g][exp_label] != 'NA':            
    #        dis_genes.append(g)      
    #de = genomics.sort_(de, idx=1, reverse_=True)
    #de_genes = []
    #for i in de:        
    #    de_genes.append(i[0])
    #genes = []
    #genes = genomics.intersection(de_genes, exp_genes)
    #genes = genomics.intersection(genes, dis_genes)
    #results = initiate_table1(rows=genes, cols=['Expression','DE','Discordance'])
    #for g in genes:
    #    results[g]['Expression'] = exp_[g][exp_label]
    #    results[g]['Discordance'] = dis_[g][exp_label]
    #cnt = len(de)
    #for i in de:
    #    if i[0] in results:
    #        results[i[0]]['DE'] = cnt
    #    cnt -= 1
    #genomics.write_table1(results, '/Users/woojunshim/Research/cardiac_sc/comparison/'+label+'_vs_c1_table.txt')

    
    ### ENRICHMENT TEST FOR DE GENES FOR SINGLE-CELL CARDIAC DATASETS
    #ref_ = read_table1('/Users/woojunshim/Research/Data/genes_with_go_term/GO.0007498.txt', numerical=False)
    #ref = []
    #for i in ref_:
    #    ref.append(ref_[i]['x'])
    #results = fet_for_matrix('/Users/woojunshim/Research/cardiac_sc/comparison/d2c2_table.txt', ref)
    #genomics.write_file(results, '/Users/woojunshim/Research/cardiac_sc/comparison/d2c2_mesoderm_fet.txt')



    ### EXTRACT BROAD H3K27ME3 DOMAINS FROM ENCODE HUMAN DATA FOR FIBROBLAST 
    #temp = genomics.read_file1('/Users/woojunshim/Research/bigdata/ENCODE/hg19/ENCODE_human_H3K27me3_samples_description.txt')
    #cols = []
    #for i in temp:
    #    if 'fibroblast' in i[1]:
    #        cols.append(i[0])

    #print cols
    #ids = read_table1('/Users/woojunshim/Research/bigdata/ENCODE/hg19/H3K27me3/ENCODE_human_H3K27me3_assigned_id.txt', numerical=False)
    #widths = read_table1('/Users/woojunshim/Research/bigdata/ENCODE/hg19/H3K27me3/ENCODE_human_H3K27me3_breadth.txt')
    #cc = get_colnames(widths)
    #genes = get_rownames(widths)
    #broad = initiate_table(widths)
    #for c in cc:
    #    temp = []
    #    for g in genes:
    #        if widths[g][c] != float(0):
    #            temp.append([g, widths[g][c]])
    #    temp = genomics.sort_(temp, idx=1, reverse_=True)
    #    idx = len(temp) / 20
    #    qq = set()
    #    for i in range(idx):
    #        qq.add(ids[temp[i][0]][c])
    #        broad[temp[i][0]][c] = 1
    #    file_ = genomics.read_file1('/Users/woojunshim/Research/bigdata/ENCODE/hg19/H3K27me3/'+c+'.bed')
    #    results = []
    #    for j in file_:
    #        if j[3] in qq:
    #            results.append([j[0], j[1], j[2], j[3]])
    #    genomics.write_file(results, '/Users/woojunshim/Research/bigdata/ENCODE/hg19/H3K27me3/broad/'+c+'_broad.bed')
    #genomics.write_table1(broad, '/Users/woojunshim/Research/bigdata/ENCODE/hg19/H3K27me3/ENCODE_human_H3K27me3_broad.txt')

    #genes = ['TBX20','LTBP4','FXYD1','CXCL14','NAV1','FOSL2','FNDC3B','ASS1','CRISPLD2','SOCS2','TSPAN4','ADAMTS5','FNDC3A','THBS1','SPARCL1']
    #broad = read_table1('/Users/woojunshim/Research/bigdata/ENCODE/hg19/H3K27me3/ENCODE_human_H3K27me3_broad.txt')
    #broad = read_table1('/Users/woojunshim/Research/Data/new_assigned/H3K27me3_top5_binary_table.txt')
    #results = []
    #cc = get_colnames(broad)
    #for g in genes:
    #    if g not in broad:
    #        results.append([g, 'NA'])
    #    else:
    #        pos = 0            
    #        for c in cc:
    #            pos += broad[g][c]
    #        results.append([g, float(pos)/len(cc)])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/new_assigned/Roadmap_selected_genes_prop.txt')







    ### SEPARATE 'H3K27ME3_BROAD_DOMAINS.TXT' INTO CELL-TYPES
    #cell = 'E065'
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/new_assigned/broad/H3K27me3_broad_domains.txt')
    #results = []
    #for i in temp:
    #    if i[4] != cell:
    #        genomics.write_file(results, '/Users/woojunshim/Research/Data/new_assigned/broad/'+cell+'_broad.bed')
    #        results = [[i[0], i[1], i[2], i[3]]]
    #        cell = i[4]
    #    else:
    #        results.append([i[0], i[1], i[2], i[3]])

    ### CALCULATE BROAD DOMAIN PROPS AND WHETHER IN FIBROBLAST 




    ### CREATE A BREADTH TABLE FROM ASSIGNED PEAK FILE
    #a,b = create_breadth_table('/Volumes/backup/Research/bigdata/ENCODE/hg19/H3K27me3/ENCODE_human_H3K27me3_assigned.txt', col_id=1, gene_id=3, peak_id=0, breadth_id=2, id_table=True)
    #genomics.write_table1(a, '/Volumes/backup/Research/bigdata/ENCODE/hg19/H3K27me3/ENCODE_human_H3K27me3_breadth.txt')
    #genomics.write_table1(b, '/Volumes/backup/Research/bigdata/ENCODE/hg19/H3K27me3/ENCODE_human_H3K27me3_assigned_id.txt')

    ### CREATE A BED FILE FOR ALL ASSIGNED H3K27ME3 DOMAINS
    #temp = read_table1('/Users/woojunshim/Research/Data/new_assigned/H3K27me3_tss_2.5kb_combined_id.txt', numerical=False)
    #aa = open('/Volumes/backup/Research/bigdata/roadmap/broad_peaks/assigned/H3K27me3/H3K27me3_centre_combined.txt', 'r')
    #ref = {}
    #cols = get_colnames(temp)
    #for c in cols:
    #    ref[c] = set()
    #    for g in temp:
    #        if temp[g][c] != 'NA':
    #            ref[c].add(temp[g][c])
    #results = []
    #for i in aa:
    #    i = i.strip().split()
    #    if i[3] in ref[i[5]]:
    #        results.append(i)
    #genomics.write_file(results, '/Volumes/backup/Research/bigdata/roadmap/broad_peaks/assigned/H3K27me3/H3K27me3_centre_included.txt')

    ### CREATE BED FILES FOR PROMOTERS (+2.5KB OF TSS)
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/hg19_TSS_.txt')
    #results = []
    #for i in temp:
    #    if i[2] == '+':
    #        if int(i[3])-2500 <= 0:
    #            value = 0
    #        else:
    #            value = int(i[3])-2500
    #        results.append([i[1], value, i[3], i[5], 'promoter'])

    #    elif i[2] == '-':
    #        results.append([i[1], i[4], int(i[4])+2500, i[5], 'promoter'])

    #    results.append([i[1], i[3], i[4], i[5], 'intra'])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/hg19_promoter_intra.txt')

    ### COUNT LOCATIONS OF ASSIGNED H3K27ME3 DOMAINS
    #ref = read_table1('/Users/woojunshim/Research/Data/new_assigned/H3K27me3_tss_2.5kb_combined_id.txt', numerical=False)
    #used = {}
    #temp = genomics.read_file1('/Volumes/backup/Research/bigdata/roadmap/broad_peaks/assigned/H3K27me3/H3K27me3_locations.txt')
    #intra, promoter, inter = 0,0,0
    #for i in temp:
    #    if i[1] not in used:
    #        used[i[1]] = {}
    #    if i[0] not in used[i[1]]:
    #        used[i[1]][i[0]] = set()
    #    if i[2] not in used[i[1]][i[0]]:
    #        used[i[1]][i[0]].add(i[2])
    #        if i[3] == 'intra':
    #            intra += 1
    #        elif i[3] == 'promoter':
    #            promoter += 1
    #total = 0 
    #for g in ref:
    #    for c in ref[g]:
    #        if ref[g][c] != 'NA':
    #            total += 1
    #            if ref[g][c] not in used[c]:
    #                inter += 1
    #print 'total =',total
    #print 'intra =',intra
    #print 'promoter =',promoter
    #print 'inter =',inter



    ### TESTING ENRICHMENT OF VARIABLY EXPRESSED TFS
    #temp = read_table1('/Users/woojunshim/Research/Data/new_assigned/H3K27me3_z.txt')
    #results = {}
    #cols = get_colnames(temp)
    #for g in temp:
    #    results[g] = 0
    #    for c in cols:
    #        results[g] += temp[g][c]
    #min_, max_ = 999999, 0 
    #for g in results:
    #    if results[g] < min_:
    #        min_ = results[g]
    #    if results[g] > max_:
    #        max_ = results[g]
    #for g in results:
    #    results[g] = float(results[g]-min_) / (max_ - min_)
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/new_assigned/tables/repressive_hg19_cont.txt')

    ### PERFORMANCE TEST 
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/new_assigned/tables/repressive_hg19_prop.txt', sort_by=1)
    #input_ = []
    #for i in temp:
    #    input_.append(i[0])
    #print input_[0:10]
    #results = sliding_fet(input_, regulated_tf)
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/new_assigned/tables/fet_prop.txt')

    #temp = read_table1('/Users/woojunshim/Research/Data/new_assigned/H3K27me3_top5_binary_table.txt')
    #results = {}
    #for g in temp:
    #    results[g] = 1
    #    for c in temp[g]:
    #        results[g] += int(temp[g][c])
    #min_, max_ = 99999, 0 
    #for g in results:
    #    if results[g] < min_:
    #        min_ = results[g]
    #    if results[g] > max_:
    #        max_ = results[g]
    #for g in results:
    #    results[g] = float(results[g]-min_) / (max_ - min_)
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/new_assigned/tables/repressive_hg19_prop.txt')

    ### CALCULATE ENTROPY OF EITHER WIDTH OR BROAD VARIABLE ALONE
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/new_assigned/tables/repressive_hg19_prop.txt', sort_by=1)
    #idx = len(temp) / 20
    #print idx
    #input_ = []
    #for i in range(len(temp)):
    #    input_.append(temp[i][0])
    #results = entropy_for_gene_list(input_, regulated_tf, idx)
    #print results

    ### TOP 1,000 GENES
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/new_assigned/tables/repressive_hg19_cont.txt', sort_by=1)
    #input_ = []
    #for i in range(len(temp)):
    #    input_.append(temp[i][0])
    #a = float(len(genomics.intersection(input_, regulated_tf))) / 1000
    #print a
    #b = point_fet1(input_, regulated_tf, cut_off=1000)
    #print b


    ### MERGE ALL ASSIGNED PEAKS WITH VARIABLY EXPRESSED TF LABELS 
    #pathway = '/Volumes/backup/Research/bigdata/roadmap/broad_peaks/assigned/'
    #menu = ['H3K4me1','H3K4me3','H3K9me3','H3K27me3','H3K27ac','H3K36me3']
    #genes = set()
    #temp = read_table1('/Volumes/backup/Research/bigdata/roadmap/broad_peaks/assigned/H3K27ac/H3K27ac_tss_2.5kb.txt')
    #cols = get_colnames(temp)
    #print len(cols)
    #data_ = {}    
    #for i in menu:
    #    print i
    #    data_[i] = {}
    #    temp = read_table1(pathway+'/'+i+'/'+i+'_tss_2.5kb_z.txt')
    #    cols = get_colnames(temp)
    #    for c in cols:
    #        all_ = []
    #        for g in temp:
    #            all_.append(temp[g][c])
    #        mean_ = np.mean(all_)
    #        std_ = np.std(all_)
    #        for g in temp:
                #temp[g][c] = (temp[g][c] - mean_) / std_
    #            genes.add(g)
    #            if g not in data_[i]:
    #                data_[i][g] = {}
                #data_[i][g][c] = (temp[g][c] - mean_) / std_
    #            data_[i][g][c] = temp[g][c]
    #results = []
    #for g in genes:
    #    if (g in data_['H3K4me1']) and (g in data_['H3K4me3']) and (g in data_['H3K9me3']) and (g in data_['H3K27me3']) and (g in data_['H3K27ac']) and (g in data_['H3K36me3']):
    #        if g in regulated_tf:
    #            tag = 1
    #        else:
    #            tag = 0
    #        for c in cols:
    #            if (c in data_['H3K4me1'][g]) and (c in data_['H3K4me3'][g]) and (c in data_['H3K9me3'][g]) and (c in data_['H3K27me3'][g]) and (c in data_['H3K27ac'][g]) and (c in data_['H3K36me3'][g]):
    #                results.append([g, data_['H3K4me1'][g][c], data_['H3K4me3'][g][c], data_['H3K9me3'][g][c], data_['H3K27me3'][g][c], data_['H3K27ac'][g][c], data_['H3K36me3'][g][c], tag])
    #genomics.write_file(results, pathway+'hm_data_integrated.txt')


    ### CATEGORISE 
    #temp = read_table1('/Users/woojunshim/Research/Data/logit_regression/RPKM_relative_absence.txt')
    #results = initiate_table(temp)
    #for g in temp:
    #    for c in temp[g]:
    #        if temp[g][c] > float(2):
    #            results[g][c] = 1
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/logit_regression/RPKM_relative_high_binary.txt')

    # MERGE ALL DATA
    #h3k27me3 = read_table1('/Users/woojunshim/Research/Data/logit_regression/H3K27me3_relative_absence.txt')
    #label = read_table1('/Users/woojunshim/Research/Data/logit_regression/RPKM_relative_high_binary.txt')
    #results = []
    #genes = genomics.intersection(get_rownames(h3k27me3), get_rownames(label))
    #print len(genes)
    #cols = get_colnames(h3k27me3)
    #for g in genes:
    #    for c in cols:
    #        results.append([h3k27me3[g][c], int(label[g][c]), g])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/logit_regression_input.txt')

    #genes = genomics.read_file_items('/Users/woojunshim/Research/Data/new_assigned/tables/repressive_hg19_cont_prop.txt', col=0)
    #print genes[:10]
    #temp = read_table1('/Users/woojunshim/Research/Data/new_assigned/H3K27me3_top5_binary_table.txt')
    #genes = get_rownames(temp)
    #results = {}
    #for g in temp:
    #    results[g] = 0
    #    for c in temp[g]:
    #        results[g] += int(temp[g][c])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/broad_domain_counts.txt')

    #aa = genomics.read_file1('/Users/woojunshim/Research/Data/broad_domain_counts.txt', sort_by=1)
    #a,b = [], []
    #for i in aa:
    #    if i[0] in regulated_tf:
    #        a.append(float(i[1]))
    #    else:
    #        b.append(float(i[1]))
    #s, p = stat.mann(a,b)
    #print s,p



    # PROBABILITY OF BEING 
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/logit_regression/logit_regression_input.txt', sort_by=0)
    #cutoff = 6
    #results = []
    #current = [0, 0]    
    #for i in temp:
    #    if float(i[0]) < cutoff:
    #        results.append(current)
    #        current = [0,0]
    #        cutoff -= 1
    #    else:
    #        current[0] += 1
    #        if float(i[1]) == float(1):
    #            current[1] += 1
    #print results


    ### ANNOTATE CAGE DATA
    #ref = genomics.read_file_dic('/Users/woojunshim/Research/Data/FANTOM/hg19_cage_tag_anno.txt', id_idx=0, col_idx=1, numerical=False)
    #aa = genomics.read_file1('/Users/woojunshim/Research/Data/tables/CAGE_samples.txt')
    #results = [['#Column_id','Description','Tissue']]
    #for i in aa:
    #    results.append([i[0], ref[i[0]], i[2][:-1]])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/tables/CAGE_samples_description.txt')

    #ref = genomics.read_file_dic('/Users/woojunshim/Research/Data/Roadmap_epigenomes.txt', id_idx=0, col_idx=2, numerical=False)
    #results = genomics.read_file1('/Users/woojunshim/Research/Data/roadmap_description.txt')
    #for i in range(len(results)):
    #    results[i].extend([ref[results[i][0]]])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/roadmap_description_new.txt')

    #pathway = '/Users/woojunshim/Research/Data/genes_with_go_term/'
    #files = ['GO.0007507', 'GO.0007420', 'GO.0030324', 'GO.0031016', 'GO.0061061']
    #for file in files:
    #    temp = read_table1(pathway+file+'.txt', numerical=False)
    #    results = []
    #    for i in temp:
    #        if temp[i]['x'] in tf_list:
    #            results.append(temp[i]['x'])
    #    genomics.write_file(results, pathway+file+'_tf.txt')



    ### COUNT NUMBER OF GENES 
    ### AND PVALUE
    #ref = genomics.read_file_items('/Users/woojunshim/Research/Data/GO_CC_nucleus.txt')
    #input__ = genomics.read_file1('/Users/woojunshim/Research/Data/new_assigned/tables/repressive_hg19_cont_prop.txt', sort_by=1)
    #input_ = []
    #for i in input__:
    #    input_.append(i[0])
    #print input_[0:10]
    #cnt = count_members(input_[:1359], ref)
    #print cnt
    #p = point_fet(input_, ref, 1359)
    #print p


    ### NCRNA GENE LIST
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/ensembl_coding_genes.txt')
    #results = []
    #nc = []
    #for i in temp:
    #    if len(i) == 2:
    #        results.append(i[1])
    #results = list(set(results))
    #genomics.write_file_items(results, '/Users/woojunshim/Research/Data/all_coding_genes.txt')
    #results = set(results)
    #for i in temp:
    #    if len(i) == 1:
    #        if i[0] not in results:
    #            nc.append(i[0])
    #nc = list(set(nc))
    #genomics.write_file_items(nc, '/Users/woojunshim/Research/Data/all_nc_genes.txt')

    #input_ = read_table1('/Users/woojunshim/Research/Data/57epigenomes.RPKM.nc.txt')
    #cols = get_colnames(input_)
    #results = {}
    #ref = {}
    #for i in temp:
    #    if len(i) == 3:
    #        ref[i[1]] = i[2]
    #for g in input_:
    #    if g in ref:
    #        name = ref[g]
    #        results[name] = {}
    #        for c in cols:
    #            results[name][c] = input_[g][c]
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/57epigenomes.RPKM.nc_symbols.txt')

    ### EXTRACT TERMS (1359 TOP GENES)
    #pathway = '/Users/woojunshim/Research/Data/1359/' 
    #terms = genomics.read_file_items('/Users/woojunshim/Research/Data/1359/selected_terms.txt')
    #files_, names_ = ['first_1359_bp.txt', 'second_1359_bp.txt', 'bottom_1359_bp.txt'], ['Top_1359','Next_1359','Bottom_1359']
    #files = []
    #for i in files_:
    #    files.append(pathway+i)
    #results = extract_elements(files, names_, ids=terms, id_idx=2, value_idx=3, log_convert=True, default_value=0.0)
    #genomics.write_table1(results, pathway+'go_enrichment_table_selected.txt')

    ### CELL-TYPE SPECIFICITY USING ENTROPY
    #results = calculate_entropy_table(exp_, count_table=False, relative_expression=True)
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/entropy_exp.txt')

    ### MERGE HOMER PEAKS 
    #output_ = open('/Users/woojunshim/Research/Data/homer_peaks/H3K27me3/homer_merged_peaks.txt', 'w')
    #for e in epigenomes:
    #    print e
    #    temp = genomics.read_file1('/Users/woojunshim/Research/Data/homer_peaks/H3K27me3/'+e+'_homer_peaks.txt')
    #    for no in range(len(temp)):
    #        i = temp[no]
    #        output_.write(i[1]+'\t'+i[2]+'\t'+i[3]+'\t'+'peak_'+str(no)+'\t'+e+'\t'+str(int(float(i[6])))+'\n')
    #output_.close()


    ### RT FROM SPP PEAKS
    #results = calculate_rt('/Users/woojunshim/Research/Data/H3K27me3_width_table.txt', '/Users/woojunshim/Research/Data/H3K27me3_top5_binary_table.txt')
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/H3K27me3_rt_table.txt')



    ### CORRECT MINUS COORDINATES
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/hg19_transcript_up2500_sorted.txt')
    #for i in range(len(temp)):
    #    if int(temp[i][1]) < 0:
    #        temp[i][1] = 1
    #    if int(temp[i][2]) < 0:
    #        temp[i][2] = 1
    #genomics.write_file(temp, '/Users/woojunshim/Research/Data/hg19_transcript_up2500_sorted_.txt')

    ### 1000 UPSTREAM TRANSCRIPTS
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/hg19_TSS_.txt')
    #results = []
    #for i in range(len(temp)):
    #    item = temp[i]
    #    if item[2] == '+':
    #        results.append([item[1], int(item[3])-2500, item[4], item[5]])
    #    else:
    #        results.append([item[1], item[3], int(item[4])+2500, item[5]])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/hg19_transcript_2500up.txt')


    ### MERGE PEAKS 
    #results = []
    #pathway = '/Users/woojunshim/Research/Data/spp_peaks/H3K27me3/'
    #print len(epigenomes)
    #for e in epigenomes:
    #    print e
    #    temp = genomics.read_file1(pathway+e+'_broadpeak.txt')
    #    for no in range(len(temp)):
    #        i = temp[no]
    #        width = int(float(i[2]) - float(i[1]))
    #        results.append([i[0], i[1], i[2], 'peak_'+str(no), e, width])
    #genomics.write_file(results, pathway+'spp_merged_peaks.txt')


    ### COUNT THE NUMBER OF GENES USED FOR EUCLIDEAN DISTANCE CALCULATIONS
    #prefix = 'exp'
    #pathway = '/Users/woojunshim/Research/cardiac_sc/'+prefix+'/'
    #menu = ['d0','d2','d5','d15','d30']
    #results = []
    #for d in menu:
    #    temp = read_table1(pathway+prefix+'_'+d+'.txt', numerical=False)
    #    cnt = 0
    #    for g in temp:
    #        tag = 0
    #        for c in temp[g]:
    #            if temp[g][c] =='NA':
    #                tag = 1
    #        if tag == 0:
    #            cnt += 1
    #    results.append([d, cnt])
    #genomics.write_file(results, pathway+prefix+'_included_genes_cnt.txt')

    ### 




    ### CREATE MATRIX FOR DISTANCE ANALYSIS
    #pathway = '/Users/woojunshim/Research/cardiac_sc/exp/'
    #menu = ['d30c1_old','d30c2_old']
    #genes = set()    
    #for m in menu:
    #    temp = genomics.read_csv(pathway+m+'.csv')
    #    aa = convert_to_table(temp)
    #    for g in aa:
    #        genes.add(g)
    #results = initiate_table1(rows=list(genes), cols=menu, initial_value='NA')
    #for m in menu:
    #    temp = genomics.read_csv(pathway+m+'.csv')
    #    aa = convert_to_table(temp)
    #    min_, max_ = 99999, 0 
    #    for g in aa:
    #        if aa[g]['expression'] !='NA':
    #            value = float(aa[g]['expression'])
    #            if value < min_:
    #                min_ = value
    #            if value > max_:
    #                max_ = value
    #    for g in aa:
    #        if aa[g]['expression'] != 'NA':
    #            aa[g]['expression'] = float(float(aa[g]['expression']) - min_) / (max_ - min_)
    #    for g in aa:
    #        results[g][m] = aa[g]['expression']
    #genomics.write_table1(results, pathway+'exp_d30.txt')


    ### NEW BOVINE DATASET
    #temp = read_table1('/Users/woojunshim/Research/bovine/new/expression_data_by_read_count.txt', numerical=False)
    #cols_ = get_colnames(temp)
    #cols = []
    #genes = genomics.read_file_items('/Users/woojunshim/Research/bovine/new/homologues_human_one2one.txt', col=2)
    #genes = genomics.intersection(genes, get_rownames(temp))
    #print len(genes)
    #for c in cols_:
    #    if 'NE' in c:
    #        cols.append(c)
    #ref = genomics.read_file_dic('/Users/woojunshim/Research/Data/new_assigned/tables/repressive_hg19_cont_prop.txt', id_idx=0, col_idx=1)
    #results = calculate_discordance_for_table(temp, cols=cols, rows=genes, ref=ref) 
    #genomics.write_table1(results, '/Users/woojunshim/Research/bovine/new/discordance_by_read_count_.txt')

    ### REMOVED GENES 
    #a = read_table1('/Users/woojunshim/Research/bovine/new/NEV_homologues.txt', numerical=False)
    #row1 = get_rownames(a)
    #b = read_table1('/Users/woojunshim/Research/bovine/new/NEV_homologues_.txt', numerical=False)
    #row2 = set(get_rownames(b))
    #results = []
    #for i in row1:
    #    if i not in row2:
    #        results.append(i)
    #genomics.write_file_items(results, '/Users/woojunshim/Research/bovine/new/removed_genes.txt')

    ### ADD OTHER IDS 
    #temp = read_table1('/Users/woojunshim/Research/bovine/new/discordance_by_read_count_.txt')
    #ref = genomics.read_file('/Users/woojunshim/Research/bovine/new/homologues_human_one2one.txt', [0,1,3], rowname='2')    
    #for i in temp:
    #    temp[i]['cow_ensembl'] = ref[i][0]
    #    temp[i]['cow_gene'] = ref[i][1]
    #    temp[i]['human_ensembl'] = ref[i][2]
    #genomics.write_table1(temp, '/Users/woojunshim/Research/bovine/new/discordance_by_read_count.txt')

    ### FINALISE READ COUNT TABLE
    #genes = genomics.read_file_items('/Users/woojunshim/Research/bovine/new/included_genes.txt', col=4)
    #print genes[0]
    #results = calculate_discordance_for_table('/Users/woojunshim/Research/bovine/new/expression_data_.txt', cols=cols, rows=genes, ref=ref, log=False, pseudo=0)
    #genomics.write_table1(results, '/Users/woojunshim/Research/bovine/new/discordance_by_read_count_.txt')


    ### REMAP ANALYSIS 
    #temp = open('/Volumes/backup/Research/remap/remap2018_all_macs2_hg19_v1_2.bed', 'r')
    #results = {}
    #table_ = {}
    #cols = set()
    #for i in temp:
    #    i = i.strip().split()
    #    qq = i[3].split('.')
    #    if qq[1] not in results:
    #        results[qq[1]] = set()
    #        table_[qq[1]] = {}
    #    results[qq[1]].add(qq[2])
    #    cols.add(qq[2])
    #print len(cols)
    #for g in table_:
    #    for c in cols:
    #        if c in results[g]:
    #            table_[g][c] = 1
    #        else:
    #            table_[g][c] = 0
    #genomics.write_table1(table_, '/Users/woojunshim/Research/Data/remap/remap_summary_table.txt')




    ### CREATE A TABLE FOR ASSIGNED H3K27ME3 DOMAINS IDS     
    #ref = genomics.read_file_dic('/Users/woojunshim/Research/Data/new_assigned/H3K27me3_top5_threshold.txt', id_idx=0, col_idx=1)
    #genes = genomics.read_file_items('/Users/woojunshim/Research/Data/new_assigned/tables/repressive_hg19_cont_prop.txt', col=0)
    #results = initiate_table1(genes, epigenomes, initial_value='NA')
    #qq = initiate_table1(genes, epigenomes, initial_value=0)
    #temp = open('/Volumes/backup/Research/bigdata/roadmap/broad_peaks/H3K27me3/merged_H3K27me3_assigned_uniq.txt', 'r')
    #cnt = 0
    #for i in temp:        
    #    i = i.strip().split()
    #    if i[3] in results:
    #        cnt += 1
    #        if cnt % 10000 == 0:
    #            print cnt
    #        if int(i[1]) > qq[i[3]][i[2]]:
    #            results[i[3]][i[2]] = i[0]
    #            qq[i[3]][i[2]] = int(i[1])
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/new_assigned/H3K27me3_assigned_domains.txt')


    ### BED FILES FOR BROAD H3K27ME3 DOMAINS 
    #temp = read_table1('/Users/woojunshim/Research/Data/new_assigned/H3K27me3_top5_binary_table.txt')
    #pathway = '/Users/woojunshim/Research/Data/new_assigned/'
    #ref = read_table1('/Users/woojunshim/Research/Data/new_assigned/H3K27me3_assigned_domains.txt', numerical=False)
    #results = []
    #cols = get_colnames(ref)
    #genes = get_rownames(temp)
    #for c in cols:
    #    aa = {}
    #    for g in genes:
    #        if temp[g][c] == float(1):
    #            aa[ref[g][c]] = g
    #    print len(aa)
    #    bb = open('/Volumes/backup/Research/bigdata/roadmap/broad_peaks/'+c+'-H3K27me3.broadPeak', 'r')
    #    for i in bb:
    #        i = i.strip().split()
    #        if i[3] in aa:
    #            results.append([i[0], i[1], i[2], i[3], c, aa[i[3]]])
    #genomics.write_file(results, pathway+'broad_H3K27me3_domains.txt')





    ### FIND GENES NOT IN RT SCORE TABLE
    ### FIND GENES WITH DIFFERENT NAMES BETWEEN BOVINE AND HUMAN 
    #temp = genomics.read_file1('/Users/woojunshim/Research/bovine/new/homologues_human_one2one.txt')
    #results = []
    #for i in temp:
    #    if not 'ENSBTAG' in i[1]:
    #        if i[1] != i[2]:
    #            results.append([i[1], i[2]])
    #genomics.write_file(results, '/Users/woojunshim/Research/bovine/new/different_genes.txt')

    ### BOVINE DATASET
    #ref = genomics.read_file_dic('/Users/woojunshim/Research/Data/new_assigned/tables/repressive_hg19_cont_prop.txt', id_idx=0, col_idx=1)
    #mapping = genomics.read_file_dic('/Users/woojunshim/Research/bovine/new/homologues_human_one2one.txt', id_idx=1, col_idx=2, numerical=False)
    #exp_ = read_table1('/Users/woojunshim/Research/bovine/new/expression_data.txt')
    #genes = get_rownames(exp_)
    #cols = get_colnames(exp_)
    #results = initiate_table1(genes, cols)    
    #for c in cols:
    #    print c
    #    input_ = {}
    #    for g in genes:
    #        input_[g] = float(exp_[g][c])
    #    aa = calculate_discordance(input_, ref, pseudo_=0, fill_missing=True, log_conversion=False, gene_mapping=mapping)
    #    print aa[0:10]
    #    for i in aa:
    #        results[i[0]][c] = i[1]
    #genomics.write_table1(results, '/Users/woojunshim/Research/bovine/new/discordance_new.txt')

    #temp = read_table1('/Users/woojunshim/Research/bovine/new/expression_data.txt')    
    #genes = get_rownames(temp)
    #cols = get_colnames(temp)
    #table_ = {}
    #for g in genes:
    #    if g in mapping:
    #        gene = mapping[g]            
    #    else:
    #        gene = g

    #    table_[gene] = {}
    #    for c in cols:
    #        table_[gene][c] = temp[g][c]
    #genomics.write_table1(table_, '/Users/woojunshim/Research/bovine/new/expression_data_.txt')

    #results = calculate_discordance_for_table(input_='/Users/woojunshim/Research/bovine/new/expression_data_.txt', ref=ref, log=False, pseudo=0)
    #ref1 = genomics.read_file_dic('/Users/woojunshim/Research/bovine/new/homologues_human_one2one.txt', id_idx=2, col_idx=0, numerical=False)
    #ref2 = genomics.read_file_dic('/Users/woojunshim/Research/bovine/new/homologues_human_one2one.txt', id_idx=2, col_idx=1, numerical=False)
    #ref3 = genomics.read_file_dic('/Users/woojunshim/Research/bovine/new/homologues_human_one2one.txt', id_idx=2, col_idx=3, numerical=False)    
    #for g in results:
    #    results[g]['cow_ensembl'] = 'NA'
    #    results[g]['cow_symbol'] = 'NA'
    #    results[g]['human_ensembl'] = 'NA'
    #    if g in ref1:
    #        results[g]['cow_ensembl'] = ref1[g]
    #    if g in ref2:
    #        results[g]['cow_symbol'] = ref2[g]
    #    if g in ref3:
    #        results[g]['human_ensembl'] = ref3[g]
    #genomics.write_table1(results, '/Users/woojunshim/Research/bovine/new/discordance_raw_exp_.txt')







    ### EXTRACT CENTRE POSITIONS OF ASSIGNED H3K27ME3 PEAKS ACROSS CELL-TYPES
    #ref_ = read_table1('/Volumes/backup/Research/bigdata/roadmap/broad_peaks/assigned/H3K27me3/H3K27me3_tss_2.5kb_combined_id.txt', numerical=False)
    #cols = get_colnames(ref_)
    #results = []
    #for c in cols:
    #    print c
    #    ref = {}        
    #    for g in ref_:
    #        if ref_[g][c] != 'NA':
    #            ref[ref_[g][c]] = g
    #    temp = open('/Volumes/backup/Research/bigdata/roadmap/broad_peaks/'+c+'-H3K27me3.broadPeak', 'r')
    #    for i in temp:
    #        i = i.strip().split()
    #        if i[3] in ref:
    #            centre = (int(i[1]) + int(i[2])) / 2
    #            results.append([i[0], str(centre), str(centre+1), i[3], c, ref[i[3]]])
    #genomics.write_file(results, '/Volumes/backup/Research/bigdata/roadmap/broad_peaks/H3K27me3/H3K27me3_centre_positions_merged.txt')

    ### IDENTIFY WHETHER GENES ARE INCUDED IN 
    #thre = 300 
    #temp = read_table1('/Users/woojunshim/Research/Data/prostate_cancer/prostate_discordance.txt')
    #results = create_empty_table(rows=get_rownames(temp), cols=get_colnames(temp))
    #cols = get_colnames(temp)
    #for c in cols:
    #    aa = get_rownames_by_sorting_table(temp, col=c)
    #    for i in range(thre):
    #        results[aa[i]][c] = 1
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/prostate_cancer/top300_dis.txt')

    ### CALCULATE PROPORTIONS OF GENES (HIGH VS LOW)
    #temp = read_table1('/Users/woojunshim/Research/Data/prostate_cancer/SPINK1_.txt', numerical=False)
    #pos, neg = [], []
    #for i in temp:
    #    if temp[i]['SPINK1'] == '1':
    #        pos.append(temp[i]['names'])
    #    else:
    #        neg.append(temp[i]['names'])
    #t = read_table1('/Users/woojunshim/Research/Data/prostate_cancer/top300_dis.txt')
    #cnt_p = len(pos)
    #cnt_n = len(neg)
    #results = []
    #for g in t:
    #    cnt = 0
    #    for aa in pos:
    #        if t[g][aa] == float(1):
    #            cnt += 1
    #    pp = float(cnt) / cnt_p
    #    cnt = 0
    #    for aa in neg:
    #        if t[g][aa] == float(1):
    #            cnt += 1
    #    nn = float(cnt) / cnt_n
    #    results.append([g, pp, nn])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/prostate_cancer/top300_dis_prop.txt')

    ### WILCOXON RANK SUM TEST FOR HIGH VS LOW PROSTATE 
    #map_ = read_table1('/Users/woojunshim/Research/Data/prostate_cancer/kegg_description.txt', numerical=False)
    #mapping = {}
    #for i in map_:
    #    mapping['hsa'+map_[i]['path_id']] = map_[i]['path_name']
    #pos = set(pos)
    #neg = set(neg)
    #ref_ = read_table1('/Users/woojunshim/Research/Data/KEGG/gene_kegg_table.txt')
    #results = []
    #cols = get_colnames(ref_)
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/prostate_cancer/top300_dis_prop.txt')
    #results = []
    #for c in cols:
    #    ref = []
    #    for g in ref_:
    #        if ref_[g][c] == float(1):
    #            ref.append(g)        
    #    pp, nn = [], []
    #    for i in temp:
    #        if i[0] in ref:
    #            pp.append(float(i[1]))
    #            nn.append(float(i[2]))
         
    #    if (np.sum(pp)==0) and (np.sum(nn)==0):
    #        continue
    #    else:                  
        
    #        s, p = stat.mann(pp, nn, alternative_='greater')
    #        results.append([c, mapping[c], p])
    #results.insert(0, ['#KEGG_ID','Description','p-value'])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/prostate_cancer/top300_dis_prop_mann.txt')


    ### COMPARE SCORES OF KEGG PATHWAY GENES BETWEEN SPINK1-HIGH VS LOW GROUPS 
    #ids = read_table1('/Users/woojunshim/Research/Data/prostate_cancer/SPINK1.txt', numerical=False)
    #results = []
    #for i in ids:
    #    if float(ids[i]['value']) > 4:
    #        tag = 1
    #    else:
    #        tag = 0
    #    qq = ids[i]['names'].split('y')        
    #    y_ = qq[1]
    #    q = qq[0].split('x')
    #    x_ = q[1]
    #    results.append([x_, y_, tag])
    #    ids[i]['SPINK1'] = tag
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/prostate_cancer/SPINK1_high_low_map.txt')
    #genomics.write_table1(ids, '/Users/woojunshim/Research/Data/prostate_cancer/SPINK1_.txt')


    ### CREATE A TABLE FOR MIXOLOGY DATA 
    #tag = 'expr'
    #pathway = '/Users/woojunshim/Research/Data/mixology/'
    #results = {}
    #cols = []
    #for i in range(1, 501):
    #    cols.append(tag+'_'+str(i))
    #for c in cols:
    #    temp = genomics.read_file1(pathway+c+'.txt')
    #    for j in temp:
    #        if j[0] not in results:
    #            results[j[0]] = {}
    #            for cc in cols:
    #                results[j[0]][cc] = 0
    #        results[j[0]][c] = j[1]
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/mixology/'+tag+'_table.txt')

    #results = fet_for_matrix(input_table=pathway+'expr_table.txt', positives=regulated_tf)
    #genomics.write_file(results, pathway+'fet_mixology_expr.txt')

    ### FET FOR TOP 100 GENES, MIXOLOGY DATASETS
    #temp = read_table1('/Users/woojunshim/Research/Data/mixology/disc_table.txt')
    #results = []
    #cols = get_colnames(temp)
    #thre = 100
    #for c in cols:
    #    input_ = get_rownames_by_sorting_table(temp, c, with_value=False)
    #    p = point_fet1(input_, regulated_tf, thre, alternative_='greater')
    #    results.append([c, p])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/mixology/fet_disc_top100.txt')



    ### FET FOR DEVELOPMENTAL TERMS 
    #rt_ = genomics.read_file1('/Users/woojunshim/Research/Data/new_assigned/tables/repressive_hg19_cont_prop.txt', sort_by=1)
    #rt = []
    #for i in rt_:
    #   if i[0] in mrna:
    #       rt.append(i[0])
    #pathway = ''
    #files_ = ['GO.0007492.txt','GO.0007498.txt','GO.0007398.txt']
    #files_ = ['GO.0072358.txt','GO.0007417.txt','GO.0055123.txt','GO.0035270.txt','GO.0035272.txt','GO.0002520.txt','GO.0007399.txt','GO.0060541.txt','GO.0061458.txt','GO.0001501.txt']
    #names = ['GO:0007492-Endoderm_development','GO:0007498-Mesoderm_development','GO:0007398-Ectoderm_development']   
    #names = ['GO:0072358-Cardiovascular_system_development','GO:0007417-Central_nervous_system_development','GO:0055123-Digestive_system_development','GO:0035270-Endocrine_system_development','GO:0035272-Exocrine_system_development','GO:0002520-Immune_system_development','GO:0007399-Nervous_system_development','GO:0060541-Respiratory_system_development','GO:0061458-Reproducive_system_development','GO:0001501-Skeletal_system_development']

    #results = []
    #fet = []
    #for i in range(len(files_)):
    #    temp = read_table1('/Users/woojunshim/Research/Data/genes_with_go_term/'+files_[i], numerical=False)
    #    ref = []
    #    for m in temp:
    #        ref.append(temp[m]['x'])
    #    rr = prop_membership_for_list(rt, ref, 10)
    #    ff = perform_fet_with_sliding_window(rt, ref, bin_no=10, output='p-value', tail='greater')
    #    results.append([names[i]])
    #    fet.append([names[i]])
    #    for j in rr:
    #        results[-1].extend([j])
    #    for j in ff:
    #        fet[-1].extend([j])
    #fet.insert(0, ['#term'])
    #for i in range(10,110,10):
    #    fet[0].extend([i])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/KEGG/prop_bp_pluripotency_.txt')
    #genomics.write_file(fet, '/Users/woojunshim/Research/Data/KEGG/fet_bp_pluripotency_.txt')



    ### EXTRACT KEGG FET RESULTS
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/KEGG/kegg_description.txt')
    #ref = {}
    #to_extract = set(genomics.read_file_items('/Users/woojunshim/Research/Data/KEGG/disease_terms.txt'))
    #for i in temp:
    #    if len(i) == 3:            
    #        ref['hsa'+i[1]] = i[2]
    
    #aa = genomics.read_file1('/Users/woojunshim/Research/Data/KEGG/prop_kegg_10percent.txt')
    #results = []
    #all_ = []
    #for i in aa:
    #    label = i[0]+':'+ref[i[0]]        
    #    if i[0] in to_extract:
    #        i[0] = label
    #        results.append(i)        
    #    i[0] = label
    #    all_.append(i)

    #genomics.write_file(results, '/Users/woojunshim/Research/Data/KEGG/prop_kegg_disease.txt')
    #all_.insert(0, ['#term'])
    #for i in range(10,110,10):
    #    all_[0].extend([i])
    #genomics.write_file(all_, '/Users/woojunshim/Research/Data/KEGG/prop_all_kegg.txt')



    ### FET FOR KEGG PATHWAYS
    #rt_ = genomics.read_file1('/Users/woojunshim/Research/Data/new_assigned/tables/repressive_hg19_cont_prop.txt', sort_by=1)
    #rt = []
    #for i in rt_:
   # 	if i[0] in mrna:
   # 		rt.append(i[0])
   # ref = read_table1('/Users/woojunshim/Research/Data/KEGG/gene_kegg_table.txt')
   # cols = get_colnames(ref)
   # results = []
   
    #for c in cols:  
   # 	print
    #	print c  	
   # 	ref_ = []
   # 	for g in ref:
   # 		if ref[g][c] == float(1):
   # 			ref_.append(g)
   # 	print len(ref_)
        #rr = perform_fet_with_sliding_window(rt, ref=ref_, bin_no=20, output='p-value', tail='greater') # regulated_tf = variably_expressed_TFs
   #     rr = prop_membership_for_list(rt, ref_, 10)        
   #     results.append([c])
   #     for i in rr:
   #     	results[-1].extend([i])
   # genomics.write_file(results, '/Users/woojunshim/Research/Data/KEGG/prop_kegg_10percent.txt')



    ### CREATE KEGG PATHWAY - GENE MAPPING TABLE
    #entrez = genomics.read_file1('/Users/woojunshim/Research/Data/KEGG/kegg_to_entrez.txt')
    #gtk = {}
    #kegg_all = []
    #for i in entrez:
    #    if len(i) == 3:
    #        if i[1].startswith('hsa'):
    #            if i[2] not in gtk:                
    #                gtk[i[2]] = []
    #            k = i[1][3::]
    #            gtk[i[2]].append(k)
    #            kegg_all.append(i[1])    
    #kegg_all = list(set(kegg_all))
    #print len(gtk['1284'])
    #print len(gtk['595'])


    #ref = genomics.read_file('/Users/woojunshim/Research/Data/KEGG/symbol_to_entrez.txt', [0], rowname='1')
    #tt = genomics.read_file_items('/Users/woojunshim/Research/Data/KEGG/symbol_to_entrez.txt', col=0)
    #tt = tt[1::]    
    #results = create_empty_table(rows=tt, cols=kegg_all)
    #for i in gtk:
    #    if i in ref:
    #        gene = ref[i][0][0]            
    #        if len(gtk[i]) != 0:                
    #            for j in gtk[i]:                    
    #                results[gene]['hsa'+j] = 1
    #cnt = 0
    #for l in results['COL4A2']:
    #    cnt += results['COL4A2'][l]
    #print cnt
    #cnt = 0
    #for l in results['CCND1']:
    #    cnt += results['CCND1'][l]
    #print cnt
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/KEGG/gene_kegg_table.txt')




    ### Roadmap cell-type descriptions
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/roadmap_.txt')    
    #print temp
    #cols = set(get_colnames(exp_))
    #results = []
    #for e in temp:        
    #    if e[0] in tissue_groups_:
    #        if e[0] in cols:
    #            tag = 'Y'
    #        else:
    #            tag = 'N'
    #        results.append([e[0], e[1], tag])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/Roadmap_IDs_details.txt')

    ### EXTRACT KEGG GENE LISTS
    #pathway = '/Users/woojunshim/Research/Data/KEGG/'
    #files_ = ['hsa00190-Oxidative phosphorylation.txt','hsa04142-Lysosome.txt','hsa04260-Cardiac muscle contraction.txt','hsa04340-Hedgehog signaling pathway.txt','hsa04510-Focal adhesion.txt','hsa04512-ECM-receptor interaction.txt','hsa04514-Cell adhesion molecules (CAMs).txt','hsa04612-Antigen processing and presentation.txt','hsa04670-Leukocyte transendothelial migration.txt','hsa04810-Regulation of actin cytoskeleton.txt','hsa04916-Melanogenesis.txt',"hsa05010-Alzheimer's disease.txt","hsa05012-Parkinson's disease.txt","hsa05016-Huntington's disease.txt",'hsa05110-Vibrio cholerae infection.txt','hsa05200-Pathways in cancer.txt','hsa05410-Hypertrophic cardiomyopathy (HCM).txt','hsa05414-Dilated cardiomyopathy.txt','hsa05416-Viral myocarditis.txt']
    
    #for j in files_:
    #    results = []
    #    temp = genomics.read_file1(pathway+j)
    #    for i in temp:
    #        if '_(RefSeq)_' in i[0]:
    #            gene = i[0].split('_(RefSeq)_')
    #            g = gene[1].split(',_')     
    #            if ';' in g[0]:
    #                value = g[0].split(';')[0]
    #            else:
    #                value = g[0]
    #            results.append(value)
    #    genomics.write_file_items(results, pathway+j+'.txt')

    ### KEGG FET
    #pathway = '/Users/woojunshim/Research/Data/KEGG/'
    #files_ = ['hsa05215-Prostate cancer','hsa00190-Oxidative phosphorylation','hsa04142-Lysosome','hsa04260-Cardiac muscle contraction','hsa04340-Hedgehog signaling pathway','hsa04510-Focal adhesion','hsa04512-ECM-receptor interaction','hsa04514-Cell adhesion molecules (CAMs)','hsa04612-Antigen processing and presentation','hsa04670-Leukocyte transendothelial migration','hsa04810-Regulation of actin cytoskeleton','hsa04916-Melanogenesis',"hsa05010-Alzheimer's disease","hsa05012-Parkinson's disease","hsa05016-Huntington's disease",'hsa05110-Vibrio cholerae infection','hsa05200-Pathways in cancer','hsa05410-Hypertrophic cardiomyopathy (HCM)','hsa05414-Dilated cardiomyopathy','hsa05416-Viral myocarditis']
    #input_ = read_table1('/Users/woojunshim/Research/Data/prostate_cancer/prostate_discordance.txt')    
    #input_ = read_table1('/Users/woojunshim/Research/Data/prostate_cancer/prostate_normalized_spatial_transcriptomics.txt')
    #threshold = 300
    #results = {}
    #for f in files_:
    #    label = f.replace(' ','_')
    #    results[label] = {}
    #cols = get_colnames(input_)
    #print len(cols)
    #for i in range(len(files_)):
    #    print i
    #    ref = set(genomics.read_file_items(pathway+files_[i]+'.txt.txt'))
    #    for c in cols:
    #        a = get_rownames_by_sorting_table(input_, col=c, with_value=False)
    #        aa = point_fet1(a, ref, threshold, alternative_='greater')
    #        label = files_[i].replace(' ','_')
    #        results[label][c] = aa
    #genomics.write_table1(results, pathway+'kegg_fet_table_exp.txt')



    ### SPINK1 
    ### TAKE 70 TRANSCRIPTOMES ( LOG2(RPKM+1) > 4) OUT OF 406
    ### 1. AVERAGE EXPRESSION VALUES / DISCORDANCE SCORES
    ### 2. GO ANALYSIS ON THE TOP 100 GENES (ENRICHMENT OF CANCER PATHWAYS)
    #temp = read_table1('/Users/woojunshim/Research/Data/prostate_cancer/SPINK1.txt', numerical=False)
    #ids = []
    #for i in temp:
    #    if float(temp[i]['value']) > 4:
    #        ids.append(temp[i]['names'])
    #ids = set(ids)
    #print len(ids)
    #exp = read_table1('/Users/woojunshim/Research/Data/prostate_cancer/prostate_normalized_spatial_transcriptomics.txt', numerical=False)    
    #dis = read_table1('/Users/woojunshim/Research/Data/prostate_cancer/prostate_discordance.txt')
    #genes = get_rownames(dis)
    #cols = get_colnames(dis)
    #results = create_empty_table(genes, ['high','low'])
    #for c in cols:
    #    for g in genes:
    #        if c in ids:
    #            results[g]['high'] += float(dis[g][c])
    #        else:
    #            results[g]['low'] += float(dis[g][c])
    #for g in genes:
    #    results[g]['high'] = results[g]['high'] / len(ids)
    #    results[g]['low'] = results[g]['low'] / (406 - len(ids))
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/prostate_cancer/SPINK1_dis.txt')

    #files = []
    #pathway = '/Users/woojunshim/Research/Data/prostate_cancer/'
    #aa = ['KEGG_top300_SPINK1_high_discordance.txt', 'KEGG_top300_SPINK1_low_discordance.txt', 'KEGG_top300_SPINK1_high_expression.txt', 'KEGG_top300_SPINK1_low_expression.txt']
    #menu = ['High_Dis','Low_Dis','High_Exp','Low_Exp']
    #terms = ['hsa05200:Pathways_in_cancer','hsa04512:ECM-receptor_interaction','hsa05215:Prostate_cancer','hsa04510:Focal_adhesion']
    #terms = []
    #for a in aa:
    #    files.append(pathway+a)
    #    temp = genomics.read_file1(pathway+a)
    #    for i in temp:
    #        if 'hsa' in i[1]:                
    #            terms.append(i[1])
    #    terms = list(set(terms))
    #results = extract_elements(files, names=menu, ids=terms, id_idx=1, value_idx=11, log_convert=True)
    #genomics.write_table1(results, pathway+'SPINK1_KEGG_full_table.txt')

    #temp = read_table1('/Users/woojunshim/Research/Data/prostate_cancer/SPINK1_KEGG_full_table.txt')
    #results = []
    #cols = get_colnames(temp)
    #for c in cols:
    #    aa = get_rownames_by_sorting_table(temp, col=c, with_value=False)
    #    cnt = 0
    #    for m in aa:
    #        if m not in results:
    #            results.append(m)
    #            cnt += 1
    #        if cnt == 8:
    #            break
    #for m in aa:
    #    if m not in results:
    #        results.append(m)
    #print len(results)
    #genomics.write_file_items(results, '/Users/woojunshim/Research/Data/prostate_cancer/kegg_order.txt')




    ### TESTING SLIDING FET    
    # input_ = a list of ranked genes
    # ref = a list of the positive genes       
    #results = perform_fet_with_sliding_window(input_, ref=regulated_tf, bin_no=100, output='p-value', tail='greater') # regulated_tf = variably_expressed_TFs
    #genomics.write_file_items(results, 'test_dis.txt')
    

    ### RT VS. EXPRESSION VALUES 
    ### ONLY CONSIDER GENES THAT ARE EXPRESSED IN AT LEAST 10% OF CELL-TYPES (I.E. 5 CELL-TYPES) 
    #ref = genomics.read_file_dic('/Volumes/backup/Research/Data/new_assigned/tables/repressive_hg19_cont_prop.txt', col_idx=1, id_idx=0)
    #results = [['#gene','RT','mean','CV','min','max']]
    #for g in exp_:
    #    cnt = 0
    #    all_ = []
    #    if g in ref:
    #        for c in exp_[g]:
    #            if float(exp_[g][c]) > 1:
    #                cnt += 1
    #                all_.append(float(exp_[g][c]))
    #        if cnt > 4:
    #        	mean_ = np.mean(all_)
    #        	sd_ = np.std(all_)
    #        	min_ = mean_ - 1.96 * sd_ / np.sqrt(cnt)
    #        	max_ = mean_ + 1.96 * sd_ / np.sqrt(cnt)
    #        	results.append([g, ref[g], mean_, sd_/mean_, min_, max_])    
    #genomics.write_file(results, '/Volumes/backup/Research/Data/rt_vs_exp_ori.txt')


    ### ADDING PERCENTILE RANK POSITION 
    #temp = genomics.read_file1('/Volumes/backup/Research/Data/rt_vs_exp_ori.txt', sort_by=1)
    #genes = []
    #for i in temp:
    #    genes.append(i[0])
    #a = divide_into_bins(genes, bins=100)
    #yy = {}
    #for i in range(len(a)):
    #    for j in a[i]:
    #        yy[j] = i+1
    #for i in range(len(temp)):
    #    temp[i].extend([yy[temp[i][0]]])
    #temp.insert(0, ['#gene','RT','mean','CV','min','max','rank'])
    #genomics.write_file(temp, '/Volumes/backup/Research/Data/rt_vs_exp_ori_.txt')

    ### 
    #cols = get_colnames(exp_)
    #temp = genomics.read_file1('/Volumes/backup/Research/Data/new_assigned/tables/repressive_hg19_cont_prop.txt', sort_by=1)
    #genes = []
    #count = {}
    #total = 0
    #for i in temp:
    #    if total==15000:
    #        break
    #    else:            
    #        if (i[0] in mrna) and (i[0] in exp_):
    #            cnt = 0 
    #            for c in cols:
    #                if float(exp_[i[0]][c]) > 1:
    #                    cnt += 1
    #            count[i[0]] = cnt
    #            if cnt > 0:
    #                genes.append(i[0])
    #                total += 1
    #print len(genes)
    #aa = divide_into_bins(genes, bins=150)
    #results = {}
    #for c in cols:
    #    results[c] = []

    #for i in range(len(aa)):
    #    for c in cols:
    #        qq = 0 
    #        for j in aa[i]:
    #            if exp_[j][c] > 1:
    #                qq += 1
    #        results[c].append(float(qq)/len(aa))
    #output_ = []
    #for c in results:
    #    output_.append([c])
    #    for i in results[c]:
    #        output_[-1].extend([i])
    #genomics.write_file(output_, '/Volumes/backup/Research/Data/rt_vs_prop_expression_15000_new.txt')





            #results.append([j, i+1, float(count[j])/46])
    #genomics.write_file(results, '/Volumes/backup/Research/Data/rt_rank_15000.txt')

    ### AVERAGE EXPRESSION VALUES ACROSS RT RANK POSITION (FOR ALL CELL-TYPES)
    #ref = genomics.read_file('/Volumes/backup/Research/Data/rt_rank_15000.txt', [0], rowname='1')    
    #results = []
    #for c in cols:
    #    results.append([c])
    #    for i in range(150):
    #        all_ = []
    #        for j in ref[str(i+1)]:
    #            if j[0] in exp_:
    #                if exp_[j[0]][c] > 1 :
    #                    all_.append(np.log2(exp_[j[0]][c]))
    #        if len(all_) != 0:
    #            value = np.sum(all_) / len(all_)
    #            results[-1].extend([value])
    #genomics.write_file(results, '/Volumes/backup/Research/Data/rt_vs_exp_new_15000.txt')

    ### CALCULATE AVERAGE PROPORTIONS AND MAX AND MIN
    #temp = genomics.read_file1('/Volumes/backup/Research/Data/rt_rank_15000.txt')
    #results = {}
    #for i in temp:
    #    if i[1] not in results:
    #        results[i[1]] = []
    #    results[i[1]].append(float(i[2]))
    #output_ = []
    #for i in results:
    #    mean_ = np.mean(results[i])
    #    sd_ = np.std(results[i])
    #    max_ = mean_ + 1.96 * sd_ / np.sqrt(len(results[i]))
    #    min_ = mean_ - 1.96 * sd_ / np.sqrt(len(results[i]))
    #    output_.append([i, mean_, max_, min_])
    #genomics.write_file(output_, '/Volumes/backup/Research/Data/rt_vs_prop_expression_15000.txt')





    ### PERCENT OF REFSEQ GENES WITH A RT SCORE
    #temp = genomics.read_file1('/Volumes/backup/Research/Data/hg19_TSS_.txt')
    #genes = []
    #for i in temp:
   # 	genes.append(i[5])
    #genes = list(set(genes))
    #print len(genes)
    #ref_ = genomics.read_file1('/Volumes/backup/Research/Data/new_assigned/tables/repressive_hg19_cont_prop.txt')
    #ref = set()
    #for i in ref_:
   # 	ref.add(i[0])
    #cnt = 0
    #present, absent = [], []
    #for i in genes:
   # 	if i in ref:
    #		cnt += 1
   # 		present.append(i)
   # 	else:
   # 		absent.append(i)
   # present = list(set(present))
   # absent = list(set(absent))
   # print float(cnt) / len(genes)
   # genomics.write_file_items(present, '/Volumes/backup/Research/Data/rt_positive_genes.txt')
   # genomics.write_file_items(absent, '/Volumes/backup/Research/Data/rt_negative_genes.txt')



    ### FET FOR VARIABLY EXPRESSED TFS, BY RT SCORE
    #temp = genomics.read_file1('/Volumes/backup/Research/Data/new_assigned/tables/repressive_hg19_cont_prop.txt', sort_by=1)
    #input_ = []
    #for i in temp:
   # 	input_.append(i[0])
    #results = sliding_fet(input_, regulated_tf, output_='p-value', convert_to_percentile=True, percentile_bin = 0.01)
    #results = prop_membership_for_list(input_, regulated_tf, bins=100)
    #genomics.write_file_items(results, '/Volumes/backup/Research/Data/new_assigned/prop_variably_expressed_tf_by_rt.txt')

    ### ENRICHMENT ANALYSIS BETWEEN EXP AND DIS OF ROADMAP DATA
    #ref = set(genomics.read_file_items('/Users/woojunshim/Research/Data/house_keeping_genes.txt', col=0))
    #ref = regulated_tf
    #menu = ['H3K4me1','H3K4me3','H3K9me3','H3K27me3','H3K27ac','H3K36me3']  
    #menu = [1]  
    #pathway = '/Users/woojunshim/Research/Data/'    
    #for m in menu:
    #    print m
        #results = fet_for_matrix(pathway+m+'_tss_2.5kb_combined.txt', ref)
    #    results = fet_for_matrix('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.txt', ref)
        #genomics.write_file(results, pathway+m+'_fet_house_keeping_genes.txt')
    #    genomics.write_file(results, pathway+'Expression_fet_variably_expressed_tf.txt')
    #results = fet_for_matrix(pathway+'46epigenomes.discordance.txt', ref)
    #genomics.write_file(results, pathway+'fet_variably_expressed_genes_dis.txt')

    # DISTRIBUTION OF 1.VARIABLY EXPRESSED TFS OR 2.HOUSE-KEEPING GENES FROM ROADMAP
    #ref = set(genomics.read_file_items('/Users/woojunshim/Research/Data/house_keeping_genes.txt', col=0))
    #ref = regulated_tf
    #results = prop_membership_for_matrix('/Users/woojunshim/Research/Data/46epigenomes.discordance.txt', ref, bins=100)
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/46epigenomes.discordance.variably_expressed_tf.distribution.txt')

    ### PROSTATE CANCER CELL DEMARCATION ANALYSIS
    #temp = read_table1('/Users/woojunshim/Research/Data/prostate_cancer/prostate_normalized_spatial_transcriptomics.txt')
    #genomics.write_table1(temp, '/Users/woojunshim/Research/Data/prostate_cancer/prostate_normalized_spatial_transcriptomics_.txt')

    #temp = read_table1('/Users/woojunshim/Research/Data/prostate_cancer/prostate_normalized_spatial_transcriptomics_z.txt')
    #gene = 'SPINK1'
    #results = []
    #cols = get_colnames(temp)
    




    ### SPATIALLY RESOLVED RNA-SEQ (PROSTATE CANCER)
    # 1. RUN THE DISCORDANCE SCORE
    #temp = read_table1('/Users/woojunshim/Research/Data/prostate_cancer/prostate_normalized_spatial_transcriptomics.txt')
    #ref = genomics.read_file_dic('/Users/woojunshim/Research/Data/new_assigned/tables/repressive_hg19_cont_prop.txt', col_idx=1, id_idx=0)
    #results = calculate_discordance_for_table(temp, ref, log=True, pseudo=1)
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/prostate_cancer/prostate_discordance.txt')

    # 2. CREATE THE POSITIVE GENE SET
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/prostate_cancer/KEGG_prostate_cancer_genes_extract.txt')
    #results = []
    #for i in temp:
    #    if '_(RefSeq)_' in i[0]:
    #        gene = i[0].split('_(RefSeq)_')
    #        print gene            
    #        g = gene[1].split(',_')
    #        results.append(g[0])
    #genomics.write_file_items(results, '/Users/woojunshim/Research/Data/prostate_cancer/KEGG_prostate_cancer_genes.txt')

    # 3. FET USING THE CANCER POSITIVE GENES 
    #ref = genomics.read_file_items('/Users/woojunshim/Research/Data/prostate_cancer/COSMIC_cancer_genes.txt')
    #ref = genomics.read_file_items('/Users/woojunshim/Research/Data/prostate_cancer/KEGG_prostate_cancer_genes.txt')
    #ref_ = ref
    #ref_ = []
    #for i in ref:
    #    if i in tf_list:
    #        ref_.append(i)
    #print len(ref_)
    #genomics.write_file(ref_, '/Users/woojunshim/Research/Data/prostate_cancer/COSMIC_cancer_tf.txt')
    #pathway = '/Users/woojunshim/Research/Data/prostate_cancer/'
    #inputs = [pathway+'prostate_discordance.txt', pathway+'prostate_normalized_spatial_transcriptomics.txt']
    #labels = ['Discordance', 'Expression']
    #for i in range(len(inputs)):
    #    results = fixed_fet_for_matrix(inputs, labels, ref_, rank=5)
    #    results = best_fet_for_matrix(inputs, labels, ref_)
    #results = point_fet_(inputs, labels, ref_, cut_off=300)
    #print results
    #genomics.write_file(results, pathway+'prostate_fet_for_kegg_top300_genes_tf.txt')

    # 4. ADD X-Y- COORDINATES TO THE FET TABLE
    #temp = genomics.read_file1(pathway+'prostate_fet_for_kegg_top300_genes_tf.txt')
    #results = []
    #for i in temp:
    #    if i[2] !='colname':
    #        a = i[2].split('y')
    #        x_ = a[0].split('x')
    #        y_ = a[1]
    #        print x_[1], y_
    #        results.append([i[0], i[1], x_[1], y_])
    #genomics.write_file(results, pathway+'prostate_fet_for_kegg_top300_genes_tf_table.txt')



    ### CREATE TISSUE GROUP FILES FOR MOUSE SCRNA-SEQ DATA
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/Tabula_Muris/annotations_facs_SmartSeq2.txt')
    #results = []
    #for i in temp:
    #    if (i[0]=='TRUE') or (i[0]=='FALSE'):
    #        label = i[2]
    #    else:
    #        label = i[0]
    #    results.append([label, i[-3]])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/Tabula_Muris/SmartSeq2_samples.txt')

    # CONVERT HUMAN GENES TO MOUSE GENES
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/Tabula_Muris/mouse_human_gene_mapping.txt')
    #results = {}
    #for i in temp:
    #    if i[0] not in results:
    #        results[i[0]] = []                
    #    results[i[0]].append(i[3])
    #output = []
    #for i in results:
    #    output.append(results[i])
    #genomics.write_file(output, '/Users/woojunshim/Research/Data/Tabula_Muris/mouse_human_gene_mapping_table.txt')

    # FET
    #pathway = '/Users/woojunshim/Research/Data/Tabula_Muris/'
    #labels = ['Discordance', 'Expression']
    #menu = ['TabulaMuris_10x_discordance_for_tissue.txt', 'TabulaMuris_10x_expression_for_tissue.txt']
    #files = []
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/Tabula_Muris/mouse_human_gene_mapping_table.txt')
    #ref = {}
    #for i in temp:
    #    if len(i) == 2:
    #        ref[i[1]] = i[0]
    #positive = []
    #for i in regulated_tf:
    #    if i in ref:
    #        positive.append(ref[i])
    #print len(positive)
    #print positive[:10]
    #for i in range(len(menu)):
    #    files.append(pathway+menu[i])        
    #results = best_fet_for_matrix(files, labels, ref_=positive)
    #genomics.write_file(results, pathway+'mouse_scrna_droplet_10x_fet.txt')


    ### CALCULATE TAG DENSITY FOR H3K36ME3
    # 1. CALCULATE SIZE OF TRANSCRIPTS
    #results = []
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/hg19_longest_TSS_.txt')
    #for i in temp:
    #    size = int(i[2]) - int(i[1])
    #    results.append([i[3], size])
    #genomics.write_file(results,'/Users/woojunshim/Research/Data/hg19_longest_TSS_size.txt')

    # 2. CALCULATE TAG DENSITY
    #size = genomics.read_file_dic('/Users/woojunshim/Research/Data/hg19_longest_TSS_size.txt', col_idx=1, id_idx=0)
    #results = {}
    #for g in size:
    #    results[g] = {}
    #    for e in epigenomes:
    #        results[g][e] = 0
    #for e in epigenomes:
    #    print e
    #    temp = open('/Volumes/Backup/H3K36me3/'+e+'_H3K36me3_tags.txt', 'r')
    #    qq = set()
    #    for i in temp:
    #        i = i.strip().split()
    #        g = i[4]
    #        value = (int(i[2]) - int(i[1])) * int(i[3])
    #        qq.add(g)
    #        results[g][e] += value

    #    for m in qq:
    #        results[m][e] = float(results[m][e]) / size[m]
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/H3K36me3/H3K36me3_tag_density.txt')

    # 3. CALCULATE DS 
    #temp = read_table1('/Users/woojunshim/Research/Data/H3K36me3/H3K36me3_tag_density.txt')
    #ref = genomics.read_file_dic('/Users/woojunshim/Research/Data/new_assigned/tables/repressive_hg19_cont_prop.txt', col_idx=1, id_idx=0)
    #results = calculate_discordance_for_table(temp, ref, log=True, pseudo=1)
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/H3K36me3/H3K36me3_tag_density_discordance.txt')

    # 4. FET 
    #pathway = '/Users/woojunshim/Research/Data/H3K36me3/'
    #labels = ['Discordance', 'Expression']
    #menu = ['H3K36me3_tag_density_discordance.txt', 'H3K36me3_tag_density.txt']
    #files = []
    #for i in range(len(menu)):
    #    files.append(pathway+menu[i])        
    #results = best_fet_for_matrix(files, labels, ref_=regulated_tf)
    #genomics.write_file(results, pathway+'H3K36me3_fet.txt')




    ### VARIABLY EXPRESSED GENES ANALYSIS
    #cols = get_colnames(exp_)
    #table_ = subset_table('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.txt', rows=regulated_tf, cols=cols)
    #genomics.write_table1(table_, '/Users/woojunshim/Research/Data/variably_expressed_genes_table.txt')



    ### ROADMAP IDS
    #aa = open('roadmap_id_single_line.txt', 'w')
    #for e in epigenomes:
   # 	aa.write(e+' ')
   # aa.close()

    ### FET FOR MULTI-OMICS APPLICATIONS
    #ref_ = get_list_from_table('/Users/woojunshim/Research/Data/genes_with_go_term/GO.0032502.txt', col='x')
    #ref = []
    #for i in ref_:
   # 	if i in tf_list:
   # 		ref.append(i)
    #ref = regulated_tf
    #print len(ref)
   # pathway = '/Users/woojunshim/Research/Data/proteomics/'
    #pathway = '/Users/woojunshim/Research/Data/FANTOM/'
   # items = ['HPM_discordance_protein.txt', 'HPM_protein_exp_table_final.txt']
    #items = ['hg19_cage_discordance_selected.txt','hg19_cage_expression_selected.txt']
    #names = ['Discordance','Expression']
    #files = []
    #for i in range(len(items)):
   # 	files.append(pathway+items[i])

    #results = best_fet_for_matrix_cage(files, names, ref)
    #genomics.write_file(results, pathway+'CAGE_best_fet_development_term.txt')

    ### NEW FET FOR DAY 30 CLUSTER 2
    #temp = genomics.read_csv('/Users/woojunshim/Research/Data/Clayton/d30c2.csv')
    #results = []
    #for i in temp:
    #    if i[6] != 'NA':
    #        results.append(i)
    #results = remove_ff_element(results)
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/Clayton/d30c2_table.txt')

    #terms = ['GO.0007507', 'GO.0048738', 'GO.0072358']
    #terms = ['GO.0030017']
    #for term in terms:

    #    temp = read_table1('/Users/woojunshim/Research/Data/genes_with_go_term/'+term+'.txt', numerical=False)
    #    ref_ = []
    #    for g in temp:        
    #        ref_.append(temp[g]['x'])
    #    ref_ = set(ref_)   
    #    ref = []
    #    print len(ref_)

    #    table_ = read_table1('/Users/woojunshim/Research/Data/Clayton/d30c2_table.txt')

    #    rt = genomics.read_file_dic('/Users/woojunshim/Research/Data/new_assigned/tables/repressive_hg19_cont_prop.txt', col_idx=1, id_idx=0)
    #    results = calculate_discordance_for_table(table_, rt)
    #    dis_, exp_ = [], []
    #    exp, dis = [], []
    #    for g in table_:
    #        if float(table_[g]['mean_exp_w_0']) > 0:
    #            exp_.append([g, float(table_[g]['mean_exp_w_0'])])
    #            if (g in ref_) and (g in tf_list):
    #                ref.append(g)
    #    exp_ = genomics.sort_(exp_, idx=1, reverse_=True)
    #    for i in exp_:
    #        exp.append(i[0])

    #    for g in results:
    #        if float(results[g]['mean_exp_w_0']) > 0:
    #            dis_.append([g, float(results[g]['mean_exp_w_0'])])
    #    dis_ = genomics.sort_(dis_, idx=1, reverse_=True)
    #    for i in dis_:
    #        dis.append(i[0])

    #    print len(ref)
    #    out_ = {}
    #    for i in range(1,101):
    #        out_[str(i)] = {}
    #        out_[str(i)]['Discordance'] = 1
    #        out_[str(i)]['Expression'] = 1

    #    r1 = sliding_fet(exp, ref, output_='p-value', convert_to_percentile=True, percentile_bin = 0.01)
    #    r2 = sliding_fet(dis, ref, output_='p-value', convert_to_percentile=True, percentile_bin = 0.01)

    #    for i in range(len(r1)):
    #        out_[str(i+1)]['Expression'] = r1[i]
    #        out_[str(i+1)]['Discordance'] = r2[i]

    #    genomics.write_table1(out_, '/Users/woojunshim/Research/Data/Clayton/d30c2_'+term+'_fet.txt')
    #    genomics.write_file_items(ref, '/Users/woojunshim/Research/Data/Clayton/d30c2_'+term+'_positive.txt')


    ### DENDROGRAM ANALYSIS FOR 6 DIFFERENT SPECIES
    # 1. IDENTIFY COMMON GENES (FOR ONLY COMMON GENES)
    #genes = set()
    #record = {}
    #record['ciona_intestinalis'] = set()
    #temp = read_table1('/Users/woojunshim/Research/Data/ciona/ciona_dis_table_.txt', numerical=False)
    #for g in temp:
    #    genes.add(g)
    #    record['ciona_intestinalis'].add(g)
    #menu = ['danio_rerio','galas_galas','homo_sapiens','mus_musculus','sus_scrofa']    
    #for m in menu:
    #    record[m] = set()
    #    temp = genomics.read_csv('/Users/woojunshim/Research/Data/interspecies/heart/discordance_'+m+'_20181112.csv')
    #    for i in temp:
    #        if not i[0].startswith('GENE'):
    #            genes.add(i[2])
    #            record[m].add(i[2])
    #final = []
    #print len(record['ciona_intestinalis'])
    #menu.append('ciona_intestinalis')
    #for g in genes:
    #    tag = 1
    #    for m in menu:
    #        if g not in record[m]:
    #            tag = 0
    #    if tag == 1:
    #        final.append(g)
    #print len(final)

    # 1. IDENTIFY GENES (ALTERNATIVE METHODS)
    #final_d, final_e = set(), set()
    #temp = read_table1('/Users/woojunshim/Research/Data/ciona/ciona_dis_table_.txt', numerical=False)
    #qq = get_rownames_by_sorting_table(temp, col='X20FHP')
    #for i in range(100):
    #    final_d.add(qq[i][0])

    #for m in menu:
    #    temp = genomics.read_csv('/Users/woojunshim/Research/Data/interspecies/heart/discordance_'+m+'_20181112.csv')
    #    temp = temp[1::]
    #    qq = []
    #    for i in temp:
    #        qq.append([i[2], float(i[4])])
    #    qq = genomics.sort_(qq, idx=1, reverse_=True)
    #    for i in range(100):
    #        final_d.add(qq[i][0])    

    #temp = read_table1('/Users/woojunshim/Research/Data/ciona/ciona_exp_table_.txt', numerical=False)
    #qq = get_rownames_by_sorting_table(temp, col='X20FHP')
    #for i in range(100):
    #    final_e.add(qq[i][0])

    #for m in menu:
    #    temp = genomics.read_csv('/Users/woojunshim/Research/Data/interspecies/heart/discordance_'+m+'_20181112.csv')
    #    temp = temp[1::]
    #    qq = []
    #    for i in temp:
    #        qq.append([i[2], float(i[3])])
    #    qq = genomics.sort_(qq, idx=1, reverse_=True)
    #    for i in range(100):
    #        final_e.add(qq[i][0])
    #menu.append('ciona_intestinalis')

    #print len(final_d), len(final_e)

    # 2. CREATE A DATA MATRIX
    #dis = {}
    #for g in final_d:
    #    dis[g] = {}
    #    for m in menu:
    #        dis[g][m] = 0
    #temp1 = read_table1('/Users/woojunshim/Research/Data/ciona/ciona_dis_table_.txt', numerical=False)

    #for g in final_d:
    #    if g in temp1:
    #        dis[g]['ciona_intestinalis'] = temp1[g]['X20FHP']
    #for m in menu[0:len(menu)-1]:
    #    temp = genomics.read_csv('/Users/woojunshim/Research/Data/interspecies/heart/discordance_'+m+'_20181112.csv')
    #    for i in temp:
    #        if i[2] in final_d:
    #            dis[i[2]][m] = i[4]
    #genomics.write_table1(dis, '/Users/woojunshim/Research/Data/interspecies/heart/interspecies_discordance_table_top100.txt')
    
    #exp = {}
    #for g in final_e:
    #    exp[g] = {}
    #    for m in menu:
    #        exp[g][m] = 0
    #temp2 = read_table1('/Users/woojunshim/Research/Data/ciona/ciona_exp_table_.txt', numerical=False)

    #for g in final_e:
    #    if g in temp2:
    #        exp[g]['ciona_intestinalis'] = temp2[g]['X20FHP']
    #for m in menu[0:len(menu)-1]:
    #    temp = genomics.read_csv('/Users/woojunshim/Research/Data/interspecies/heart/discordance_'+m+'_20181112.csv')
    #    for i in temp:
    #        if i[2] in final_e:
    #            exp[i[2]][m] = i[3]
    #genomics.write_table1(exp, '/Users/woojunshim/Research/Data/interspecies/heart/interspecies_expression_table_top100.txt')



   






    ### FET FOR CAGE DATA
    #results = [['p-value','rank','method','tissue']]
    #results = [['p-value','method','tissue']]
    #exp = read_table1('/Users/woojunshim/Research/Data/FANTOM/hg19_cage_expression_selected.txt')
    #dis = read_table1('/Users/woojunshim/Research/Data/FANTOM/hg19_cage_discordance_selected.txt')
    #cols_ = genomics.read_file1('/Users/woojunshim/Research/Data/FANTOM/development_sample_ids.txt')
    #cols = []
    #for i in cols_:
    #	cols.append(i[0])
    #ref__ = read_table1('/Users/woojunshim/Research/Data/genes_with_go_term/GO.0032502.txt', numerical=False)
    #ref_ = set()
    #for i in ref__:
   # 	ref_.add(ref__[i]['x'])    
    #cnt = 0
    #for c in cols:
    #	cnt += 1
   # 	print cnt
   # 	input_ = []
   # 	genes = set()
   # 	temp = []
   # 	ref = set()    	
   # 	for g in exp:
   # 		if '@chr' not in g:
   # 			name = g.split('@')[1]    				
    #			if name not in genes:
   # 				if float(exp[g][c]) > 0:
   # 					temp.append([name, float(exp[g][c])])
   # 					genes.add(name)
   # 					if (name in ref_) and (name in tf_list):
   # 						ref.add(name)
   # 	temp = genomics.sort_(temp, idx=1, reverse_=True)    	
   # 	for i in temp:
   # 		input_.append(i[0])    	
   # 	aa = sliding_fet(input_, ref)
    	#value = np.min(aa)
    	#idx_ = aa.index(value)
    	#results.append([value, idx_, 'Expression', c])
   # 	results.append([aa[4], 'Expression', c])    	

    #	input_ = []
   # 	genes = set()
   # 	temp = []
   # 	ref = set()    	
   # 	for g in dis:
   # 		if '@chr' not in g:
   # 			name = g.split('@')[1]
   # 			if name not in genes:
   # 				if float(dis[g][c]) > 0:
   # 					temp.append([name, float(dis[g][c])])
   # 					genes.add(name)
   # 					if (name in ref_) and (name in tf_list):
   # 						ref.add(name)
   # 	temp = genomics.sort_(temp, idx=1, reverse_=True)
   # 	for i in temp:
   # 		input_.append(i[0])
   # 	bb = sliding_fet(input_, ref)    	
    	#value = np.min(bb)
    	#idx_ = bb.index(value)
    	#results.append([value, idx_, 'Discordance', c])
   # 	results.append([bb[4], 'Discordance', c]) 

    #genomics.write_file(results, '/Users/woojunshim/Research/Data/FANTOM/hg19_cage_dis_vs_exp_development_top5.txt')
    	










    ### REMOVE TSS IDS CAGE DATA
    #temp = open('/Users/woojunshim/Research/Data/FANTOM/hg19_cage_expression_table.txt', 'r')
    #results = []
    #cnt=0
    #for i in temp:
   # 	i = i.strip().split()
   # 	cnt += 1
   # 	if cnt % 10000 == 0:
   # 		print cnt
   # 	if '@' in i[0]:
   # 		g = i[0].split('@')[1]
   # 		i[0] = g
   # 	results.append(i)
   # genomics.write_file(results, '/Users/woojunshim/Research/Data/FANTOM/hg19_cage_expression.txt')


    ### EXTRACT CAGE SAMPLES
    #ref_ = open('/Users/woojunshim/Research/Data/FANTOM/cage_development_samples.txt', 'r')
    #results = []
    #cnt = 0
    #for i in ref_:
   # 	i = i.strip().split()
   # 	if i[0].startswith('#'):
   # 		cnt += 1
   # 		name = ''
   # 		for m in range(1, len(i)):
   # 			name += i[m]+'_'    			
   # 		continue
   # 	else:
   # 		results.append([i[0], cnt, name])
   # genomics.write_file(results, '/Users/woojunshim/Research/Data/FANTOM/development_sample_ids.txt') 

    # CALCULATE FET AND EXTRACT STATUSTICS FOR CAGE DATA
    #temp = 


    ### CIONA FET
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/ciona/ciona_dis_table.txt')
    #results = []
    #for i in temp:
    #    if (i[0] != 'no_mouse_gene_to_map') and (i[0] != 'no_human_gene_to_map'):
    #        results.append(i)
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/ciona/ciona_dis_table_.txt')

    #results = {}
    #for i in range(1,101):
    #    results[str(i)] = {}
    #    results[str(i)]['Discordance'] = 1
    #    results[str(i)]['Expression'] = 1

    #temp = read_table1('/Users/woojunshim/Research/Data/ciona/ciona_exp_table_.txt', numerical=False)
    #ref__ = read_table1('/Users/woojunshim/Research/Data/genes_with_go_term/GO.0007507.txt', numerical=False)
    #genes = []
    #yy = []
    #for g in temp:
    #    if float(temp[g]['X20FHP']) > 0:
    #        genes.append(g)
    #        yy.append([g, float(temp[g]['X20FHP'])])
    #genes = set(genes)
    #yy = genomics.sort_(yy, idx=1, reverse_=True)
    #input_ = []
    #for i in yy:
    #    input_.append(i[0])
    #ref_ = []
    #for i in ref__:
    #    if (ref__[i]['x'] in genes) and (ref__[i]['x'] in tf_list):
    #        ref_.append(ref__[i]['x'])
    #aa = sliding_fet(input_, ref_)
    #for i in range(len(aa)):
    #    results[str(i+1)]['Expression'] = aa[i]

    #temp = read_table1('/Users/woojunshim/Research/Data/ciona/ciona_dis_table_.txt', numerical=False)
    #ref__ = read_table1('/Users/woojunshim/Research/Data/genes_with_go_term/GO.0007507.txt', numerical=False)
    #yy = []
    #for g in temp:
    #    if float(temp[g]['X20FHP']) > 0:            
    #        yy.append([g, float(temp[g]['X20FHP'])])
    #yy = genomics.sort_(yy, idx=1, reverse_=True)
    #input_ = []
    #for i in yy:
    #    input_.append(i[0])
    #aa = sliding_fet(input_, ref_)
    #for i in range(len(aa)):
    #    results[str(i+1)]['Discordance'] = aa[i]

    #
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/ciona/ciona_fet_heart_development.txt')





    ## COUNT THE NUMBER OF GENES WITH A DISEASE TERM
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/disease/ALL_SOURCES_ALL_FREQUENCIES_genes_to_phenotype.txt')
    #genes = set()
    #for i in temp:
    #    genes.add(i[1])
    #print len(genes)

    ### CAGE DATA ANALYSIS
    # 1. CREATE A RT TABLE FOR CAGE DATA
    #temp = open('/Users/woojunshim/Research/Data/FANTOM/hg19_cage_tag_table_new.txt', 'r')
    #ref_ = genomics.read_file_dic('/Users/woojunshim/Research/Data/new_assigned/tables/repressive_hg19_cont_prop.txt', col_idx=1, id_idx=0)
    #genes = []
    #for i in temp:
    #    i = i.strip().split()
    #    if not i[0].startswith('col'):
    #        genes.append(i[0])
    #print 'read done', len(genes)
    #output = []
    #for g in genes:
    #    g_ = g.split('@')[1]
    #    if g_ in ref_:
    #        output.append([g, ref_[g_]])
    #genomics.write_file(output, '/Users/woojunshim/Research/Data/new_assigned/tables/repressive_hg19_cont_prop_cage.txt')

    # 2. CALCULATE DISCORDANCE SCORES 
    #ref_ = genomics.read_file_dic('/Users/woojunshim/Research/Data/new_assigned/tables/repressive_hg19_cont_prop.txt', col_idx=1, id_idx=0)
    #results = calculate_discordance_for_table('/Users/woojunshim/Research/Data/FANTOM/hg19_cage_tag_table_new.txt', ref_)
    #results = calculate_discordance_for_table(exp_, ref_)
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/46epigenomes.discordance.txt')




    ### PROTEOMICS ANALYSIS
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/proteomics/HPM_protein_level_expression_matrix.txt')
    #genomics.write_file(temp, '/Users/woojunshim/Research/Data/proteomics/HPM_protein_level_expression_table.txt')

    #for i in range(len(temp)):
    #    temp[i][1] = temp[i][1].split('.')[0]
    #genomics.write_file(temp, '/Users/woojunshim/Research/Data/proteomics/HPM_protein_level_expression_table.txt')

    ### CONVERT REFSEQ PROTEIN TO GENE SYMBOL
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/proteomics/refseq_protein_to_gene_symbol.txt')
    #ref = {}
    #for i in temp:
    #    if len(i) == 3:
    #        ref[i[2]] = i[1]

    #table_ = read_table1('/Users/woojunshim/Research/Data/proteomics/HPM_gene_level_epxression_table_.txt')
    #results = {}
    #cols = get_colnames(table_)
    #for g in table_:
    #    if g in ref:
    #        results[ref[g]] = {}
    #        for c in cols:
    #            results[ref[g]][c] = table_[g][c]
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/proteomics/HPM_gene_level_epxression_table_final.txt')

    #ref_ = genomics.read_file_dic('/Users/woojunshim/Research/Data/new_assigned/tables/repressive_hg19_cont_prop.txt', col_idx=1, id_idx=0)
    #temp = read_table1('/Users/woojunshim/Research/Data/proteomics/HPM_protein_level_expression_table_final.txt')    
    #results = calculate_discordance_for_table(temp, ref_)
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/proteomics/HPM_discordance_protein.txt')

    # NORMALISED DISCORDANCE SCORE FOR 1000 GENES FROM EACH CELL-TYPE ACROSS CELL-TYPES
    #temp = read_table1('/Users/woojunshim/Research/Data/proteomics/HPM_discordance_protein.txt')
    #genes = set()
    #cols = get_colnames(temp)
    #for c in cols:
    #    aa = sort_column(temp, c)
    #    for m in range(200):
    #        genes.add(aa[m][0])
    #print len(genes)
    #new = subset_table('/Users/woojunshim/Research/Data/proteomics/HPM_discordance_protein.txt', rows=genes, cols=cols)
    #genomics.write_table1(new, '/Users/woojunshim/Research/Data/proteomics/HPM_discordance_protein_selected.txt')

    #results = {}
    #for g in genes:
    #    results[g] = {}
    #    for c in cols:
    #        results[g][c] = 0
    #for c in cols:
    #    sum_ = 0
    #    for g in genes:
    #        sum_ += new[g][c]
    #    for g in genes:
    #        results[g][c] = new[g][c] / sum_

    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/proteomics/HPM_protein_exp_selected_normalised.txt')

    #yy = {}
    #for g in genes:
    #    yy[g] = {}
    #    sum_ = 0
    #    for c in cols:
    #        sum_ += results[g][c]
    #    for c in cols:
    #        yy[g][c] = results[g][c] / sum_

    #genomics.write_table1(yy, '/Users/woojunshim/Research/Data/proteomics/HPM_protein_exp_selected_normalised_both.txt')


    ### FET FOR PROTEOMICS DEVELOPMENT TISSUE TYPES
    #cols = ['Fetal_Heart','Fetal_Liver','Fetal_Gut','Fetal_Ovary','Fetal_Testis','Fetal_Brain']
    #temp = read_table1('/Users/woojunshim/Research/Data/genes_with_go_term/GO.0032502.txt', numerical=False)
    #positives = []
    #for i in temp:
    #    if temp[i]['x'] in tf_list:
    #        positives.append(temp[i]['x'])
    #print positives[0:10]
    #print len(positives)
    #results = fet_for_matrix('/Users/woojunshim/Research/Data/proteomics/HPM_protein_exp_table_final.txt', positives)
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/proteomics/HPM_exp_fet.txt')

    # COLLECT LOWEST P-VALUE AND THE POSITION FROM BOTH DISCORDANCE AND EXPRESSION VALUES
    #temp = read_table1('/Users/woojunshim/Research/Data/proteomics/HPM_discordance_protein.txt')
    #cols = get_colnames(temp)
    #results = [['p-value','rank','method','tissue']]
    #a = genomics.read_file1('/Users/woojunshim/Research/Data/proteomics/HPM_discordance_fet_development.txt')    
    #for i in a:
    #    if i[0] in cols:
    #        temp = []
    #        for m in range(1, len(i)):
    #            temp.append(float(i[m]))
    #        min_ = np.min(temp)
    #        idx = temp.index(min_)+1
    #        results.append([min_, idx, 'discordance',i[0]])

    #a = genomics.read_file1('/Users/woojunshim/Research/Data/proteomics/HPM_exp_fet_development.txt')    
    #for i in a:
    #    if i[0] in cols:
    #        temp = []
    #        for m in range(1, len(i)):
    #            temp.append(float(i[m]))
    #        min_ = np.min(temp)
    #        idx = temp.index(min_)+1
    #        results.append([min_, idx, 'expression',i[0]])

    #genomics.write_file(results, '/Users/woojunshim/Research/Data/proteomics/HPM_dis_vs_exp_all.txt')

    ### FET FOR PROTEOMICS DATA
    # WITH THE VARIABLY EXPRESSED GENES







    ### MEAN H3K27ME3 WIDTH
    #ref = read_table1('/Users/woojunshim/Research/Data/H3K27me3_width_table.txt', numerical=True)
    #house = genomics.read_file_items('/Users/woojunshim/Research/Data/house_keeping_genes.txt', col=0)
    #house = set(house)
    #cols = get_colnames(ref)
    #no = len(cols)
    #results = []
    #for g in ref:
   # 	if g in mrna:
#	    	sum_ = 0 
	#    	for c in ref[g]:
	#    		sum_ += ref[g][c]	    	
	#    	if g in regulated_tf:
	#    		results.append([float(sum_)/no, 'TF'])
	#    	if g in house:
	#    		results.append([float(sum_)/no, 'House-keeping'])
	#    	results.append([float(sum_)/no, 'All'])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/mean_H3K27me3_breadths.txt')

    ### DISCORDANCE SCORES FOR SELECTED CARDIAC GENES
    #cols = ['E095','E104','E105','E082','E071','E070','E059','E058','E057','E047','E038','E037','E024','E016','E003','E006','E005','E004']
    #genes = ['GATA4','GATA6','NKX2-5','TBX5','TBX20','MYH6','MYH7','MYL2','MYL3','TNNI3']
    #table_ = subset_table('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.txt', rows=genes, cols=cols)
    #ref_ = genomics.read_file_dic('/Users/woojunshim/Research/Data/new_assigned/tables/repressive_hg19_cont_prop.txt', col_idx=1, id_idx=0)
    #results = calculate_discordance_for_table(exp_, ref_)
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/discordance_table.txt')



    

    ### CAGE DATA ANALYSIS
    #ref_ = genomics.read_file_dic('/Users/woojunshim/Research/Data/new_assigned/tables/repressive_hg19_cont_prop.txt', col_idx=1, id_idx=0)
    #results = calculate_discordance_for_table('/Users/woojunshim/Research/Data/FANTOM/hg19_cage_tag_table_new.txt', ref_)
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/FANTOM/hg19_cage_discordance_table.txt')


    ### WILCOXON RANK SUM TEST FOR BOVINE DATASETS
    #negative = ['NE001407','NE001572','NE001634','NE001735','NE001887','NE001981']
    #positive = ['NE001455','NE001513','NE001636','NE001783','NE001831','NE003837']
    #temp = read_table1('/Users/woojunshim/Research/bovine/bovine_discordance_score_updated__.txt', numerical=False)
    #genes = get_rownames(temp)
    #results = []
    #for g in genes:
    #    neg, pos = [], []
    #    for i in negative:
    #        neg.append(float(temp[g][i]))
    #    for i in positive:
    #        pos.append(float(temp[g][i]))
    #    s, p = stat.wilcoxon(pos, neg)
    #    results.append([g, s, p])
    #genomics.write_file(results, '/Users/woojunshim/Research/bovine/rank_comparison.txt')

    ### CALCULATE AVE. EXPRESSION VALUES OF HOUSE-KEEPING GENES
    #ref = genomics.read_file_items('/Users/woojunshim/Research/Data/house_keeping_genes.txt', col=0)
    #temp = read_table1('/Users/woojunshim/Research/Data/GTEX/GTEX_tissue_exp_ave_table.txt', numerical=True)
    #genes = get_rownames(temp)
    #tissues = ['Heart_-_Left_Ventricle','Brain_-_Cortex','Pancreas','Lung','Muscle_-_Skeletal']
    #temp = subset_table('/Users/woojunshim/Research/Data/GTEX/GTEX_tissue_exp_ave_table.txt', rows=genes, cols=tissues)
    #genomics.write_table1(temp, '/Users/woojunshim/Research/Data/GTEX/GTEX_tissue_exp_ave_table_subset.txt')

    #results = []
    #for g in ref:
    #    if g in temp:
    #        a = []
    #        for c in temp[g]:
    #            a.append(temp[g][c])
    #        mean_ = np.mean(a)
    #        sd_ = np.std(a)
    #        results.append([g, mean_, sd_])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/GTEX/house_keeping_genes_ave_exp.txt')

    ### CHECK EEF2 VS GAPDH
    #tissues = ['Heart_-_Left_Ventricle','Brain_-_Cortex','Pancreas','Lung','Muscle_-_Skeletal']
    #genes = ['GAPDH','EEF2']
    #for t in tissues:
    #    print t
    #    for g in genes:
    #        print temp[g][t]
    #    print

    #ref = genomics.read_file_dic('/Users/woojunshim/Research/Data/new_assigned/tables/repressive_hg19_cont_prop.txt', col_idx=1, id_idx=0)
    #min_ = 1
    #for g in ref:
    #    if (float(ref[g]) != float(0)):
    #        if float(ref[g]) < min_:
    #            min_ = float(ref[g])
    #print min_
    #dis = {}
    #for g in genes:
    #    if g in ref:
    #        value = ref[g]
    #    else:
    #        value = min_
    #    dis[g] = {}
    #    for t in tissues:
    #        dis[g][t] = np.log(temp[g][t]+1) * value
    #genomics.write_table1(dis, '/Users/woojunshim/Research/Data/GTEX/GTEX_tissue_dis_subset.txt')

    #for t in tissues:
    #    aa = []
    #    for g in genes:
    #        if float(dis[g][t]) > 0:
    #            aa.append(float(dis[g][t]))
    #    mean_ = np.mean(aa)
    #    sd_ = np.std(aa)
    #    print 
    #    print mean_, sd_
    #    for g in genes:
    #        dis[g][t] = (float(dis[g][t]) - mean_) / sd_
    #genomics.write_table1(dis,'/Users/woojunshim/Research/Data/GTEX/GTEX_tissue_dis_subset_z.txt' )
    
    #for t in tissues:
    #    aa = []
    #    for g in genes:
    #        if float(temp[g][t]) > 0:
    #            aa.append(float(temp[g][t]))
    #    mean_ = np.mean(aa)
    #    sd_ = np.std(aa)
    #    for g in genes:
    #        temp[g][t] = (float(temp[g][t]) - mean_) / sd_
    #genomics.write_table1(temp, '/Users/woojunshim/Research/Data/GTEX/GTEX_tissue_exp_ave_table_subset_z.txt')

    #tissues = ['Heart_-_Left_Ventricle','Brain_-_Cortex','Pancreas','Lung','Muscle_-_Skeletal']
    #genes = ['GAPDH','EEF2','NKX2-5','TNNI3','NEUROD2','GFAP','PTF1A','REG1B','TBX4','SFTPB','MYOD1','TNNI2']
    #temp = read_table1('/Users/woojunshim/Research/Data/GTEX/GTEX_tissue_exp_subset_z_.txt')




    ### FISHER'S EXACT TEST FOR INTER-SPECIES DATA (CARDIAC)
    #temp = read_table1('/Users/woojunshim/Research/Data/genes_with_go_term/GO.0007507.txt', numerical=False)
    #ref_ = []
    #for g in temp:
    #    ref_.append(temp[g]['x'])
    #ref_ = set(ref_)    

    #pathway = '/Volumes/OMICS2018-A1171/04_Data/RNA-seq samples from diverse species/heart/'
    #menu = ['discordance - cavia porcellus.csv', 'discordance - Ciona intestinalis.csv', 'discordance - Danio rerio.csv', 'discordance - Galus Galus.csv', 'discordance - Homo sapiens.csv', 'discordance - Mus musculus.csv', 'discordance - Sus scrofa.csv']
    #names = ['Cavia porcellus','Ciona intestinalis','Danio rerio','Galus Galus','Homo sapiens','Mus musculus','Sus scrofa']    
    #for n in range(len(names)):
    #    ref = []
    #    name = names[n]
    #    file = pathway+menu[n]
    #    a = open(file, 'r')
    #    genes = []
    #    exp_ = []
    #    for line in a:            
    #        line = line.split(',')
    #        g = line[1].strip('"')
    #        if line[0].startswith('"ENSG'):
    #            if float(line[4]) > float(0):
    #                genes.append(g)
    #                exp_.append([g, float(line[4])])                    
    #                if (g in ref_) and (g in tf_list):
    #                    ref.append(g)
    #    print
    #    print len(ref)        
    #    print name
    #    exp_ = genomics.sort_(exp_, idx=1, reverse_=True)
    #    exp = []
    #    for i in exp_:
    #        exp.append(i[0])
    #    results = {}
    #    for i in range(1,101):
    #        results[str(i)] = {}
    #        results[str(i)]['Expression'] = 1
    #        results[str(i)]['Discordance'] = 1
    #    print exp[0:10], len(exp)
    #    print genes[0:10], len(genes)
    #    r1 = sliding_fet(genes, ref, output_='p-value', convert_to_percentile=True, percentile_bin = 0.01)
    #    r2 = sliding_fet(exp, ref, output_='p-value', convert_to_percentile=True, percentile_bin = 0.01)
    #    print r1[0:10]
    #    print r2[0:10]
    #    for i in range(len(r1)):
    #        results[str(i+1)]['Discordance'] = r1[i]
    #        results[str(i+1)]['Expression'] = r2[i]
    #    genomics.write_table1(results, '/Users/woojunshim/Research/Data/interspecies/'+name+'_fet.txt')
    #    genomics.write_file_items(ref, '/Users/woojunshim/Research/Data/interspecies/'+name+'_GO.0007507_genes.txt')




    ### EXTRACT NORMALISED EXPRESSION & DISCORDANCE SCORE MATRICES FROM GTEX DATASET
    #temp = read_table1('/Users/woojunshim/Research/Data/GTEX/GTEX_tissue_exp_ave_table.txt', numerical=True)
    #genes = ['NKX2-5','MYL7','NEUROD1','GFAP','PTF1A','REG1B','NKX2-8','SFTPB','MYOD1','TNNI2','GAPDH','GPI']
    #ref = genomics.read_file_dic('/Users/woojunshim/Research/Data/new_assigned/tables/repressive_hg19_cont_prop.txt', col_idx=1, id_idx=0)
    #exp, dis = {}, {}
    #tissues = ['Heart_-_Left_Ventricle','Brain_-_Cortex','Pancreas','Lung','Muscle_-_Skeletal']
    #cols = get_colnames(temp)
    #max_, min_ = 0, 1

    #for g in genes:
   # 	exp[g] = {}
    #	aa = []
   # 	for c in cols:
   # 		aa.append(np.log10(temp[g][c]))
   # 	mean_ = np.mean(aa)
   # 	sd_ = np.std(aa)
   # 	for t in tissues:
    		#exp[g][t] = (np.log10(temp[g][t]) - mean_) / sd_
   # 		exp[g][t] = np.log10(temp[g][t]+1)
   # 		if exp[g][t] > max_:
   # 			max_ = exp[g][t]
   # 		if exp[g][t] < min_:
   # 			min_ = exp[g][t]
   # for g in genes:
   # 	for t in tissues:
   # 		exp[g][t] = (exp[g][t] - min_) / (max_ - min_)
   # print max_, min_
   # max_, min_ = 0, 1

    #for g in genes:
   # 	dis[g] = {}
    	#aa = []
    	#for c in cols:
    #		value = np.log10(temp[g][c]) * ref[g]
   # 		aa.append(value)
   # 	mean_ = np.mean(aa)
   # 	sd_ = np.std(aa)
    #	for t in tissues:
   # 		value = np.log10(temp[g][t]+1) * ref[g]
   # 		dis[g][t] = value
   # 		if value > max_:
   # 			max_ = value
   # 		if value < min_:
   # 			min_ = value
   # for g in genes:
   # 	for t in tissues:
   # 		dis[g][t] = (dis[g][t] - min_) / (max_ - min_)
   # print max_, min_
   # genomics.write_table1(exp, '/Users/woojunshim/Research/Data/GTEX/GETX_selected_exp_normalised.txt')
    #genomics.write_table1(dis, '/Users/woojunshim/Research/Data/GTEX/GETX_selected_dis_normalised.txt')

    # WHAT ABOUT Z-SCORES ?
    #for g in genes:
   # 	exp[g] = {}
   # 	dis[g] = {}
   # 	for t in tissues:
   # 		exp[g][t] = 0
   # 		dis[g][t] = 0

    #for t in tissues:
   # 	all_ = set()
   # 	for g in temp:
   # 		if temp[g][t] > 0:
   # 			if g in ref:
   # 				all_.add(g)
   # 	aa = []
   # 	bb = []
   # 	for g in all_:
   # 		aa.append(temp[g][t])
   # 		bb.append((np.log(temp[g][t])+1) * ref[g])
   # 	mean_ = np.mean(aa)
   # 	sd_ = np.std(aa)
   # 	for ga in genes:
   # 		exp[ga][t] = (temp[ga][t] - mean_) / sd_

    #	mean_ = np.mean(bb)
   # 	sd_ = np.std(bb)
   # 	for ga in genes:
   # 		dis[ga][t] = (((np.log(temp[ga][t])+1) * ref[ga]) - mean_) / sd_
   # genomics.write_table1(exp, '/Users/woojunshim/Research/Data/GTEX/GETX_expression.txt')
   # genomics.write_table1(dis, '/Users/woojunshim/Research/Data/GTEX/GETX_discordance.txt')

    # MERGE EXP AND DISCORDANCE TABLES 
    #a = read_table1('/Users/woojunshim/Research/Data/GTEX/GETX_expression.txt', numerical=True)
    #b = read_table1('/Users/woojunshim/Research/Data/GTEX/GETX_discordance.txt', numerical=True)
    #results = {}
    #cols = get_colnames(a)
    #genes = get_rownames(a)
    #for g in genes:
   #		results[g] = {}
   	#	for c in cols:
   #			name = c.split('_-_')[0]
   #			results[g][name+'-Exp'] = a[g][c]
   #			results[g][name+'-Dis'] = b[g][c]
   # genomics.write_table1(results, '/Users/woojunshim/Research/Data/GTEX/GETX_exp_dis_table.txt')

    


    ### MERGE FETAL LIVER CHIP-SEQ SAMPLES
    #t1 = genomics.read_file1('/Users/woojunshim/Research/Data/fetal_liver/GSM1598044_Fetal_liver_H3K4me3_rep1_peaks.txt')
    #t2 = genomics.read_file1('/Users/woojunshim/Research/Data/fetal_liver/GSM1598045_Fetal_liver_H3K4me3_rep2_peaks.txt')
    #results = []
    #cnt = 1
    #for i in t1:
   # 	results.append([i[0], i[1], i[2], 'peak_'+str(cnt)])
    #	cnt += 1
    #for i in t2:
   # 	results.append([i[0], i[1], i[2], 'peak_'+str(cnt)])
    #	cnt += 1
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/fetal_liver/fetal_liver_h3k4me3.txt')

    ### ASSIGN GENES TO FETAL LIVER
    #results = assign_genes('/Users/woojunshim/Research/Data/fetal_liver/fetal_liver_h3k4me3.txt', '/Users/woojunshim/Research/Data/hg19_TSS_.txt', min_distance=0, max_distance=9999999999, centre=False, width=True, gene_include=True)
    #aa = sort_assigned_genes(results)
    #genomics.write_file(aa, '/Users/woojunshim/Research/Data/fetal_liver/fetal_liver_h3k4me3_assigned.txt')

    ### PROCESS '/Users/woojunshim/Research/Data/fetal_liver/GSE63634_Fetal_organs_RefSeq_Gene_FPKM.txt'
    #temp = open('/Users/woojunshim/Research/Data/fetal_liver/GSE63634_Fetal_organs_RefSeq_Gene_FPKM.txt', 'r')
    #results = []
    #for i in temp:
   # 	i=i.strip().split()    	
   # 	results.append(i)
   # genomics.write_file(results, '/Users/woojunshim/Research/Data/fetal_liver/fetal_FPKM_table.txt')

    ### CREATE A MERGED INPUT TABLE
    #aa = calculate_ave_columns('/Users/woojunshim/Research/Data/fetal_liver/fetal_FPKM_table.txt', cols=['Fetal_liver_RNA_rep1','Fetal_liver_RNA_rep2'])
    #bb = genomics.read_file1('/Users/woojunshim/Research/Data/fetal_liver/fetal_liver_h3k4me3_assigned.txt')
    #results = {}
    #pathway = '/Users/woojunshim/Research/Data/roadmap_test/'
    #epi = ['E095','E070','E096','E066','E100','E098']
    #epi = ['E098']
    #menu = ['H3K4me3','Expression','Discordance']
    #ref = genomics.read_file_dic('/Users/woojunshim/Research/Data/new_assigned/tables/repressive_hg19_cont_prop.txt', col_idx=1, id_idx=0)
    #bb = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K4me3/All_widths_H3K4me3.txt', numerical=True)

    #exp = {}
    #for g in aa:
   # 	if aa[g] > 0:
   # 		results[g] = {}
   # 		for m in menu:
   # 			results[g][m] = 0
   # 		results[g]['Expression'] = aa[g]
   # 		exp[g] = aa[g]   

    #for e in epi:
    #    results = {}
    #    exp = {}
    #    for g in exp_:
    #        if exp_[g][e] > 0:
    #            results[g] = {}
    #            for m in menu:
    #                results[g][m] = 0
    #            results[g]['Expression'] = exp_[g][e]
    #            exp[g] = exp_[g][e]


    #    disc = calculate_discordance(exp, ref)
    #    for i in disc:
    #        results[i[0]]['Discordance'] = i[1]
    #    for g in exp:
    #        if g in bb:
    #            if bb[g][e] != float(0):
    #                results[g]['H3K4me3'] = bb[g][e]
    #    genomics.write_table1(results, pathway+e+'/new_scores.txt')

    #for i in bb:    	
    #	if i[0] in exp:
   # 		results[i[0]]['H3K4me3'] = i[1]
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/fetal_liver/new_scores.txt')

    #temp = read_table1('/Users/woojunshim/Research/Data/Paige/new/input_matrix.txt')
    
    #exp = extract_dic_column('/Users/woojunshim/Research/Data/NCC/exp_NCC_.txt', 'RPKM')
    #k4 = extract_dic_column('/Users/woojunshim/Research/Data/NCC/H3K4me3_NCC_.txt', 'width')    
    #disc = calculate_discordance(exp, ref)
    #exp = extract_dic_column('/Users/woojunshim/Research/Data/Palpant/exp_palpant.txt', 'CPC_RNAseq')
    #k4 = extract_dic_column('/Users/woojunshim/Research/Data/Palpant/H3K4me3_palpant_.txt', 'width')    
    #disc = calculate_discordance(exp, ref)
    #results = {}
    #for g in exp:
   # 	results[g] = {}
   # 	for m in menu:
   # 		results[g][m] = 0
   # 	results[g]['Expression'] = exp[g]
   # 	results[g]['H3K4me3'] = 0
   # 	results[g]['Discordance'] = 0
   # for g in k4:
   # 	if g in results:
   # 		results[g]['H3K4me3'] = k4[g]
   # for i in disc:
   # 	results[i[0]]['Discordance'] = i[1]
    
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/Palpant/new_scores_old.txt')

    ### CHECK GENE RANKS FOR CPC 
    #temp = read_table1('/Users/woojunshim/Research/Data/Palpant/new_scores.txt')
    #list1 = []
    #for g in temp:
    #    if float(temp[g]['Discordance']) > 0:
    #        list1.append([g, float(temp[g]['Discordance'])])

    #temp = read_table1('/Users/woojunshim/Research/Data/Palpant/new_scores_old.txt')
    #list2 = []
    #for g in temp:
    #    if float(temp[g]['Discordance']) > 0:
    #        list2.append([g, float(temp[g]['Discordance'])])

    #list1 = genomics.sort_(list1, idx=1, reverse_=True)
    #list2 = genomics.sort_(list2, idx=1, reverse_=True)
    #print len(list1)
    #cnt = 0
    #a,b = [], []
    #for i in range(len(list1)):
    #    a.append(list1[i][0])
    #    b.append(list2[i][0])
    #print a[0:10], b[0:10]
    #for i in range(len(list1)):
    #    if a[i] == b[i]:
    #        cnt += 1
    #print cnt



    ### GET POSITIVE GENES
    #tt = read_table1('/Users/woojunshim/Research/Data/genes_with_go_term/GO.0014032.txt', numerical=False)
    #tt = read_table1('/Users/woojunshim/Research/Data/genes_with_go_term/GO.0007507.txt', numerical=False)
    #tt = read_table1('/Users/woojunshim/Research/Data/genes_with_go_term/GO.0001889.txt', numerical=False)
    #pos = []
    #pathway = '/Users/woojunshim/Research/Data/fetal_liver/'
    #pathway = '/Users/woojunshim/Research/Data/Palpant/'
    #pathway = '/Users/woojunshim/Research/Data/NCC/'
    #for g in tt:
   # 	pos.append(tt[g]['x'])    
   # positives = find_positive_genes(pathway+'new_scores.txt', col='Expression', ref1=pos, ref2=tf_list)
    #print len(positives), positives
    #genomics.write_file_items(positives, pathway+'positives.txt')
    
    ### GET POSITIVE GENES FOR ROADMAP DATA
    #for e in epi:
    #    tt = read_table1(pathway+e+'/go_genes.txt', numerical=False)
    #    pos = []
    #    for g in tt:
    #        pos.append(tt[g]['x'])
    #    positives = find_positive_genes(pathway+e+'/new_scores.txt', col='Expression', ref1=pos, ref2=tf_list)
    #    print len(positives)
    #    genomics.write_file_items(positives, pathway+e+'/positives.txt')

    ### CALCULATE RT FOR H3K27ME3
    #exp = read_table1('/Users/woojunshim/Research/Data/new_assigned/H3K27me3_z.txt', numerical=True)
    #step1 = {}
    #temp = []
    #for g in exp:
    #    step1[g] = 0
    #    for c in exp[g]:
    #        step1[g] += exp[g][c]
    #    temp.append(step1[g])
    #mean_ = np.mean(temp)
    #sd_ = np.std(temp)
    #max_ = np.max(temp)
    #min_ = np.min(temp)
    #diff = max_ - min_
    #for g in step1:
    #    step1[g] = (step1[g]-min_) / diff
    #genomics.write_file(step1, '/Users/woojunshim/Research/Data/new_assigned/H3K27me3_sum_z.txt')

    #prop = genomics.read_file_dic('/Users/woojunshim/Research/Data/new_assigned/H3K27me3_top5_prop_all_genes.txt', col_idx=1, id_idx=0, numerical=True)
    #min_value = 1
    #for g in prop:
    #    if prop[g] < min_value:
    #        min_value = prop[g]

    #for g in step1:
    #    if g in prop:
    #        step1[g] = step1[g] * prop[g]

    #genomics.write_file(step1, '/Users/woojunshim/Research/Data/new_assigned/H3K27me3_intermediate.txt')

    #min_, max_ = 100, 0
    #for g in step1:
    #    if step1[g] < min_:
    #        min_ = step1[g]
    #    if step1[g] > max_:
    #        max_ = step1[g]
    #diff = max_ - min_
    #for g in step1:
    #    step1[g] = (step1[g]-min_) / diff
    #genomics.write_file(step1, '/Users/woojunshim/Research/Data/new_assigned/H3K27me3_rt_final.txt')    

    ### RE-CALCULATE PROPORTION TABLE WITH A PSEUDOCOUNT
    #exp = read_table1('/Users/woojunshim/Research/Data/new_assigned/H3K27me3_z.txt', numerical=True)
    #genes = get_rownames(exp)
    #tt = genomics.read_file_dic('/Users/woojunshim/Research/Data/new_assigned/H3K27me3_top5_prop_all_genes.txt', col_idx=1, id_idx=0)
    #results = []
    #min_ = float(1)/112
    #for g in genes:
    #    if g in tt:
    #        results.append([g, float((int(tt[g]*111)) + 1) / 112])
    #    else:
    #        results.append([g, min_])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/new_assigned/H3K27me3_top5_prop_all_genes_updated.txt')
        


    ### PRODUCT 
    #temp1 = genomics.read_file_dic('/Users/woojunshim/Research/Data/new_assigned/H3K27me3_sum_z.txt', col_idx=1, id_idx=0)
    #ref = genomics.read_file_dic('/Users/woojunshim/Research/Data/new_assigned/H3K27me3_top5_prop_all_genes_updated.txt', col_idx=1, id_idx=0)
    #min_ = 1
    #max_ = 0
    #for g in temp1:
    #    temp1[g] = temp1[g] * ref[g]
    #    if temp1[g] < min_:
    #        min_ = temp1[g]
    #    if temp1[g] > max_:
    #        max_ = temp1[g]
    #diff = max_ - min_
    #for g in temp1:
    #    temp1[g] = (temp1[g]-min_) / diff
    #genomics.write_file(temp1, '/Users/woojunshim/Research/Data/new_assigned/H3K27me3_rt_final_.txt')    

    ### HEATMAP FOR SELECTED GENES ACROSS SELECTED CELL-TYPES
    # 1. COLLET EXPRESSION DATA
    #datas = ['/Users/woojunshim/Research/Data/Paige/expression/expression_data_ave_symbol.txt', '/Users/woojunshim/Research/Data/NCC/score_table_.txt','/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.txt','/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.txt','/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.txt']
    #cols = ['day14','Exp','E066','E096','E100']
    #names = ['Cardiac','Neuronal','Liver','Lung','Skeletal_muscle']
    #genes = ['NKX2-5','MYL7','NEUROD1','GFAP','HNF1B','FGB','FOXF2','SFTPB','MYOD','TNNI2','GAPDH','HPRT1']
    #results = {}
    #for g in genes:
    #    results[g] = {}
    #    for n in names:
    #        results[g][n] = 0
    #for i in range(len(datas)):
    #    data = datas[i]
    #    col = cols[i]    
    #    name = names[i]    
    #    temp = read_table1(data, numerical=True)
    #    aa = []
    #    all_ = set()
    #    for g in temp:
    #        aa.append(temp[g][col])    
    #        all_.add(g) 
    #    mean_ = np.mean(aa)
    #    sd_ = np.std(aa)        
    #    for g in genes:
    #        if g in all_:
    #            results[g][name] = (temp[g][col] - mean_) / sd_
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/new_assigned/heatmap/exp_z_table.txt')


    



    ### CREATE A MATRIX FOR ASSIGNED PEAKS FOR SELECTED CARDIAC GENES
    #genes = ['GATA4','NKX2-5','MYH6','MYH7','TNNI3']
    #genes = ['TBX20','LTBP4','FXYD1','CXCL14','NAV1','FOSL2','FNDC3B','ASS1','CRISPLD2','SOCS2','TSPAN4','ADAMTS5','FNDC3A','TNBS1','SPARCL1']


    #genes = set(genes)
    #hms = ['H3K4me1','H3K4me3','H3K9me3','H3K27ac','H3K27me3','H3K36me3']
    #hms = ['H3K27me3']
    #pathway1 = '/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/assigned/'
    #pathway2 = '/Users/woojunshim/Research/Data/width_plots/'    
    #pathway2 = '/Volumes/backup/Research/bigdata/ENCODE/hg19/H3K27me3/'
    #for hm in hms:
   # 	print hm
  	# 	temp = read_table1(pathway1+hm+'/'+hm+'_tss_2.5kb.txt')
   # 	cols = get_colnames(temp)
   # 	results = {}
   # 	for g in genes:
   # 		results[g] = {}
   # 		for c in cols:
   # 			results[g][c] = 'NA'
   # 	qq = open(pathway1+hm+'/'+hm+'_tss_2.5kb_overlap_combined.txt', 'r')
   # 	cnt = 0
   # 	for i in qq:
   # 		if cnt == len(genes)*len(cols):
   # 			break
   # 		i = i.strip().split()
   # 		c = i[1]    		
   # 		if i[3] in genes:    			
   # 			if int(temp[i[3]][c]) == int(i[2]):
   # 				results[i[3]][c] = i[0]
   # 				cnt += 1
   # 	genomics.write_table1(results, pathway2+hm+'_assigned_peaks_cardiac_genes.txt')

    ### H3K27ME3 
    #temp = read_table1('/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/assigned/H3K27me3/H3K27me3_tss_2.5kb_combined_id.txt', numerical=False)
    #cols = get_colnames(temp)
    #results = {}
    #for g in temp:
   # 	if g in genes:
   # 		results[g] = {}
   # 		for c in cols:
   # 			results[g][c] = temp[g][c]
   # genomics.write_table1(results, pathway2+'H3K27me3_assigned_peaks_cardiac_genes.txt') 

    ### EXTRACT COORDINATES OF PEAKS
    #genes = ['MYH7','NKX2-5','MYH6']
    #genes = ['TNNI3']
    #coor_ =  genomics.read_file1('/Users/woojunshim/Research/Data/width_plots/hg19_gene_coordinates.txt')
    #coor_ = genomics.read_file1('/Volumes/backup/Research/bigdata/ENCODE/hg19/H3K27me3/ENCODE_human_selected_genes_coordinates.txt')
    #coor = {}
    #for i in coor_:
   # 	coor[i[-1]] = [int(i[1]), int(i[2])]
   # for g in genes:
#	    for hm in hms:
	#    	results = []	    	
	#    	ref = read_table1(pathway2+hm+'_assigned_peaks_cardiac_genes.txt', numerical=False)
    #        ref = read_table1('/Volumes/backup/Research/bigdata/ENCODE/hg19/H3K27me3/ENCODE_human_H3K27me3_assigned_id.txt', numerical=False)
	#    	temp = read_table1('/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/assigned/'+hm+'/'+hm+'_tss_2.5kb.txt')
    #        temp = read_table1('/Volumes/backup/Research/bigdata/ENCODE/hg19/H3K27me3/ENCODE_human_H3K27me3_breadth.txt')
	#    	cols = get_colnames(temp)
	#    	for c in cols:
	#    		to_collect = ref[g][c]
	#    		temp = open('/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/'+c+'-'+hm+'.broadPeak', 'r')
    #            temp = open('/Volumes/backup/Research/bigdata/ENCODE/hg19/H3K27me3/'+c+'.bed', 'r')
	#    		for i in temp:
	#    			i = i.strip().split()
	#    			if i[3] == to_collect:
	#    				overlap = get_overlap_coordinate([int(i[1]), int(i[2])], coor[g])
	#    				if overlap[0] != int(0):
	#    					start = overlap[0] - coor[g][0]
	#    					end = overlap[1] - coor[g][0]
	#    					width = end-start
	#    					results.append([c, start, end, width])
	#    				break
	#    	results = genomics.sort_(results, idx=3, reverse_=True)
	#    	genomics.write_file(results, '/Volumes/backup/Research/bigdata/ENCODE/hg19/H3K27me3/'+g+'_human_ENCODE_coordinates.txt')

    ### EXTRACT CELL-TYPES OF HUMAN ENCODE
    #temp = genomics.read_file1('/Volumes/backup/Research/bigdata/ENCODE/hg19/ENCODE_human_H3K27me3_metadata.tsv')
    #results = []
    #for i in temp:
    #    if (i[0].startswith('ENCFF')) and (i[2].startswith('stable')):
    #        results.append([i[0], i[6]])
    #genomics.write_file(results, '/Volumes/backup/Research/bigdata/ENCODE/hg19/ENCODE_human_H3K27me3_samples_description.txt')

    ### MERGE ALL BED FILES IN TO A SINGLE FILE
    #pathway = '/Volumes/backup/Research/bigdata/ENCODE/hg19/H3K27me3/'
    #ref = genomics.read_file_items('/Volumes/backup/Research/bigdata/ENCODE/hg19/ENCODE_human_H3K27me3_samples_description.txt', col=0)
    #print len(ref)
    #results = []
    #cnt = 0
    #for i in ref:
    #    print cnt+1
    #    cnt += 1
    #    temp = genomics.read_file1(pathway+i+'.bed')
    #    for j in temp:
    #        width = int(j[2]) - int(j[1])
    #        results.append([j[0], j[1], j[2], j[3], i, width])
    #genomics.write_file(results, pathway+'ENCODE_human_H3K27me3_merged.txt')




    #genes = ['MYH7','NKX2-5']
    #coor_ =  genomics.read_file1('/Users/woojunshim/Research/Data/width_plots/hg19_gene_coordinates.txt')
    #coor = {}
    #results = []
    #for i in coor_:
   # 	coor[i[-1]] = [int(i[1]), int(i[2])]
   # for g in genes:

	#    for hm in hms:
	    		    	
	#    	ref = read_table1(pathway2+hm+'_assigned_peaks_cardiac_genes.txt', numerical=False)
	#    	temp = read_table1('/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/assigned/'+hm+'/'+hm+'_tss_2.5kb.txt')
	#    	cols = get_colnames(temp)
	#    	for c in cols:
	#    		to_collect = ref[g][c]
	#    		temp = open('/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/'+c+'-'+hm+'.broadPeak', 'r')
	#    		for i in temp:
	#    			i = i.strip().split()
	#    			if i[3] == to_collect:
	#    				results.append([i[0], i[1], i[2], c, hm, g])
	#    				break




    #genomics.write_file(results, '/Users/woojunshim/Research/Data/width_plots/peak_coordinates.txt')

    #a1 = [172654409,172668022]
    #a2 = [172612315,172664815]
    #tt = get_overlap_coordinate(a1,a2)
    #print tt


    ### H3K4ME3 FOR TEM 
    #temp =  genomics.read_file1('/Volumes/OMICS2018-A1171/WorkingSpace/WooJun/TEM/GSM2370646_CD4_T_cells_EM_H3K4me3.csv')
    #results = {}
    #for i in temp:
    #    if ',' in i[1]:
    #        g = i[1].split(',')[0]
    #    else:
    #        g = i[1]
    #    if g not in results:
    #        results[g] = int(i[8])
    #    if int(i[8]) > results[g]:
    #        results[g] = int(i[8]) 
    #genomics.write_file(results, '/Volumes/OMICS2018-A1171/WorkingSpace/WooJun/TEM/H3K4me3_genes.txt')

    ### REMOVE DUPLICA GENE NAMES FROM EXP_MATRIX.TXT
    #temp = read_table1('/Volumes/OMICS2018-A1171/WorkingSpace/WooJun/TEM/exp_matrix.txt')
    #results = {}
    #for i in temp:
    #    if ',' in i:
    #        g = i.split(',')[0]
    #    else:
    #        g = i
    #    print g
    #    results[g] = {}
    #    results[g]['0h'] = temp[i]['0h']
    #    results[g]['150m'] = temp[i]['150m']
    #genomics.write_table1(results, '/Volumes/OMICS2018-A1171/WorkingSpace/WooJun/TEM/exp_matrix_.txt')




    ### CREATE AN EXPRESSION MATRIX
    #a = genomics.read_file1('/Users/woojunshim/Desktop/results/TEM/CD4_T_cells_EM_0h_exp.txt')
    #b = genomics.read_file1('/Users/woojunshim/Desktop/results/TEM/CD4_T_cells_EM_150m_exp.txt')
    #results = {}
    #for i in a:
    #    if i[0] not in results:
    #        results[i[0]] = {}
    #        results[i[0]]['0h'] = 0
    #        results[i[0]]['150m'] = 0
    #    results[i[0]]['0h'] = i[1]
    #for i in b:
    #    if i[0] not in results:
    #        results[i[0]] = {}
    #        results[i[0]]['0h'] = 0
    #        results[i[0]]['150m'] = 0
    #    results[i[0]]['150m'] = i[1]    
    #genomics.write_table1(results, '/Users/woojunshim/Desktop/results/TEM/exp_matrix.txt')

    ### EXTRACT H3K4ME3 BED
    #temp = genomics.read_file1('/Users/woojunshim/Desktop/results/TEM/GSM2370646_CD4_T_cells_EM_H3K4me3.csv')
    #results = []
    #for i in temp:
    #    results.append([i[5],i[6],i[7]])
    #genomics.write_file(results, '/Users/woojunshim/Desktop/results/TEM/CD4_T_cells_EM_H3K4me3.txt')

    ### ADD TF LIST
    #ref1 = set(genomics.read_file_items('/Users/woojunshim/Desktop/results/day14_deg/day14_positives.txt'))
    #ref2 = set(genomics.read_file_items('/Users/woojunshim/Desktop/results/day14_deg/positive_genes_all_genes.txt'))
    #temp = read_table1('/Users/woojunshim/Desktop/results/day14_deg/input_matrix_all.txt')
    #for i in temp:
    #    if i in tf_list:
    #        temp[i]['TF'] = '1'
    #    else:
    #        temp[i]['TF'] = '0'
    #    if i in ref1:
    #        temp[i]['positive_TF'] = '1'
    #    else:
    #        temp[i]['positive_TF'] = '0'
    #    if i in ref2:
    #        temp[i]['all_positive'] = '1'
    #    else:
    #        temp[i]['all_positive'] = '0'


    #genomics.write_table1(temp, '/Users/woojunshim/Desktop/results/day14_deg/input_matrix_all_.txt')

    ### 
    ### DISCORDANCE SCORE IS NOT A MERE COLLECTION OF HIGHLY EXPRESSED TF
    #ref = set(genomics.read_file_items('/Users/woojunshim/Research/Data/new_assigned/GO.0007420_genes.txt'))
    #rt = genomics.read_file_dic('/Users/woojunshim/Research/Data/new_assigned/tables/repressive_hg19_cont_prop.txt', col_idx=1, id_idx=0, numerical=True)
    #temp = read_table1('input_matrix_all.txt', numerical=False)
    #temp = exp_
    #aa = []
    #bb = []
    #bb_ = {}
    #results = []
    #for g in temp:
    #    aa.append([g, temp[g]['E082']])
    #    bb_[g] = float(temp[g]['E082'])
    #aa = genomics.sort_(aa, idx=1, reverse_=True)
    #tt = calculate_discordance(bb_, rt)
    #for i in tt:
    #    bb.append([i[0], float(i[1])])
    #bb = genomics.sort_(bb, idx=1, reverse_=True)    
    
    #results.append(['Expression'])
    #cnt = 0
    #for i in aa:   
    #    if i[0] in tf_list:     
    #        cnt += 1
    #        if i[0] in ref:
    #            print i[0]
    #            results[-1].extend([cnt])

    #results.append(['Discordance'])
    #cnt = 0
    #print
    #for i in bb:     
    #    if i[0] in tf_list:   
    #        cnt += 1
    #        if i[0] in ref:
    #            print i[0]
    #            results[-1].extend([cnt])   
    #genomics.write_file(results, 'E082_exp_discordance_positive_test_tf.txt')


    ### ASSIGN GENES TO H3K4ME3
    #results = assign_genes('/Users/woojunshim/Desktop/results/TEM/CD4_T_cells_EM_H3K4me3.txt', '/Users/woojunshim/Research/Data/hg19_TSS_.txt', min_distance=0, max_distance=2500, centre=False, width=True, gene_include=True)

    #out_ = sort_assigned_genes(results)
    #genomics.write_file(out_, '/Users/woojunshim/Desktop/results/TEM/CD4_T_cells_EM_H3K4me3_assigned.txt')    


    ### GET POSITIVE GENES 
    #all_ = set(genomics.read_file_items('/Users/woojunshim/Research/Data/new_assigned/GO.0030217_genes.txt'))
    #results = []
    #t1 = genomics.read_file1('/Volumes/OMICS2018-A1171/WorkingSpace/WooJun/TEM/exp_matrix.txt', sort_by=1)
    #t1 = read_table1('/Volumes/OMICS2018-A1171/WorkingSpace/WooJun/TEM/exp_matrix_.txt', numerical=True)
    #for i in t1:
        #if i[0] in all_:
        #    results.append(i[0])
    #    if t1[i]['150m'] > float(1):
    #        if (i in all_):
    #            results.append(i)
    #print len(results)
    #genomics.write_file_items(results, '/Volumes/OMICS2018-A1171/WorkingSpace/WooJun/TEM/positive_genes_all_genes_GO.0030217.txt')

    ### FILLING 0 VALUES FOR RT 
    #temp = genomics.read_file_dic('/Users/woojunshim/Research/Data/new_assigned/tables/repressive_hg19_cont_prop.txt', col_idx=1, id_idx=0, numerical=True)
    #for g in temp:
   # 	if temp[g] == float(0):
   # 		temp[g] = temp['PRY2']  # minimum value
   # genomics.write_file(temp, '/Users/woojunshim/Research/Data/new_assigned/tables/repressive_hg19_cont_prop_.txt')


    ### CREATE INPUT TABLES
    #results = {}    
    #t1 = read_table1('/Volumes/OMICS2018-A1171/WorkingSpace/WooJun/TEM/exp_matrix_.txt')
    #exp = []
    #genes = []
    #menu = ['Discordance','Expression','DE','H3K4me3']
    #exp = {}
    #for g in t1:
   # 	if t1[g]['150m'] > float(0):    
   #     	genes.append(g)
   #     	results[g] = {}
   #     	for m in menu:
   #     		results[g][m] = 0
   #     	results[g]['Expression'] = t1[g]['150m']        	
   #     	exp[g] = float(t1[g]['150m'])
   # genes = set(genes)
   # print len(genes)    

    #k4me3 = genomics.read_file1('/Volumes/OMICS2018-A1171/WorkingSpace/WooJun/TEM/H3K4me3_genes.txt')
    #for i in k4me3:
    #    g = i[0]
    #    if g in genes:
    #        results[g]['H3K4me3'] = i[1]    

    #ref_ = genomics.read_file_dic('/Users/woojunshim/Research/Data/new_assigned/tables/repressive_hg19_cont_prop.txt', col_idx=1, id_idx=0)
    #disc = calculate_discordance(exp, ref_, pseudo_=1, fill_missing=True, log_conversion=True)
    #print len(disc)
    #for i in disc:    	
   # 	results[i[0]]['Discordance'] = i[1]

    #t1 = genomics.read_file1('/Volumes/OMICS2018-A1171/WorkingSpace/WooJun/TEM/DEG/output_score.txt')
    #for i in t1:
    #    if ',' in i[0]:
    #        g = i[0].split(',')[0]
    #    else:
    #        g = i[0]               
    #    if g in genes:
    #        results[g]['DE'] = -float(i[4])            
        
    #genomics.write_table1(results, '/Volumes/OMICS2018-A1171/WorkingSpace/WooJun/TEM/input_matrix_all.txt')


    ### FIND POSITIVE GENES 
    #results = read_table1('/Users/woojunshim/Research/Data/Paige/new/input_matrix_all.txt')

    #ref_ = set(genomics.read_file_items('/Users/woojunshim/Research/Data/Paige/new/GO.0007507_genes_9606.txt'))
    #expressed = []
    #for g in results:
   # 	if (results[g]['Expression'] > float(0)) and (g in ref_) and (g in tf_list):    		
   # 		expressed.append(g)
   # print len(expressed)
    
    #genomics.write_file_items(expressed, '/Users/woojunshim/Research/Data/Paige/new/day14_positives.txt')




    ### PERFORMANCE ANALYSIS 
    #output_ = '/Users/woojunshim/Research/Data/test/day14_deg/'

    #positives = genomics.read_file_items('/Users/woojunshim/Research/Data/Paige/new/positive_genes_all_genes.txt')
    #t1 = genomics.read_file1('/Users/woojunshim/Research/Data/Paige/expression/expression_data_ave_symbol.txt', sort_by=1)
    #Expression = []
    #genes = []
    #for i in t1:
    #    Expression.append(i[0])
    #    genes.append(i[0])
    #genes = set(genes)
    #t2 = genomics.read_file1('/Users/woojunshim/Research/Data/Paige/h3k4me3/paige_h3k4me3_day14_assigned_genes.txt', sort_by=1)
    #H3K4me3 = []
    #for i in t2:
    #    if i[0] in genes:
    #        H3K4me3.append(i[0])
    #t3 = genomics.read_file1('/Users/woojunshim/Research/Data/test/day14_deg/output_score.txt', sort_by=5)
    #DE = []
    #for i in t3:
    #    if i[0] in genes:
    #        DE.append(i[0])
    #exp_values = {}
    #for i in t1:
    #    exp_values[i[0]] = float(i[1])
    #ref = genomics.read_file_dic('/Users/woojunshim/Research/Data/new_assigned/tables/repressive_hg19_cont_prop.txt', col_idx=1, id_idx=0, numerical=True)
    #temp = calculate_discordance(exp_values, ref, pseudo_=1, exp_filter=0.0, fill_missing=True, log_conversion=True)
    #Discordance = []
    #for i in temp:
    #    Discordance.append(i[0])

    #menu = [Expression, DE, H3K4me3, Discordance]
    #names = ['Expression','DE','H3K4me3','Discordance']

    #for m_ in range(len(menu)):
    #    result_x = []
    #    result_y = []
    #    for i in range(len(genes)):
    #        result_x.append([i])
    #        result_y.append([i])
    #    area = []
    #    m = menu[m_]
    #    name = names[m_]
    #    a,b,c,d = get_performance_stats(m, positives)
    #    s1,s2 = calculate_performance(a,b,c,d)
    #    a_ = calculate_roc_auc(s2,s1)
    #    area.append([name, a_])
    #    for i in range(len(s1)):
    #        result_x[i].extend([s2[i]])
    #        result_y[i].extend([s1[i]])
    #    result_x.insert(0, names)
    #    result_y.insert(0, names)
    #genomics.write_file(result_x, output_+'roc_x.txt')
    #genomics.write_file(result_y, output_+'roc_y.txt')
    #genomics.write_file(area, output_+'auc.txt')
        



    ### ENRICHMENT ANALYSIS FOR DIFFERENT HMS
    #ref = set(genomics.read_file_items('/Users/woojunshim/Research/Data/house_keeping_genes.txt', col=0))
    #ref = regulated_tf
    #menu = ['H3K4me1','H3K4me3','H3K9me3','H3K27me3','H3K27ac','H3K36me3']  
    #menu = [1]  
    #pathway = '/Users/woojunshim/Research/Data/new_assigned/'
    #for m in menu:
    #    print m
        #results = fet_for_matrix(pathway+m+'_tss_2.5kb_combined.txt', ref)
    #    results = fet_for_matrix('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.txt', ref)
        #genomics.write_file(results, pathway+m+'_fet_house_keeping_genes.txt')
    #    genomics.write_file(results, pathway+'Expression_fet_variably_expressed_tf.txt')



    #ref = set(genomics.read_file_items('/Users/woojunshim/Research/Data/house_keeping_genes.txt', col=0))
    #ref = regulated_tf
    #input_ = []
    #for g in exp_:
    #	input_.append([g, float(exp_[g]['E071'])])
    #input_ = genomics.sort_(input_, idx=1, reverse_=True)
    #print input_[0:5]
    #input_list = []
    #for m in input_:
    # 	input_list.append(m[0])
    #a = point_fet(input_list, ref, cut_off_=0.25, output_='p-value', alternative_='greater')
    #print a

    ### RUN ANALYSIS ON BOVINE DATASET
    # 1. EXTRACT VALID HUMAN GENE REF TABLE
    #temp = genomics.read_file1('/Users/woojunshim/Research/bovine/homologues_human_bovine_table.txt')
    #results = []
    #for i in temp:
    #    if i[-1] == 'ortholog_one2one':
    #        results.append([i[-2]])
    #        if len(i) == 5:
    #            results[-1].extend([i[-3]])                
    #        else:
    #            results[-1].extend([i[-2]])
    #        results[-1].extend([i[1]])
    #genomics.write_file(results, '/Users/woojunshim/Research/bovine/human_to_bovine_updated.txt')

    # 2. GENERATE EXPRESSION TABLE
    #temp = open('/Users/woojunshim/Research/bovine/5.txt', 'r')
    #ref_ = open('/Users/woojunshim/Research/bovine/human_to_bovine_updated.txt', 'r')
    #ref = {}
    #for i in ref_:
    #    i = i.strip().split()
    #    ref[i[2]] = i[1]
    #results = []
    #for i in temp:
    #    i = i.replace('"','')
    #    i = i.strip().split()   
    #    if len(i) == 203: 
    #        if i[1] in ref:     
    #            g = ref[i[1]]
    #            tag = False
    #            for m in range(3,len(i)):
    #                if i[m] =='NA':
    #                    tag = True
    #                    break
    #            if tag == False:
    #                results.append([g])
    #                for m in range(3,len(i)):
    #                    results[-1].extend([i[m]])
    #genomics.write_file(results, '/Users/woojunshim/Research/bovine/expression_Chris_TPM_.txt')

    #temp = open('/Users/woojunshim/Research/bovine/5.txt', 'r')
    #results = ''
    #output_ = open('/Users/woojunshim/Research/bovine/names.txt', 'w')
    #for i in temp:
    #    i = i.replace('"','')
    #    i = i.strip().split()
    #    if i[0] == 'external_gene_name':
    #        for j in range(1, len(i)):
    #            results += i[j]+'\t'
    #        break
    #output_.write(results+'\n')

    # 3. RUN THE ANALYSIS 
    #temp = read_table1('/Users/woojunshim/Research/bovine/expression_Chris_TPM_.txt')
    #cols = get_colnames(temp)
    #rows = get_rownames(temp)
    #ref = genomics.read_file_dic(filename='/Users/woojunshim/Research/Data/new_assigned/tables/repressive_hg19_cont_prop.txt', col_idx=1, id_idx=0, numerical=True)
    #convert = genomics.read_file_dic('/Users/woojunshim/Research/bovine/human_to_bovine_updated.txt', col_idx=0, id_idx=1, numerical=False)
    #results = {}
    #cnt = 0
    #for c in cols:
    #    cnt += 1
    #    print cnt
    #    input_ = {}
    #    for r in rows:            
    #        input_[r] = temp[r][c]
    #    aa = calculate_discordance(input_, ref, pseudo_=1, fill_missing=True, log_conversion=True)
    #    for i in aa:
    #        g = i[0]
    #        if g not in results:
    #            results[g] = {}
    #            for c1 in cols:
    #                results[g][c1] = 0
    #        results[g][c] = i[1]
    #genomics.write_table1(results, '/Users/woojunshim/Research/bovine/bovine_discordance_score_updated.txt')


    # 4. FINAL TOUCH-UP (ADDING BOVINE GENE IDS)
    #temp = genomics.read_file1('/Users/woojunshim/Research/bovine/bovine_discordance_score_updated.txt')
    #ref = genomics.read_file_dic('/Users/woojunshim/Research/bovine/human_to_bovine_updated.txt', id_idx=1, numerical=False)
    #for i in range(len(temp)):
    #    g = temp[i][0]
    #    if g in ref:
    #        h = ref[g][0]
    #        e = ref[g][1]
    #        temp[i].insert(1, e)
    #        temp[i].insert(1, h)
    #temp[0].insert(0, 'Ensembl_ID')
    #temp[0].insert(0, 'Human')
    #temp[0].insert(0, 'Bovine')
    #genomics.write_file(temp, '/Users/woojunshim/Research/bovine/bovine_discordance_score_updated_.txt')




    # 5. CHECK BETWEEN OLD AND NEW TABLES





    ### EXTRACT BED FILES
    #temp = extract_cols('/Users/woojunshim/Desktop/TEM/GSM2370646_CD4_T_cells_EM_H3K4me3.csv', cols=[5,6,7])
    #genomics.write_file(temp, 'CD4_T_cells_EM_H3K4me3.txt')

    ### CALCULATE AVE. OVERLAP GENE NUMBERS FOR PEAKS (FOR EACH GENE)
    #pathway = '/Users/woojunshim/Research/Data/new_assigned/'
    #temp = read_table1(pathway+'H3K27me3_faithfulness.txt', numerical=True)
    #results = []
    #for g in temp:
    #    count = 0
    #    total = 0
    #    for c in temp[g]:
    #        if int(temp[g][c]) != 0:
    #            total += 1
    #            count += int(temp[g][c])
    #    results.append([g, float(count)/total])
    #genomics.write_file(results, pathway+'Mean_overlapped_genes_by_peaks.txt')

    # CALCULATE CUMULATIVE PROPORTIONS    
    #temp = genomics.read_file1(pathway+'Mean_overlapped_genes_by_peaks.txt', sort_by=1)
    #uu = []
    #for i in temp:        
    #    uu.append(i[1])
    #print uu
    #uu.sort()
    #print np.max(uu)
    #current = 1.1
    #results = []
    #total = len(uu)
    #cnt = 0
    #for i in range(len(uu)):
    #    cnt += 1
    #    if uu[i] > current:
    #        results.append([current, float(cnt)/total])            
    #        current = uu[i] + 0.1
    #genomics.write_file(results, pathway+'Mean_overlapped_genes_by_peaks_cum.txt')

    #groups = set()
    #cols = get_colnames(exp_)
    #print len(cols)
    #output = []
    #for c in cols:
    #    t = tissue_groups_[c]
    #    if t != 'Other':
    #        output.append([c, t])
    #    groups.add(t)    
    #print groups
    #print len(groups)
    #genomics.write_file(output, '/Users/woojunshim/Research/Data/Roadmap_exp_cell_types_selected.txt')

    ### FOR VARIABLY EXPRESSED GENES, CALCULATE EXPRESSION VARIATION (EXPRESSION - MEAN, FOR EACH GENE)
    #results = {}
    #cols = get_colnames(exp_)
    #for g in stable_tf:
    #    results[g] = {}
    #    temp = []
    #    for c in cols:
    #        temp.append(float(exp_[g][c]))
    #    mean_ = np.mean(temp)
    #    sd_ = np.std(temp)
    #    for c in cols:
    #        results[g][c] = (exp_[g][c] - mean_) / sd_
    #genomics.write_table1(results, pathway+'Exp_gene_centred_stably_expressed_tf.txt')









    ### GENERATE EPIGENOME LIST     
    #results = []
    #only = []
    #cols = set(get_colnames(exp_))
    #for i in epigenomes:
    #    results.append(i)
    #    if i in cols:
    #        only.append(i)
    #genomics.write_file_items(results, '/Users/woojunshim/Research/Data/epigenomes_list_.txt')
    #genomics.write_file_items(only, '/Users/woojunshim/Research/Data/epigenomes_list_exp.txt')



    ### REMOVE DUPLICATE ENTRIES
    #temp = open('/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/assigned/H3K27me3/H3K27me3_tss_2.5kb_overlap_combined.txt', 'r')
    #output_ = open('/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/assigned/H3K27me3/H3K27me3_tss_2.5kb_overlap_combined_uniq.txt', 'w')
    #results = {}
    #for i in temp:
    #    i = i.strip().split()
    #    if i[2] not in results:
    #        results[i[2]] = {}
    #    if i[0] not in results[i[2]]:
    #        results[i[2]][i[0]] = set()
    #    if i[3] not in results[i[2]][i[0]]:
    #        output_.write(i[0]+'\t'+i[1]+'\t'+i[2]+'\t'+i[3]+'\n')
    #        results[i[2]][i[0]].add(i[3])
    #output_.close()

    ### IDENTIFY PEAKS ASSIGNED TO GENES 
    #temp = open('/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/assigned/H3K27me3/H3K27me3_tss_2.5kb_overlap_combined_uniq.txt', 'r')
    #results = {}
    #table_ = {}
    #for i in temp:
    #    i = i.strip().split()
    #    g = i[3]
    #    if g in mrna:
    #        if g not in results:
    #            results[g] = {}
    #            table_[g] = {}
    #            for c in epigenomes:
    #                results[g][c] = 0
    #                table_[g][c] = 'NA'
    #        if int(i[2]) > results[g][i[1]]:
    #            results[g][i[1]] = int(i[2])
    #            table_[g][i[1]] = i[0]
    #genomics.write_table1(table_, '/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/assigned/H3K27me3/H3K27me3_tss_2.5kb_combined_id.txt')

    ### 'FAITHFULNESS' ANALYSIS
    #table_ = read_table1('/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/assigned/H3K27me3/H3K27me3_tss_2.5kb_combined_id.txt', numerical=False)
    #ref_ = {}
    #genes = get_rownames(table_)
    #cols = get_colnames(table_)
    #for c in cols:
    #    ref_[c] = {}        
    #temp = open('/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/assigned/H3K27me3/H3K27me3_tss_2.5kb_overlap_combined_uniq.txt', 'r')
    #for i in temp:
    #    i = i.strip().split()
    #    if i[0] not in ref_[i[1]]:
    #        ref_[i[1]][i[0]] = 0
    #    ref_[i[1]][i[0]] += 1

    #results = {}
    #for g in genes:
    #    results[g] = {}
    #    for c in cols:
    #        id_ = table_[g][c]
    #        if id_ == 'NA':
    #            results[g][c] = 0
    #        else:
    #            results[g][c] = ref_[c][id_]
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/new_assigned/H3K27me3_faithfulness.txt')




    ### 'FAITHFULNESS' ANALYSIS
    #ref_ = {}    
    #table_ = read_table1('/Users/woojunshim/Research/Data/new_assigned/H3K27me3_tss_2.5kb_combined.txt', numerical=False)
    #cols = get_colnames(table_)
    #results = {}
    #temp = open('/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/H3K27me3/merged_H3K27me3_assigned_uniq.txt', 'r')
    #for i in temp:
    #    i = i.strip().split()
    #    if i[3] in mrna:
    #        if i[2] not in ref_:
    #            ref_[i[2]] = {}
    #        if i[1] not in ref_[i[2]]:
    #            ref_[i[2]][i[1]] = 0
    #        ref_[i[2]][i[1]] += 1
    #print 'Read complete'
    #for g in mrna:
    #    results[g] = {}
    #    for c in cols:                 
    #        w = table_[g][c]
    #        results[g][c] = 0
    #        if w != '0':
    #            results[g][c] = ref_[c][w]
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/new_assigned/H3K27me3_faithfulness.txt')











    ### MERGE ALL H3K27ME3 PEAKS INTO A SINGLE FILE
    #pathway = '/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/'      
    #output_ = open(pathway+'H3K27me3/merged_H3K27me3.txt', 'w')
    #for e in epigenomes:
    #    print e
    #    temp = genomics.read_file1(pathway+e+'-H3K27me3.broadPeak')
    #    for i in temp:
    #        width = int(i[2]) - int(i[1])
    #        output_.write(str(i[0])+'\t'+str(i[1])+'\t'+str(i[2])+'\t'+str(i[3])+'\t'+str(width)+'\t'+e+'\n')        
    #output_.close()


    ### OPTIMISATION TO FIND A THRESHOLD FOR BROAD PEAKS
    ### USING FET AT EACH PERCENTILE BIN FOR ENRICHMENT OF VARIABLY EXPRESSED TFS
    #temp = read_table1('/Users/woojunshim/Research/Data/new_assigned/H3K27me3_tss_2.5kb_combined.txt', numerical=True)    
    #cols = get_colnames(temp)
    #results = {}

    #for c in cols:
    #    aa = []
    #    for g in temp:
    #        if temp[g][c] > 0:
    #            aa.append(temp[g][c])
    #    aa.sort(reverse=True)        
    #    idx = int(len(aa) * 0.05)
    #    results[c] = aa[idx]
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/new_assigned/top5_cutoffs.txt')

    #for c in cols:
    #    print c
    #    input_ = []
    #    for g in temp:
    #        if temp[g][c] > 0:
    #            input_.append([g, temp[g][c]])
    #    input_ = genomics.sort_(input_, idx=1, reverse_=True)
    #    genes = []
    #    for i in input_:
    #        genes.append(i[0])
    #    aa = sliding_fet(genes, regulated_tf, convert_to_percentile=True, percentile_bin = 0.01)        
    #    results[c] = aa
    #    print aa.index(min(aa))
    #genomics.write_file_dic(results, '/Users/woojunshim/Research/Data/new_assigned/optimisation_h3k27me3_variably_expressed_tf_.txt')


    ### 
    #temp = read_table1('/Users/woojunshim/Research/Data/Palpant/new/new_scores.txt')
    #a = []
    #ref_ = genomics.read_file_items('/Users/woojunshim/Research/Data/Palpant/GO.0007507_genes_9606.txt')
    #for g in temp:
    #    if float(temp[g]['Exp']) != float(0):
    #        a.append(g)
    #ref = genomics.intersection(a, ref_)
    #genomics.write_file_items(ref, '/Users/woojunshim/Research/Data/Palpant/positive_genes_all_genes.txt')






    ### PAIGE H3K4ME3 
    #results = assign_genes('/Users/woojunshim/Research/Data/Paige/h3k4me3/paige_h3k4me3_day14.bed', '/Users/woojunshim/Research/Data/hg19_TSS_.txt', min_distance=0, max_distance=2500, centre=False, width=True, gene_include=True)
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/Paige/h3k4me3/paige_h3k4me3_day14_assigned.txt')
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/Paige/h3k4me3/paige_h3k4me3_day14_assigned.txt')
    #results = {}
    #for i in temp:
    #    if len(i) == 5:            
    #        if i[1] not in results:
    #            results[i[1]] = 0
    #        if int(i[-1]) > results[i[1]]:
    #            results[i[1]] = int(i[-1])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/Paige/h3k4me3/paige_h3k4me3_day14_assigned_genes.txt')

    # CREATE A MATRIX 
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/Paige/h3k4me3/paige_h3k4me3_day14_assigned_genes.txt')
    #aa = read_table1('/Users/woojunshim/Research/Data/Paige/exp_d14.txt')
    #results = {}
    #for i in temp:
    #    if i[0] not in results:
    #        results[i[0]] = {}
    #        results[i[0]]['H3K4me3'] = i[1]
    #        results[i[0]]['Exp'] = 0
    #for g in aa:
    #    if g not in results:
    #        results[g] = {}
    #        results[g]['Exp'] = aa[g]['day14']
    #        results[g]['H3K4me3'] = 0
    #    results[g]['Exp'] = aa[g]['day14']
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/Paige/input_matrix.txt')

    # FIND A POSITIVE GENES 
    #ref_ = genomics.read_file_items('/Users/woojunshim/Research/Data/new_assigned/GO_0007507_genes.txt')
    #ref_ = set(ref_)
    #ref = []
    #temp = read_table1('/Users/woojunshim/Research/Data/Paige/new/new_scores.txt', numerical=True)
    #for g in temp:
    #    if (temp[g]['Exp'] > 0) and (g in ref_) and (g in tf_list):
    #        ref.append(g)
    #genomics.write_file_items(ref, '/Users/woojunshim/Research/Data/Paige/day14_positives.txt')


    ### CHECK PALAPNT RANKS 



    ### PERFORMANCE ANALYSIS
    #pathway = '/Users/woojunshim/Research/Data/Palpant/'
    #pathway = '/Users/woojunshim/Research/Data/NCC/'
    #pathway = '/Users/woojunshim/Research/Data/Paige/'
    #temp = read_table1(pathway+'score_table_.txt', numerical=True)
    #temp = read_table1(pathway+'input_matrix.txt', numerical=True)
    #ref_pathway = '/Users/woojunshim/Research/Data/new_assigned/tables/'
    #menu = ['repressive_hg19_cont_mad', 'repressive_hg19_cont_prop', 'repressive_hg19_prop']
    #results = {}
    #exp = {}
    #for g in temp:
    #    results[g] = {}
    #    for m in menu:
    #        results[g][m] = 0.0
    #for g in temp:
    #    results[g]['Exp'] = np.log10(temp[g]['Exp']+1)
    #    results[g]['H3K4me3'] = temp[g]['H3K4me3']
    #    exp[g] = temp[g]['Exp']
    #for m in menu:
    #    ref = genomics.read_file_dic(ref_pathway+m+'.txt', col_idx=1, id_idx=0, numerical=True)
    #    disc = calculate_discordance(exp, ref, 1, 0.0, fill_missing=True, log_conversion=True)
    #    for i in disc:
    #        results[i[0]][m] = i[1]
    #genomics.write_table1(results, pathway+'new_scores.txt')

    # CALCULATE PERFORMANCE STATS
    #pathway = '/Users/woojunshim/Desktop/results/day14_deg/'
    #pathway = '/Volumes/OMICS2018-A1171/WorkingSpace/WooJun/TEM/'
    #pathway = '/Users/woojunshim/Research/Data/fetal_liver/'
    #pathway = '/Users/woojunshim/Research/Data/Paige/new/'
    #pathway = '/Users/woojunshim/Research/Data/NCC/'
    #pathway = '/Users/woojunshim/Research/Data/roadmap_test/'

    #positives = genomics.read_file_items('/Users/woojunshim/Desktop/results/day14_deg/day14_positives.txt')
    #positives = genomics.read_file_items(pathway+'positive_genes_.txt')
    #positives = genomics.read_file_items(pathway+'new/day14_positives.txt')

    #positives_ = genomics.read_file_items(pathway+'positive_genes.txt')
    #positives_ = positives_ + genomics.read_file_items(pathway+'positives_.txt')
    #ref1 = genomics.read_file_items('/Users/woojunshim/Research/Data/Paige/new/GO.0007507_genes_9606.txt')
    #positives = find_positive_genes(pathway+'new_scores.txt', col='Expression', ref1=positives_)
    #genomics.write_file_items(positives, pathway+'positives.txt')

    #positives = genomics.read_file_items(pathway+'positives.txt')
    #positives = genomics.read_file_items('/Volumes/OMICS2018-A1171/WorkingSpace/WooJun/TEM/positive_genes_tf_GO.0030217.txt')
    #print len(positives)
    #temp = read_table1('/Volumes/OMICS2018-A1171/WorkingSpace/WooJun/TEM/input_matrix_all.txt', numerical=True)
    #for ee in epi:
    #    print
    #    print ee
    #    positives = genomics.read_file_items(pathway+ee+'/positives.txt')
    #    temp = read_table1(pathway+ee+'/new_scores.txt', numerical=True)

    #    cols = get_colnames(temp)
    #    rows = get_rownames(temp)
    #    roc_x, roc_y, prc_x, prc_y = {}, {}, {}, {}
    #    auc = {}
    #    auc2 = {}
    #    for i in range(len(rows)):
    #        roc_x[i], roc_y[i], prc_x[i], prc_y[i] = {}, {}, {}, {}
    #        for c in cols:
    #            roc_x[i][c] = 0
    #            roc_y[i][c] = 0
    #            prc_x[i][c] = 0
    #            prc_y[i][c] = 0            
    #    prc_xs, prc_ys = {}, {}
    #    for c in cols:
    #        prc_xs[c] = []
    #        prc_ys[c] = []
    #        auc[c] = 0
    #    for c in cols:
    #        print c
    #        aa = []
    #        for g in temp:
    #            aa.append([g, temp[g][c]])
    #        aa = genomics.sort_(aa, idx=1, reverse_=True)        
    #        input_ = []
    #        for i in aa:
    #            input_.append(i[0])
    #        a,b,e,d = get_performance_stats(input_, positives)
    #        s1,s2 = calculate_performance(a,b,e,d)        

    #        for i in range(len(s1)):                   
    #            roc_y[i][c] = str(s1[i])
    #            roc_x[i][c] = str(s2[i])
    #        auc[c] = calculate_roc_auc(s2, s1)
    #        s1,s2 = calculate_performance(a,b,e,d, option='prc')
    #        if len(s1) != len(s2):
    #            print 'problem!'
    #        prc_ys[c] = s1
    #        prc_xs[c] = s2
    #        auc2[c] = calculate_roc_auc(s2,s1)
    #    nrow = 0
    #    for c in cols:
    #        if len(prc_ys[c]) > nrow:
    #            nrow = len(prc_ys[c])
    #    print nrow
    #    for c in cols:
    #        diff = len(prc_ys[c]) - nrow
    #        if diff != 0:
    #            value = prc_ys[c][0]
    #            for i in range(diff):
    #                prc_ys[c].insert(0, value)
    #                prc_xs[c].insert(0, 0)
    #    for i in range(nrow):
    #        prc_x[i] = {}
    #        prc_y[i] = {}
    #        for c in cols:
    #            prc_x[i][c] = prc_xs[c][i]
    #            prc_y[i][c] = prc_ys[c][i]
    #    genomics.write_table1(roc_x, pathway+ee+'/roc_x_.txt')
    #    genomics.write_table1(roc_y, pathway+ee+'/roc_y_.txt')
    #    genomics.write_table1(prc_x, pathway+ee+'/prc_x_.txt')
    #    genomics.write_table1(prc_y, pathway+ee+'/prc_y_.txt')
    #    genomics.write_file(auc, pathway+ee+'/auc_roc_.txt')
    #    genomics.write_file(auc2, pathway+ee+'/auc_prc_.txt')

    #cols = get_colnames(roc_x)
    #qq = []
    #for c in cols:
    #    x,y = [], []
    #    for i in roc_x:
    #        x.append(float(roc_x[i][c]))
    #        y.append(float(roc_y[i][c]))
    #    ww = calculate_roc_auc(x,y)
    #    qq.append([c,ww])
    #genomics.write_file(qq, pathway+'new/auc.txt')


    #temp = read_table1('/Volumes/OMICS2018-A1171/WorkingSpace/WooJun/TEM/input_matrix_all.txt')
    #positives = set(genomics.read_file_items('/Volumes/OMICS2018-A1171/WorkingSpace/WooJun/TEM/positive_genes_tf_GO.0030217.txt'))
    #for g in temp:
    #    if g in positives:
    #        temp[g]['positive_tf'] = 1
    #    else:
    #        temp[g]['positive_tf'] = 0
    #genomics.write_table1(temp,'/Volumes/OMICS2018-A1171/WorkingSpace/WooJun/TEM/input_matrix_all_.txt' )






    ### TEST FOR GET_PERFORMANCE_STATS
    #temp = read_table1('/Users/woojunshim/Research/Data/Palpant/score_table.txt', numerical=True)
    #input_ = []
    #aa= []
    #for g in temp:
    #    aa.append([g, temp[g]['Corrected']])
    #aa = genomics.sort_(aa, idx=1, reverse_=True)
    #for g in aa:
    #    input_.append(g[0])
    #positives = genomics.read_file_items('/Users/woojunshim/Research/Data/Palpant/positive_genes_.txt')
    #print len(input_), len(positives)
    #positives = input_[0:20]

    
    #a,b,c,d = get_performance_stats(input_, positives)
    #print a[0:10], b[0:10], c[:10], d[:10]
    #s1,s2 = calculate_performance(a,b,c,d,option='prc')
    #genomics.write_file_items(s1, '/Users/woojunshim/Research/Data/palpant_precision1.txt')
    #genomics.write_file_items(s2, '/Users/woojunshim/Research/Data/palpant_recall1.txt')



    #print len(regulated_tf)

    ### ADDING ENSG SYMBOLS TO GENES 
    #ref_ = open('/Users/woojunshim/Research/Data/Ensembl_gene_symbols_conversion_.txt', 'r')
    #ref_ = open('/Users/woojunshim/Research/Data/mm10_ensembl_symbols.txt', 'r')
    #ref = {}
    #for i in ref_:
    #    i = i.strip().split()
    #    if len(i) == 3:
    #        if i[2] not in ref:
    #            ref[i[2]] = i[1]
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/new_assigned/repressive_tendency_H3K27me3.txt', sort_by=1)
    #temp = genomics.read_file1('/Users/woojunshim/Research/bigdata/ENCODE/mm10/H3K27me3/repressive_tendency_table_new_mm10.txt', sort_by=1)
    #for i in range(len(temp)):
    #    g = temp[i][0]
    #    if g in ref:
    #        temp[i].insert(1, ref[g])
    #    else:
    #        temp[i].insert(1, 'NA')
    #genomics.write_file(temp, '/Users/woojunshim/Research/bigdata/ENCODE/mm10/H3K27me3/repressive_tendency_table_new_mm10_.txt')
    #genomics.write_file(temp, '/Users/woojunshim/Research/Data/new_assigned/repressive_tendency_H3K27me3_.txt')


    ### CREATE A TABLE FOR TOP 5 GO TERMS 
    #pathway = '/Users/woojunshim/Research/Data/new_assigned/'
    #menu = ['H3K4me1','H3K4me3','H3K27ac','H3K36me3','H3K9me3','H3K27me3']
    #results = []
    #for m in menu:
    #    a = get_items(pathway+m+'_top200_GO.txt', keywords=['1','2','3','4','5'], value_idx=2, key_idx=0)
    #    for l in a:
    #        results.append(l)    
    #print results
    #files = []
    #for m in menu:
    #    files.append(pathway+m+'_top200_GO.txt')
    #qq = extract_elements(files, names=menu, ids=results, id_idx=2, value_idx=3, log_convert=True)
    #genomics.write_table1(qq, pathway+'Top200_genes_5_terms.txt')

    ### IDENTIFY H3K27ME3-SPECIFIC GO TERMS
    #pathway = '/Users/woojunshim/Research/Data/new_assigned/'
    #menu = ['H3K4me1','H3K4me3','H3K27ac','H3K36me3','H3K9me3']
    #terms = set()
    #for m in menu:
   # 	temp = genomics.read_file1(pathway+m+'_top200_GO.txt')
   # 	for i in temp:
   # 		if float(i[3]) < 1.0e-10:
   # 			terms.add(i[1])
   # temp = genomics.read_file1(pathway+'H3K27me3_top200_GO.txt')
   # results = []
   # cnt = 0
   # for i in temp:
   # 	if i[1] not in terms:
   # 		results.append(i)
   # 		cnt += 1
   # genomics.write_file(results, pathway+'H3K27me3_top200_selected_GO.txt')


    #pathway = '/Users/woojunshim/Research/Data/new_assigned/'
    #menu = ['H3K4me1','H3K4me3','H3K27ac','H3K36me3','H3K9me3','H3K27me3']
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/new_assigned/H3K27me3_top200_selected_GO.txt')
    #terms = []   
    #for i in range(22):
   # 	terms.append(temp[i][2])
    #print terms
    #files = []
    #for m in menu:
    #    files.append(pathway+m+'_top200_GO.txt')
    #qq = extract_elements(files, names=menu, ids=terms, id_idx=2, value_idx=3, log_convert=True)
    #print qq
    #genomics.write_table1(qq, pathway+'H3K27me3_top200_selected_GO_all.txt')

    ### EXTRACT GO TERMS FOR TOP 50 VARIABLY EXPRESSED TF
    #menu = ['H3K4me1','H3K4me3','H3K27ac','H3K36me3','H3K9me3','H3K27me3']
    #menu = ['E004','E038','E070','E087','E095']
    #pathway = '/Users/woojunshim/Research/Data/variably_expressed_tf/'
    #temp = genomics.read_file_items('/Users/woojunshim/Research/Data/variably_expressed_tf/selected_terms.txt')
    #terms = temp
    #for i in range(22):
   #    terms.append(temp[i][2])
    #print terms
    #files = []
    #for m in menu:
    #    files.append(pathway+m+'_GO.txt')
    #qq = extract_elements(files, names=menu, ids=terms, id_idx=2, value_idx=3, log_convert=True)
    #print qq
    #genomics.write_table1(qq, pathway+'variably_expressed_tf_top50_selected_go_terms.txt')

    ### EXTRACT GO TERMS FOR TOP 1% DS GENES FOR ROADMAP SAMPLES
    #menu = ['H3K4me1','H3K4me3','H3K27ac','H3K36me3','H3K9me3','H3K27me3']
    #menu = ['E004','E038','E070','E087','E095']
    #pathway = '/Users/woojunshim/Research/Data/variably_expressed_tf/'
    #temp = genomics.read_file_items('/Users/woojunshim/Research/Data/variably_expressed_tf/selected_terms.txt')
    #terms = temp
    #for i in range(22):
   #    terms.append(temp[i][2])
    #print terms
    #files = []
    #for m in menu:
    #    files.append(pathway+m+'_GO.txt')
    #qq = extract_elements(files, names=menu, ids=terms, id_idx=2, value_idx=3, log_convert=True)
    #print qq
    #genomics.write_table1(qq, pathway+'variably_expressed_tf_top50_selected_go_terms.txt')



    ### CONSISTENCY ANALYSIS 
    #results = []
    #a = read_table1('/Users/woojunshim/Research/Data/new_assigned/H3K27me3_tss_2.5kb.txt')
    #b = read_table1('/Users/woojunshim/Research/Data/H3K27me3_repressive_tendency_old.txt')
    #cols = get_colnames(b)
    #t = len(cols)
    #for g in b:
    #    if g in a:
    #        cnt = 0
    #        for c in cols:
    #            if float(a[g][c]) == float(b[g][c]):
    #                cnt += 1
    #        results.append([g, float(cnt)/t])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/new_assigned/consistency.txt')


    ### ENRICHMENT ANALYSIS FOR DNA-BINDING AND VARIABLY EXPRESSED TFS FOR DIFFERENT HMS



    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/new_assigned/H3K27me3_mad.txt')
    #results = []
    #for i in temp:
    #    results.append([i[1], i[2]])
    #genomics.write_file(results, '/Users/woojunshim/Research/Documents/manuscripts/H3K27me3/manuscript/script/mad.txt')

    ### CONVERT MAD VALUES INTO THE RANGE [0,1]
    #temp = genomics.read_file1('/Users/woojunshim/Research/Documents/manuscripts/H3K27me3/manuscript/script/mad.txt', sort_by=1)
    #max_ = temp[0][1]
    #min_ = temp[-1][1]
    #for i in range(len(temp)):
    #    temp[i][1] = float((temp[i][1] - min_)) / (max_ - min_)
    #genomics.write_file(temp, '/Users/woojunshim/Research/Documents/manuscripts/H3K27me3/manuscript/script/mad_scores.txt')

    ### SUM MAD AND REPRESSIVE TENDENCY SCORES
    #ref1, ref2 = {}, {}
    #a = open('/Users/woojunshim/Research/Documents/manuscripts/H3K27me3/manuscript/script/mad_scores.txt', 'r')
    #for i in a:
    #    i = i.strip().split()
    #    if i[0] not in ref1:
    #        ref1[i[0]] = float(i[1])
    #b = open('/Users/woojunshim/Research/Documents/manuscripts/H3K27me3/manuscript/script/repressive_hg19.txt', 'r')
    #for i in b:
    #    i = i.strip().split()
    #    if i[0] not in ref2:
    #        ref2[i[0]] = float(i[1])
    #results = {}
    #for g in ref1:
    #    results[g] = ref1[g] * ref2[g]
    #genomics.write_file(results, '/Users/woojunshim/Research/Documents/manuscripts/H3K27me3/manuscript/script/repressive_mad_combined_times.txt')



    ### STREAMLINE PROCESSING ALL DIFFERENT TYPES OF HMS UNTIL THE REPRESSIVE TENDENCY SCORES
    #pathway = '/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/assigned/'
    #menu = ['H3K4me1','H3K4me3','H3K9me3','H3K27ac','H3K36me3']
    #ref_ = open('/Users/woojunshim/Research/Data/hg19_TSS_1bp.txt', 'r')
    #ref = {}
    #for i in ref_:
    #    i = i.strip().split()
    #    if i[-1] not in ref:
    #        ref[i[-1]] = int(i[1])
    #for m in menu:
    #    print m
    #    line = 'bedtools intersect -a '
    #    file_a = pathway+m+'/'+'unassigned_'+m+'_peaks.txt '
    #    file_b = pathway+'hg19_TSS_2.5kb_upstream.txt '
    #    line += file_a + '-b '+file_b + '-wa -wb | awk {\'print $1\"\t\"$2\"\t\"$3\"\t\"$4\"\t\"$5\"\t\"$9\'} > '+pathway+m+'/'+'unassigned_'+m+'_tss_2.5kb_overlap.txt' 
    #    print line
    #    os.system(line)
    #    results = {}
    #    temp = open(pathway+m+'/'+'unassigned_'+m+'_tss_2.5kb_overlap.txt', 'r')
    #    un = {}
    #    for i in temp:
    #        i = i.strip().split()
    #        w = int(i[2]) - int(i[1])
    #        centre = (int(i[1]) + int(i[2])) / 2
    #        dist = np.abs(ref[i[-1]] - centre)
    #        if i[-1] not in un:
    #            un[i[-1]] = {}
    #        if i[4] not in un[i[-1]]:
    #            un[i[-1]][i[4]] = [dist, w, i[3]]
    #        else:
    #            if un[i[-1]][i[4]][0] > dist:
    #                un[i[-1]][i[4]][0] = dist
    #                un[i[-1]][i[4]][1] = w
    #                un[i[-1]][i[4]][2] = i[3]
    #    out_ = open(pathway+m+'/'+'unassigned_'+m+'_tss_2.5kb_overlap_final.txt', 'w')
    #    for g in un:
    #        for c in un[g]:
    #            out_.write(str(un[g][c][2])+'\t'+c+'\t'+str(un[g][c][1])+'\t'+g+'\n')
    #    out_.close()

    #    a = genomics.read_file1(pathway+m+'/'+m+'_tss_2.5kb_overlap.txt')
    #    t = open(pathway+m+'/'+'unassigned_'+m+'_tss_2.5kb_overlap_final.txt', 'r')
    #    for i in t:
    #        i = i.strip().split()
    #        a.append([i[0], i[1], i[2], i[3]])
    #    genomics.write_file(a, pathway+m+'/'+m+'_tss_2.5kb_overlap_combined.txt')

    #    tem = open(pathway+m+'/'+m+'_tss_2.5kb_overlap_combined.txt', 'r')  
    #    qq = read_table1('/Users/woojunshim/Research/Data/broadPeaks/All_widths_'+m+'.txt')  
    #    epigenomes = get_colnames(qq)        
    #    results = {}
    #    for i in tem:
    #        i = i.strip().split()
    #        g = i[3]
    #        w = int(i[2])
    #        c = i[1]
    #        if g not in results:
    #            results[g] = {}
    #            for e in epigenomes:
    #                results[g][e] = 0
    #        if w > results[g][c]:
    #            results[g][c] = w
    #    genomics.write_table1(results, pathway+m+'/'+m+'_tss_2.5kb.txt')
    #    results_ = calculate_repressive_tendency(results, cols=epigenomes)
    #    genomics.write_file(results_, pathway+m+'/repressive_tendency_'+m+'.txt')

          
    ### TEST 
    #temp = open('/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/assigned/H3K4me1/H3K4me1_tss_2.5kb_overlap_combined.txt', 'r')
    #results = []
    #for i in temp:
    #    i=i.strip().split()
    #    if i[-1] == 'LOC100506869':
    #        results.append(i)
    #genomics.write_file(results, 'test.txt')

    ### FIND NUMBER OF GENES WITH A HM SIGNAL 
    #pathway = '/Users/woojunshim/Research/Data/new_assigned/'
    #menu = ['H3K4me1','H3K4me3','H3K27ac','H3K9me3','H3K36me3','H3K27me3']    
    #for m in menu:
    #    temp = read_table1(pathway+m+'_tss_2.5kb.txt')
    #    results = {}
    #    cols = get_colnames(temp)
    #    for c in cols:
    #        results[c] = 0
    #    for c in cols:
    #        for g in temp:                  
    #                
    #            if float(temp[g][c]) != float(0):
    #                results[c] += 1
    #    genomics.write_file(results, '/Users/woojunshim/Research/Data/new_assigned/no_genes_with_'+m+'.txt')





    ### OVERLAP PROPORTIONS OR JACCARD INDEX
    #pathway = '/Users/woojunshim/Research/Data/new_assigned/'
    #menu = ['H3K4me1','H3K4me3','H3K27ac','H3K36me3','H3K9me3','H3K27me3']

    ### SIMILARITY BETWEEN TOP 100 COMMON GENES OF DIFFERENT HMS
    #ref = {}
    #for m in menu:
    #    temp = genomics.read_file1(pathway+m+'_top5_prop_all_genes.txt', sort_by=1)
    #    ref[m] = []
    #    for i in range(200):
    #        ref[m].append(temp[i][0])
    #results = {}

    #for m1 in menu:
    #    results[m1] = {}        
    #    for m2 in menu:
    #        if m1 == m2:
    #            results[m1][m2] = 1
    #        else:
    #            sim = jaccard_index(ref[m1], ref[m2])
    #            results[m1][m2] = sim
    #genomics.write_table1(results, pathway+'top200_common_genes_jaccard.txt')


   


    # FIRST CALCULATE PROPORTIONS 
    #pp = read_table1(pathway+'H3K27me3_tss_2.5kb.txt')
    #mrna = get_rownames(pp)
    #print len(mrna)
    #for m in menu:
    #    print m
    #    ref_ = genomics.read_file1(pathway+'no_genes_with_'+m+'.txt')
    #    epigenomes = []
    #    for i in ref_:
    #        if int(i[1]) >= 15000:
    #            epigenomes.append(i[0])
    #    temp = subset_table(pathway+m+'_tss_2.5kb.txt', rows=mrna, cols=epigenomes)    
    #    genes = get_rownames(temp)      
    #    ref = {}
    #    for c in epigenomes:
    #        qq = []        
    #        ref[c] = []
    #        for g in genes:
    #            if float(temp[g][c]) != float(0):
    #                qq.append([g, float(temp[g][c])])
    #        qq = genomics.sort_(qq, idx=1, reverse_=True)
    #        for i in range(15000):            
    #            ref[c].append(qq[i][0]) 
    #        ref[c] = segment_lists(ref[c], bin_size=100)
        #print 'bin = ',len(ref[c])
    #    results = {}
    #    cell_types = len(epigenomes)
    #    print len(epigenomes)
    #    for i in range(150):
    #        print i
    #        results[i+1] = []
    #        for c1 in range(cell_types-1):
    #            cell1 = epigenomes[c1]
    #            for c2 in range(c1+1, cell_types):
    #                cell2 = epigenomes[c2]
    #                a = jaccard_index(ref[cell1][i], ref[cell2][i])
    #                results[i+1].append(a)            
    #    genomics.write_file_dic(results, pathway+'jaccard_15000_all_genes_by_'+m+'.txt')

    # GENERATE RANDOM JACCARD INDEX
    #results = []
    #no = len(epigenomes)

    #for i in range(150):
    #    print i
    #    results.append([i+1])
    #    for c1 in range(no-1):
    #        cell1 = epigenomes[c1]
    #        ref1 = genomics.random_sample(mrna, 100)          
    #        for c2 in range(c1+1, no):
    #            cell2 = epigenomes[c2]
    #            ref2 = genomics.random_sample(mrna, 100)
    #            a = jaccard_index(ref1, ref2)
    #            results[-1].append(a)
    #print results
    #genomics.write_file(results, pathway+'jaccard_15000_all_genes_by_random.txt')





    ### FOR SC DAY15 AND 30
    #temp = genomics.read_file1('/Users/woojunshim/Research/Documents/manuscripts/H3K27me3/manuscript/script/day30.txt')
    #results = []
    #for i in temp:        
    #    gene = i[0].split('_')[0]
    #    results.append([gene, i[1]])
    #genomics.write_file(results, '/Users/woojunshim/Research/Documents/manuscripts/H3K27me3/manuscript/script/day30_.txt')


    ### COMBINE RESULTS FROM ASSIGNED AND UNASSIGNED 
    #a = genomics.read_file1('/Volumes/Backup/Research/bigdata/ENCODE/mm10/H3K27me3/unassigned_H3K27me3_tss_2.5kb_mm10_overlap_final.txt')
    #temp = open('/Volumes/Backup/Research/bigdata/ENCODE/mm10/H3K27me3/H3K27me3_tss_2.5kb_overlap_mm10.txt', 'r')
    #for i in temp:
    #    i = i.strip().split()
    #    a.append([i[0], i[1], i[2], i[3]])
    #genomics.write_file(a, '/Volumes/Backup/Research/bigdata/ENCODE/mm10/H3K27me3/H3K27me3_tss_2.5kb_mm10_overlap_combined.txt')

    ### ASSIGN UNASSIGNED H3K27ME3 PEAKS TO THE NEAREST TSS TO THE CENTRE POSITION
    #ref_ = open('/Users/woojunshim/Research/Data/hg19_TSS_1bp.txt', 'r')
    #ref_ = open('/Users/woojunshim/Research/Data/mm10_TSS_1bp.txt', 'r')
    #ref = {}
    #for i in ref_:
    #    i = i.strip().split()
    #    if i[-1] not in ref:
    #        ref[i[-1]] = int(i[1])
    #results = {}
    #temp = open('/Volumes/Backup/Research/bigdata/ENCODE/mm10/H3K27me3/unassigned_H3K27me3_tss_2.5kb_mm10_overlap.txt', 'r')
    #un = {}
    #for i in temp:
    #    i = i.strip().split()
    #    w = int(i[2]) - int(i[1])
    #    centre = (int(i[1]) + int(i[2])) / 2
    #    dist = np.abs(ref[i[-1]] - centre)
    #    if i[-1] not in un:
    #        un[i[-1]] = {}
    #    if i[4] not in un[i[-1]]:
    #        un[i[-1]][i[4]] = [dist, w, i[3]]
    #    else:
    #        if un[i[-1]][i[4]][0] > dist:
    #            un[i[-1]][i[4]][0] = dist
    #            un[i[-1]][i[4]][1] = w
    #            un[i[-1]][i[4]][2] = i[3]
    #out_ = open('/Volumes/Backup/Research/bigdata/ENCODE/mm10/H3K27me3/unassigned_H3K27me3_tss_2.5kb_mm10_overlap_final.txt', 'w')
    #for g in un:
    #    for c in un[g]:
    #        out_.write(str(un[g][c][2])+'\t'+c+'\t'+str(un[g][c][1])+'\t'+g+'\n')
    #out_.close()



    ### 
    #temp = open('/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/assigned/unassigned_H3K27me3_tss_2.5kb_overlap.txt', 'r')
    #un = []    
    #for i in temp:
    #    i = i.strip().split()



    ### FIND UNASSIGNED PEAKS 
    #mark = 'H3K27me3'
    #print mark
    #results = []
    #temp = read_table1('/Volumes/Backup/Research/bigdata/ENCODE/mm10/H3K27me3/'+mark+'_widths_mm10_z.txt')
    #epigenomes = get_colnames(temp)
    #pathway = '/Volumes/Backup/Research/bigdata/ENCODE/mm10/H3K27me3/'
    #cnt = 0
    #ref_ = open(pathway+mark+'_tss_2.5kb_overlap_mm10.txt', 'r')
    #ref = {}
    #for i in ref_:
    #    i = i.strip().split()
    #    if i[1] not in ref:
    #        ref[i[1]] = set()
    #    ref[i[1]].add(i[0])
    #for e in epigenomes:
    #    temp = open(pathway+'bed/'+e+'.bed', 'r')
    #    cnt += 1
    #    print cnt
    #    for i in temp:
    #        i = i.strip().split()
    #        if i[3] not in ref[e]:
    #            results.append([i[0], i[1], i[2], i[3], e])
    #genomics.write_file(results, pathway+'unassigned_'+mark+'_peaks_mm10.txt')


    ### 
    #temp = read_table1('/Volumes/Backup/Research/bigdata/ENCODE/mm10/H3K27me3/H3K27me3_tss_2.5kb_combined_mm10.txt')
    #epigenomes = get_colnames(temp)
    #results = calculate_repressive_tendency('/Volumes/Backup/Research/bigdata/ENCODE/mm10/H3K27me3/H3K27me3_tss_2.5kb_combined_mm10.txt', cols=epigenomes)
    #genomics.write_file(results, '/Volumes/Backup/Research/bigdata/ENCODE/mm10/H3K27me3/repressive_tendency_table_new_mm10.txt')

    ###
    #a = genomics.read_file_dic('/Users/woojunshim/Research/Documents/manuscripts/H3K27me3/manuscript/script/repressive_hg19.txt', col_idx=1)
    #b = genomics.read_file_dic('/Users/woojunshim/Research/Data/new_assigned/repressive_tendency_table_new.txt', col_idx=1)
    #genes = set()
    #for g in a:
    #    genes.add(g)
    #for g in b:
    #    genes.add(g)
    #q,w = [], []
    #genes = list(genes)
    #for g in genes:
    #    if (g in a) and (g in b):
    #        q.append(a[g])
    #        w.append(b[g])
    #print len(q), len(w)
    #s, p = stat.pearson(q,w)
    #print s

    ### CREATE A H3K27ME3 WIDTH FILE 
    #temp = open('/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/assigned/H3K27me3_tss_2.5kb_overlap_combined.txt', 'r')  
    #qq = read_table1('/Volumes/Backup/Research/bigdata/ENCODE/mm10/H3K27me3/H3K27me3_widths_mm10_z.txt')  
    #epigenomes = get_colnames(qq)
    #temp = open('/Volumes/Backup/Research/bigdata/ENCODE/mm10/H3K27me3/H3K27me3_tss_2.5kb_mm10_overlap_combined.txt', 'r')
    #results = {}
    #for i in temp:
    #    i = i.strip().split()
    #    g = i[3]
    #    w = int(i[2])
    #    c = i[1]
    #    if g not in results:
    #        results[g] = {}
    #        for e in epigenomes:
    #            results[g][e] = 0
    #    if w > results[g][c]:
    #        results[g][c] = w
    #genomics.write_table1(results, '/Volumes/Backup/Research/bigdata/ENCODE/mm10/H3K27me3/H3K27me3_tss_2.5kb_combined_mm10.txt')


    ### WRITE A BED FILE FOR REFSEQ TSS + 2.5KB REGION
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/hg19_TSS_.txt')
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/mm10_TSS.txt')
    #results = []
    #for i in temp:
    #    chr_ = i[1]
    #    gene = i[5]
    #    if i[2] == '+':
    #        start = int(i[3]) - 2500
    #        end = int(i[4])   
    #        if start <= 0:
    #            start = 0        
    #    elif i[2] == '-':
    #        end = int(i[4]) + 2500
    #        start = int(i[3])
    #    results.append([chr_, start, end, gene, i[2]])
    #genomics.write_file(results, '/Volumes/Backup/Research/bigdata/ENCODE/mm10/H3K27me3/mm10_TSS_2.5kb_upstream.txt')


    ### WRITE BED FILES WITH THE CENTRE POSITION AND WIDTH
    #pathway = '/Volumes/Backup/Research/bigdata/ENCODE/mm10/H3K27me3/'
    #results = []    
    #hms = ['H3K4me3','H3K4me1','H3K9me3','H3K27ac','H3K36me3']
    #hms = ['H3K27me3']
    #for hm in hms:
    #    temp = read_table1('/Volumes/Backup/Research/bigdata/ENCODE/mm10/H3K27me3/'+hm+'_widths_mm10.txt')
    #    cnt = 1
    #    epigenomes = get_colnames(temp)
    #    print hm, len(epigenomes)
    #    results = open(pathway+hm+'_centre_combined.txt', 'w')
    #    for e in epigenomes:
    #        print cnt
    #        cnt += 1        
    #        temp = open(pathway+'/bed/'+e+'.bed', 'r')    
    #        line = 1        
    #        for i in temp:
    #            i = i.strip().split()
             #   start = i[1]
    #            start = (int(i[1]) + int(i[2])) / 2
    #            end = start + 1
             #   end = i[2]            
    #            chr_ = i[0]
    #            width = int(i[2]) - int(i[1])
    #            results.write(chr_+'\t'+str(start)+'\t'+str(end)+'\t'+str(i[3])+'\t'+str(width)+'\t'+e+'\n')
    #            line += 1
    #    results.close()

   

    #menu = ['H3K27ac','H3K36me3','H3K9me3','H3K4me1','H3K4me3','H3K27me3']
    #pathway = '/Users/woojunshim/Research/Data/new_assigned/'

    ### EXTRACT HOX GENES 
    #temp = read_table1('/Users/woojunshim/Research/Data/new_assigned/H3K27me3_tss_2.5kb.txt')
    #genes = get_rownames(temp)
    #results = []
    #for g in genes:
    #    if 'HOX' in g:
    #        results.append(g)
    #genomics.write_file_items(results, '/Users/woojunshim/Research/Data/new_assigned/HOX_genes.txt')

    ### FISHER'S EXACT TEST
    #terms = ['GO_0030017_genes','GO_0007507_genes','HOX_genes']
    #models = ['day15_combined_times','day15_hybrid','day15_result_old']
    #for t in terms:
    #    print
    #    print t
    #    ref_ = genomics.read_file_items(pathway+t+'.txt', col=0)
    #    results = []
    #    pp = []
    #    for m in models:
    #        print m
    #        temp = read_table1('/Users/woojunshim/Research/Documents/manuscripts/H3K27me3/manuscript/script/'+m+'.txt')
    #        a = []
    #        for g in temp:
    #            a.append([g, float(temp[g]['discordance_score'])])
    #        a = genomics.sort_(a, idx=1, reverse_=True)
    #        input_ = []
    #        for i in a:
    #            input_.append(i[0]) 

    #        aa = sliding_fet(input_, ref_, percentile_bin = 1, convert_to_percentile=False)
    #        aa.insert(0, m)
    #        results.append(aa)

            #pp.append([m])
            #ref_ = set(ref_)
            #for i in range(len(input_)):
            #    if input_[i] in ref_:
            #        pp[-1].extend([i+1])   



        #genomics.write_file(results, pathway+t+'_enrichment.txt')
        #genomics.write_file(pp, pathway+t+'_rank.txt')




    ### CALCULATE THE FINAL REPRESSIVE TENDENCY SCORE (RT * PROP)
    #pathway = '/Users/woojunshim/Research/bigdata/ENCODE/mm10/H3K27me3/'
    #menu = ['H3K27me3']
    #for m in menu:
    #    results = []
    #    rt = genomics.read_file_dic(pathway+'repressive_tendency_table_new_mm10.txt', col_idx=1)
    #    prop = genomics.read_file_dic(pathway+m+'_top5_prop_all_genes_mm10.txt', col_idx=1)        
    #    min_ = float(1) / 93
    #    for g in rt:
    #        if g not in prop:
    #            prop[g] = min_
    #        results.append([g, rt[g] * prop[g]])
    #    genomics.write_file(results, pathway+'repressive_tendency_'+m+'_final_mm10.txt')

    ### COLLECT TOP 5% GENES AND IDENTIFY MOST COMMON ELEMENTS 
    #pathway = '/Users/woojunshim/Research/bigdata/ENCODE/mm10/H3K27me3/'
    #pathway = '/Users/woojunshim/Research/Data/new_assigned/'
    #menu = ['H3K27me3']
    #cc = []
    #for m in menu:
    #    temp = read_table1(pathway+m+'_tss_2.5kb_combined.txt')
    #    cols = get_colnames(temp)
    #    no = len(cols)
    #    results = {}
    #    for c in cols:
    #        t = []
    #        for g in temp:                       
    #            if float(temp[g][c]) != float(0):
    #                t.append([g, float(temp[g][c])])
    #        t = genomics.sort_(t, idx=1, reverse_=True)
    #        idx = int(len(t) * 0.05)  

    #        for i in range(idx):
    #            g = t[i][0]
    #            if g not in cc:
    #                cc[g] = {}
    #                for c1 in cols:
    #                    cc[g][c1] = 0
    #            cc[g][c] = 1
    #    genomics.write_table1(cc, pathway+'H3K27me3_top5_binary_table.txt')

    #        cc.append([c, t[idx][1]])
    #    genomics.write_file(cc, pathway+'H3K27me3_top5_threshold.txt')

    #        for i in range(idx):
    #            item = t[i]
    #            g = item[0]               
    #            if g not in results:
    #                results[g] = 0
    #            results[g] += 1
    #    for g in results:
    #        results[g] = float(results[g]) / no
    #    genomics.write_file(results, pathway+m+'_top5_prop_all_genes_mm10.txt')


    ### SIMILARITY ANALYSIS USING JACCARD INDEX 
    #pathway = '/Users/woojunshim/Research/Data/broadPeaks/'
    #epis = ['E095','E071','E038']  # 3 selected cell-types

    ### GENERATE RANDOM SIMILARITY 
    #iter_ = 111
    #exp_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/All_widths_H3K27me3.txt')
    #cols = get_colnames(exp_)
    #for e in epis:
    #    genes = []
    #    results = {}
    #    for i in range(100):
    #        results[i+1] = []        
    #    for gg in exp_:
    #        if float(exp_[gg][e]) != float(0):
    #            genes.append([gg, float(exp_[gg][e])])
    #    genes = genomics.sort_(genes, idx=1, reverse_=True)
    #    a = []
    #    for i in genes:
    #        a.append(i[0])        
    #    for c in cols:            
    #        b = []
    #        for p in exp_:
    #            if float(exp_[p][c]) != float(0):
    #                b.append(p)   
    #        b = genomics.random_sample(b)                    
    #        tt = segment_jaccard(a,b, bin_size=0.01)
    #        for m in range(len(tt)):
    #            results[m+1].append(tt[m])
    #    genomics.write_file_dic(results, pathway+'similarity_analysis/'+e+'_background_similarity.txt')

    ### NUMBER OF GENES WITH H3K27ME3 PEAKS
    #print 'Total mRNA genes =', len(mrna)
    #temp = read_table1('/Users/woojunshim/Research/Data/new_assigned/H3K27me3_tss_2.5kb_combined.txt')
    #cols = get_colnames(temp)
    #rows = get_rownames(temp)
    #results = []
    #for c in cols:
    #    cnt = 0
    #    for g in mrna:
    #        if g in temp:
    #            if float(temp[g][c]) != float(0):
    #                cnt += 1
    #    results.append([c, cnt])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/new_assigned/no_genes_with_H3K27me3.txt')





    ## CALCULATE JACCARD INDEX (FORE AND BACKGROUNDS)
    #for e in epis:        
    #    for m in menu:
    #        pos, neg = {}, {}
    #        for qq in range(100):
    #            pos[qq+1] = []
    #            neg[qq+1] = []
    #        temp = read_table1(pathway+'All_widths_'+m+'.txt')
    #        genes = get_rownames(temp)
    #        cols = get_colnames(temp)
    #        fore_ = []
    #        for g in genes:
    #            if float(temp[g][e]) != float(0):
    #                fore_.append([g, float(temp[g][e])])
    #        fore_ = genomics.sort_(fore_, idx=1, reverse_=True)            
    #        fore = []
    #        for i in fore_:
    #            fore.append(i[0])
    #        for c in cols:
    #            if c!= e:
    #                back_ = []
    #                for g in genes:
    #                    if float(temp[g][c]) != float(0):
    #                        back_.append([g, float(temp[g][c])])
    #                back_ = genomics.sort_(back_, idx=1, reverse_=True)
    #                back = []
    #                for i in back_:
    #                    back.append(i[0])
    #                tt = segment_jaccard(fore, back, 0.01)
    #                for mm in range(len(tt)):
    #                    pos[mm+1].append(tt[mm])
    #                back = genomics.random_sample(back)
    #                tt = segment_jaccard(fore, back, 0.01)
    #                for mm in range(len(tt)):
    #                    neg[mm+1].append(tt[mm])
    #        genomics.write_file_dic(pos, pathway+'similarity_analysis/'+e+'_foreground_jaccard_'+m+'.txt')
    #        genomics.write_file_dic(neg, pathway+'similarity_analysis/'+e+'_background_jaccard_'+m+'.txt')

    ## WILCONXON RANK SUM TEST (ONE-SIDED) BETWEEN FORE AND BACKGROUNDS
    #for e in epis:
    #    results = []
    #    for m in menu:
    #        fore = genomics.read_file_dic(pathway+e+'_foreground_jaccard_'+m+'.txt')
    #        back = genomics.read_file_dic(pathway+e+'_background_jaccard_'+m+'.txt')
    #        for i in fore:
    #            s,p = stat.mann(fore[i], back[i], alternative_='greater')
    #            results.append([i, p, m])
    #    genomics.write_file(results, pathway+e+'_wilcoxon_test.txt')



    ### CREATE A MATRIX FOR BREADTH TABLE FOR ALL HMS 
    #for m in menu:
    #    pathway = '/Users/woojunshim/Research/Data/broadPeaks/'+m+'/'
    #    results = {} 
    #    epis = []
    #    genes = set()
    #    for r,d,files in os.walk(pathway):            
    #        for f in files:
    #            e = f[0:4]
    #            if 'E' in e:
    #                epis.append(e)
    #                temp = genomics.read_file1(pathway+f)
    #                for i in temp:
    #                    genes.add(i[1])
    #    print len(genes)
    #    for g in genes:
    #        results[g] = {}
    #        for e in epis:
    #            results[g][e] = 0        
    #    for r,d,files in os.walk(pathway):
    #        for f in files:
    #            e = f[0:4]   
    #            if 'E' in e:     
    #                temp = genomics.read_file1(pathway+f)
    #                for i in temp:
    #                    g = i[1]                                      
    #                    w = float(i[2])                        
    #                    results[g][e] = int(w)                   
    #    genomics.write_table1(results, '/Users/woojunshim/Research/Data/broadPeaks/All_widths_'+m+'.txt')


    ### GENE RANK TABLE
    #temp = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/All_widths_H3K27me3_z.txt')
    #results = initiate_table(temp)
    #cols = get_colnames(temp)
    #rows = get_rownames(temp)    
    #for c in cols:   
    #    temp_ = []
    #    for g in temp:
    #        temp_.append([g, float(temp[g][c])])
    #    temp_ = genomics.sort_(temp_, idx=1, reverse_=True)      
    #    for m in range(len(temp_)):
    #        item = temp_[m]
    #        results[item[0]][c] = m+1
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/H3K27me3_rank_table.txt')           

    ### MEAN ASSOCIATION SCORES (PERCENTILE BIN) ACROSS CELL-TYPES
    #temp = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/All_widths_H3K27me3_z.txt')
    #results = []
    #cols = get_colnames(temp)
    #rows = get_rownames(temp)    
    #for c in cols:
    #    temp_ = []
    #    for g in temp:
    #        temp_.append([g, float(temp[g][c])])
    #    temp_ = genomics.sort_(temp_, idx=1, reverse_=True)        
    #    tt = []
    #    for l in temp_:
    #        tt.append(l[1])        
    #    sorted_ = segment_lists(tt,bin_size=0.01)
    #    for m in range(len(sorted_)):
    #        a = sorted_[m]
    #        results.append([np.mean(a), m+1])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/H3K27me3_widths_mean.txt')


    ### SUMA SCORES 
    #temp = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/All_widths_H3K27me3_z.txt')
    #results = {}
    #sum_, max_, min_ = 0,0,9999
    #for g in temp:
    #    results[g] = [0, 0]
    #    for c in temp[g]:
    #        results[g][0] += float(temp[g][c])
    #    sum_ += results[g][0]
    #    if results[g][0] > max_:
    #        max_ = results[g][0]
    #    if results[g][0] < min_:
    #        min_ = results[g][0]
    #for g in results:
    #    results[g][1] = (results[g][0] - min_) / (max_ - min_)
    #output_ = open('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/suma_roadmap.txt', 'w')
    #for g in results:
    #    output_.write(g+'\t'+str(results[g][0])+'\t'+str(results[g][1])+'\n')
    #output_.close()

    


    ### ASSESSING ESTIMATION OF THE REPRESSIVE TENDENCY SCORE
    ### CALCULATE MEAN AND SD AND SEE IF THE ORIGINAL SCORE COMPLIES (I.E. WITHIN 1 SD OF THE EMPIRICAL BOOTSTRAPPING DISTRIBUTION)
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/bootstrapping_empirical_dist.txt')
    #ref = genomics.read_file_dic('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/new_repressive_tendency.txt', col_idx=1)
    #results = []
    #for i in temp:
    #    g = i[0]
    #    all_ = []
    #    for m in range(1, len(i)):
    #        all_.append(float(i[m]))
    #    mean_ = np.mean(all_)
    #    sd_ = np.std(all_)
    #    diff = np.abs(ref[g] - mean_)
    #    if diff <= sd_:
    #        answer = 1
    #    else:
    #        answer = 0
    #    results.append([g, mean_, sd_, answer])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/bootstrapping_within_1sd.txt')

    

    ### 
    #temp = open('/Users/woojunshim/Research/Data/epigenomes_list.txt', 'w')
    #line = ''
    #for e in epigenomes:
    #    line += e + ' '
    #temp.write(line)
    


    ### BOOTSTRAPPING ANALYSIS 
    #test = genomics.random_sample(epigenomes, replacement=True)
    #print test
    #results = calculate_repressive_tendency('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/All_widths_H3K27me3_z.txt', cols=test)
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/test.txt')

    ### BOOTSTRAPPING 2
    #n= 10
    #epigenomes = epigenomes[0:10]
    #ref = genomics.read_file1('/Users/woojunshim/Research/Data/new_assigned/tables/repressive_hg19_cont_prop.txt', sort_by=1, reverse_=True)
    #print ref[0:10]
    #genes = []
    #boot = {} 
    #q = []
    #for i in ref:
    #    genes.append(i[0])   
    #    boot[i[0]] = 0
    #    q.append(i[1])
    #results = {}
    #for g in genes:
    #    results[g] = []
    #for i in range(n):
    #    if i % 10 == 0:
    #        print i
    #    w = []
    #    temp = []
    #    cols = genomics.random_sample(epigenomes, replacement=True)
    #    print cols

    #    b = calculate_rt('/Users/woojunshim/Research/Data/H3K27me3_width_table.txt', '/Users/woojunshim/Research/Data/H3K27me3_top5_binary_table.txt', cols=cols)
    #    for g in genes:            
    #        results[g].append(b[g])
    #output_ = []
    #for g in results:
    #    output_.append([g])
    #    for m in results[g]:
    #        output_[-1].extend([m])
    #genomics.write_file(output_, '/Users/woojunshim/Research/Data/bootstrapping/bootstrapping_result_new.txt')


    ### BOOTSTRAPPING 
    #a_ = genomics.read_file1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/new_repressive_tendency.txt')
    #ref = {}
    #for i in range(len(a_)):
    #    l = a_[i]
    #    ref[l[0]] = [i+1, float(l[1])] 
    #genes = []
    #boot = {} 
    #q = []
    #for g in a:
    #    genes.append(g)   
    #    boot[g] = 0
    #    q.append(a[g])
    #cor = []
    #for i in range(n):
    #    if i % 10 == 0:
    #        print i
    #    w = []
    #    temp = []
    #    cols = genomics.random_sample(epigenomes, replacement=True)
    #    b = calculate_repressive_tendency('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/All_widths_H3K27me3_z.txt', cols)
    #    for g in genes:            
    #        w.append(b[g])
    #        temp.append([g, b[g]])
    #    temp = genomics.sort_(temp, idx=1, reverse_=True)
    #    s, p =stat.pearson(q,w)
    #    cor.append(s)
    #    for i in range(len(temp)):
    #        item = temp[i]
    #        g = item[0]
    #        diff1 = np.abs(ref[g][0] - (i+1))
    #        diff2 = np.abs(ref[g][1] - item[1])
    #        if (diff1 <= 20) or (diff2 <= 0.01):
    #            boot[g] += 1
    #for g in genes:
    #    boot[g] = float(boot[g]) / n
    #genomics.write_file_items(cor, '/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/bootstrapping_pearson.txt')
    #genomics.write_file(boot, '/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/bootstrapping_result.txt')

    

    ### CHECK CORRELATION BETWEEN OLD AND NEW REPRESSIVE TENDENCY SCORES
    ### PEARSONS CORRELATION = 0.8547
    #old = genomics.read_file1('/Users/woojunshim/Research/Documents/manuscripts/H3K27me3/manuscript/script/repressive_hg19.txt')
    #new = genomics.read_file1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/new_repressive_tendency.txt')
    #g1, g2 = {}, {}
    #for n in range(len(old)):
    #    i = old[n]
    #    g1[i[0]] = float(i[1])
    #for n in range(len(new)):
    #    i = new[n]
    #    g2[i[0]] = float(i[1])   
    #genes = []
    #for g in g1:
    #    if g in g2:
    #        genes.append(g)
    #print len(genes)
    #a,b = [], []
    #for g in genes:
    #    a.append(g1[g])
    #    b.append(g2[g])
    #r, p = stat.pearson(a,b)
    #print r

    ### SATURATION ANALYSIS USING NEW METHOD
    #temp = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/All_widths_H3K27me3_z.txt')
    #cols = get_colnames(temp)
    #results = []
    #for ii in range(1):
    #    order = genomics.random_sample(cols)        
    #    track = {}
    #    for g in temp:
    #        track[g] = [0, 0]  # [score, rank]
    #        for c in order[0:3]:
    #            track[g][0] += float(temp[g][c])        
    #    pp = []
    #    for g in temp:
    #        pp.append([g, track[g][0]])
    #    pp = genomics.sort_(pp, idx=1, reverse_=True)        
    #    max_ = pp[0][1]
    #    min_ = pp[-1][1]
    #    for i in range(len(pp)):
    #        pp[i][1] = (float(pp[i][1]) - min_) / (max_ - min_)
    #    print pp[0:10]
    #    for n in range(len(pp)):
    #        m = pp[n]
    #        track[m[0]][0] = m[1]
    #        track[m[0]][1] = n+1
    #    previous = track
    #print track['NKX2-5']

    #
    #result1, result2, result3, result4, result5 = saturation1(input_='/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/All_widths_H3K27me3_z.txt', iter_=1000, step_=3)
    #genomics.write_file(result1, '/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/saturation_mean_score_change.txt')
    #genomics.write_file(result2, '/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/saturation_mean_rank_change.txt')
    #genomics.write_file(result3, '/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/saturation_prop_stable_genes_top3.txt')
    #genomics.write_file(result4, '/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/saturation_prop_stable_genes_top4.txt')
    #genomics.write_file(result5, '/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/saturation_prop_stable_genes_top5.txt')


    ### NEW METHOD TO CALCULATE REPRSSIVE TENDENCY SCORE
    ### 1. CALCULATE Z-SCORE OF THE H3K27ME3 WIDTH ACROSS CELL-TYPES 
    ### 2. FOR EACH GENE I, SUM ITS Z-SCORES
    ### 3. SORT ALL GENES IN THE DESCENDING ORDER OF THE VALUE
    ### 4. CONVERT THOSE VALUES IN A RANGE [0,1]
    #temp = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/All_widths_H3K27me3_z.txt')
    #temp = read_table1('/Users/woojunshim/Research/Data/mm10/h3k27me3/H3K27me3_widths_mm10_z.txt')
    #results = {}
    #ref = []
    #for g in temp:
    #    results[g] = 0
    #    for c in temp[g]:
    #        results[g] += float(temp[g][c])
    #    ref.append([g, results[g]])
    #ref = genomics.sort_(ref, idx=1, reverse_=True)
    #max_ = ref[0][1]
    #min_ = ref[-1][1]
    #for i in range(len(ref)):
    #    ref[i][1] = (float(ref[i][1]) - min_) / (max_ - min_)
    #genomics.write_file(ref, '/Users/woojunshim/Research/Data/mm10/h3k27me3/mm10_new_repressive_tendency.txt')



    ### CALCULATE PROPORTIONS OF H3K27ME3 WIDTHS (GENE-SPECIFIC)
    ### FOR FIGURE 3
    #width = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/All_widths_H3K27me3.txt')
    #width = read_table1('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.txt')
    #results = {}
    #for g in width:
    #    sum_ = 0
    #    for c in width[g]:
    #        sum_ += float(width[g][c]) 
    #    if sum_ > 0:
    #        results[g] = {}
    #        for c in width[g]:
    #            results[g][c] = round(float(width[g][c]) / sum_, 6)
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/All_widths_H3K27me3_ratio.txt')
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.ratio.txt')

    ### CALCULATE SPEARMAN'S RHO BETWEEN RATIOS OF EXPRESSION AND H3K27ME3 WIDTH
    #exp = read_table1('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.ratio.txt')
    #width = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/All_widths_H3K27me3_ratio.txt')
    #results = []
    #cols = get_colnames(exp)
    #for g in width:
    #    a,b = [], []
    #    if g in exp:
    #        for c in cols:
    #            a.append(float(width[g][c]))
    #            b.append(float(exp[g][c]))
    #        r, p = stat.spearman(a,b)
    #        results.append([g, r])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/spearman_ratios_exp_h3k27me3.txt')


    ### CALCULATE SUM OF H3K27ME3 DOMAINS WIDTHS FOR ALL GENES 
    #width = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/All_widths_H3K27me3.txt')
    #results = {}
    #for g in width:
    #    results[g] = 0
    #    for c in width[g]:
    #        results[g] += float(width[g][c])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/All_widths_H3K27me3_sum.txt')


    ### NUMBER OF GENES ASSOCIATED H3K27ME3
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/H3K27me3_broadest_only_1kb_refseq.txt')
    #a = select_items(input_=temp, keyword='E083', idx=4)
    #print a[:10]
    #print len(a)
    #results = {}
    #for i in temp:
    #    if i[4] not in results:
    #        results[i[4]] = 0
    #    results[i[4]] += 1
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/H3K27me3_broadest_only_1kb_refseq_gene_numbers.txt')


    ### ADD H3K27ME3 SIGNAL TO EACH ITEM IN 'H3K27ME3_BROADEST_ONLY_1KB_REFSEQ.TXT'
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/H3K27me3_broadest_only_1kb_refseq.txt')
    #for i in range(len(temp)):
    #    u = temp[i]
    #    s,e = union_width([float(u[1]),float(u[2])],[float(u[6]),float(u[7])])
    #    w = e - s
    #    temp[i].extend([w])
    #genomics.write_file(temp, '/Users/woojunshim/Research/Data/H3K27me3_broadest_only_1kb_refseq_.txt')

    ### ASSIGN GENES 
    #pathway = '/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/H3K27me3/'
    #results = []
    #print epigenomes
    #for c in epigenomes[:1]:     
    #    print c   
    #    ref_ = open(pathway+c+'-H3K27me3.broadPeak', 'r')
    #    ref = {}
    #    for p in ref_:
    #        p = p.strip().split()
    #        ref[p[3]] = [p[0], p[1], p[2]]        
    #    temp = assign_genes(input_file=pathway+c+'-H3K27me3.broadPeak', tss_='/Users/woojunshim/Research/Data/hg19_TSS_.txt', min_distance=0, max_distance=999999999, centre=False, width=True, gene_include=True)
    #    idx = int(len(temp) * 0.05)
    #    print idx
    #    print temp[0:10]
    #    print ref[temp[0][0]]



    ### CALCULATE REPRESSIVE TENDENCY SCORE BASED ON ALL ASSIGNED H3K27ME3 DOMAINS, WITHIN +/- 1KB OF REFSEQ TSS
    #results = {}
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/H3K27me3_broadest_only_1kb_refseq.txt')
    #for i in temp:
    #    g = i[-1]
    #    if g not in results:
    #        results[g] = 0
    #    start, end = union_width([i[1], i[2]], [i[6], i[7]])
    #    results[g] += int(end) - int(start)
    #for g in results:
    #    results[g] = float(results[g]) / 222000 
    #genomics.write_file(results,'/Users/woojunshim/Research/Data/H3K27me3_broadest_only_1kb_refseq_repressive_tendency.txt' )

    #s,e = union_width([172658672,172661320], [172661315,172663315])
    #print s,e
    #print e-s
    #print is_within(1726, [172658672,172667940])

    ### NORMALISE ALL H3K27ME3 ASSIGNED (SINGLE DOMAIN TO A GENE) USING FEATURE SCALING [0,1]
    ### TO GENERATE REPRESSIVE TENDENCY SCORE BASED ON CONTINUOUS H3K27ME3 VALUES, RATHER THAN DISCRETE
    #pathway = '/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/'
    #results = []
    #for c in epigenomes:
    #    temp = genomics.read_file1(pathway+c+'_H3K27me3_genes.txt')
    #    for i in temp:
    #        results.append([i[3], i[4], i[5], i[1], c])
    #genomics.write_file(results, pathway+'H3K27me3_combined.txt')

    ### CALCULATE DISSIMILARITY BETWEEN ROADMAP RNA-SEQ SAMPLES 
    #t = '/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.scaled.txt'
    #new = transpose(t)
    #results = calculate_dissimilarity(input_=t, method='spearman', svd=True, threshold=0.9)
    #results = calculate_dissimilarity1(results)
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.scaled.dis.txt')

    ### TEST SVD FUNCTION
    #tt = read_table1('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.scaled.txt')
    #print tt['RNF14']
    #rows = get_rownames(tt)
    #cols = get_colnames(tt)
    #results = perform_svd(tt, rows, cols)
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.scaled.pc.txt')

    ### SVD
    #tt = read_table1('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.txt')
    #results = scale_table(tt)    
    #genes = get_rownames(tt)
    #print genes[0]
    #print tt[genes[0]]
    #cols = get_colnames(tt)
    #tt = transpose_table1(tt, as_list_=False)
    #tt = '/Users/woojunshim/Research/Data/57epigenomes.RPKM.symbols.txt'
    #results = convert_to_array(tt)  
    #print
    #print results[0]
    #print
    #print cols
    #print results[0]  
    #u,s,v = np.linalg.svd(results, full_matrices=False) 
    #l = len(s)
    #sm = np.zeros((l, l),int)
    #np.fill_diagonal(sm, s)    
    #print u[0,10]   
    #print u.shape, s.shape, v.shape
    #q = np.matmul(u[:18706,:46],sm)
    #q = np.matmul(q, v)
    #print q[0]
    #print len(q[0])

    #print q[0]
    #a = find_no_eigens(s)



    ### EXTRACT ALL DOMAINS FOR E095
    #temp = genomics.read_file1('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_negative_results_.txt')
    #cell = 'E070'
    #results = select_items(temp, cell, 4)
    #genomics.write_file(results, '/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/E070_.txt')

    ### EXTRACT SIGNIFICANT NEGATIVE AND POSITIVE DOMAINS (E095)
    #temp = genomics.read_file1('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/E070_.txt', sort_by=8)
    #results = []
    #for i in temp:
    #    if float(i[-1]) < 0.05:
    #        results.append(i)
    #results = genomics.sort_(results, idx=8, reverse_=False)    
    #genomics.write_file(results, '/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/E070_significant.txt')

    ### DIVIDE Z-SCORE BY PROP. OF POSITIVE SAMPLES
    #results = divide_by_prop_samples('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/E070_significant.txt', 111, 9, 4)
    #results = genomics.sort_(results, idx=9, reverse_=False)
    #genomics.write_file(results, '/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/E070_significant_.txt')


    ### CREATE A LOG2(x_i / x_bar) ROADMAP EXPRESSION TABLE
    ### FIRST REMOVE ANY GENES WITH MEAN EXPRESSION VALUE < 1.0
    #results = {}
    #cols = get_colnames(exp_)
    #genes = get_rownames(exp_)
    #for g in genes:
    #    sum_ = []
    #    for c in cols:
    #        sum_.append(float(exp_[g][c]))
    #    mean_ = np.mean(sum_)        
    #    if g=='RNF14':
    #        print mean_
    #    if mean_ >= 1.0:
    #        results[g] = {}
    #        for c in cols:
    #            if float(exp_[g][c]) == float(0):
    #                results[g][c] = 'NA'
    #            else:
    #                value = np.log2(float(exp_[g][c]) / mean_)
    #                results[g][c] = round(value, 6)
    #                if g=='RNF14' and c=='E071':
    #                    print value
    #                    print float(exp_[g][c]) / mean_
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/57epigenomes.RPKM.symbols_fold_change.txt')


    ### CALCULATING P-VALUES OF H3K27ME3 DATA USING EMPIRICAL DISTRIBUTION
    #pathway = '/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/'
    #temp = genomics.read_file1(pathway+'H3K27me3_gene_permutation_test_.txt')
    #results = open(pathway+'H3K27me3_gene_permutation_test__.txt', 'w')
    #for i in temp:
    #    z = stat.z_score(float(i[1]), 0.2219152, 0.005969884)
    #    p = stat.p_value(z)
    #    if z < 0:
    #        p = 1 -p
    #    results.write(i[0]+'\t'+i[1]+'\t'+i[3]+'\t'+str(z)+'\t'+str(p)+'\n')
    #results.close()


    ### EXTRACT TOP 1000 REGIONS FOR EACH CELL-TYPE FROM 'H3K27ME3_BROAD_DOMAINS_NEGATIVE_MERGED_DETAIL.TXT'
    #temp = genomics.read_file1('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_gene_permutation_test_.txt', sort_by=3, reverse_=False)
    #print temp[0:10]
    #ids = set()
    #for e in epigenomes:
    #    cnt = 0
    #    for i in temp:            
    #        if e in i[2]:
    #            ids.add(i[0])
    #            cnt += 1
    #        if cnt == 1000:
    #            break
    #print len(ids)
    #ref = open('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_negative_merged_detail.txt', 'r')
    #results = open('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_top1000s_negative.txt', 'w')
    #for i in ref:
    #    i = i.strip().split()
    #    yy = ''
    #    if i[3] in ids:
    #        if len(i) == 7:
    #            yy = i[3]+'\t'+i[4]+'\t'+i[5]+'\t'+i[6]
    #        if len(i) == 8:
    #            yy += '\t'+i[7]
    #        results.write(yy+'\n')
    #results.close()

    ### EXTRACT EMPIRICAL DISSIMILARITY SCORES (BACKGROUND)
    #pathway = '/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/'
    #temp = genomics.read_file1(pathway+'H3K27me3_gene_permutation_test_.txt')
    #results = []
    #for i in temp:
    #    results.append(float(i[1]))
    #genomics.write_file_items(results, pathway+'H3K27me3_gene_empirical_background.txt')



    ### REMOVE GENETIC ELEMENTS WITHOUT VALUE
    #temp = genomics.read_file1('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_negative_merged.txt')
    #results = []
    #for i in temp:
    #    if len(i) == 5:
    #        results.append(i)
    #genomics.write_file(results,'/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_negative_merged_.txt' )

    ### ADD ITEM ID TO 'H3K27me3_broad_domains_merged.txt'
    #temp = genomics.read_file1('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_negative_merged.txt')
    #for i in range(len(temp)):
    #    temp[i].insert(3, 'item_'+str(i+1))
    #genomics.write_file(temp, '/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_negative_merged_.txt')

    ### CALCULATING DISSIMILARITY FOR H3K27ME3 (GENE-BASED)
    #temp = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_widths.txt')
    #genes = get_rownames(temp)
    #cols = get_colnames(temp)
    #results = {}
    #ref = {}
    #for c in cols:
    #    ref[c] = []
    #    for g in genes:
    #        ref[c].append(temp[g][c])
    #for c1 in cols:
    #    results[c1] = {}
    #    print c1
    #    for c2 in cols:
    #        r,p = stat.spearman(ref[c1], ref[c2])
    #        results[c1][c2] = r
    #new = calculate_dissimilarity(results)
    #genomics.write_table1(new, '/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_gene_dissimilarity.txt')


    ### GENERATE A PSEUDO DATA 
    ### TO TEST A DIFFERENT DISSIMILARITY MATRIX
    #results = []
    #cols = set(get_colnames(exp_))
    #temp = genomics.read_file1('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_significant_detail.txt')
    #for m in range(len(temp)):
    #    i = temp[m]
    #    names = list(i[4].split(';')[:-1])        
    #    new = ''
    #    del temp[m][4]
    #    for n in names:
    #        if n in cols:
    #            new += n+';'
    #    temp[m].insert(4, new)
    #genomics.write_file(temp, '/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_significant_detail_short.txt')


    ### PERMUTATION TEST FOR EXPRESSION DATA (RNA-SEQ)
    #pathway = '/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/'
    #results = identify_hotspots(pathway+'H3K27me3_broad_domains_significant_detail.txt', pathway+'H3K27me3_broad_domains_dissimilarity.txt', 3, 4)
    #genomics.write_file(results, pathway+'H3K27me3_broad_domains_permutation_test.txt')

    ### PERMUTATION TEST FOR H3K27ME3 DOMAINS
    #pathway = '/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/'
    #results = identify_hotspots(pathway+'H3K27me3_broad_domains_merged.txt', pathway+'H3K27me3_gene_dissimilarity.txt', 3, 4)
    #genomics.write_file(results, pathway+'H3K27me3_gene_permutation_test_.txt')

    ### PERMUTATION TEST FOR DISSIMILARITY 
    #ns = [2,5,10,20,50,100]
    #for n in ns:
    #    test = get_random_dissimilarity('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_dissimilarity.txt', no_samples=n)
    #    genomics.write_file_items(test, '/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/test/'+str(n)+'_H3K27me3_random_samples.txt')
    #    print n

    ### 
    #genomics.write_file_items(epigenomes, '/Users/woojunshim/Research/cell-type-specificity/data/roadmap_cell_type_order1.txt')

    #temp = read_table1('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_dissimilarity.txt')
    #temp = read_table1('/Users/woojunshim/Research/cell-type-specificity/data/RNA-seq/spearman_dissimilarity_roadmap_rpkm.txt')
    #print temp['E095']['E105']

    ### 
    #temp = genomics.read_file1('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_significant_detail.txt')
    #pos, neg = [], []
    #for i in temp:
    #    if float(i[5]) < 0:
    #        neg.append(i[6])
    #    else:
    #        pos.append(i[6])
    #print len(pos), len(neg)
    #pos = list(set(pos))
    #neg = list(set(neg))
    #print len(pos), len(neg)
    #print pos
    #ref = stable_tf
    #a,b,c,d = 0,0,0,0
    #for g in mrna:
    #    if g in ref:
    #        if g in pos:
    #            a += 1
    #        else:
    #            b += 1
    #    else:
    #        if g in pos:
    #            c += 1
    #        else:
    #            d += 1
    #o, p = stat.fisher(a,b,c,d)
    #print a,b,c,d
    #print o, p
    #genomics.write_file_items(neg, '/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_significant_negative_genes.txt')


    ### COLLECT GENE NAMES 
    #cells = ['E095','E070','E081','E083']
    #for c in cells:
    #    temp = genomics.read_file_items('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/'+c+'_significant.txt', col=6)
    #    print len(temp)
    #    a = set(temp)
    #    print len(a)
    #    genomics.write_file_items(list(a), '/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/'+c+'_significant_genes.txt')

    ### PROPORTIONS OF HOT-SPOTS IN PROMOTERS, INTERGENIC OR INTRAGENIC REGIONS
    #cells = ['E095','E070','E081','E083']
    #for c in cells:
    #    results = [0, 0, 0]
    #    total = 0
    #    temp = genomics.read_file1('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/'+c+'_significant.txt', sort_by=7)
    #    for i in temp:
    #        total += 1
    #        if np.abs(i[7]) <= 1000:
    #            results[0] += 1
    #        elif (np.abs(i[7]) > 1000) and len(i) == 9:
    #            results[1] += 1
    #        else:
    #            results[2] += 1
    #    results[0] = float(results[0]) / total
    #    results[1] = float(results[1]) / total
    #    results[2] = float(results[2]) / total
    #    genomics.write_file(results, '/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/'+c+'_significant_stat.txt')

    ### CLEAR UP FILE 'H3K27ME3_BROAD_DOMAIN_NEGATIVE_RESULTS.TXT'
    #results = []
    #temp = genomics.read_file1('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_negative_results.txt')
    #for i in temp:
    #    if len(i) == 11:
    #        results.append(i)
    #genomics.write_file(results, '/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_negative_results_.txt')

    ### STATISTICS (PROMOTER, INTRAGENIC OR INTERGENIC)
    #results = [0,0,0]
    #total = 0
    #temp = genomics.read_file1('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_negative_results_.txt')
    #for i in temp:
    #    if len(i) > 7:
    #        if i[1]=='start':
    #            continue
    #        if (float(i[9]) != 0) and (float(i[10]) != 9999999):
    #            total += 1
    #            if np.abs(int(i[6])) <= 1000:  # promoter
    #                results[0] += 1
    #            elif (np.abs(int(i[6])) > 1000) and i[7] == 'NA':
    #                results[1] += 1
    #            else:
    #                results[2] += 1
    #results[0] = float(results[0]) / total
    #results[1] = float(results[1]) / total
    #results[2] = float(results[2]) / total
    #print total
    #genomics.write_file(results, '/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_significant_stat_total.txt')

    ### DETAILED STATS
    #results = [[],[],[]]
    #for e in epigenomes:
    #    temp = genomics.read_file1('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_significant_detail.txt')
    #    t = select_items(temp, e, idx=4)
    #    results[0].append(0)
    #    results[1].append(0)
    #    results[2].append(0)
    #    total = 0        
    #    for i in t:
    #        if float(i[5]) > 0:
    #            total += 1
    #            if np.abs(int(i[7])) <= 1000:  # promoter
    #                results[0][-1] += 1
    #            elif (np.abs(int(i[7])) > 1000) and len(i) == 9:
    #                results[1][-1] += 1
    #            else:
    #                results[2][-1] += 1
    #    if total > 0:
    #        results[0][-1] = float(results[0][-1]) / total
    #        results[1][-1] = float(results[1][-1]) / total
    #        results[2][-1] = float(results[2][-1]) / total
    #genomics.write_file(results, '/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_significant_stat_positives_detail.txt')

    ### DISTANCE TO THE CLOEST GENE (NEGATIVES VS POSITIVES)
    #temp = genomics.read_file1('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_significant_detail.txt')
    #results = []
    #for i in temp:
    #    if float(i[5]) > 0:
    #        tag = 'positive'
    #    else:
    #        tag = 'negative'
    #    results.append([np.abs(int(i[7])), tag])
    #genomics.write_file(results, '/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_significant_distances.txt')

    ### FISHER'S EXACT TEST FOR NEGATIVE AND POSITIVE GROUPS 
    #temp = genomics.read_file1('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_significant_detail.txt')
    #genes = []
    #all_ = []
    #for i in temp:
    #    all_.append(i[6])
    #    if float(i[5]) < 0:
    #        genes.append(i[6])
    #genes = list(set(genes))
    #all_ = list(set(all_))
    #ref = set(list(regulated_tf) + list(regulated_nontf))
    #a,b,c,d = 0, 0, 0, 0
    #for g in all_:
    #    if g in ref:
    #        if g in genes:
    #            a += 1
    #        else:
    #            b += 1
    #    else:
    #        if g in genes:
    #            c += 1
    #        else:
    #            d += 1
    #print a,b,c,d
    #o, p = stat.fisher(a,b,c,d)
    #print o, p


    ### COMBINE H3K27ME3_BROAD_DOMAINS_NEGATIVE_MERGED_DETAIL.TXT AND H3K27ME3_GENE_PERMUTATION_TEST_.TXT INTO SINGLE FILE
    #values = genomics.read_file('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_gene_permutation_test_.txt', [1, 3,4], rowname='0')    
    #temp = genomics.read_file1('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_negative_merged_detail.txt')
    #for i in range(len(temp)):
    #    item = temp[i]
    #    id_ = item[3]
    #    if id_ in values:
    #        if len(item) == 7:
    #            temp[i].extend(['NA'])
    #        temp[i].extend([values[id_][0][0], values[id_][0][1], values[id_][0][2]])
    #temp.insert(0, ['chr','start','end','id','samples','closest','distance','overlap','dissimilarity','z','p'])
    #genomics.write_file(temp, '/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_negative_results.txt')



    ### CREATE BED 
    #temp = genomics.read_file1('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/E070_significant.txt')
    #results = []
    #for i in temp:
    #    results.append([i[0], i[1], i[2], i[3]])
    #genomics.write_file(results, '/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/E070_significant.bed')



    ### ANALYSIS ON H3K27ME3_BROAD_DOMAINS_SIGNIFICANT_DETAIL.TXT, GIVEN A CELL-TYPE
    #temp = genomics.read_file1('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_significant_detail.txt')
    #cells = ['E083','E081','E095','E070']
    #for c in cells:
    #    selected = select_items(temp, c, idx=4)
    #    for m in range(len(selected)):
    #        selected[m][5] = float(selected[m][5])
    #    selected = genomics.sort_(selected, idx=5, reverse_=False)
    #    genomics.write_file(selected, '/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/'+c+'_significant.txt')

    ### IDENTIFY CLOSEST GENES TO THE HOT-SPOTS
    #results = assign_genes('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_significant_.txt', '/Users/woojunshim/Research/Data/hg19_TSS_.txt')
    #temp = genomics.read_file1('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_significant_.txt')
    #for m in range(len(temp)):        
    #    id_ = results[m][0]
    #    gene = results[m][1]
    #    distance = results[m][2]
    #    included = results[m][3]
    #    if id_ == temp[m][3]:
    #        temp[m].extend([gene, distance])
    #        if len(included) != 0:
    #            pp = ''
    #            for l in included:
    #                pp += l+';'
    #            temp[m].extend([pp])
    #genomics.write_file(temp, '/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_significant_detail.txt')


    #results = assign_genes('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_negative_merged_.txt', '/Users/woojunshim/Research/Data/hg19_TSS_.txt')
    #temp = genomics.read_file1('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_negative_merged_.txt')
    #for m in range(len(temp)):        
    #    id_ = results[m][0]
    #    gene = results[m][1]
    #    distance = results[m][2]
    #    included = results[m][3]
    #    if id_ == temp[m][3]:
    #        temp[m].extend([gene, distance])
    #        if len(included) != 0:
    #            pp = ''
    #            for l in included:
    #                pp += l+';'
    #            temp[m].extend([pp])
    #genomics.write_file(temp, '/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_negative_merged_detail.txt')

    ### EXTRACT H3K27ME3 SIGNIFICANT ITEMS FOR A GIVEN CELL-TYPE
    #cell='E095'
    #ref_file = [[cell]]
    #results = select_lines(input_file='/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_gene_permutation_test_.txt', ref_file=ref_file, id_idx=3)    
    #genomics.write_file(results, '/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/'+cell+'_H3K27me3_gene_significant.txt')

    ### ADD ITEM LABELS 
    #results = add_labels('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_significant.txt', col_idx=3)
    #genomics.write_file(results, '/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_significant_.txt')

    ### IDENTIFY SIGNIFICANT (P < 1.0 * 10^-6) HOT-SPOTS 
    #pathway = '/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/'
    #idx = set()
    #temp = open(pathway+'H3K27me3_negative_broad_background_z.txt', 'r')
    #cnt = 0
    #v = []
    #for i in temp:
    #    i = i.strip().split()
    #    value = float(i[0])
    #    if np.abs(value) > 4.75342:
    #        idx.add(cnt)
    #        v.append(value)
    #    cnt += 1
    #print len(idx), len(v)
    #temp = open(pathway+'H3K27me3_broad_domains_negative_merged.txt', 'r')
    #cnt = 0
    #results = []
    #uu = 0
    #for i in temp:
    #    i = i.strip().split()
    #    if cnt in idx:            
    #        results.append([i[0], i[1], i[2], i[3], v[uu]])            
    #        uu += 1
    #    cnt += 1
    #genomics.write_file(results, pathway+'H3K27me3_broad_domains_significant.txt')




    ### CALCULATE Z-SCORE / CORRECTED P-VALUE FOR EACH BROAD H3K27ME3 NEGATIVE 
    #results = convert_to_z('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_negative_broad_background_specificity_roadmap.txt', exclude_values=[float(0)])
    #p = []
    #for i in results:
    #    value = stat.p_value(i, side='both')
    #    p.append(value)
    #corrected = stat.corrected_p(p)
    #genomics.write_file_items(corrected, '/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_negative_broad_background_fdr.txt')


    ### CONVERT SPEARMAN'S SIMILARITY TO DISSIMILARITY MATRIX
    #results = calculate_dissimilarity('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_spearman_roadmap.txt')
    #genomics.write_table1(results, '/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_dissimilarity.txt')

    ### CREATE A MERGED FILE FROM 'H3K27me3_broad_domains_flat_annotated.txt'
    #results = merge_into_single_lines('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_flat_annotated.txt', col_idx=3)
    #print 'read done'
    #output_ = open('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_merged.txt', 'w')
    #for chr_ in results:
    #    for id_ in results[chr_]:
    #        temp = id_.split('_')
    #        start, end = temp[0], temp[1]
    #        output_.write(chr_+'\t'+start+'\t'+end+'\t')
    #        for c in results[chr_][id_]:
    #            output_.write(c+';')
    #        output_.write('\n')
    #output_.close()

    ### SORT OUT H3K27me3_broad_domains_flat_annotated.txt FOR SPEARMAN'S CORRELATION
    #results = create_cell_type_array('H3K27me3_broad_domains_flat_annotated.txt', start=1, end=2, cell_idx=3, cell_list=epigenomes)
    #print len(results['E095']), len(results['E016'])
    #output_ = calculate_correlation_for_lists(results)
    #genomics.write_table1(output_, 'H3K27me3_broad_domains_spearman_roadmap.txt')
        


    ### CREATE A FLAT BED FILE FOR BROAD H3K27ME3 DOMAINS ACROSS CELL-TYPES
    #results = []
    #for epi in epigenomes:
    #    temp_ = open('/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/H3K27me3/'+epi+'-H3K27me3.broadPeak.short', 'r')
    #    temp = []
    #    for i in temp_:
    #        i = i.strip().split()
    #        temp.append(i)
    #        width = int(i[2]) - int(i[1])
    #        temp[-1].extend([width])
    #    temp = genomics.sort_(temp, idx=4, reverse_=True)
    #    print temp[0:10]
    #    value = []
    #    for i in temp:
    #        value.append(i[4])
    #    elbow = find_elbow(value)
    #    print epi, elbow
    #    print
    #    for m in range(elbow):
    #        results.append([temp[m][0], temp[m][1], temp[m][2], temp[m][3]])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/H3K27me3_broad_domains_flat.txt')





    ### REMOVE ITEMS WITH A VALUE OF 0
    #temp = open('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/h3k27me3.bedgraph.bed', 'r')
    #results = []
    #for i in temp:
    #    i = i.strip().split()
    #    if int(i[3]) != 0:
    #        results.append(i)
    #genomics.write_file(results, '/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/h3k27me3.bedgraph.txt')

    ### CATEGORISE SIGNALS FROM 'H3K27ME3.BEDGRAPH.BED' 
    #results = aggregate_regions('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/h3k27me3.bedgraph.txt', step=5, threshold=4)
    #genomics.write_file(results, '/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/h3k27me3_hotspots_over50.txt')


    ### DOUBLE CHECKING DATA MATRIX (FANTOM 5)
    #genes = ['p1@NKX2-5','p1@TBX20']
    #exp = subset_table('/Users/woojunshim/Research/Data/FANTOM/hg19_cage_tag_table_new.txt', rows=genes, numerical=True)
    #genomics.write_table1(exp, '/Users/woojunshim/Research/Data/FANTOM/test.txt')


    ### RUN ANALYSIS ON FANTOM CARDIAC DATASETS
    ### EXECUTES A COMMAND LINE FROM WITHIN PYTHON
    #cols = genomics.read_file_items('/Users/woojunshim/Research/Data/FANTOM/cardiac/heart_samples.txt', col=0)
    #names = genomics.read_file_items('/Users/woojunshim/Research/Data/FANTOM/cardiac/heart_samples.txt', col=1)
    #genes = genomics.read_file_items('/Users/woojunshim/Research/Data/FANTOM/repressive_tendency_hg19_CAGE.txt', col=0)    
    #pathway = '/Users/woojunshim/Research/Data/FANTOM/cardiac/'
    #exp = subset_table('/Users/woojunshim/Research/Data/FANTOM/hg19_cage_tag_table_new.txt', rows=genes, cols=cols, numerical=True)
    #print 'finished reading'
    #for n in range(len(cols)):
    #    c = cols[n]
    #    name = names[n]
    #    input_ = {}
    #    for g in exp:
    #        if float(exp[g][c]) >= 0:
    #            input_[g] = float(exp[g][c])
    #    genomics.write_file(input_, 'temp.txt')
    #    os.system('python /Users/woojunshim/Research/Documents/manuscripts/H3K27me3/manuscript/script/discordance.py -i temp.txt -p 1 -l True -f 0 -s /Users/woojunshim/Research/Data/FANTOM/repressive_tendency_hg19_CAGE.txt -o '+pathway+name+'_.txt')

    ### IDENTIFY TOP 300 GENES BY DISCORDANCE SCORES
    #pathway = '/Users/woojunshim/Research/Data/FANTOM/cardiac/'
    #files_ = ['tpm_of_heart,_adult,_diseased_post-infarction,_donor1.CNhs11757.10050-101G5.txt','tpm_of_heart,_adult,_diseased,_donor1.CNhs11758.10051-101G6.txt','tpm_of_heart,_adult,_pool1.CNhs10621.10016-101C7.txt','tpm_of_heart,_fetal,_pool1.CNhs10653.10046-101G1.txt','tpm_of_left_atrium,_adult,_donor1.CNhs11790.10079-102A7.txt','tpm_of_left_ventricle,_adult,_donor1.CNhs11789.10078-102A6.txt']  
    #names = ['heart_post-infarction','heart_adult_diseased','heart_adult','heart_fetal','heart_left_atrium','heart_left_ventricle']
    #files = []
    #for i in files_:
    #    files.append(pathway+i)
    #results = create_overlap_table(files, names, threshold=300)
    #genomics.write_table1(results, pathway+'top_300_by_discordance.txt')

    ### EXTRACT A FEW LINES FROM hg19.cage_peak_phase1and2combined_tpm_ann.osc.txt
    #temp = open('/Users/woojunshim/Research/Data/FANTOM/hg19.cage_peak_phase1and2combined_tpm_ann.osc.txt', 'r')
    #results = []
    #cnt = 0
    #for i in temp:
    #    i = i.replace(' ', '_')
    #    i = i.strip().split()
    #    results.append([])
    #    for m in i:
    #        results[-1].extend([m])
    #    cnt += 1
    #    if cnt == 6000:
    #        break
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/FANTOM/test_.txt')


    ### CAGE PEAK LOCATIONS AND GENE MAPPING FILE
    #temp = open('/Users/woojunshim/Research/Data/FANTOM/hg19.cage_peak_phase1and2combined_tpm_ann.osc.txt', 'r')
    #results = []
    #for i in temp:
    #    i = i.replace(' ', '_')
    #    i = i.strip().split()
    #    if not i[0].startswith('#'):            
    #        results.append([i[0], i[1]])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/FANTOM/cage_to_tss_mapping.txt')





    ### CONVERT FANTOM5 CAGE-TAGS FILE (hg19.cage_peak_phase1and2combined_tpm_ann.osc.txt.gz) TO A TABLE 
    ### TOTAL 1,829 SAMPLES
    # EXTRACT CELL-TYPE DESCRIPTIONS
    #temp = open('/Users/woojunshim/Research/Data/FANTOM/hg19.cage_peak_phase1and2combined_tpm_ann.osc.txt', 'r')
    #anno = []
    #results = {}
    #cnt = 0    
    #cols = 1829
    #for i in temp:
    #    i = i.replace(' ','_')
    #    i = i.strip().split()
    #    if i[0].startswith('##ColumnVariables'):            
    #        name = i[0].split('=')[1]
    #        if name.startswith('tpm'):
    #            cnt += 1
    #            anno.append(['col_'+str(cnt), name])
        #elif i[0].startswith('chr'):
        #    g = i[1]
        #    results[g] = {}
        #    for j in range(1829):
        #        col = 'col_'+str(cols-j)
        #        results[g][col] = i[-j]
    #print 'writing files...'
    #genomics.write_file(anno, '/Users/woojunshim/Research/Data/FANTOM/hg19_cage_tag_anno.txt')
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/FANTOM/hg19_cage_tag_table.txt')

    ###     
    #ref_ = open('/Users/woojunshim/Research/Data/FANTOM/cage_to_tss_mapping.txt', 'r')
    #ref = {}
    #for i in ref_:
    #    i = i.strip().split()
    #    if i[0] not in ref:
    #        ref[i[0]] = i[1]
    #temp = open('/Users/woojunshim/Research/Data/FANTOM/hg19.cage_peak_phase1and2combined_tpm.osc.txt', 'r')
    #results = {}    
    #cnt = 1
    #for i in temp:
    #    i = i.replace(' ', '_')
    #    i = i.strip().split()        
    #    if i[0] in ref:
    #        cnt += 1            
    #        gene = ref[i[0]]
    #        results[gene] = {}
    #        for j in range(len(i)-1):
    #            results[gene]['col_'+str(j+1)] = round(float(i[j+1]), 6)  
    #    if cnt % 10000 == 0:
    #        print cnt-1
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/FANTOM/bb.txt')






    ### SUM H3K27ME3 SIGNALS (SCORES FOR FANTOM PEAKS) FROM PROCESSED BED FILE 
    ### DESINGED FOR CAGE PEAKS 
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/FANTOM/cage_hg19_tss_h3k27me3.txt')
    #results = {}
    #for i in temp:
    #    name = i[4]+'@'+i[5]
    #    width = int(i[2]) - int(i[1])
    #    if name not in results:
    #        results[name] = 0
    #    results[name] += int(i[9]) * width
    #for n in results:
    #    results[n] = float(results[n]) / (2000*111)  
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/FANTOM/repressive_tendency_hg19_CAGE.txt')


    ### CONVERT 'H3K27ME3_100bp_annotated.txt' TO A TABLE 
    #temp = open('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_100bp_annotated.txt', 'r')
    #results = {}
    #cnt = 0
    #for i in temp:
    #    i = i.strip().split()
    #    cnt += 1
    #    cells = set(i[3].split(';')[:-1])
    #    results[str(cnt)] = {}
    #    for c in epigenomes:
    #        if c in cells:
    #            results[str(cnt)][c] = 1
    #        else:
    #            results[str(cnt)][c] = 0
    #genomics.write_table1(results, '/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_100bp_table.txt')


    ### PRINT RANGES OF POSITIVES AND NEGATIVES 
    #temp = open('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_background_specificity_roadmap.txt', 'r')
    #c1, c2 = [1,0], [1,0]   
    #for i in temp:
    #    i = i.strip().split()
    #    if (float(i[0]) < c1[0]) and (float(i[0])!=float(0)):
    #        c1[0] = float(i[0])
    #    if float(i[0]) > c1[1]:
    #        c1[1] = float(i[0])
    #    if len(i) > 1:
    #        if float(i[1]) < c2[0] and (float(i[1])!=float(0)):
    #            c2[0] = float(i[1])
    #        if float(i[1]) > c2[1]:
    #            c2[1] = float(i[1])
    #print c1
    #print c2
    #[0.219237322646, 1.08131080016]  positives H3K27me3
    #[0.219237322646, 1.09164419208]  negatives H3K27me3

    ### HISTOGRAM FOR POSITIVE AND NEGATIVE (H3K27ME3) BACKGROUNDS
    #temp = open('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_background_specificity_roadmap.txt', 'r')
    #p1, p2 = [], []
    #for i in temp:
    #    i = i.strip().split()
    #    if float(i[0]!=float(0)):
    #        p1.append(float(i[0]))
        #if (len(i) > 1) and (float(i[1])!=float(0)):
        #    p2.append(float(i[1]))
    #histogram(p1)

    ### CREATE A FILE FOR CONTINUOUS EXPRESSION OF GENES (I.E. PROPORTIONS)
    #cols = get_colnames(exp_)
    #genes = get_rownames(exp_)
    #results = initiate_table(exp_)
    #for g in genes:
    #    total = 0
    #    for c in cols:
    #        total += float(exp_[g][c])
    #    if total != float(0):
    #        for c in cols:
    #            results[g][c] = exp_[g][c] / total
    #genomics.write_table1(results, '46epigenomes.RPKM.symbols.prop.txt')


    ### WHAT IS THE AVERAGE EXPECTED DISSIMILARITY?
    #temp = read_table1('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_broad_domains_dissimilarity.txt')
    #cells = get_colnames(temp)
    #total = len(cells) * len(cells)
    #sum_ = 0
    #for c1 in cells:
    #    for c2 in cells:
    #        sum_ += temp[c1][c2]
    #print 'Average expected dissimilarity =', float(sum_) / total
    # 0.379532695089 for H3K27me3 (for all)
    # 0.386169050703 for H3K27me3 (broad only)

    ### CALCULATE POSITIVE AND NEGATIVE BACKGROUNDS FOR 
    #pathway = '/home/uqwshim/data/'
    #results = calculate_dissimilarity_background(pathway+'H3K27me3_100bp_annotated.txt', pathway+'H3K27me3_dissimilarity_roadmap.txt', background_value=0.379532695089, col_idx=3, separator=';', calculate_negative=True)
    #genomics.write_file(results, pathway+'H3K27me3_background_specificity_roadmap.txt')

    ### CREATE FILE FOR NEGATIVE CELL-TYPES 
    ### THE ORDER FOLLOWS 'H3K27me3_100bp_annotated.txt'
    #pathway = '/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/'
    #results = find_complements('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_100bp_annotated.txt', col_idx=3, ref=epigenomes)
    #print len(results)
    #output = calculate_dissimilarity_background1(results, pathway+'H3K27me3_dissimilarity_roadmap.txt', background_value=0.379532695089, col_idx=0, separator=';', calculate_negative=False)
    #genomics.write_file(output, pathway+'H3K27me3_background_specificity_roadmap_negatives.txt')


    ### AVERAGE FPKM FOR SELECTED NEURONAL DATASETS    
    #pathway = '/Users/woojunshim/Research/application/neural/'
    #batch = [['ENCFF097JQF_ENCSR000AFJ_rep2.tsv','ENCFF011IOJ_ENCSR000AFJ_rep1.tsv'],['ENCFF724SSX_ENCSR000AFD_rep2.tsv','ENCFF927TYW_ENCSR000AFD_rep1.tsv'],['ENCFF652PQZ_ENCSR000AEY_rep2.tsv','ENCFF520PXU_ENCSR000AEY_rep1.tsv'],['ENCFF917ANZ_ENCSR000AEW_rep2.tsv','ENCFF817YTS_ENCSR000AEW_rep1.tsv'],['ENCFF571GOC_ENCSR244ISQ_rep2.tsv','ENCFF043UOR_ENCSR244ISQ_rep1.tsv']]
    #for l in range(len(batch)):
    #    batch[l][0] = pathway+batch[l][0]
    #    batch[l][1] = pathway+batch[l][1]
    #names = ['temporal_lobe','occipital_lobe','frontal_cortex','cerebellum','neural_progenitor_cells']
    #for i in range(len(batch)):
    #    b = batch[i]
    #    n = names[i]
    #    aa = average_tsv(b, value_idx=6)
    #    genomics.write_file(aa, pathway+n+'_ave_fpkm.txt')

    ### CONVERT IDS
    #ref = '/Users/woojunshim/Research/Data/Ensembl_gene_symbols_conversion_.txt'
    #for i in range(len(names)):
    #    results = []
    #    n = names[i]
    #    temp = genomics.read_file1(pathway+n+'_ave_fpkm.txt')
    #    aa = []
    #    for i in temp:
    #        aa.append([i[0]])
    #    bb = convert_id(aa, ref, 1, 2)
    #    for i in range(len(temp)):
    #        results.append([bb[i], temp[i][1]])
    #    genomics.write_file(results, pathway+n+'_ave_fpkm_.txt')

    ### CREATE SUMMARY STATISTICS FOR NEURAL DATASETS (DISCORDANCE SCORE)
    #top = 100
    #ref = {}
    #all_genes = set()
    #for i in range(len(names)):
    #    n = names[i]
    #    temp = genomics.read_file1(pathway+n+'_discordance.txt')
    #    ref[n] = set()
    #    for m in range(top):
    #        item = temp[m]
    #        g = item[0]
    #        ref[n].add(g)
    #        all_genes.add(g)
    #results = {}
    #for g in all_genes:
    #    results[g] = {}
    #    for n in names:
    #        if g in ref[n]:
    #            results[g][n] = 1
    #        else:
    #            results[g][n] = 0
    #genomics.write_table1(results, pathway+'top100_by_discordance.txt')

    ### CALCULATE CORRELATION BETWEEN CELL-TYPES USING 100 BP H3K27ME3 BINARY OUTCOMES
    #r = calculate_cell_type_correlation2('/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_100bp_annotated.txt', cells=epigenomes)
    #genomics.write_table1(r, '/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_similarity_roadmap.txt')
    #genomics.write_table1(p, '/Users/woojunshim/Research/cell-type-specificity/data/H3K27me3/H3K27me3_correlation_p_roadmap.txt')


    ### BIN BED FILES INTO 100 BP BINS ACROSS CELL-TYPES
    #epigenomes =['E001', 'E095', 'E083']
    #pathway = '/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/H3K27me3/'
    #files, names = [], []
    #for e in epigenomes:
    #    files.append(pathway+e+'-H3K27me3.broadPeak.short')
    #    names.append(e)
    #results = create_flat_bed(files, names)
    #genomics.write_file(results, pathway+'H3K27me3_100bp_annotated.txt')


    ### CREATE A SHORT BED FILES 
    #pathway = '/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/'
    #for e in epigenomes:
    #    results = []
    #    temp = open(pathway+e+'-H3K27me3.broadPeak', 'r')
    #    for i in temp:
    #        i = i.strip().split()
    #        results.append([])
    #        for m in range(3):
    #            results[-1].extend([i[m]])
    #        results[-1].extend([e])
    #    genomics.write_file(results, pathway+e+'-H3K27me3.broadPeak.short')

    ### CREATE A SINGLE TEXT FOR ROADMAP FILES & NAMES
    #result = ''
    #names = ''
    #for e in epigenomes:
    #    result += e+'-H3K27me3.broadPeak.short '
    #    names += e+' '
    #genomics.write_file_items([result], '/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/H3K27me3_files.txt')
    #genomics.write_file_items([names], '/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/H3K27me3_names.txt')

    ### ADD END COORDINATES FOR 100 BP BED FILE
    #temp = genomics.read_file1('/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/bedgraph/h3k27me3.bedgraph_100bp.txt')
    #for i in range(len(temp)):
    #    temp[i][1] = int(temp[i][1]) + 1
    #    temp[i].insert(2, int(temp[i][1])+99)
    #genomics.write_file(temp, '/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/bedgraph/h3k27me3.bedgraph_100bp.bed')




    ### CALCULATE DISCORDANCE SCORES USING OTHER HMS (ACROSS ROADMAP CELL-TYPES) AND PERFORM GO TERM ENRICHMENT (DNA BINDING GO:0003677)
    ### CREATES 2 TABLE FILES FOR P-VALUES (ONE FOR DISCORDANCE SCORE, ANOTHER FOR EXPRESSION VALUE) FOR EACH HM
    #cols = get_colnames(exp_)
    #hms = ['H3K27me3','H3K4me3','H3K4me1','H3K9me3','H3K36me3','H3K27ac']
    #positives = genomics.read_file_items('/Users/woojunshim/Research/Data/latency_tables/GO_0003677_genes.txt')    
    #positives = list(regulated_tf)
    #print len(regulated_tf)
    #for hm in hms:
    #    ref_ = open('/Users/woojunshim/Research/Data/latency_tables/'+hm+'_repressive_tendency_table.txt', 'r')
    #    ref = {}
    #    min_ = 1.0
    #    result1, result2 = [], []
    #    for i in ref_:
    #        i = i.strip().split()
    #        ref[i[0]] = float(i[1])
    #        if float(i[1]) < min_:
    #            min_ = float(i[1])
    #    for c in cols:
    #        disc, exp = [], []
    #        all_genes = []
    #        result1.append([c])
    #        result2.append([c])
    #        for g in exp_:
    #            if exp_[g][c] > 1:
    #                all_genes.append([g, exp_[g][c]])
    #        all_genes = genomics.sort_(all_genes, idx=1, reverse_=True)
    #        for i in all_genes:
    #            exp.append(i[0])
    #        disc_temp = []
    #        for g in exp:
    #            if g not in ref:
    #                factor = min_
    #            else:
    #                factor = ref[g]
    #            disc_temp.append([g, np.log10((exp_[g][c] + 1)) * factor])
    #        disc_temp = genomics.sort_(disc_temp, idx=1, reverse_=True)
    #        for i in disc_temp:
    #            disc.append(i[0])
    #        a = sliding_fet(input_list=disc, ref_list=positives, output_='p-value', convert_to_percentile=True, percentile_bin = 0.01)
    #        b = sliding_fet(input_list=exp, ref_list=positives, output_='p-value', convert_to_percentile=True, percentile_bin = 0.01)
    #        for i in a:
    #            result1[-1].extend([i])
    #        for i in b:
    #            result2[-1].extend([i])
    #    genomics.write_file(result1, '/Users/woojunshim/Research/Data/latency_tables/variably_expressed_tf/discordance_fet_'+hm+'.txt')
    #    genomics.write_file(result2, '/Users/woojunshim/Research/Data/latency_tables/variably_expressed_tf/expression_fet_'+hm+'.txt')



    ### LATENCY TABLE FOR OTHER HMS
    #hms = ['H3K27me3','H3K4me3','H3K4me1','H3K9me3','H3K36me3','H3K27ac']
    #no_assays = {}
    #no_assays['H3K27me3'], no_assays['H3K4me3'], no_assays['H3K4me1'], no_assays['H3K9me3'], no_assays['H3K36me3'], no_assays['H3K27ac'] = 111, 111, 111, 111, 111, 82
    #for hm in hms:   
    #    results = {}
    #    no_assay = 0
    #    for epi in epigenomes:     
    #        try:
    #            temp = genomics.read_file1('/Users/woojunshim/Research/Data/broadPeaks/'+hm+'/'+epi+'_'+hm+'_genes.txt', sort_by=2)
    #            values = []
    #            for i in temp:
    #                values.append(i[2])
    #            ep = find_elbow(values)
    #            for m in range(ep):
    #                g = temp[m][1]                    
    #                if g not in results:
    #                    results[g] = 0
    #                results[g] += 1                
    #        except:
    #            continue
    #    for g in results:
    #        results[g] = float(results[g]) / no_assays[hm]
    #    genomics.write_file(results, '/Users/woojunshim/Research/Data/latency_tables/'+hm+'_repressive_tendency_table.txt')

    ### CALCULATE EXPECTED BACKGROUND DISSIMILARITY FOR ROADMAP RPKM
    #ref_ = read_table1('/Users/woojunshim/Research/cell-type-specificity/data/spearman_dissimilarity_roadmap_rpkm.txt')
    #count = 0
    #cols = get_colnames(ref_)
    #sum_ = 0
    #for c1 in cols:
    #    for c2 in cols:
    #        if c1 == c2:
    #            continue
    #        else:
    #            sum_ += ref_[c1][c2]
    #            count += 1
    #print sum_ / count

    ### TEST FUNCTION FOR (OVERALL) CELL-TYPE SPECIFICITY = OBSERVED DISSIMILARITY / EXPECTED BACKGROUND DISSIMILARITY
    ### DISSIMILARITY = (1 - SPEARMAN'S RHO) / 2
    ### TISSUE-GROUP SPECIFIC EXAMPLE
    #cols = get_colnames(exp_)    
    #positives = ['E104','E105','E065','E095','E100']
    #result = calculate_overall_specificity(positives, '/Users/woojunshim/Research/cell-type-specificity/data/spearman_dissimilarity_roadmap_rpkm.txt', expected=0.12096884274)
    #print result
    
    ### RANDOM SELECTION OF 5 POSITIVES TO COMPARED WITH TISSUE-GROUP SPECIFIC EXAMPLE
    #n = 1000 
    #sum_ = 0
    #track = []
    #for i in range(n):
    #    positives = genomics.random_sample(cols, n_samples=5)
    #    result = calculate_overall_specificity(positives, '/Users/woojunshim/Research/cell-type-specificity/data/spearman_dissimilarity_roadmap_rpkm.txt', expected=0.12096884274)
    #    sum_ += result
    #    track.append(result)
    #print sum_ / n
    #genomics.write_file_items(track, '/Users/woojunshim/Research/cell-type-specificity/data/random_5_positives_iter_100.txt')




    ### SORT AND LIST ROADMAP CELL-TYPES BY TISSUE GROUPS (AS DEFINED BY ROADMAP PAPER)
    #cols = get_colnames(exp_)
    #results = []
    #for t in tissue_groups:
    #    ref = set(tissue_groups[t])
    #    for c in cols:
    #        if c in ref:
    #            results.append(c)
    #genomics.write_file_items(results, '/Users/woojunshim/Research/cell-type-specificity/data/roadmap_cell_type_order.txt')

    ### CALCULATE DISSIMILAIRTY (1-SPEARMAN'S RHO) CORRELATION BETWEEN COLUMNS OF ROADMAP RNA-SEQ
    #cols = get_colnames(exp_)
    #results = {}
    #for c1 in cols:
    #    list1 = []
    #    results[c1] = {}
    #    for g in exp_:
    #        list1.append([g, exp_[g][c1]])
    #    for c2 in cols:
    #        list2 = []
    #        for g in exp_:
    #            list2.append([g, exp_[g][c2]])
    #        r, p = cor_btw_lists(list1, list2, method_='spearman')
    #        results[c1][c2] = (1 - r) / 2
    #genomics.write_table1(results, '/Users/woojunshim/Research/cell-type-specificity/data/spearman_dissimilarity_roadmap.txt')

    ### TEST FOR CELL-TYPE DISIMILARITY MATRIX
    #matrix = read_table1('/Users/woojunshim/Research/cell-type-specificity/data/test_matrix.txt')
    #a = [1,1,1,0,0,0]
    #b = [1,0,1,0,1,0]
    #c = [1,1,1,1,1,1]
    #d = [0,0,0,1,0,0]
    #t = d
    #results = []
    #for i in range(len(t)):
    #    q = 0
    #    for j in range(len(t)):
    #        q1 = np.abs(t[i]-t[j])
    #        q += q1 * matrix[str(i+1)][str(j+1)]
    #    results.append(q)
    #print results
    #print np.sum(results)


    ### BINARY OUTCOME GENERATOR
    #results = generate_binary_bootstrapping(200, p=0.5)
    #print np.mean(results), np.std(results)


    ### BIN 'h3k27me3.bedgraph.bed' file into 100 bins
    #results = bin_bed_file('/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/bedgraph/h3k27ac.bedgraph.bed')
    #genomics.write_file(results, '/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/bedgraph/h3k27ac.bedgraph_100bp.bed')

    ### CALCULATE BIONOMIAL P-VALUES FOR EACH 1KB BIN AND BONFERRONI CORRECT 
    #temp = genomics.read_file1('/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/bedgraph/h3K27me3_merged_1kb_bin.bedgraph')
    #b_ = 1 - 0.008213
    #for i in range(len(temp)):
    #    item = temp[i]
    #    p_ = 0.008213**int(item[3]) * b_**(111-int(item[3])) 
    #    p__ = p_ * 92966704
    #    if p__ > 1:
    #        p__ = 1.0
    #    temp[i].extend([p_, p__])
    #genomics.write_file(temp, '/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/bedgraph/h3K27me3_merged_1kb_bin_p.txt')

    ### CALCULATE TOTAL GENOME SIZE
    ### hg19 = 3095677412 = 30956774.12 (per 100 bp)
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/hg19.chrom.sizes_short.txt')
    #total = 0
    #for i in temp:
    #    total += int(i[1])
    #print total

    ### CALCULATE EXPECTED H3K27ME3 COUNTS 
    ### H3K27ME3 DOMAINS = 683918122 (per 100 bp)
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/h3k27me3.bedgraph_100bp.txt')
    #bp = 0
    #for i in temp:
    #    bp += int(i[2])
    #print bp

    ### EXPECTED H3K27ME3 COUNTS (PER 100 BP) BY COLLATING ALL 111 CELL-TYPES = 0.1990 / 100 BP
    ### CALCULATE BINOMIAL P-VALUES 
    #total = 111
    #for i in range(112):
    #    value = (0.199**i) * ((1-0.199)**(total-i))
    #    print i, value




    ### SUM THE COUNTS (FROM 'h3k27me3_merged_1kb_bin.bedgraph')
    #total = 0
    #temp = genomics.read_file1('/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/bedgraph/h3k27me3_merged_1kb_bin.bedgraph')
    #for i in temp:
    #    total += int(i[3])
    #print total

    # WE HAVE 84760293 COUNTS 
    # HENCE, PROPORTION = 84760293 / (92966704 * 111) = 0.008213


    ### IDENTIFY THE HIGHEST COUNT FOR EACH 1KB BIN
    #temp_ = open('/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/bedgraph/h3k27me3_merged_1kb_sorted.bedgraph', 'r')
    #print 'read done'
    #results = []
    #chr_ = 'chr1'
    #current = 1
    #cnt = 0
    #for i in temp_:
    #    i = i.strip().split()
    #    if int(i[1]) == current:
    #        if cnt < int(i[3]):
    #            cnt = int(i[3])
    #    else:
    #        results.append([chr_, current, i[2], cnt])
    #        if chr_ != i[0]:
    #            print chr_
    #        chr_ = i[0]
    #        current = int(i[1])
    #        cnt = int(i[3])
    #genomics.write_file(results, '/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/bedgraph/h3k27me3_merged_1kb_bin.bedgraph')    


    ### CREATE BED FILE FOR 1KB BIN 
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/hg19.chrom.sizes_short.txt')
    #size = 1000
    #results = []
    #for i in temp:
    #    total = int(i[1])
    #    chr_ = i[0]
    #    current = 0
    #    while (current + size < total):
    #        results.append([chr_, current+1, current+size])
    #        current += size
    #    results.append([chr_, current+1, total])
    #genomics.write_file(results, '/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/hg19_1kb_bin.txt')

    ### CREATE A TABLE FOR H3K27ME3 NEW ASSIGNEMENT FILES
    #pathway = '/Users/woojunshim/Research/Data/new_assignment/annotated_broad/'
    #cols = get_colnames(broad_)
    #results = {}
    #for c in cols:
    #    temp = genomics.read_file1(pathway+c+'_H3K27me3_new_anno1.txt')
    #    for i in temp:
    #        g = i[4]
    #        v = i[3]
    #        if g not in results:
    #            results[g] = {}
    #            for c1 in cols:
    #                results[g][c1] = 0
    #        results[g][c] = v
    #genomics.write_table1(results, pathway+'H3K27me3_new_assignment_table.txt')


    ### CREATE FANTOM5 TSS BED FILES
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/FANTOM/hg19.cage_peak.txt')
    #results = []
    #for i in temp:
    #    if i[3] == '+':
    #        start_ = int(i[1]) - 1000
    #        end_ = int(i[1]) + 1000
    #    else:
    #        start_ = int(i[2]) - 1000
    #        end_ = int(i[2]) + 1000
    #    if start_ < 1:
    #        start_ = 1
    #    results.append([i[0], start_, end_, i[3], i[4], i[5]])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/FANTOM/hg19.tss_upstream1000_downstream1000.txt')

    ### PROCESS FANTOM5 TSS FILES 
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/FANTOM/mm9.cage_peak_phase1and2combined_ann.txt')
    #results = []
    #for i in temp:
    #    if ('chr' in i[0]) and (i[0] not in i[1]):
    #        a = i[0].split(':')
    #        chr_ = a[0]
    #        b = a[1].split('..')
    #        start_ = b[0]
    #        end_ = b[1][:-2]
    #        strand_ = b[1][-1]
    #        c = i[1].split('@')
    #        p_ = c[0]
    #        gene_ = c[1]
    #        results.append([chr_, start_, end_, strand_, p_, gene_])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/FANTOM/mm9.cage_peak.txt')



    ### JACCARD INDEX BETWEEN TOP 5% H3K4ME3 AND H3K27ME3-POSITIVE GENES
    #k4 = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K4me3_widths_z.txt')
    #k27 = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_widths_z.txt')
    #k27_positive = set(genomics.read_file_items('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_broad_genes.txt'))
    #results = []
    #cols = get_colnames(exp_)
    #for c in cols:
    #    expressed = set()
    #    expressed_full = []
    #    for g in exp_:
    #        if exp_[g][c] > 1:
    #            expressed.add(g)
    #            expressed_full.append([g, exp_[g][c]])
    #    thre = int(len(expressed) * 0.05)
    #    expressed_full = genomics.sort_(expressed_full, idx=1, reverse_=True)
    #    k4_, k27_ = [], []        
    #    for g in expressed:
    #        if g not in k4:
    #            width = 1
    #        else:
    #            width = k4[g][c]
    #        k4_.append([g, width])
    #    k4_ = genomics.sort_(k4_, idx=1, reverse_=True)
    #    k4_ = k4_[:thre]        
    #    k27_ = expressed_full[:thre]
    #    a,b = [], []
    #    for i in k4_:
    #        a.append(i[0])
    #    for i in k27_:
    #        b.append(i[0])
    #    pp = jaccard_index(a,b)
    #    results.append([c, pp])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/H3K4me3_H3K27me3-positive_jaccard.txt')

     

    ### CALCULATE CORRELATION BETWEEN H3K4ME3 AND H3K27ME3 WIDTHS
    #results = calculate_correlation('/Users/woojunshim/Research/Data/broadPeaks/H3K4me3_widths_z.txt', '/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_widths_z.txt')
    #new = []
    #all_ = set(all_)
    #for i in range(len(results)):
    #    g = results[i][0]
    #    if g in all_:
    #        if g in regulated_tf:
    #            tag = 1
    #        elif g in regulated_nontf:
    #            tag = 2
    #        elif g in stable_tf:
    #            tag = 3
    #        elif g in stable_nontf:
    #            tag = 4
    #        new.append([g, results[i][1], results[i][2], tag])
    #genomics.write_file(new, '/Users/woojunshim/Research/Data/H3K4me3_H3K27me3_spearman.txt')

    ### CALCULATE LONGEST TRANSCRIPTS FOR MM10 
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/hg19_TSS_.txt')
    #results = {}
    #for i in temp:
    #    if i[5] not in results:
    #        results[i[5]] = 0
    #    width = int(i[4]) - int(i[3])
    #    if width > results[i[5]]:
    #        results[i[5]] = width
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/hg19_longest_TSS.txt')

    ### COUNT BROAD DOMAINS (HG19 AND MM10)
    #broad_ = read_table1('/Users/woojunshim/Research/Data/mm10/h3k27me3/genes_broad_h3k27me3_binary_mm10.txt')
    #broad = {}
    #cols = get_colnames(broad_)
    #for g in broad_:
    #    if g not in broad:
    #        broad[g] = 0
    #    for c in cols:
    #        broad[g] += int(broad_[g][c])
    #genomics.write_file(broad, '/Users/woojunshim/Research/Data/mm10_broad_count.txt')

    ### CORRELATIOB BETWEEN LENGTH OF GENE BODY AND THE NUMBER OF BROAD H3K27ME3 DOMAINS
    #temp1 = genomics.read_file1('/Users/woojunshim/Research/Data/mm10_broad_count.txt', sort_by=1)
    #temp = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_widths.txt')
    #cols = get_colnames(temp)
    #temp1 = []
    #for g in temp:
    #    temp1.append([g])
    #    sum_ = 0
    #    for c in cols:
    #        sum_ += int(temp[g][c])
    #    temp1[-1].extend([sum_/len(cols)])
    #temp2 = genomics.read_file1('/Users/woojunshim/Research/Data/mm10_TSS_length.txt', sort_by=1)
    #ref = {}
    #for i in temp2:
    #    ref[i[0]] = int(i[1])
    #count, width = [], []
    #for i in temp1:
    #    g = i[0]
    #    if g in ref:
    #        count.append(i[1])
    #        width.append(ref[g])
    #print len(count), len(width)
    #s, p =stat.spearman(count, width)
    #print s, p

    ### FET FOR TOP 5% GENES BY TSS LENGTH (FOR 4 GENE GROUPS)
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/mm10_TSS_length.txt', sort_by=1)
    #a,b,c,d = 0,0,0,0
    #thre = len(temp) * 0.05
    #for i in range(len(temp)):
    #    g = temp[i][0]
    #    if g in tf_list:
    #        if i < thre:
    #            a += 1
    #        else:
    #            b += 1
    #    else:
    #        if i < thre:
    #            c += 1
    #        else:
    #            d += 1
    #s, p = stat.fisher(a,b,c,d)
    #print s, p

    ### COMPARE SIZE OF GENES AND TSS SIZE (BETWEEN TF AND NON-TF)
    #temp = read_table1('/Users/woojunshim/Research/Data/mm10/h3k27me3/genes_broad_h3k27me3_binary_mm10.txt')
    #length = genomics.read_file1('/Users/woojunshim/Research/Data/mm10_TSS_length.txt')
    #leng = {}
    #for i in length:
    #    leng[i[0]] = int(i[1])
    #genes = get_rownames(temp)
    #a = []
    #b = []
    #for g in genes:
    #    if g in leng:
    #        if g in tf_list:
    #            a.append(leng[g])
    #        else:
    #            b.append(leng[g])
    #s, p = stat.mann(a,b,alternative_='two-sided')
    #print s,p


    ### DATA ANALYSIS FOR GO TERMS (ENAKSHI)
    ### EXTRACT ALL GO TERMS 
    #days = [2,5,15,30]    
    #days = [1]
    #pathway = '/Users/woojunshim/Research/Data/Clayton/GO/'
    #pathway = '/Users/woojunshim/Research/Data/competition/'

    #results = {}
    #for d in days:
    #    temp = genomics.read_file1(pathway+'competition_go.txt')
    #    for m in temp:
    #        u = m[0].split('~')            
    #        if u[0] not in results:
    #            results[u[0]] = [u[1]]
    ##        results[u[0]][-1].extend([d])
    #results_ = dic_to_list(results, list_=True)    
    #genomics.write_file(results_, pathway+'go_list_combined.txt')

    ### GET ALL GENES EACH GO TERMS
    #import godata
    #import webservice   
    #texon = 9606
    #texon = 10090
    #temp = genomics.read_file1(pathway+'go_list_combined.txt')
    #terms = []
    #results = {}
    #for t in temp:
    #    terms.append(t[0])
    #    results[t[0]] = []
    #terms = ['GO:0030017','GO:0007507']
    #terms = ['GO:0007507']
    #terms = ['GO:0007420','GO:0061061']
    #terms = ['GO:0030217','GO:0006955']
    #go = godata.GO('gene_association_goa_ref_human', 'go-basic.obo')
    #results = []
    #go = godata.GO('gene_association.mgi', 'go-basic.obo')
    #for t in terms:
    #    print t
    #    results = []
    #    t_ = go.getGenes(terms_or_term=t, evid = None, taxa = texon, rel = None, include_more_specific = True)
    #    for m in t_:
        #    results[t].append(m)    
    #        results.append(m)
    #    genomics.write_file_items(results, '/Users/woojunshim/Research/Data/new_assigned/'+t+'_genes.txt')
    #ll = []
    #all_ = set()
    #for i in results:
    #    ll.append([i])
    #    for a in results[i]:
    #        if a not in all_:
    #            all_.add(a)
    #        ll[-1].extend([a])
    #genomics.write_file(ll, pathway+'GO_genes_.txt')
    #all_ = list(all_)
    #genomics.write_file_items(all_, pathway+'all_genes_.txt')

    ### MOUSE SPECIFIC CONVERSION TABLE
    #a = genomics.read_file(pathway+'uniprot-yourlist.txt', [1], rowname='0')
    #b = genomics.read_file(pathway+'mapping_table_.txt', [1], rowname='0')
    #results = []
    #for g in a:
    #    if a[g][0][0] in b:
    #        results.append([g, b[a[g][0][0]][0][0]])
    #genomics.write_file(results, pathway+'mapping_table1.txt')


    ### MAPPING IDS FOR GENES
    #ref_ = genomics.read_file(pathway+'mapping_table1.txt', [1], rowname='0')
    #go_ = genomics.read_file1(pathway+'GO_genes_.txt')
    #results = []
    #for i in go_:
    #    results.append([i[0]])
    #    for m in i[1:]:
    #        if m in ref_:
    #            results[-1].extend([ref_[m][0][0]])
    #genomics.write_file(results, pathway+'GO_genes.txt')

    ### RUN FET FOR EACH GO TERM
    ### FIRST FOR DISCORDANCE AND EXP (NEW)
    #pathway_ = '/Users/woojunshim/Research/Data/Clayton/genes/old/'
    #ref_ = {}
    #temp = genomics.read_file1(pathway+'GO_genes.txt')
    #for i in temp:
    #    ref_[i[0]] = set()
    #    for m in i[1:]:
    #        ref_[i[0]].add(m)  
    #days = ['d2','d5','d15','d30']
    #days = [1]
    #clus = {}
    #old = {}
    #clus['d0'] = ['c1','c2','c3']
    #clus['d2'] = ['c1','c2','c3']
    #clus['d5'] = ['c1','c2','c3'] 
    #clus['d15'] = ['c1','c2']
    #clus['d30'] = ['c1','c2']
    #old['d0'] = ['c1','c2','c3','c4']
    #old['d2'] = ['c1','c2','c3']
    #old['d5'] = ['c1','c2','c3','c4'] 
    #old['d15'] = ['c1','c2']
    #old['d30'] = ['c1','c2']
    #comp = ['LT-HSC_exp','LT-HSC_discord']
    #for d in days:        
    #    temp = genomics.read_file_items(pathway+d+'_go.txt')
    #    temp = genomics.read_file_items(pathway+'competition_go.txt')
    #    to_do = []
    #    for i in temp:
    #        aa = i.split('~')
    #        to_do.append(aa[0])
    #    print len(to_do)
    #    for c in comp:
    #        print c
    #        results = {}
    #        for t in to_do:
    #            results[t] = {}
    #            for i in range(100):
    #                results[t][str(i)] = 1.0
    #            positives = list(ref_[t])                
    #            temp = genomics.read_file1(pathway+c+'.txt', sort_by=2) 
    #            print temp[0:10]               
    #            genes = []
    #            for i in temp[2:]:
    #            for i in temp:
    #                genes.append(i[0])
    #            rr = sliding_fet(input_list=genes, ref_list=positives, output_='p-value', convert_to_percentile=True, percentile_bin = 0.01)
    #            r = stat.corrected_p(rr)
    #            for i in range(100):
    #                results[t][str(i)] = r[i]
            #print results 
    #        print
    #        genomics.write_table1(results, pathway+c+'_fet_fdr_by_discordance.txt')

      

            


    ### GET GENES FOR GO TERMS
    #import godata
    #import webservice
    #term = 'GO:0007507'    
    #texon = 9606
    #texon = 10090
    #pathway = '/Users/woojunshim/Research/Data/NCC/'    
    #pathway = '/Users/woojunshim/Research/Data/Pax6/'
    #pathway = '/Users/woojunshim/Research/Data/Palpant/'
    #go = godata.GO('gene_association_goa_ref_human', 'go-basic.obo')
    #go = godata.GO('gene_association.mgi', 'go-basic.obo')
    #t_ = go.getGenes(terms_or_term=term, evid = None, taxa = texon, rel = None, include_more_specific = True)
    #results = []
    #for item in t_:
    #    results.append(item)
    #genomics.write_file_items(results, pathway+'GO.'+term[3:]+'_genes_'+str(texon)+'.txt')   

    ### ANNOTATE WHETHER DOMAINS ARE BROAD OR NOT 
    #pathway = '/Users/woojunshim/Research/Data/new_assignment/'
    #for e in epigenomes:
    #    temp = genomics.read_file1(pathway+e+'_H3K27me3_new.txt', sort_by = 3)
    #    values = []
    #    for i in temp:
    #        values.append(i[3])
    #    elbow = find_elbow(values)
    #    for n in range(len(temp)):
    #        if n < elbow:
    #            temp[n].extend([1])
    #        else:
    #            temp[n].extend([0])
    #    genomics.write_file(temp, pathway+'annotated_broad/'+e+'_H3K27me3_new_anno1.txt')

    ### CREATE A REPRESSIVE TENDENCY TABLE FOR NEW ASSIGNMENT FILES
    #pathway = '/Users/woojunshim/Research/Data/new_assignment/annotated_broad/'
    #results = {}
    #for e in epigenomes:
    #    temp = genomics.read_file1(pathway+e+'_H3K27me3_new_anno1.txt')
    #    for i in temp:
    #        if i[4] not in results:
    #            results[i[4]] = 0            
    #        if i[5] == '1':
    #            results[i[4]] += 1
    #output_ = []
    #for g in results:
    #    output_.append([g, float(results[g]) / len(epigenomes)])
    #output_ = genomics.sort_(output_, idx=1, reverse_=True)
    #genomics.write_file(output_, pathway+'repressive_tendency.txt')

    ### CREATE A LONGEST TSS PLUS 2.5KB DOWNSTREAM 
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/hg19_longest_TSS_plus2500.txt')
    #results = []
    #for i in temp:
    #    results.append([i[1], i[2], i[3], i[0]])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/hg19_longest_TSS_plus2500_.txt')

    ### NOW IDENTIFY THE LONGEST DOMAIN FOR EACH GENE ACROSS CELL-TYPES
    #cols = get_colnames(broad_)
    #temp = open('/Users/woojunshim/Research/Data/new_assignment/H3K27me3_centres_tss_overlap.bed', 'r')
    #ref_ = {}
    #for i in temp:
    #    i = i.strip().split()
    #    if i[4] not in ref_:
    #        ref_[i[4]] = {}
    #    g = i[5]
    #    w = int(i[3])
    #    if g not in ref_[i[4]]:
    #        ref_[i[4]][g] = [0, 0, 0, 0, 0]
    #    if w > int(ref_[i[4]][g][3]) :
    #        ref_[i[4]][g] = [i[0], i[1], i[2], w, g]
    #for c in cols:
    #    results = []
    #    for m in ref_[c]:
    #        results.append([ref_[c][m][0], ref_[c][m][1], ref_[c][m][2], ref_[c][m][3], ref_[c][m][4]])
    #    genomics.write_file(results, '/Users/woojunshim/Research/Data/new_assignment/'+c+'_H3K27me3_new.txt')


    ### CREATE A FLAT BED FILE FOR H3K27ME3 DOMAINS (WITH CENTRE POSITION)
    #pathway = '/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/'
    #cols = get_colnames(broad_)
    #print len(cols)
    #results = []
    #cnt = 0
    #for c in cols:
    #    cnt += 1
    #    print cnt
    #    temp = genomics.read_file1(pathway+c+'-H3K27me3.broadPeak')
    #    for i in temp:
    #        width_ = int(i[2]) - int(i[1])
    #        centre_ = (int(i[1]) + int(i[2])) / 2
    #        results.append([i[0], centre_, centre_+1, width_, c])
    #genomics.write_file(results, pathway+'H3K27me3-centres_merged.bed')


    ### COMBINE H3K27ME3 WIDTHS (WHETHER BROAD OR NON-BROAD)
    #cols = get_colnames(exp_)
    #results = []
    #for c in cols:
    #    temp = genomics.read_file1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/'+c+'_H3K27me3_genes.txt')
    #    for i in temp:
    #        results.append([i[3], i[4], i[5], i[1]])
    #genomics.write_file(results, '/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/bedgraph/h3k27me3_broadest_only.bed')

    ### DISTRIBUTION OF BROAD PEAK COUNTS FOR TF 
    #tf_list = set(tf_list)
    #temp = read_table1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_binary.txt')
    #results = {}
    #total= 0
    #for g in temp:
    #    if g in tf_list:
    #        cnt = 0
    #        total += 1
    #        for c in temp[g]:
    #            cnt += temp[g][c]
    #        if str(int(cnt)) not in results:
    #            results[str(int(cnt))] = 0
            
    #        results[str(int(cnt))] += 1         
    #for m in results:
    #    results[m] = float(results[m]) / total  

    #genomics.write_file(results, '/Users/woojunshim/Research/Data/TF_dist.txt')



    ### DENSITY OF GENES FOR BROAD-TSS COUNTS 
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/genes_broad_tss_stats.txt')
    #total = {}
    #counts = {}
    #tf_list = set(tf_list)
    #for i in temp:
    #    if int(i[1]) not in total:
    #        total[int(i[1])] = 0
    #    if int(i[1]) not in counts:
    #        counts[int(i[1])] = {}
    #        counts[int(i[1])]['TF'] = 0
    #        counts[int(i[1])]['non_TF'] = 0
    #    total[int(i[1])] += 1
    #    if i[0] in tf_list:
    #        counts[int(i[1])]['TF'] += 1
    #    else:
    #        counts[int(i[1])]['non_TF'] += 1
    #for i in counts:
    #    counts[i]['TF'] = counts[i]['TF'] / total[i]
    #    counts[i]['non_TF'] = counts[i]['non_TF'] / total[i]
    #genomics.write_table1(counts, '/Users/woojunshim/Research/Data/density_broad_counts.txt')



    ### PUTTING A TAB BEFORE GENE NAMES
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/all_h3k27me3_tss_up1000_values_gene.txt')
    #results = []
    #cnt = 0
    #for i in temp:
    #    results.append([cnt+1, i[0], i[1]])
    #    cnt += 1
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/all_h3k27me3_tss_up1000_values_gene_tab.txt')


    ### SUM H3K27ME3 COVERAGE VALUES FOR TSS + 1KB REGIONS FOR GENES
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/h3k27me3_tss_up1000_down100_values.txt')
    #results = {}
    #for i in temp:
    #    if i[3] not in results:
    #        results[i[3]] = 0
    #    value = (int(i[2]) - int(i[1])) * int(i[4])
    #    results[i[3]] += value
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/h3k27me3_tss_up1000_down100_values_gene.txt')


    ### CREATE Z-SCORE TABLES FOR LOG-CONVERTED RNA-SEQ AND H3K27ME3 WIDTHS
    #wid_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K4me3_widths.txt')
    #cols = get_colnames(exp_)
    #new1, new2 = initiate_table(wid_), initiate_table(exp_)
    #for c in cols:
    #    t1, t2 = [], []
    #    for g in wid_:
        #    wid_[g][c] = np.log10(wid_[g][c]+1)
    #        t1.append(wid_[g][c])
    #    mean_ = np.mean(t1)
    #    sd_ = np.std(t1)
    #    for g in wid_:
    #        new1[g][c] = round((wid_[g][c] - mean_) / sd_, 5)

    #    for g in exp_:
        #    exp_[g][c] = np.log10(exp_[g][c]+1)
    #        t2.append(exp_[g][c])
    #    mean_ = np.mean(t2)
    #    sd_ = np.std(t2)
    #    for g in exp_:
    #        new2[g][c] = round((exp_[g][c] - mean_) / sd_, 5)
    #genomics.write_table1(new1, '/Users/woojunshim/Research/Data/broadPeaks/H3K4me3_widths_z.txt')
    #genomics.write_table1(new2, '/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols_z.txt')




    ### NEW MELANOMA DATASETS
    #pathway = '/Users/woojunshim/Research/melanoma/Data/'
    #tfs = ['BRN2_KD','BRN2_OE','MITF_KD','MITF_OE','NFIB_KD','NFIB_OE']
    #for tf in tfs:
    #    results = {}
    #    ref_ = '/Users/woojunshim/Research/Data/genes_broad_h3k27me3_tss_stats_hg19_new.txt'
    #    results1 = product_analysis1(pathway+tf+'.txt', exp_col='sample_exp', ref_file=ref_, ref_col=2, pseudo_=None, header=False, exp_filter=0.0, fill_missing=True, log_conversion=True)
    #    results2 = product_analysis1(pathway+tf+'.txt', exp_col='control_exp', ref_file=ref_, ref_col=2, pseudo_=None, header=False, exp_filter=0.0, fill_missing=True, log_conversion=True)
    #    for i in results1:
    #        g = i[0]
    #        if g not in results:
    #            results[g] = {}
    #            results[g]['sample'] = i[1]
    #    for i in results2:
    #        g = i[0]
    #        results[g]['control'] = i[1]
    #    for i in results:
    #        results[i]['diff.'] = results[i]['sample'] - results[i]['control']
    #    genomics.write_table1(results, pathway+tf+'_result_log.txt')


    ### COLLECT BROAD DOMAINS AND CREATE A BED FILE (HUMAN)
    #thre = read_table1('/Users/woojunshim/Research/Data/broadPeaks/elbow_points.txt')
    #tss = genomics.read_file('/Users/woojunshim/Research/bigdata/roadmap/broad_peaks/bedgraph/overlap_h3k27me3_tss_hg19_all_info_uniq.txt', [3], rowname='5')
    #results = [['#chr','start','end','associated_gene','cell_type','overlap_TSS']]
    #cnt, total = 0, 0
    #for e in epigenomes:
    #    temp = genomics.read_file1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/'+e+'_H3K27me3_genes.txt')
    #    cutoff = int(thre[e]['H3K27me3'])
    #    ref_ = tss[e]
    #    ref = set()
    #    for i in ref_:
    #        ref.add(i[0])        
    #    cnt += cutoff
    #    total += len(temp)
    #    for n in range(cutoff):
    #        i = temp[n]
    #        if i[1] in ref:
    #            tag = 'Y'
    #        else:
    #            tag = 'N'
    #        results.append([i[3], i[4], i[5], i[1], e, tag])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/collected_peaks_summary_hg19.txt')

    ### CREATE A FLAT FILE FOR BROAD DOMAINS (MM10)


    ### COLLECT BROAD DOMAINS AND CREATE A BED FILE (MM10)
    #cells = genomics.read_file_items('/Users/woojunshim/Research/Data/mm10/h3k27me3/selected_metadata.txt', col=0)
    #peaks = genomics.read_file('/Users/woojunshim/Research/Data/mm10/h3k27me3/overlap_centre_h3k27me3_1.5kb_tss_mm10_uniq_.txt', [3, 5], rowname='4')
    #broad = read_table1('/Users/woojunshim/Research/Data/mm10/h3k27me3/genes_broad_h3k27me3_binary_mm10.txt')
    #results = [['#chr','start','end', 'centre', 'associated_gene','cell_type','centre_within_1.5kb_TSS']]
    #for c in cells:
    #    temp = genomics.read_file('/Users/woojunshim/Research/Data/mm10/h3k27me3/genes/'+c+'_genes.txt', [3,4,5], rowname='1')
    #    genes = []
    #    for g in broad:
    #        if broad[g][c] == float(1):
    #            genes.append(g)
    #    genes = set(genes)
    #    tss = []
    #    for i in peaks[c]:
    #        tss.append(i[0])
    #    tss = set(tss)
    #    for i in genes:            
    #        chr_ = temp[i][0][0]
    #        start_ = temp[i][0][1]
    #        end_ = temp[i][0][2]
    #        centre_ = (int(start_) + int(end_)) / 2
    #        if i in tss:
    #            tag = 'Y'
    #        else:
    #            tag = 'N'
    #        results.append([chr_, start_, end_, centre_, i, c, tag])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/collected_peaks_summary_mm10.txt')

    ### FIND TISSUE-TYPE SPECFIC TERMS    
    #results = []    
    #files = ['Heart_-_Atrial_Appendage','Brain_-_Cerebellum','Skin_-_Sun_Exposed_(Lower_leg)']
    #cnt = {}
    #overlap = {}
    #for f in files:
    #    temp = genomics.read_file1('/Users/woojunshim/Research/Data/GTEX/results_new/GO/'+f+'_BP_product.txt')
    #    for i in temp:
    #        if i[2] != 'NA':
    #            if i[2] not in cnt:
    #                cnt[i[2]] = 0
    #            cnt[i[2]] += 1     
    #for f in files:
    #    temp = genomics.read_file1('/Users/woojunshim/Research/Data/GTEX/results_new/GO/'+f+'_BP_tpm.txt')
    #    for i in temp:
    #        if i[2] != 'NA':
    #            if i[2] not in overlap:
    #                overlap[i[2]] = 0
    #            overlap[i[2]] += 1    
    #for f in files:
    #    t1 = genomics.read_file1('/Users/woojunshim/Research/Data/GTEX/results_new/GO/'+f+'_BP_product.txt')        
    #    for i in t1:  
    #        if i[2] != 'NA':   
    #            if i[2] not in overlap:
    #                if cnt[i[2]] ==1:                     
    #                    results.append(i[2])
    #            else:
    #                if (overlap[i[2]] == 1) and (cnt[i[2]] == 1):
    #                    results.append(i[2]) 
    #genomics.write_file_items(results, '/Users/woojunshim/Research/Data/GTEX/results_new/GO/specific_terms_left_ventricle_cerebellum_sun_exposed.txt')

    ### CREATE A TABLE FOR GO TERMS
    #files = ['Heart_-_Atrial_Appendage','Brain_-_Cerebellum','Skin_-_Sun_Exposed_(Lower_leg)']
    #ref_ = set(genomics.read_file_items('/Users/woojunshim/Research/Data/GTEX/results_new/GO/specific_terms_left_ventricle_cerebellum_sun_exposed.txt'))
    #for f in files:
    #    product = genomics.read_file('/Users/woojunshim/Research/Data/GTEX/results_new/GO/'+f+'_BP_product.txt', [3], rowname='2')
    #    tpm = genomics.read_file('/Users/woojunshim/Research/Data/GTEX/results_new/GO/'+f+'_BP_tpm.txt', [3], rowname='2')
    #    results = {}
    #    for i in product:
    #        if i != 'NA':
    #            if (i not in results) and (i in ref_):
    #                results[i] = {} 
    #                results[i]['Discordant_score'] = product[i][0][0]            
    #                if i not in tpm:
    #                    value = 1.0
    #                else:
    #                    value = tpm[i][0][0]
    #                results[i]['TPM'] = value
    #    genomics.write_table1(results, '/Users/woojunshim/Research/Data/GTEX/results_new/GO/'+f+'_combined.txt')


    ### CREATE A TABLE FOR GO TERMS (GTEX)
    #t = 'Heart_-_Left_Ventricle'
    #product = genomics.read_file('/Users/woojunshim/Research/Data/GTEX/results_new/GO/'+t+'_BP_product.txt', [3], rowname='2')
    #tpm = genomics.read_file('/Users/woojunshim/Research/Data/GTEX/results_new/GO/'+t+'_BP_tpm.txt', [3], rowname='2')
    #results = {}
    #for i in product:
    #    if i != 'NA':
    #        if i not in results:
    #            results[i] = {} 
    #            results[i]['Discordant_score'] = product[i][0][0]            
    #        if i not in tpm:
    #            value = 1.0
    #        else:
    #            value = tpm[i][0][0]
    #        results[i]['TPM'] = value
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/GTEX/results_new/GO/'+t+'_combined.txt')

    

    ### COLLECT ENTROPY SCORES FOR 100 GENES (GTEX) AND CREATE A TABLE
    #groups = genomics.read_file_items('/Users/woojunshim/Research/Data/GTEX/GTEX_48_tissue_groups.txt')
    #results = []
    #top = 100
    #ref_ = genomics.read_file('/Users/woojunshim/Research/Data/GTEX/results_new/entropy_tpm.txt', [1], rowname='0')    
    #for g in groups:
    #    temp = genomics.read_file1('/Users/woojunshim/Research/Data/GTEX/results_new/'+g+'_rank_100_counts_tpm.txt', sort_by=1)
    #    results.append([g])
    #    for i in temp[:top]:            
    #        results[-1].extend([ref_[i[0]][0][0]])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/GTEX/results_new/entropy_scores_tpm.txt')

    ### CALCULATE ENTROPY FOR GTEX
    #results = calculate_entropy_table('/Users/woojunshim/Research/Data/GTEX/results_new/normalised_counts_tpm_per100.txt')
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/GTEX/results_new/entropy_tpm.txt')


    ### NORMALISE COUNTS (GTEX)
    #groups = genomics.read_file_items('/Users/woojunshim/Research/Data/GTEX/GTEX_48_tissue_groups.txt')
    #samples = genomics.read_file('/Users/woojunshim/Research/Data/GTEX/GTEX_sample_numbers.txt', [1], rowname='0')    
    #results = {}
    #for g in groups:
    #    temp = genomics.read_file1('/Users/woojunshim/Research/Data/GTEX/results_new/'+g+'_rank_100_counts_tpm.txt')
    #    for i in range(len(temp)):
    #        temp[i][1] = float(temp[i][1]) * int(samples[g][0][0])
    #    new = normalise_counts(temp, int(samples[g][0][0]), 100)
    #    for m in new:
    #        if m[1] != float(0):
    #            if m[0] not in results:
    #                results[m[0]] = {}
    #                for c in groups:
    #                    results[m[0]][c] = 0
    #            results[m[0]][g] = m[1] 
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/GTEX/results_new/normalised_counts_tpm_per100.txt')


    ### EXPRESSION PROPORTION FIGURE 7A (BROAD VS NON-BROAD)
    #cols = get_colnames(exp_)    
    #temp = genomics.read_file('/Users/woojunshim/Research/bigdata/roadmap/broad_peaks/bedgraph/h3k27me3_flat_.txt', [3, 4], rowname='5')
    #results_b, results_n = [], []
    #for c in cols:        
    #    totals_b = [0,0,0,0]  # count number of genes with broad/non-broad domains that are expressed
    #    totals_n = [0,0,0,0]
    #    genes_with_domains = {}        
    #    for i in temp[c]:
    #        if i[0] in exp_:
    #            genes_with_domains[i[0]] = i[1]
    #            if i[1] == '1':  # broad domain
    #                if i[0] in regulated_tf:
    #                    totals_b[0] += 1
    #                elif i[0] in regulated_nontf:
    #                    totals_b[1] += 1
    #                elif i[0] in stable_tf:
    #                    totals_b[2] += 1
    #                elif i[0] in stable_nontf:
    #                    totals_b[3] += 1            
    #            elif i[1] == '0':  # non-broad domain
    #                if i[0] in regulated_tf:
    #                    totals_n[0] += 1
    #                elif i[0] in regulated_nontf:
    #                    totals_n[1] += 1
    #                elif i[0] in stable_tf:
    #                    totals_n[2] += 1
    #                elif i[0] in stable_nontf:
    #                    totals_n[3] += 1
    #    expressed_b = [0,0,0,0]
    #    expressed_n = [0,0,0,0]
    #    print totals_b, totals_n        
    #    for g in genes_with_domains:
    #        if exp_[g][c] > 1:                
    #            if genes_with_domains[g] == '1':
    #                if g in regulated_tf:
    #                    expressed_b[0] += 1
    #                elif g in regulated_nontf:
    #                    expressed_b[1] += 1
    #                elif g in stable_tf:
    #                    expressed_b[2] += 1
    #                elif g in stable_nontf:
    #                    expressed_b[3] += 1
    #            elif genes_with_domains[g] == '0':
    #                if g in regulated_tf:
    #                    expressed_n[0] += 1
    #                elif g in regulated_nontf:
    #                    expressed_n[1] += 1
    #                elif g in stable_tf:
    #                    expressed_n[2] += 1
    #                elif g in stable_nontf:
    #                    expressed_n[3] += 1   
    #    print expressed_b, expressed_n
    #    print   
    #    if 0 not in expressed_b:
    #        results_b.append([c, float(expressed_b[0])/totals_b[0], float(expressed_b[1])/totals_b[1], float(expressed_b[2])/totals_b[2], float(expressed_b[3])/totals_b[3]]) 
    #    if 0 not in expressed_n:
    #        results_n.append([c, float(expressed_n[0])/totals_n[0], float(expressed_n[1])/totals_n[1], float(expressed_n[2])/totals_n[2], float(expressed_n[3])/totals_n[3]]) 
    #genomics.write_file(results_b, '/Users/woojunshim/Research/Data/exp_prop_broad_gene_groups_new.txt')
    #genomics.write_file(results_n, '/Users/woojunshim/Research/Data/exp_prop_non_broad_gene_groups_new.txt')



    ### EXPRESSION PROPORTION FIGURE 7B (TSS VS NON-TSS)
    #cols = get_colnames(exp_)    
    #temp = genomics.read_file('/Users/woojunshim/Research/bigdata/roadmap/broad_peaks/bedgraph/h3k27me3_flat_.txt', [3, 4], rowname='5')
    #tss_p = genomics.read_file('/Users/woojunshim/Research/bigdata/roadmap/broad_peaks/bedgraph/overlap_h3k27me3_tss_hg19_all_info_uniq.txt', [3], rowname='5')
    #tss_n = genomics.read_file('/Users/woojunshim/Research/bigdata/roadmap/broad_peaks/bedgraph/not_overlap_h3k27me3_tss_hg19_all_info.txt', [3], rowname='5')
    #results_b, results_n = [], []
    #for c in cols:        
    #    totals_b = [0,0,0,0]  # count number of genes with broad/non-broad domains that are expressed
    #    totals_n = [0,0,0,0]
    #    genes_with_domains = {}    
    #    tss_p_, tss_n_ = set(), set()    
    #    for i in tss_p[c]:
    #        tss_p_.add(i[0])
    #    for i in tss_n[c]:
    #        tss_n_.add(i[0])
    #    print len(tss_p_), len(tss_n_)
    #    for i in temp[c]:
    #        if i[0] in exp_:
    #            genes_with_domains[i[0]] = i[1]
    #            if i[0] in tss_p_:   # overlap TSS
    #                if i[0] in regulated_tf:
    #                    totals_b[0] += 1
    #                elif i[0] in regulated_nontf:
    #                    totals_b[1] += 1
    #                elif i[0] in stable_tf:
    #                    totals_b[2] += 1
    #                elif i[0] in stable_nontf:
    #                    totals_b[3] += 1            
    #            elif i[0] in tss_n_:  # non-TSS
    #                if i[0] in regulated_tf:
    #                    totals_n[0] += 1
    #                elif i[0] in regulated_nontf:
    #                    totals_n[1] += 1
    #                elif i[0] in stable_tf:
    #                    totals_n[2] += 1
    #                elif i[0] in stable_nontf:
    #                    totals_n[3] += 1
    #    expressed_b = [0,0,0,0]
    #    expressed_n = [0,0,0,0]
    #    print totals_b, totals_n        
    #    for g in genes_with_domains:
    #        if exp_[g][c] > 1:                
    #            if g in tss_p_:
    #                if g in regulated_tf:
    #                    expressed_b[0] += 1
    #                elif g in regulated_nontf:
    #                    expressed_b[1] += 1
    #                elif g in stable_tf:
    #                    expressed_b[2] += 1
    #                elif g in stable_nontf:
    #                    expressed_b[3] += 1
    #            elif g in tss_n_:
    #                if g in regulated_tf:
    #                    expressed_n[0] += 1
    #                elif g in regulated_nontf:
    #                    expressed_n[1] += 1
    #                elif g in stable_tf:
    #                    expressed_n[2] += 1
    #                elif g in stable_nontf:
    #                    expressed_n[3] += 1   
    #    print expressed_b, expressed_n
    #    print   
    #    if 0 not in expressed_b:
    #        results_b.append([c, float(expressed_b[0])/totals_b[0], float(expressed_b[1])/totals_b[1], float(expressed_b[2])/totals_b[2], float(expressed_b[3])/totals_b[3]]) 
    #    if 0 not in expressed_n:
    #        results_n.append([c, float(expressed_n[0])/totals_n[0], float(expressed_n[1])/totals_n[1], float(expressed_n[2])/totals_n[2], float(expressed_n[3])/totals_n[3]]) 
    #genomics.write_file(results_b, '/Users/woojunshim/Research/Data/exp_prop_tss_gene_groups_new.txt')
    #genomics.write_file(results_n, '/Users/woojunshim/Research/Data/exp_prop_non_tss_gene_groups_new.txt')



        



                        
   

    ### NEW SUPPLEMENTARY FIGURE 7B (EXPRESSION PROPORTIONS WHEN OVERLAP TSS)
    #cols = get_colnames(exp_)
    #results = []
    #temp = genomics.read_file('/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/bedgraph/not_overlap_h3k27me3_tss_hg19_all_info.txt', [3], rowname='5')
    #for c in cols:
    #    cnt, total = 0, 0
    #    for i in temp[c]:
    #        g = i[0]
    #        if g in exp_:
    #            total += 1
    #            if exp_[g][c] > 1:
    #                cnt += 1
    #    results.append([c, float(cnt)/total])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/expressed_prop_no_tss_overlap_overall.txt')


    #cols = get_colnames(exp_)
    #results = []
    #temp = genomics.read_file('/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/bedgraph/not_overlap_h3k27me3_tss_hg19_all_info.txt', [3], rowname='5')
    #for c in cols:
    #    cnt1, cnt2, cnt3, cnt4, total = 0, 0,0,0,0
    #    for i in temp[c]:
    #        g = i[0]
    #        if g in exp_:                
    #            if exp_[g][c] > 1:
    #                total += 1
    #                if g in regulated_tf:
    #                    cnt1 += 1
    #                elif g in regulated_nontf:
    #                    cnt2 += 1
    #                elif g in stable_tf:
    #                    cnt3 += 1
    #                elif g in stable_nontf:
    #                    cnt4 += 1

    #    results.append([c, float(cnt1)/total, float(cnt2)/total, float(cnt3)/total, float(cnt4)/total])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/expressed_prop_no_tss_overlap_gene_groups.txt')


    ### IDENTIFY CELL-TYPE SPECIFIC SIGNIFICANT GO TERMS (POSITIVES AND NEGATIVES)
    #pathway = '/Users/woojunshim/Research/Data/'
    #cols = ['E038','E082','E095']  
    #terms = {}
    #for c in cols:
    #    temp = genomics.read_file1(pathway+c+'_GO_BP_H3k27me3_negative_top100_tf.txt')
    #    for i in temp:
    #        if i[2] not in terms:
    #            terms[i[2]] = 0
    #        terms[i[2]] += 1
    #for c in cols:
    #    temp = genomics.read_file1(pathway+c+'_GO_BP_H3k27me3_negative_top100_tf.txt')
    #    results = []
    #    for i in temp:
    #        if terms[i[2]] == 1:
    #            results.append(i)
    #    genomics.write_file(results, pathway+c+'_GP_BP_H3K27me3_negative_top100_tf_specific.txt')



    ### DISCRETISE FDR TABLE
    #high = [0, 0.0001]  # 3
    #middle = [0.0001, 0.05] # 2
    #low = [0.05, 1] # 1
    #pathway = '/Users/woojunshim/Research/Data/'
    #cols = ['E038','E082','E095']    
    #for c in cols:
    #    results = {}
    #    temp = read_table1(pathway+c+'_H3K27me3_positive_vs_negative_top100_tf.txt')
    #    for i in temp:
    #        results[i] = {}
    #        results[i]['positive'] = 1
    #        results[i]['negative'] = 1
    #    for t in temp:
    #        for l in temp[t]:
    #            if temp[t][l] < 0.0001:
    #                results[t][l] = 3
    #            elif temp[t][l] < 0.05:
    #                results[t][l] = 2
    #    genomics.write_table1(results, pathway+c+'_H3K27me3_positive_vs_negative_top100_tf_cat.txt')


    ### CREATE A CELL-TYPE SPECIFIC GO OUTPUTS FROM POSITIVE AND NEGATIVE 
    #pathway = '/Users/woojunshim/Research/Data/'
    #cols = ['E038','E082','E095']    
    #for c in cols:
    #    ids = set()
    #    inputs = []
    #    inputs.append(pathway+c+'_GO_BP_H3k27me3_positive_top100_tf_specific.txt')         
    #    for i in inputs:
    #        temp = genomics.read_file1(i)
    #        for j in temp:
    #            if j[2] not in ids:
    #                ids.add(j[2])  
    #    inputs.append(pathway+c+'_GO_BP_H3k27me3_negative_top100_tf_specific.txt') 
    #    results = extract_elements(inputs, names=['positive','negative'], ids=list(ids), id_idx=2, value_idx=3, log_convert=False, default_value=1.0)
    #    genomics.write_table1(results, pathway+c+'_H3K27me3_positive_vs_negative_top100_tf_specific.txt')

    ### MERGE 3 GO RESULTS (E038, E082 AND E095)
    #pathway = '/Users/woojunshim/Research/Data/'
    #cols = ['E038','E082','E095']
    #inputs = []
    #for c in cols:
    #    inputs.append(pathway+c+'_GO_BP_H3K27me3_positive_top100_tf_specific.txt')
    #results = merge_go_results(inputs, cols)
    #genomics.write_table1(results, pathway+'merged_GO_results_H3K27me3_positive_top100_tf_specific.txt')

    ### TOP 100 EXPRESSED H3K27ME3-POSITIVE & NEGATIVE TFS FOR E038, E082 AND E095
    #pos = set(genomics.read_file_items('/Users/woojunshim/Research/Data/H3K27me3_positive_genes.txt'))
    #neg = set(genomics.read_file_items('/Users/woojunshim/Research/Data/H3K27me3_negative_genes.txt'))
    #cols = ['E038','E082','E095']
    #results1, results2 = {}, {}    
    #for c in cols:
    #    temp = []
    #    for g in exp_:
    #        temp.append([g, exp_[g][c]])
    #    temp = genomics.sort_(temp, idx=1, reverse_=True)
    #    cnt = 0
    #    for i in temp:
    #        if cnt == 200:
    #            break
    #        else:
    #            if (i[0] in pos) and (g in ref_):
    #                if i[0] not in results1:
    #                    results1[i[0]] = {}
    #                    for c_ in cols:
    #                        results1[i[0]][c_] = 0
    #                results1[i[0]][c] = 1
    #                cnt += 1
    #    cnt = 0
    #    for i in temp:
    #        if cnt == 200:
    #            break
    #        else:
    #            if (i[0] in neg) and (g in ref_):
    #                if i[0] not in results2:
    #                    results2[i[0]] = {}
    #                    for c_ in cols:
    #                        results2[i[0]][c_] = 0
    #                results2[i[0]][c] = 1
    #                cnt += 1
    #genomics.write_table1(results1, '/Users/woojunshim/Research/Data/H3K27me3_positive_tf_top200.txt')
    #genomics.write_table1(results2, '/Users/woojunshim/Research/Data/H3K27me3_negative_tf_top200.txt')




    ### REPRESSED H3K27ME3-POSITIVE GENES
    #ref_ = set(genomics.read_file_items('/Users/woojunshim/Research/Data/H3K27me3_positive_genes.txt'))
    #cols = get_colnames(exp_)    
    #results = []
    #widths = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/All_widths_H3K27me3.txt')
    #for c_ in cols:
    #    a,b,c,d = 0,0,0,0
    #    genes = []
    #    for g in widths:
    #        if widths[g][c_] != float(0):
    #            genes.append(g)        
    #    for g in genes:
    #        if g in exp_:
    #            if (exp_[g][c_] < 1) and (g in tf_list):
    #                if g in ref_:
    #                    a += 1
    #                else:
    #                    b += 1
    #            else:
    #                if g in ref_:
    #                    c += 1
    #                else:
    #                    d += 1
    #    s, p = stat.fisher(a,b,c,d)
    #print s, p
    #    results.append([c_, p])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/H3K27me3_positive_silent_tf_fet.txt')


    ### H3K27ME3-POSITIVE & NEGATIVE GENES 
    #aa = set()
    #pos, neg = [], []
    #for g in broad_:
    #    for c in broad_[g]:
    #        if broad_[g][c] == float(1):
    #            aa.add(g)
    #            break
    #for g in broad_:
    #    if g in aa:
    #        pos.append(g)
    #    else:
    #        neg.append(g)
    #genomics.write_file_items(pos, '/Users/woojunshim/Research/Data/H3K27me3_positive_genes.txt')
    #genomics.write_file_items(neg, '/Users/woojunshim/Research/Data/H3K27me3_negative_genes.txt')

    ### TESTING EXPRESSIONAL DIFFERENCES BETWEEN BROAD VS NON-BROAD GROUPS
    #broad, non_broad = [], []
    #epigenomes = get_colnames(exp_)
    #a,b,c,d = 0,0,0,0
    #for epi in epigenomes:
    #    for g in broad_:
    #        if g in exp_:
    #            value = exp_[g][epi]
    #            if broad_[g][epi] == float(1):
    #                broad.append(exp_[g][epi])
    #            else:
    #                non_broad.append(exp_[g][epi])
    #s,p = stat.mann(broad, non_broad, alternative_='less')
    #print s, p

    #a,b,c,d = 0,0,0,0
    #for epi in epigenomes:
    #    for g in broad_:
    #        if g in exp_:
    #            value = exp_[g][epi]
    #            if broad_[g][epi] == float(1):
    #                if value < 1:
    #                    a += 1
    #                else:
    #                    b += 1
    #            else:
    #                if value < 1:
    #                    c += 1
    #                else:
    #                    d += 1
    #s,p = stat.fisher(a,b,c,d, alternative_='greater')
    #print s, p

    ### ANALYSE ASSOCIATION BETWEEN GENE GROUPS AND TSS, BROAD DOMAINS 
    ### 1. GIVEN TSS
    #temp = genomics.read_file1('/Users/woojunshim/Research/bigdata/roadmap/broad_peaks/bedgraph/overlap_h3k27me3_tss_hg19_uniq.txt')
    #results = {}
    #cnt = 0
    #for i in range(1,5): # 1=regulated TF, 2=regualted non-TF, 3=stable TF, 4=stable non-TF
    #    results[i] = 0
    #for i in temp:
    #    g = i[3]
    #    if g in regulated_tf:
    #        results[1] += 1
    #        cnt += 1
    #    elif g in regulated_nontf:
    #        results[2] += 1
    #        cnt += 1
    #    elif g in stable_tf:
    #        results[3] += 1
    #        cnt += 1
    #    elif g in stable_nontf:
    #        results[4] += 1
    #        cnt += 1
    #print len(temp), cnt
    #print float(results[1]) / cnt, float(results[2]) / cnt, float(results[3]) / cnt, float(results[4]) / cnt

    ### 2. GIVEN BROAD
    #temp = genomics.read_file1('/Users/woojunshim/Research/bigdata/roadmap/broad_peaks/bedgraph/h3k27me3_flat.txt')
    #results = {}
    #cnt = 0
    #for i in range(1,5): # 1=regulated TF, 2=regualted non-TF, 3=stable TF, 4=stable non-TF
    #    results[i] = 0
    #for i in temp:
    #    if i[4] == '1':
    #        g = i[3]
    #        if g in regulated_tf:
    #            results[1] += 1
    #            cnt += 1
    #        elif g in regulated_nontf:
    #            results[2] += 1
    #            cnt += 1
    #        elif g in stable_tf:
    #            results[3] += 1
    #            cnt += 1
    #        elif g in stable_nontf:
    #            results[4] += 1
    #            cnt += 1
    #print len(temp), cnt
    #print float(results[1]) / cnt, float(results[2]) / cnt, float(results[3]) / cnt, float(results[4]) / cnt    

    ### 3. GIVEN TSS + BROAD
    #temp = genomics.read_file1('/Users/woojunshim/Research/bigdata/roadmap/broad_peaks/bedgraph/overlap_h3k27me3_tss_hg19_uniq.txt')
    #results = {}
    #cnt = 0
    #for i in range(1,5): # 1=regulated TF, 2=regualted non-TF, 3=stable TF, 4=stable non-TF
    #    results[i] = 0
    #for i in temp:
    #    if i[4] == '1':
    #        g = i[3]
    #        if g in regulated_tf:
    #            results[1] += 1
    #            cnt += 1
    #        elif g in regulated_nontf:
    #            results[2] += 1
    #            cnt += 1
    #        elif g in stable_tf:
    #            results[3] += 1
    #            cnt += 1
    #        elif g in stable_nontf:
    #            results[4] += 1
    #            cnt += 1
    #print len(temp), cnt
    #print float(results[1]) / cnt, float(results[2]) / cnt, float(results[3]) / cnt, float(results[4]) / cnt    

    ### 4. BACKGROUND
    #temp = genomics.read_file1('/Users/woojunshim/Research/bigdata/roadmap/broad_peaks/bedgraph/h3k27me3_flat.txt')
    #results = {}
    #cnt = 0
    #for i in range(1,5): # 1=regulated TF, 2=regualted non-TF, 3=stable TF, 4=stable non-TF
    #    results[i] = 0
    #for i in temp:
    #    
    #    g = i[3]
    #    if g in regulated_tf:
    #        results[1] += 1
    #        cnt += 1
    #    elif g in regulated_nontf:
    #        results[2] += 1
    #        cnt += 1
    #    elif g in stable_tf:
    #        results[3] += 1
    #        cnt += 1
    #    elif g in stable_nontf:
    #        results[4] += 1
    #        cnt += 1
    #print len(temp), cnt
    #print float(results[1]) / cnt, float(results[2]) / cnt, float(results[3]) / cnt, float(results[4]) / cnt   


    ### MERGE HUMAN H3K27ME3 BROAD AND NARROW FLAT FILES
    #results = []
    #temp = genomics.read_file1('/Users/woojunshim/Research/bigdata/roadmap/broad_peaks/bedgraph/h3k27me3_broad_flat.txt')
    #for i in temp:
    #    results.append(i)
    #    results[-1].extend([1])
    #temp = genomics.read_file1('/Users/woojunshim/Research/bigdata/roadmap/broad_peaks/bedgraph/h3k27me3_narrow_flat.txt')
    #for i in temp:
    #    results.append(i)
    #    results[-1].extend([0])
    #genomics.write_file(results, '/Users/woojunshim/Research/bigdata/roadmap/broad_peaks/bedgraph/h3k27me3_flat.txt')

    ### CREATE A NEW MM10 BROAD-TSS STAT FILE
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/mm10/h3k27me3/overlap_centre_h3k27me3_1.5kb_tss_mm10_uniq.txt')
    #temp = genomics.read_file1('/Users/woojunshim/Research/bigdata/roadmap/broad_peaks/bedgraph/overlap_h3k27me3_tss_hg19_uniq.txt')
    #results = {}
    #output_ = [['#gene','occurrence','proportion','TF']]
    #for i in temp:
    #    g = i[3]
    #    if g not in results:
    #        results[g] = 0
    #    results[g] += int(i[4])
    #for g in results:
    #    if g in tf_list:
    #        tag = 1
    #    else:
    #        tag = 0            
    #    output_.append([g, results[g], float(results[g]+1)/(111+1), tag])
    #genomics.write_file(output_, '/Users/woojunshim/Research/Data/genes_broad_h3k27me3_tss_stats_hg19_new.txt')



    ### EXTRACT +/- 500 BP REGIONS FOR ALL MOUSE H3K27ME3 DOMAINS AND CREATEA A FLAT BED FILE
    #pathway = '/Users/woojunshim/Research/Data/mm10/h3k27me3/genes/'
    #cells = genomics.read_file_items('/Users/woojunshim/Research/Data/mm10/h3k27me3/selected_metadata.txt', col=0)
    #broad = read_table1('/Users/woojunshim/Research/Data/mm10/h3k27me3/genes_broad_h3k27me3_binary_mm10.txt')
    #results = []
    #for c in cells:
    #    temp = genomics.read_file1(pathway+c+'_genes.txt')
    #    for i in temp:
    #        g = i[1]
    #        b = int(broad[g][c])
    #        centre = (int(i[4]) + int(i[5])) / 2
    #        start = centre - 1500
    #        end = centre + 1500
    #        results.append([i[3], start, end, g, c, b])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/mm10/h3k27me3/h3k27me3_domains_flat_1.5kb_.txt')


    


    ### CALCULATE SUM OF BROAD AND NARROW DOMAINS 
    #temp = genomics.read_file1('/Volumes/Project/Research/bigdata/roadmap/broad_peaks/bedgraph/h3k27me3_flat.txt')
    #temp = genomics.read_file1('/Users/woojunshim/Research/bigdata/roadmap/broad_peaks/bedgraph/h3k27me3_flat.txt')
    #results = 0
    #for i in temp:
    #    v = int(i[2]) - int(i[1])
    #    results += v
    #print results


    ### CREATE A FLAT BED FILE FOR BROAD AND NARROW H3K27ME3 DOMAINS
    #broad, narrow = [], []    
    #combined = []
    #pathway = '/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/'
    #thre = read_table1('/Users/woojunshim/Research/Data/broadPeaks/elbow_points.txt')
    #for epi in epigenomes:
    #    temp = genomics.read_file1(pathway+epi+'_H3K27me3_genes.txt')
    #    cutoff = thre[epi]['H3K27me3']
    #    for i in range(len(temp)):            
    #        if i < cutoff:
            #    broad.append([temp[i][3], temp[i][4], temp[i][5], temp[i][1]])
    #            combined.append([temp[i][3], temp[i][4], temp[i][5], temp[i][1], 1, epi])
    #        else:
            #    narrow.append([temp[i][3], temp[i][4], temp[i][5], temp[i][1]])
    #            combined.append([temp[i][3], temp[i][4], temp[i][5], temp[i][1], 0, epi])
    #genomics.write_file(broad, '/Volumes/Project/Research/bigdata/roadmap/broad_peaks/bedgraph/h3k27me3_broad_flat.txt')
    #genomics.write_file(narrow, '/Volumes/Project/Research/bigdata/roadmap/broad_peaks/bedgraph/h3k27me3_narrow_flat.txt')
    #genomics.write_file(combined, '/Volumes/Backup/Research/bigdata/roadmap/broad_peaks/bedgraph/h3k27me3_flat_.txt')

    ### CREATE A TSS FILE (1 BP INTERVAL) FOR ALL REFSEQ TSS
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/hg19_TSS_.txt')
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/mm10_TSS.txt')
    #results = []
    #for i in temp:
    #    if i[3] == '+':
    #        start = i[3]
    #        end = int(i[3]) + 1
    #    else:
    #        start = int(i[4])-1
    #        end = i[4]
    #    results.append([i[1], start, end, i[-1]])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/mm10_TSS_1bp.txt')


    ### PERMUATION TEST TO FIND A THRESHOLD 
    #temp = read_table1('/Users/woojunshim/Research/Data/Palpant/score_table.txt')
    #ref = genomics.read_file1('/Users/woojunshim/Research/Data/genes_broad_tss_stats.txt')
    #ref = genomics.read_file1('/Users/woojunshim/Research/Data/mm10/h3k27me3/genes_broad_h3k27me3_stats_mm10_.txt')
    #input_, ref_ = [], {} 
    #for i in ref:
    #    ref_[i[0]] = float(i[2])
    #for i in temp:
    #    input_.append([i, temp[i]['Exp']])
    #input_ = genomics.sort_(input_, idx=1, reverse_=True)
    #f, b = permutation_dist(input_, ref_, no_sampling=1000, by_sample=False)    
    #genomics.write_file(b, '/Users/woojunshim/Research/Data/CPC_background.txt')
    #means = []
    #results = []
    #for i in b:
    #    temp = np.mean(i)
    #    means.append(temp)
    #genomics.write_file(means, '/Users/woojunshim/Research/Data/CPC_background_means.txt')
        




    #results = run_permutation_test1(f,b)
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/test.txt')
    
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/CPC_diff_background.txt')
    #genomics.write_file(f, '/Users/woojunshim/Research/Data/fore.txt')
    #genomics.write_file(b, '/Users/woojunshim/Research/Data/back.txt')
    #s, p, thre = run_permutation_test(input_, ref_, find_lowest=True)
    #print s, p, thre
    #print
    #s, p, thre = run_permutation_test(input_, ref_, find_lowest=False, down_to=1000, no_sampling=100)
    #print s, p, thre
    #genomics.write_file(b, '/Users/woojunshim/Research/Data/back.txt')
    #genomics.write_file(f, '/Users/woojunshim/Research/Data/fore.txt')
    #yy, cnt, i = threshold_using_permutation(input_, ref_, no_sampling=100, down_to=5000, threshold_=0.05)
    #print cnt ,i
    #genomics.write_file_items(yy, '/Users/woojunshim/Research/Data/Palpant/permutation_fdr.txt')

    #genomics.write_file(results, '/Users/woojunshim/Research/Data/test_.txt')





   

    ### COUNT NUMBER OF BROAD H3K4ME3 DOMAINS FOR EACH GENE ACROSS CELL TYPES 
    #pathway = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Assigned_genes/all_peaks_2.5kb/'
    #results = {}
    #no_cells = len(epigenomes)
    #for e in epigenomes:
    #    temp = genomics.read_file1(pathway+e+'_all_peaks_assigned.txt')
    #    aa = set()
    #    mm = []
    #    for i in temp:
    #        g = i[1]
    #        if g not in aa:
    #            aa.add(g)
    #            mm.append([g, i[2]])
    #    mm = genomics.sort_(mm, idx=1, reverse_=True)
    #    cut_off = int(len(mm) * 0.05)
    #    for u in range(len(mm)):
    #        i = mm[u]
    #        g = i[0]
    #        if g not in results:
    #            results[g] = {}
    #            for c in epigenomes:
    #                results[g][c] = 0
    #        if u < cut_off:
    #            results[g][e] = 1                
    #for g in results:
    #    cnt = 0
    #    for c in epigenomes:
    #        if results[g][c] == 1:
    #            cnt += 1
    #    if cnt != 0:
    #        prop = round(float(1) / cnt, 3)
    #    else:
    #        prop = 0
    #    for c in epigenomes:
    #        if results[g][c] == 1:
    #            results[g][c] = prop    
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/h3k4me3_specificity_score.txt')

    ### COUNT H3K4ME3 DOMAINS FOR ALL GENES 
    #temp = read_table1('/Users/woojunshim/Research/Data/h3k4me3_specificity_score.txt')
    #results = []
    #for g in temp:
    #    cnt = 0
    #    for c in temp[g]:
    #        if temp[g][c] > 0:
    #            cnt += 1
    #    results.append([g, cnt])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/h3k4me3_specificity_counts.txt')

    ### CALCULATE JACCARD INDEX BETWEEN H3K4ME3 AND H3K27ME3 POSITIVE GENES
    #k27 = genomics.read_file1('/Users/woojunshim/Research/Data/genes_broad_tss_stats.txt')
    #k4 = genomics.read_file1('/Users/woojunshim/Research/Data/h3k4me3_specificity_counts.txt')
    #k27_, k4_ = [], []
    #k27__, k4__ = {}, {}
    #for i in k27:
    #    if i[1] > 0:
    #        k27_.append(i[0])
    #        k27__[i[0]] = i[1]
    #for i in k4:
    #    if i[1] != '0':
    #        k4_.append(i[0])
    #        k4__[i[0]] = i[1]
    #j = jaccard_index(k27_, k4_)
    #print j
    #genes = set(k27_ + k4_)
    #results = []
    #for g in genes:
    #    if g not in k27__:
    #        a = 0
    #    else:
    #        a = k27__[g]

    #    if g not in k4__:
    #        b = 0
    #    else:
    #        b = k4__[g]
    #    results.append([g, a, b])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/k27_k4_positive_counts.txt')

    ### MARK WHERE REGULATED TFS ARE RANKED
    #k4 = genomics.read_file1('/Users/woojunshim/Research/Data/h3k4me3_specificity_counts.txt')
    #for i in range(len(k4)):
    #    g = k4[i][0]
    #    if g in regulated_tf:
    #        tag = 1
    #    else:
    #        tag = 0
    #    k4[i].extend([tag])
    #k4 = genomics.sort_(k4, idx=1, reverse_=True)
    #genomics.write_file(k4, '/Users/woojunshim/Research/Data/h3k4me3_specificity_counts_.txt') 



    ### IDENTIFY CANDIDATE CELL-TYPE SPECIFIC REGULATORY GENES (GIVING CELL-TYPE SPECIICITY SCORES)
    ### HAVE TO MEET 1. CV > 1.0 BY THEIR EXPRESSION VALUES, 2. TF AND 3. EXPRESSED (RPKM > 1) AT THE CELL TYPE    
    #cells = get_colnames(exp_)
    #table_ = subset_table(exp_, rows=regulated_tf, cols=cells)
    #results = initiate_table(table_)
    #no_cells = len(cells)
    #for g in regulated_tf:
    #    cnt = 0
    #    for c in cells:
    #        if exp_[g][c] > 1:
    #            cnt += 1
    #    prop = round(float(1) / cnt, 3)
    #    for c in cells:
    #        if exp_[g][c] > 1:
    #            results[g][c] = prop
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/specificity_score_regulated_tf.txt')



    ### HYPERGEOMETRIC TEST
    #temp = read_table1('/Users/woojunshim/Research/Data/Palpant/score_table.txt')
    #input__, input_ = [], []
    #for i in temp:
    #    if temp[i]['Corrected'] > float(0):
    #        input__.append([i, temp[i]['Corrected']])    
    #input__ = genomics.sort_(input__, idx=1, reverse_=True)
    #for i in input__:
    #    input_.append(i[0])    
    #ref_ = genomics.read_file1('/Users/woojunshim/Research/Data/genes_broad_tss_stats.txt')
    #ref = []
    #for i in ref_:
    #    if i[1] != '0':
    #        ref.append(i[0])
    #results, cov = calculate_hypergeom(input_, ref, bottom_no=None, coverage=True)   
    #print len(input_), len(ref)
    #u = hypergeom(len(input_), len(ref), 1)
    #print u
    #idx = results.index(np.min(results))
    #print idx, np.min(results)
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/Palpant/hypergeom_p.txt')
    #genomics.write_file(cov, '/Users/woojunshim/Research/Data/Palpant/hypergeom_cov.txt')

    ### CALCULATE HYPERGEOMETRIC PMF
    #a,b,c = 20000, 6000, 1000
    #t = hypergeom(a,b,c)
    #x = np.arange(0, b)
    #l = t.pmf(x)
    #print l[900:999]
    

    ### GET FALT H3K27ME3 DOMAINS (BROAD AND NARROW)
    #pathway = '/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/'
    #ref = read_table1('/Users/woojunshim/Research/Data/broadPeaks/elbow_points.txt')
    #broad, narrow = [], []
    #for epi in epigenomes:
    #    temp = genomics.read_file1(pathway+epi+'_H3K27me3_genes.txt')
    #    no = int(ref[epi]['H3K27me3'])
    #    for j in range(len(temp)):
    #        i = temp[j]
    #        if j < no:
    #            broad.append([i[3], i[4], i[5], i[0]])
    #        else:
    #            narrow.append([i[3], i[4], i[5], i[0]])
    #genomics.write_file(broad, pathway+'combined_h3k27me3_broad.txt')
    #genomics.write_file(narrow, pathway+'combined_h3k27me3_narrow.txt')

    ### GET FLAT H3K27ME3 BROADEST PEAKS ONLY 
    #pathway = '/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/'
    #results = []
    #for epi in epigenomes:
    #    temp = genomics.read_file1(pathway+epi+'_H3K27me3_genes.txt')
    #    for i in temp:
    #        results.append([i[3], i[4], i[5], i[0]])
    #genomics.write_file(results, pathway+'combined_h3k27me3.txt')

    ### EXTRACT A TFBS DATA FOR A SPECIFIC TF
    #tf = 'TAL1'
    #temp = extract_lines1('/Users/woojunshim/Research/Data/TFBS/wgEncodeRegTfbsClusteredV3.bed', [3], [tf])
    #genomics.write_file(temp, '/Users/woojunshim/Research/Data/TFBS/'+tf+'.txt')

    ### WHAT IS THE TOTAL BP OF HUMAN HG19?
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/hg19.chrom.sizes_short.txt')
    #sum_ = 0
    #for i in temp:
    #    sum_ += int(i[1])
    #print sum_

    #total_h3k27me3 = 0
    #temp = genomics.read_file1('/Volumes/Project/Research/bigdata/roadmap/broad_peaks/bedgraph/h3k27me3_less5.bedgraph.bed')
    #for i in temp:
    #    if i[3] != '0':
    #        width = int(i[2]) - int(i[1])
    #        total_h3k27me3 += width
    #print total_h3k27me3

    #total_h3k27me3 = 354357432  # over 50

    ### CALCULATE POISSON FOR A GIVEN TF
    #tf = 'TFAP2A'
    #pathway = '/Users/woojunshim/Research/Data/TFBS/'
    #back_ = calculate_event_rates(pathway+'flat_tfbs.bed', cell_id=None, overall_bp=sum_)
    #fore_ = calculate_event_rates('/Users/woojunshim/Research/Data/overlap_h3k27me3_less5_tfbs.txt', cell_id=None, overall_bp=total_h3k27me3, start_=1, end_=2)
    #print back_
    #print fore_  
    # use R function 'poisson.text' to calculate P-values  
    

    

    ### PERMUTATION TEST TO FIND A THRESHOLD 
    #temp = read_table1('/Users/woojunshim/Research/Data/Palpant/score_table.txt')
    #input_ = []
    #for g in temp:
    #    input_.append([g, temp[g]['Corrected']])
    #input_ = genomics.sort_(input_, idx=1, reverse_=True)
    #ref_ = genomics.read_file1('/Users/woojunshim/Research/Data/genes_broad_tss_stats.txt')
    #ref_genes = set()
    #for i in ref_:
    #    if i[1] != '0':
    #        ref_genes.add(i[0])
    #input__ = []    
    #for i in input_:
    #    if i[0] in ref_genes:
    #        input__.append('T')
    #    else:
    #        input__.append('F')   
    #results = permutation_test(input__, no_sampling=1000, step_by=10000)
    #print results

    #print len(input__)
    #results = sliding_fet(input__, ref_list=['T'], output_='p-value', convert_to_percentile=True, percentile_bin = 0.01)
    #print results




    ### FET FOR TOP 100 GENES GTEX 
    #temp1 = read_table1('/Users/woojunshim/Research/Data/GTEX/results/combined_top_100_product.txt')
    #temp2 = read_table1('/Users/woojunshim/Research/Data/GTEX/results/combined_top_100_tpm.txt')
    #results = []
    #cols = get_colnames(temp1)
    #ref = set(list(regulated_tf)+list(regulated_nontf))
    #for c_ in cols:
    #    a,b,c,d = 0,0,0,0
    #    results.append([c_])
    #    for g in temp1:
    #        if temp1[g][c_] > 0:
    #            if g in ref:
    #                a += 1
    #            else:
    #                b += 1
    #        else:
    #            if g in ref:
    #                c += 1
    #            else:
    #                d += 1
    #    s, p = stat.fisher(a,b,c,d)
    #    results[-1].extend([p])

    #    a,b,c,d = 0,0,0,0        
    #    for g in temp2:
    #        if temp2[g][c_] > 0:
    #            if g in ref:
    #                a += 1
    #            else:
    #                b += 1
    #        else:
    #            if g in ref:
    #                c += 1
    #            else:
    #                d += 1
    #    s, p = stat.fisher(a,b,c,d)
    #    results[-1].extend([p])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/GTEX/results/fet_top_100_product.txt')





    ### ENRICHMENT ANALYSIS OF REPRESSED GENES BY BROAD-TSS DOMAINS
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/broad_tss_effect_count.txt', sort_by=1)
    #tt = []  
    #results = []  
    #for i in temp:
    #    tt.append(i[0])
    #results1, a = density_analysis(tt, ref_list=regulated_tf, bin_size_=0.01, odd_ratio_=True, background_ratio_=None, accumulative_=False)
    #results2, a = density_analysis(tt, ref_list=regulated_nontf, bin_size_=0.01, odd_ratio_=True, background_ratio_=None, accumulative_=False)
    #results3, a = density_analysis(tt, ref_list=stable_tf, bin_size_=0.01, odd_ratio_=True, background_ratio_=None, accumulative_=False)
    #results4, a = density_analysis(tt, ref_list=stable_nontf, bin_size_=0.01, odd_ratio_=True, background_ratio_=None, accumulative_=False)
    #results = [['Regulated_TF']]
    #for i in results1:
    #    results[-1].extend([i])
    #results.append(['Regulated_nonTF'])
    #for i in results2:
    #    results[-1].extend([i])
    #results.append(['Stable_TF'])
    #for i in results3:
    #    results[-1].extend([i])
    #results.append(['Stable_nonTF'])
    #for i in results4:
    #    results[-1].extend([i])
    #genomics.write_file(results,'/Users/woojunshim/Research/Data/broad_tss_effect_count_enrichment.txt')



    ### FET BTW GENES WITH AT LEAST 1 H3K27ME3 + REPRESSED 
    #tag = '2'
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/broad_tss_effect_count.txt', sort_by=1)
    #a,b,c,d = 0,0,0,0
    #for i in temp:
    #    if i[2] == tag:
    #        if float(i[1]) == 0:
    #            a += 1
    #        else:
    #            b += 1
    #    else:
    #        if float(i[1]) == 0:
    #            c += 1
    #        else:
    #            d += 1
    #s, p = stat.fisher(a,b,c,d)
    #print s, p

    ### CONVERT TABLES TO Z SCORES 
    #genes = ['TBX5','GATA4','GATA6','NKX2-5','TBX20','MYH6','MYH7','TNNI3','MYL3','MYL2']
    #cells = get_colnames(exp_)
    #file_ = '/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_widths.txt'
    #file_ = log_convert_table(file_, pseudo_=1)   
    #temp = convert_to_z(exp_, rows=genes, cols=cells, pseudo_=0.00001) 
    #min_, max_ = get_range_values_table(exp_)
    #temp = subset_table(exp_, rows=genes, cols=cells)
    #temp = find_deg_from_table(temp)
    #temp = discretise_table(temp, [[min_,1], [1,10], [10,100], [100,max_]])
    #genomics.write_table1(temp, '/Users/woojunshim/Research/Data/z_table_selected_cardiac_genes_disc_exp.txt')

    ### CALCULATE PROPORTION OF BROAD H3K27ME3 DOMAINS GIVEN REPRESSED, COMPARING BETWEEN DIFFERENT CLASSES
    #broad_ = read_table1('/Users/woojunshim/Research/Data/genes_broad_tss_table.txt')
    #results = [['#gene','prop','group']]
    #cols = get_colnames(exp_)
    #all_ = genomics.intersection(all_, get_rownames(broad_))
    #print len(all_)
    #for g in all_:
    #    ct = set()
    #    cnt = 0
    #    for c in cols:
    #        if exp_[g][c] < float(1):
    #            ct.add(c)
    #            if broad_[g][c] == float(1):
    #                cnt += 1
    #    if g in regulated_tf:
    #        tag = 1
    #    elif g in regulated_nontf:
    #        tag = 2
    #    elif g in stable_tf:
    #        tag = 3
    #    elif g in stable_nontf:
    #        tag = 4        
    #    results.append([g, int(cnt), tag])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/broad_tss_effect_count.txt')




    ### IDENTIFY PCG GENES IN ESC (E003)
    #cols = get_colnames(exp_)    
    #h3k27me3_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_binary.txt')
    #genes = genomics.intersect(get_rownames(exp_), get_rownames(h3k27me3_))    
    #h3k27me3 = subset_table(h3k27me3_, rows=genes, cols=cols)    
    #exp = subset_table(exp_, rows=genes, cols=cols)    
    #pcg = []
    ##exp = binarise_table(exp, threshold_=1)
    #menu = ['pcg_gene','h3k27me3_positives','h3k27me3_negatives','no.exp_cells','jaccard_index']
    #results = {}
    #for g in genes:
    #    results[g] = {}
    #    for c in menu:
    #        results[g][c] = 0
    #cell = 'E003'
    #for g in genes:
    #    if h3k27me3[g][cell] == float(1):
    #        pcg.append(g)
    #genomics.write_file_items(pcg, '/Users/woojunshim/Research/Data/pcg_genes_'+cell+'.txt')
    #k27_p = count_occurrence_table(h3k27me3, rank_threshold=0, convert_to_proportion=False, operator_='greater')
    #k27_n = count_occurrence_table(h3k27me3, rank_threshold=1, convert_to_proportion=False, operator_='less')
    #exp_p = count_occurrence_table(exp, rank_threshold=1, convert_to_proportion=False, operator_='greater')
    #for g in genes:
    #    a,b = [], []
    #    for c in cols:
    #        if h3k27me3[g][c] == float(0):
    #            a.append(c)
    #        if exp[g][c] > float(1):
    #            b.append(c)
    #    value = jaccard_index(a,b)
    #    results[g]['jaccard_index'] = value
    #    if g in pcg:
    #        tag = 1
    #    else:
    #        tag = 0
    #    results[g]['pcg_gene'] = tag
    #for i in k27_p:
    #    g = i[0]
    #    results[g]['h3k27me3_positives'] = i[1]
    #for i in k27_n:
    #    g = i[0]
    #    results[g]['h3k27me3_negatives'] = i[1]
    #for i in exp_p:
    #    g = i[0]
    #    results[g]['no.exp_cells'] = i[1]
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/pcg_genes_table.txt')    


    ### EXPRESSED REGULATED TF AS POSITIVES FOR CPC
    #positives = extract_expressed_genes('/Users/woojunshim/Research/Data/Palpant/regulated_tf/exp_palpant.txt', 'CPC_RNAseq', regulated_tf)
    #pathway = '/Users/woojunshim/Research/Data/Palpant/regulated_tf/'
    #tpr, fpr, auc, results = generate_scores(pathway+'exp_palpant.txt', 'CPC_RNAseq', pathway+'H3K4me3_palpant.txt', 'width', ref_='/Users/woojunshim/Research/Data/genes_broad_tss_stats.txt', ref_c=2, positive_file=positives, roc_=True, order_='descending', positive_only_tf=True, write_positives=pathway+'positive_genes.txt')
    #genomics.write_file(auc, pathway+'test_auc.txt')

    ### RUN ANALYSIS 
    #positives = '/Users/woojunshim/Research/Data/Palpant/selected_cardiac_genes.txt'
    #pathway = '/Users/woojunshim/Research/Data/Palpant/'
    #pathway = '/Users/woojunshim/Research/Data/NCC/'
    #pathway = '/Users/woojunshim/Research/Data/Pax7/'
    #pathway = '/Users/woojunshim/Research/Data/Pax6/'
    #positives = pathway+'GO.0030900_genes_10090_.txt'
    #ref_ = '/Users/woojunshim/Research/Data/genes_broad_h3k27me3_tss_stats_hg19_new.txt'
    #ref_ = '/Users/woojunshim/Research/Data/genes_broad_h3k27me3_binary_all_broadpeaks_stats_.txt'
    #ref_ = '/Users/woojunshim/Research/Data/mm10/h3k27me3/genes_broad_h3k27me3_1.5kb_tss_stats_mm10.txt'
    #tpr, fpr, auc, results = generate_scores1(pathway+'GSE66961_gene.rpkm.matrix.txt', 'e12fb', pathway+'fb_h3k4me3_.txt', 'width', ref_=ref_, ref_c=2, positive_file=positives, roc_=True, order_='descending', positive_only_tf=True, write_positives=pathway+'positive_genes_log.txt', log_conversion=True, exp_filter=0.0)
    #genomics.write_file(tpr, pathway+'test_tpr_new_log.txt')
    #genomics.write_file(auc, pathway+'test_auc_new_log.txt')
    #genomics.write_file(fpr, pathway+'test_fpr_new_log.txt')
    #genomics.write_table1(results, pathway+'score_table_.txt')

    #s, p = stat.fisher(a=741, b=7217, c=774, d=8898)
    #print s,p

    ### EXTRACT TFS FOR SATELLITE CELLS 
    #results = []
    #temp = genomics.read_file_items('/Users/woojunshim/Research/Data/Pax7/GO_0035914_10090.txt')
    #for i in temp:
    #    if i in tf_list:
    #        results.append(i)
    #genomics.write_file_items(results, '/Users/woojunshim/Research/Data/Pax7/GO_0035914_10090_TF.txt')

    ### ADD TAG OF EXPRESSION DATA 
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/Roadmap.txt')
    #ref = set(get_colnames(read_table1('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.txt')))      
    #for i in range(len(temp)):
    #    if temp[i][0] in ref:
    #        temp[i].extend(['Yes'])
    #    else:
    #        temp[i].extend(['No'])
    #genomics.write_file(temp, '/Users/woojunshim/Research/Data/Roadmap_IDs_new.txt')

    ### VERFAILLIE DATA 
    ### SEPARATE INVASIVE AND PROLIFERATIVE 
    #pathway = '/Users/woojunshim/Research/melanoma/'
    #temp = read_table1(pathway+'verf_exp.txt')
    #genes = get_rownames(temp)
    #pro = subset_table(pathway+'verf_exp.txt', rows=genes, cols=['FPKM.217','FPKM.218','FPKM.219','FPKM.220','FPKM.222','FPKM.223','FPKM.224','FPKM.226','FPKM.227'])
    #inv = subset_table(pathway+'verf_exp.txt', rows=genes, cols=['FPKM.221','FPKM.225'])
    #genomics.write_table1(pro, pathway+'ver_exp_proliferative.txt')
    #genomics.write_table1(inv, pathway+'ver_exp_invasive.txt')

    ### TEST VERFAILLIE DATA    
    ### 1. CALCULATE WEIGHTED SCORES AND RANK GENES
    #a = product_analysis2(pathway+'ver_exp_invasive.txt', '/Users/woojunshim/Research/Data/genes_broad_tss_stats.txt', ref_col=2, pseudo_=None)
    #b = rank_table(a)
    #n = int(len(get_rownames(a)) * 0.01)
    #genomics.write_table1(a, pathway+'ver_weighted_invasive.txt')
    #c = count_occurrence_table(b, rank_threshold=100, convert_to_proportion=True)
    #genomics.write_file(c, pathway+'ver_weighted_invasive_consistently_within_top200.txt')

    #a = product_analysis2(pathway+'ver_exp_proliferative.txt', '/Users/woojunshim/Research/Data/genes_broad_tss_stats.txt', ref_col=2, pseudo_=None)
    #b = rank_table(a)
    #n = int(len(get_rownames(a)) * 0.01)
    #genomics.write_table1(a, pathway+'ver_weighted_proliferative.txt')
    #c = count_occurrence_table(b, rank_threshold=100, convert_to_proportion=True)
    #genomics.write_file(c, pathway+'ver_weighted_proliferative_consistently_within_top200.txt')

    ### EXTRACT GENES THAT ARE ONLY FOUND IN EITHER STATE OF MELANOMA 
    #a_ = genomics.read_file1(pathway+'ver_weighted_proliferative_consistently_within_top200.txt')
    #b_ = genomics.read_file1(pathway+'ver_weighted_invasive_consistently_within_top200.txt')
    #a,b = [], []    
    #for i in a_:
    #    if float(i[1]) > 0:
    #        a.append(i[0])
    #for i in b_:
    #    if float(i[1]) > 0:
    #        b.append(i[0])
    #print len(a), len(b)
    #c = list(set(a + b))
    #print len(c)
    #genomics.write_file_items(a, pathway+'candidate_genes_proliferative_by_top100.txt')
    #genomics.write_file_items(b, pathway+'candidate_genes_invasive_by_top100.txt')   
    #genomics.write_file_items(c, pathway+'candidate_genes_combined_by_top100.txt')   
    #inter_ = genomics.intersect(a,b)
    #pro, inv = [], []
    #for g in a:
    #    if g not in inter_:
    #        pro.append(g)
    #for g in b:
    #    if g not in inter_:
    #        inv.append(g)
    #print len(pro), len(inv)
    #genomics.write_file_items(pro, pathway+'candidate_genes_proliferative_only_by_top100.txt')
    #genomics.write_file_items(inv, pathway+'candidate_genes_invasive_only_by_top100.txt')

    ### FIND INTERSECTION BETWEEN DEG_BY_AUTHOR AND candidate_genes_combined_by_top100.txt
    #deg = genomics.read_file1(pathway+'verf_DEG_by_author.txt')
    #can = set(genomics.read_file_items(pathway+'candidate_genes_combined_by_top100.txt'))
    #results = []
    #for i in deg:
    #    if len(i) > 1:
    #        if i[0] in can:
    #            results.append([i[0], i[1]])
    #genomics.write_file(results, pathway+'intersection_DEG_and_weighted.txt')




    ### GTEX DATA
    ### IDENTIFY COL INDEXES FOR A GIVEN TISSUE TYPE (GTEX DATA)
    ### AND CREATE A EXP TABLE FOR THE GIVEN TISSUE TYPE
    #anno_ = '/Users/woojunshim/Research/Data/GTEX/GTEX_sample_annotations.txt'
    #exp_ = '/Users/woojunshim/Research/Data/GTEX/GTEx_Analysis_2016-01-15_v7_RNASeQCv1.1.8_gene_tpm.txt'
    #name_ = 'Thyroid'
    #results = extract_samples(exp_, anno_, name_)
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/GTEX/GTEX_'+name_+'_tpm.txt')

    ### CALCULATE AVERAGE EXPRESSION VALUES FOR GENES FOR EACH TISSUE GROUP (GTEX)
    #results = {}
    #names = genomics.read_file_items('/Users/woojunshim/Research/Data/GTEX/GTEX_tissue_groups.txt')
    #cnt = 0
    #for n in names:
   # 	cnt += 1
   # 	print
    #	print n, cnt
    #	aa = extract_samples(exp_, anno_, n)
   # 	no = len(get_colnames(aa))
    #	for g in aa:
   # 		sum_ = 0
   # 		for c in aa[g]:
   # 			sum_ += float(aa[g][c])
   # 		if g not in results:
   # 			results[g] = {}
   # 			for n1 in names:
   # 				results[g][n1] = 0
   # 		results[g][n] = sum_ / no
   # genomics.write_table1(results, '/Users/woojunshim/Research/Data/GTEX/GTEX_tissue_exp_ave_table.txt')


    ### PRODUCT ANALYSIS FOR GTEX
    ### COUNT NUMBER OF OCCURRENCES THAT A GIVEN IS WITHIN TOP 100 BY THE SCORE
    #pathway = '/Users/woojunshim/Research/Data/GTEX/'
    #name = 'Left_Ventricle'
    #input_file = 'GTEX_'+name+'_tpm.txt'
    #a = product_analysis2(pathway+input_file, '/Users/woojunshim/Research/Data/genes_broad_tss_stats.txt', ref_col=2, pseudo_=None)
    #b = rank_table(a)
    #c = average_rank_table(b)
    #genomics.write_file(c, pathway+name+'_ave_rank.txt')

    ### RUNNING ANALYSIS FOR GTEX DATA
    #anno_ = '/Users/woojunshim/Research/Data/GTEX/GTEX_sample_annotations.txt'
    #exp_ = '/Users/woojunshim/Research/Data/GTEX/GTEx_Analysis_2016-01-15_v7_RNASeQCv1.1.8_gene_tpm.txt'
    #names = set()
    #anno = genomics.read_file1(anno_)
    #for i in anno:
    #    if len(i) > 2:
    #        if i[2] != 'Cells_-_Leukemia_cell_line_(CML)':
    #            if i[2] not in names:
    #                names.add(i[2])
    #names = list(names)
    #genomics.write_file_items(names, '/Users/woojunshim/Research/Data/GTEX/GTEX_tissue_groups.txt')
    #print len(names)
    #cnt = 1
    #for name_ in names[:45]:
    #    print cnt
    #    print name_
    #    cnt += 1
    #    if name_ == 'Cells_-_Leukemia_cell_line_(CML)':
    #        continue
    #    else:
    #        tab_ = extract_samples(exp_, anno_, name_)         
    #        pathway = '/Users/woojunshim/Research/Data/GTEX/'        
    #        a = product_analysis2(tab_, '/Users/woojunshim/Research/Data/genes_broad_h3k27me3_tss_stats_hg19_new.txt', ref_col=2, pseudo_=None)        
    #        b = rank_table(a)        
    #        c = count_occurrence_table(b)     
    #        genes = get_rownames(a)       
    #        genomics.write_file(c, pathway+'results_new/'+name_+'_rank_100_counts_product.txt')   
    #        b = rank_table(tab_, all_genes=genes)
    #        c = count_occurrence_table(b)         
    #        genomics.write_file(c, pathway+'results_new/'+name_+'_rank_100_counts_tpm.txt')   
            
    ### CREATE A GO TABLE FOR GTEX DATA
    #pathway = '/Users/woojunshim/Research/Data/GTEX/results/GO/'
    #groups = ['Heart_-_Left_Ventricle','Brain_-_Amygdala','Skin_-_Sun_Exposed_(Lower_leg)','Kidney_-_Cortex','Pituitary', 'Whole_blood']
    #terms = [['GO:0048738','GO:0007507','GO:0008016','GO:0003007','GO:0072359'],['GO:0007417','GO:0007268','GO:0007420','GO:0010001','GO:0048699'],['GO:0043588','GO:0008544','GO:0031424','GO:0060429','GO:0009913'],['GO:0072001','GO:0001822','GO:0001655','GO:0072006','GO:0072025'],['GO:0010817','GO:0021983','GO:0043434','GO:0009914','GO:0035270'],['GO:0002376','GO:0006952','GO:0006955','GO:0050776','GO:0002682']]
    #file_labels = ['Weighted','TPM']
    #for i in range(len(groups)):
    #    group = groups[i]
    #    term = terms[i]
    #    file1 = pathway+group+'_BP_product.txt'
    #    file2 = pathway+group+'_BP_tpm.txt'
    #    results = create_go_table(file1, file2, term, file_labels, term_col=1, value_col=3)
    #    genomics.write_table1(results, pathway+'GO_table_'+group+'.txt')

    ### CREATE A TABLE FOR TOP 100 CONSISTENTLY HIGHLY RANKED GENES (GTEX DATA)
    #groups = genomics.read_file_items('/Users/woojunshim/Research/Data/GTEX/GTEX_tissue_groups.txt')
    #pathway = '/Users/woojunshim/Research/Data/GTEX/results/'
    #inputs = []
    #labels = []    
    #for g in groups:
    #    a = pathway+g+'_rank_100_counts_tpm.txt'
    #    inputs.append(a)
    #    p = g.replace('_-_','_')
    #    labels.append(p)
    #results = create_table_from_lists(inputs, labels, col_idx=1, default_value=0, cut_off=100)
    #genomics.write_table1(results, pathway+'combined_top_100_tpm.txt')

    ### ADD TISSUE GROUPS TO GTEX_tissue_groups.txt
    #groups = genomics.read_file_items('/Users/woojunshim/Research/Data/GTEX/GTEX_tissue_groups.txt')
    #results = []
    #for g in groups:
    #    aa = g.split('_-_')
    #    name = g.replace('_-_','_')
    #    name = name.replace('(','.')
    #    name = name.replace(')','.')
    #    name = name.replace('-','.')
    #    name_ = name.split('_')
    #    if len(name_) == 1:
    #        n = name_[0]
    #    else:
    #        n = ''
    #        for l in name_[1:]:
    #            n += l
    #            n += '_'
    #    n = n[:len(n)-1]
    #    results.append([name, aa[0], n])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/GTEX/GTEX_tissue_groups_.txt')

    ### COUNT NUMBER OF TISSUE GROUPS FOR ALL GENES (GTEX DATA)
    #temp = read_table1('/Users/woojunshim/Research/Data/GTEX/results/combined_top_100_product.txt')
    #ref = genomics.read_file('/Users/woojunshim/Research/Data/genes_broad_tss_stats.txt', [1], rowname='0')
    #results = []
    #for g in temp:
    #    cnt = 0
    #    for c in temp[g]:
    #        if temp[g][c] != float(0):
    #            cnt += 1
    #    results.append([g, cnt, ref[g][0][0]])
    #results.insert(0, ['#gene','tissue_cnt','broad_tss_cnt'])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/GTEX/results/combined_top_100_product_stat.txt')

    ### IDENTIFY GENES THAT ARE WITHIN TOP 100 OF THE CARDIAC TISSUE GROUPS:
    #temp = binarise_table('/Users/woojunshim/Research/Data/GTEX/results/combined_top_100_product.txt')
    #results = check_values_in_table(temp, cols=['Skin_Not_Sun_Exposed_(Suprapubic)','Skin_Sun_Exposed_(Lower_leg)'])
    #results = check_values_in_table(temp, cols=['Heart_Atrial_Appendage','Heart_Left_Ventricle'])
    #results_ = get_counts(results, '/Users/woojunshim/Research/Data/GTEX/results/combined_top_100_product_stat.txt', 1)    
    #genomics.write_file(results_, '/Users/woojunshim/Research/Data/GTEX/results/top_100_heart_genes.txt')

    ### COMPARING MYOCYTE HYPERTROPHY AND NORMAL LEFT VENTRICLE SAMPLES (GTEX DATA SET)   
    #anno_ = '/Users/woojunshim/Research/Data/GTEX/GTEX_sample_annotations.txt'
    #exp_ = '/Users/woojunshim/Research/Data/GTEX/GTEx_Analysis_2016-01-15_v7_RNASeQCv1.1.8_gene_tpm.txt'        
    #pathway = '/Users/woojunshim/Research/Data/GTEX/'  
    #name_ = genomics.read_file_items(pathway+'normal_left_ventricle_ids.txt')    
    #name = 'normal_left_ventricle'
    #tab_ = extract_samples(exp_, anno_, name_)   
    #a = product_analysis2(tab_, '/Users/woojunshim/Research/Data/genes_broad_tss_stats.txt', ref_col=2, pseudo_=None)        
    #b = rank_table(a)        
    #c = count_occurrence_table(b)
    #c = average_rank_table(b)
    #genes = get_rownames(a)
    #genomics.write_file(c, pathway+'results/'+name+'_ave_rank_product.txt')   
    #b = rank_table(tab_, all_genes=genes)
    #c = count_occurrence_table(b)     
    #c = average_rank_table(b)    
    #genomics.write_file(c, pathway+'results/'+name+'_ave_rank_tpm.txt')  

    ### FIND SIGNIFICANTLY DIFFERENT GENE SETS (BETWEEN NORMAL LEFT VENTRICLE AND MYOCYTE HYPERTROPHY)
    #pathway = '/Users/woojunshim/Research/Data/GTEX/results/'
    #f1 = pathway+'normal_left_ventricle_rank_table_tpm.txt'
    #f2 = pathway+'myocyte_hypertrophy_rank_table_tpm.txt'
    #results = find_significant_genes(f1, f2)
    #genomics.write_file(results, pathway+'significant_genes_normal_left_ventricle_vs_myocyte_hypertrophy.txt')

    ### WE HAVE ABOUT 4,300 GENES DIFFERENTIALLY EXPRESSED GENES 
    ### NOW WE'LL IDENTIFY AMONG THESE GENES WHICH ONES ARE CONSISTENTLY HIGHLY RANKED 
    #f1 = genomics.read_file(pathway+'normal_left_ventricle_rank_100_counts_product.txt', [1], rowname='0')
    #f2 = genomics.read_file(pathway+'myocyte_hypertrophy_rank_100_counts_product.txt', [1], rowname='0')
    #ref = genomics.read_file_items(pathway+'significant_genes_normal_left_ventricle_vs_myocyte_hypertrophy.txt', col=0)
    #results = {}
    #for g in f1:
    #    results[g] = {}
    #    results[g]['normal'] = 0
    #    results[g]['hypertrophy'] = 0
    #for r in ref:
    #    if float(f1[r][0][0]) > 0:
    #        results[r]['normal'] = 1
    #    if float(f2[r][0][0]) > 0:
    #        results[r]['hypertrophy'] = 1
    #genomics.write_table1(results, pathway+'DEG_and_consistently_highly_ranked_genes_table.txt')

    ### OR WE CAN COLLECT THE AVE. RANK (USING WEIGHTED VALUE) FOR THOSE GENES 
    #f1 = genomics.read_file(pathway+'normal_left_ventricle_ave_rank_product.txt', [1], rowname='0')
    #f2 = genomics.read_file(pathway+'myocyte_hypertrophy_ave_rank_product.txt', [1], rowname='0')
    #ref = genomics.read_file_items(pathway+'significant_genes_normal_left_ventricle_vs_myocyte_hypertrophy.txt', col=0)
    #results = {}
    #for g in f1:
    #    results[g] = {}
    #    results[g]['normal'] = 0
    #    results[g]['hypertrophy'] = 0
    #for r in ref:        
    #    results[r]['normal'] = f1[r][0][0]        
    #    results[r]['hypertrophy'] = f2[r][0][0]
    #genomics.write_table1(results, pathway+'DEG_ave_rank_by_weight_table.txt')

    ### EXTRACT GENES FOR NORMAL OR HYPERTROPHIC CELLS 
    #temp = read_table1(pathway+'DEG_and_consistently_highly_ranked_genes_table.txt')
    #both = []
    #normal, h = [], []
    #for g in temp:
    #    if temp[g]['normal'] == 1.0 and temp[g]['hypertrophy'] == 1.0:
    #        both.append(g)
    #    elif temp[g]['normal'] == 1.0:
    #        normal.append(g)
    #    elif temp[g]['hypertrophy'] == 1.0:
    #        h.append(g)
    #genomics.write_file_items(both, pathway+'candidate_genes_both.txt')
    #genomics.write_file_items(normal, pathway+'candidate_genes_normal.txt')
    #genomics.write_file_items(h, pathway+'candidate_genes_hypertrophy.txt')
    



    ### FILTER OUT H3K27ME3-NEAGATIVE GENES FROM ROADMAP EXP TABLE
    #broad_ = genomics.read_file1('/Users/woojunshim/Research/Data/genes_broad_tss_stats.txt')
    #genes = []
    #for i in broad_:
    #    if i[1] != '0':
    #        genes.append(i[0])
    #results = subset_table(exp_, rows=genes, cols=get_colnames(exp_))
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols_regulated_genes.txt')

    ### ASSIGN H3K4ME3 E124 TO GENES
    #pathway = '/Users/woojunshim/Research/Data/Pax6/'
    #results_ = main('/Users/woojunshim/Research/Data/NCC/GSM714809_NCC_H3K4me3_calls.bed', '/Users/woojunshim/Research/Data/NCC/H3K4me3_NCC.txt', max_width__=2500, tss__='/Users/woojunshim/Research/Data/hg18_TSS.txt', dominant_=True, convert_DS=False, centre_=True, remove_ncrna_=False, only_width=True)
    #results_ = main(pathway+'GSM1635076_fb_H3K4me3_macs2_peaks.narrowPeak', pathway+'fb_h3k4me3.txt', max_width__=2500, tss__='/Users/woojunshim/Research/Data/mm9_TSS.txt', dominant_=True, convert_DS=False, centre_=True, remove_ncrna_=False, only_width=True)
    #results = remove_as(pathway+'fb_h3k4me3.txt')
    #genomics.write_table1(results, pathway+'fb_h3k4me3_.txt')


    ### 1. GENERATE SCORE TABLE
    #pathway = '/Users/woojunshim/Research/Data/Tsankov/'
    #pathway = '/Users/woojunshim/Research/Data/Palpant/'
    #pathway = '/Users/woojunshim/Research/Data/ENCODE/E122/'
    #pathway = '/Users/woojunshim/Research/Data/ENCODE/hindbrain_e10.5_mouse/'
    #pathway = '/Users/woojunshim/Research/Data/Pax7/'
    #pathway = '/Users/woojunshim/Research/Data/NCC/'
    #tpr,fpr,auc,table = generate_scores(pathway+'exp_NCC_.txt', 'RPKM', pathway+'H3K4me3_NCC_.txt', 'width', ref_='/Users/woojunshim/Research/Data/genes_broad_tss_stats.txt', ref_c=2, positive_file=pathway+'GO.0014032_genes_9606_.txt', roc_=True, write_positives=pathway+'positive_genes.txt')
    #tpr, fpr, auc, table = generate_scores(pathway+'exp_hindbrain_e10.5_mm10.txt', 'FPKM', '/Users/woojunshim/Research/Data/ENCODE/hindbrain_e10.5_mouse/ENCFF432UHX_mouse_h3k4me3_assigned.txt', 'width', ref_='/Users/woojunshim/Research/Data/mm10/h3k27me3/genes_broad_h3k27me3_stats_mm10_.txt', ref_c=2, positive_file=pathway+'hindbrain_e10.5_GO.0030902_positives.txt', roc_=True, write_positives=pathway+'positive_genes.txt')
    #genomics.write_file(tpr, pathway+'test_tpr.txt')
    #genomics.write_file(fpr, pathway+'test_fpr.txt')
    #genomics.write_file(auc, pathway+'test_auc.txt')
    #genomics.write_table1(table, pathway+'score_table.txt')

    

    ### FET FOR GENES (WITH Z-SCORE (WIDTH) < 0) ACROSS TISSUE GROUPS
    #temp = read_table1('/Users/woojunshim/Research/Data/H3K27me3_width_z_score_all_binary.txt')
    #genes = get_rownames(temp)
    #input_ = subset_table('/Users/woojunshim/Research/Data/H3K27me3_width_z_score_all_binary.txt', rows=genes, cols=epigenomes)
    #print len(epigenomes)
    #results = fet_by_tissue_group(input_, ref=tissue_groups_, p_threshold=0.05)
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/fet_H3K27me3_absence_tissue_groups.txt')


    ### EXTRACT H3K27me3 widths for regulated TFs AFTER CONVERTING THEM INTO Z-SCORE (WIDTH)
    #width_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_widths.txt')
    #genes = genomics.intersect(get_rownames(width_), regulated_tf)
    #genes = get_rownames(width_)
    #print len(genes)
    #cols = get_colnames(width_)
    #results = {}
    #for g in genes:        
    #    results[g] = {}
    #    for c in cols:            
    #        results[g][c] = 0.0    
    #for c in cols:
    #    temp = []
    #    for g in genes:
    #        temp.append(width_[g][c])
    #    mean_ = np.mean(temp)
    #    sd_ = np.std(temp)
    #    for g in genes:
    #        results[g][c] = stat.z_score(width_[g][c], mean_, sd_)
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/H3K27me3_width_z_score_all.txt')

    ### CONVERTING 'H3K27ME3_WIDTH_Z_SCORE_REGULATED_TF.TXT' TO BINARY TABLE
    #temp = read_table1('/Users/woojunshim/Research/Data/H3K27me3_width_z_score_all.txt')
    #for g in temp:
    #    for c in temp[g]:
    #        if temp[g][c] < float(0):
    #            temp[g][c] = 1
    #        else:
    #            temp[g][c] = 0
    #genomics.write_table1(temp, '/Users/woojunshim/Research/Data/H3K27me3_width_z_score_all_binary.txt')




    ### FET BETWEEN HOUSEKEEPING GENES (EINSBERG) AND NEGATIVE 
    #hk = set(genomics.read_file_items('/Users/woojunshim/Research/Data/HK_genes.txt'))
    #ref_ = genomics.read_file1('/Users/woojunshim/Research/Data/genes_broad_tss_stats.txt')
    #ref = set()
    #for i in ref_:
    #    if i[1] == '0':
    #        ref.add(i[0])        
    #print len(ref)
    #a,b,c,d = 0,0,0,0
    #for g in all_:
    #    if g in ref:
    #        if g in hk:
    #            a += 1
    #        else:
    #            b += 1
    #    else:
    #        if g in hk:
    #            c += 1
    #        else:
    #            d += 1
    #print a,b,c,d
    #s, p = stat.fisher(a,b,c,d)
    #print s, p


    ### SATURATION OF SIGNAL
    #results = signal_saturation1('/Users/woojunshim/Research/Data/genes_broad_tss_table.txt', iter=1000, bin_size=3)
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/signal_saturation_broad_tss_iter1000_bs10.txt')

    ### JACCARD INDEX BETWEEN BROAD GENES OF BROAD AND NARROW PEAK REPRESENTATIONS
    #broad_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_binary.txt')
    #narrow_ = read_table1('/Users/woojunshim/Research/Data/genes_broad_h3k27me3_binary_narrowpeaks.txt')
    #results = []
    #genes = genomics.intersect(get_rownames(broad_), get_rownames(narrow_))
    #for c in epigenomes:
    #    b, n = [], []
    #    for g in genes:
    #        if broad_[g][c] == float(1):
    #            b.append(g)
    #        if narrow_[g][c] == float(1):
    #            n.append(g)
    #    results.append([c, jaccard_index(b, n)])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/jaccard_index_broad_genes_broad_vs_narrow_representation.txt')

    ### ASSIGN NARROW H3K27ME3 PEAKS AND CREATE TABLES
    #pathway = '/Volumes/Project/Research/bigdata/roadmap/narrow_peaks/H3K27me3/'
    #files = []
    #labels = []
    #for epi in epigenomes[1:2]:
    #    labels.append(epi)
    #    files.append(pathway+epi+'-H3K27me3.narrowPeak')
    #a,b = assign_and_check_overlaps(files, labels, tss__='/Users/woojunshim/Research/Data/hg19_TSS_.txt')
    #genomics.write_table1(a, 'test1_.txt')
    #genomics.write_table1(b, 'test2_.txt')



    ### CPG-ASSOCIATED GENES & CPG-UNASSOCIATED GENES 
    ### ALSO CALCULATE FET (BETWEEN UNASSOCIATED GENES AND H3K27ME3-PEAK-NEGATIVE GENES)
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_stats_gene_groups.txt')
    #cpg = genomics.read_file1('/Users/woojunshim/Research/Data/CpG_genes.txt')
    #genes_ = []
    #genes_p, genes_n = set(), set()
    #for i in temp:
    #    genes_.append(i[0])
    #    if i[1] == '0.0':
    #        genes_n.add(i[0])
    #    else:
    #        genes_p.add(i[0])
    #cpg_p, cpg_n = set(), set()
    #mm = []
    #for i in cpg:
    #    cpg_p.add(i[3])
    #    mm.append(i[3])
    #for i in genes_:
    #    if i[0] not in cpg_p:
    #        cpg_n.add(i[0])  
    #print len(genes_p), len(genes_n), len(cpg_p), len(cpg_n)  
    #genomics.write_file_items(cpg_p, '/Users/woojunshim/Research/Data/CpG_positive_genes.txt')
    #genomics.write_file_items(cpg_n, '/Users/woojunshim/Research/Data/CpG_negative_genes.txt')
    #a,b,c,d = 0,0,0,0
    #for i in genes_:
    #    g = i[0]        
    #    if g in cpg_n:
    #        if g in genes_n:
    #            a += 1
    #        else:
    #            b += 1
    #    elif g in cpg_p:
    #        if g in genes_n:
    #            c += 1
    #        else:
    #            d += 1
    #print a,b,c,d
    #s, p = stat.fisher(a,b,c,d, alternative_='two-sided')
    #print s, p







    ### SLIDING FET 
    ### RANKED BY NUMBER OF BROAD-TSS PEAKS
    #ref_ = genomics.read_file1('/Users/woojunshim/Research/Data/genes_broad_tss_stats.txt',sort_by=1)
    #print ref_[:10]
    #input_ = []
    #for i in ref_:
    #    if (i[1] > 0) and (i[3] != str(5)):
    #        input_.append(i[0])  
    #print len(input_) 
    
    #groups = ['regulated_tf','regulated_nontf','stable_tf','stable_nontf']
    #results = []
    #for group in groups:
    #    results.append([group])
    #    ref_list = genomics.read_file_items('/Users/woojunshim/Research/Data/'+group+'.txt')
    #    mm = sliding_fet(input_, ref_list, output_='p-value', convert_to_percentile=True, percentile_bin = 0.01)
    #    for i in mm:
    #        results[-1].extend([i])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/fet_gene_groups_for_broad_tss.txt')

    ### TABLE FOR NUMBER OF BROAD H3K27ME3 PEAKS OVER THE TSS
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/genes_broad_tss_stats.txt')
    #results = {}
    #for i in temp:
    #    value = int(i[1])
    #    if value not in results:
    #        results[value] = 0
    #    results[value] += 1
    #results_ = []
    #for i in results:
    #    results_.append([i, results[i]])
    #genomics.write_file(results_, '/Users/woojunshim/Research/Data/count_gene_broad_tss.txt')


    ### OVERLAP PROPORTIONS OF EXPRESSED GENES (FOR ALL GENE GROUPS ACROSS CELL TYPES)
    #groups = ['regulated_tf','regulated_nontf','stable_tf','stable_nontf']
    #cols = get_colnames(exp_)
    #expressed_ = {}
    #for c in cols:
    #    expressed_[c] = []
    #    for g in all_:
    #        if exp_[g][c] > float(1):
    #            expressed_[c].append(g)
    #for group in groups:
    #    results = {}
    #    for c1 in cols:
    #        results[c1] = {}
    #        for c2 in cols:
    #            results[c1][c2] = 0.0
    #    ref_ = genomics.read_file_items('/Users/woojunshim/Research/Data/'+group+'.txt')        
    #    for c1 in cols:
    #        ref = genomics.intersect(ref_, expressed_[c1])
    #        total_ = len(ref)
    #        for c2 in cols:
    #            no = len(genomics.intersect(ref, expressed_[c2]))
    #            results[c1][c2] = round(float(no) / total_, 4)
    #    genomics.write_table1(results, '/Users/woojunshim/Research/Data/overlap_expressed_'+str(group)+'.txt')


    ### EXPRESSIONAL CORRELATION OF EXPRESSED GENES (FOR ALL GENE GROUPS ACROSS CELL TYPES)    
    #groups = ['regulated_tf','regulated_nontf','stable_tf','stable_nontf']
    #cols = get_colnames(exp_)
    #expressed_ = {}
    #for c in cols:
    #    expressed_[c] = []
    #    for g in all_:
    #        if exp_[g][c] > float(1):
    #            expressed_[c].append(g)
    #for group in groups:
    #    results = {}
    #    for c1 in cols:
    #        results[c1] = {}
    #        for c2 in cols:
    #            results[c1][c2] = 0.0
    #    ref_ = genomics.read_file_items('/Users/woojunshim/Research/Data/'+group+'.txt')        
    #    for c1 in cols:
            #ref = genomics.intersect(ref_, expressed_[c1])
            #total_ = len(ref_)
    #        value1 = []
    #        for m in ref_:
    #            value1.append(exp_[m][c1])
    #        for c2 in cols:
                #no = genomics.intersect(ref_, expressed_[c2])
    #            value2 = []
    #            for m in ref_:
    #                value2.append(exp_[m][c2])
    #            s, p = stat.spearman(value1, value2)
    #            results[c1][c2] = s
    #    genomics.write_table1(results, '/Users/woojunshim/Research/Data/spearman_expressed_'+str(group)+'.txt')

    

    ### FILTER OUT GENES WITH CV < 0.1
    #ref_ = read_table1('/Users/woojunshim/Research/Data/Paige/expression/test/paige_d2_broad_tss.txt')
    #cv_ = read_table1('/Users/woojunshim/Research/Data/cv_genes_.txt')
    #results = []
    #for g in ref_:
    #    if g in cv_:
    #        if cv_[g]['value'] > float(1):
    #            results.append([g, ref_[g]['score']]) 
    #results = genomics.sort_(results, idx=1, reverse_=True)
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/Paige/expression/test/paige_d2_broad_tss_excluded.txt')

    ### FINAL PRODUCT ANALYSIS & PERFORMANCE ANALYSIS
    ### 1. exp, 2. H3K4me3 width, 3. corrected exp. (using H3K27me3 peak proportion)
    #groups = ['Exp','H3K4me3','Corrected']
    #pathway = '/Users/woojunshim/Research/Data/Palpant/'
    #exp_ = read_table1(pathway+'TPM_ave.txt')
    #exp_c = 'CPC_RNAseq'
    #h3k4me3_ = read_table1(pathway+'H3K4me3_palpant_.txt')
    #h3k4me3_c = 'width'
    #ref_ = '/Users/woojunshim/Research/Data/genes_broad_tss_stats.txt'
    #ref_c = 2
    #g_ref = get_rownames(read_table1('/Users/woojunshim/Research/Data/genes_broad_tss_stats_table.txt'))
    #a = []
    #for g in exp_:
    #    if exp_[g][exp_c] > float(1):
    #        a.append(g)    
    #genes = genomics.intersect(a, g_ref)
    #genes = genomics.intersect(genes, get_rownames(h3k4me3_))
    #print 'genes =', len(genes)
    #positives_ = set(genomics.read_file_items(pathway+'selected_cardiac_TFs.txt'))
    #positives = extract_expressed_genes(exp_, exp_c, positives_)
    #print 'positives =', len(positives)
    #corrected = product_analysis1(exp_, exp_c, ref_, ref_c, pseudo_=None, header=False, exp_filter=1.0)    
    ### CREATE A COMBINED TABLE FOR EXP, H3K4ME3 AND PRODUCT
    #results = {}
    #for g in genes:
    #    results[g] = {}
    #    for group in groups:
    #        results[g][group] = 0.0
    #    results[g]['Exp'] = exp_[g][exp_c]
    #    results[g]['H3K4me3'] = h3k4me3_[g][h3k4me3_c]
    #for i in corrected:
    #    g = i[0]
    #    value = i[1]
    #    if g in genes:
    #        results[g]['Corrected'] = value
    #genomics.write_table1(results, pathway+'score_table.txt')



   



    ### TEST RUN ON PAIGE DAY 14 DATA (USING BROAD, BROAD + TSS, BROAD + TSS + CV)    
    #exp_data = '/Users/woojunshim/Research/Data/Paige/expression/exp_d14.txt'
    #exp_data = '/Users/woojunshim/Research/Data/Paige/expression/expression_data_ave_symbol.txt'
    #exp_col = 'day2'
    #ref_file = '/Users/woojunshim/Research/Data/genes_broad_tss_cv.txt'
    #ref_file = '/Users/woojunshim/Research/Data/genes_broad_tss_stats.txt'
    #ref_file = '/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_stats_.txt'
    #ref_col = 1
    #results = product_analysis1(exp_data, exp_col, ref_file, ref_col, pseudo_=None, header=True, exp_filter=0.0)
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/Paige/expression/test/paige_d2_broad_tss_cv.txt')

    ### CONDITIONAL PROBABILITIES BETWEEN TSS AND BROAD PEAKS
    ### A.
    #broad_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_binary.txt')
    #loc_ = read_table1('/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt')
    #genes = genomics.intersect(get_rownames(broad_), get_rownames(loc_))
    #cols = epigenomes
    #print len(genes)
    #results = [['#cell','broad','TSS','Jaccard_index','p(broad)','p(TSS)','p(TSS|broad)','p(broad|TSS)']]
    #for col in cols:
    #    broad, tss = [], []
    #    total = 0
    #    for g in genes:
    #        if loc_[g][col] != float(0):
    #            total += 1
    #            if broad_[g][col] == float(1):
    #                broad.append(g)
    #            if loc_[g][col] == float(2):
    #                tss.append(g)
    #    jaccard = jaccard_index(broad, tss)
    #    p1 = (float(len(genomics.intersect(broad, tss))) / total) / (float(len(broad)) / total)
    #    p2 = (float(len(genomics.intersect(broad, tss))) / total) / (float(len(tss)) / total)
    #    results.append([col, len(broad), len(tss), jaccard, float(len(broad)) / total, float(len(tss)) / total, p1, p2])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/cond_prop_broad_tss.txt')

    ### B. REGULATED TF | BROAD, TSS
    #broad_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_binary.txt')
    #loc_ = read_table1('/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt')
    #genes = genomics.intersect(get_rownames(broad_), get_rownames(loc_))
    #genes = genomics.intersect(genes, list(regulated_tf) + list(regulated_nontf) + list(stable_tf) + list(stable_nontf))
    #cols = epigenomes
    #print len(genes)
    #groups = ['regulated_tf', 'regulated_nontf', 'stable_tf', 'stable_nontf']
    #for group in groups:
    #    group_ = set(genomics.read_file_items('/Users/woojunshim/Research/Data/'+group+'.txt'))
    #    results = [['#cell','p('+str(group)+'|broad,TSS)','p('+str(group)+'|broad)','p('+str(group)+'|TSS)','p('+str(group)+')']]
    #    for col in cols:
    #        broad, tss, both = [], [], []
    #        total, total_ = 0, 0
    #        c_tf = 0 
    #        for g in genes:
    #            total_ += 1
    #            if g in group_:
    #                c_tf += 1
    #            if loc_[g][col] >= float(0):
    #                total += 1
    #                if broad_[g][col] == float(1):
    #                    broad.append(g)
    #                if loc_[g][col] == float(2):
    #                    tss.append(g)
    #                if broad_[g][col] == float(1) and loc_[g][col] == float(2):
    #                    both.append(g)
    #        c_both = 0
    #        for i in both:
    #            if i in group_:
    #                c_both += 1
    #        p_both = float(c_both) / len(both)
    #        c_broad = 0
    #        for i in broad:
    #            if i in group_:
    #                c_broad += 1
    #        p_broad = float(c_broad) / len(broad)
    #        c_tss = 0
    #        for i in tss:
    #            if i in group_:
    #                c_tss += 1
    #        p_tss = float(c_tss) / len(tss)        
    #        results.append([col, p_both, p_broad, p_tss, float(c_tf)/total_])
    #    genomics.write_file(results, '/Users/woojunshim/Research/Data/cond_prop_broad_tss_'+str(group)+'.txt')

    ### C. OVERLAP BETWEEN BROAD AND TSS 
    #broad_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_binary.txt')
    #loc_ = read_table1('/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt')
    #genes = genomics.intersect(get_rownames(broad_), get_rownames(loc_))
    #cols = epigenomes
    #print len(genes)
    #results =[['broad','TSS','broad.TSS']]
    #t_broad, t_tss, t_both = 0,0,0
    #for c in cols:
    #    broad, tss, both = [], [], []
    #    for g in genes:
    #        if broad_[g][c] == float(1):
    #            broad.append(g)
    #            t_broad += 1
    #            if loc_[g][c] == float(2):
    #                both.append(g)
    #                t_both += 1
    #        elif loc_[g][c] == float(2):
    #            tss.append(g)
    #            t_tss += 1
    #    results.append([c, len(broad), len(tss), len(both)])
    #total_ = t_broad + t_tss - t_both
    #results.append(['combined',float(t_broad)/total_, float(t_tss)/total_, float(t_both)/total_])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/overlap_broad_tss.txt')

    ### D. CALCULATE PROPORTION OF GENE GROUPS FOR BROAD ONLY, TSS ONLY AND BROAD + TSS ACROSS THE CELL TYPES
    #broad_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_binary.txt')
    #loc_ = read_table1('/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt')
    #genes = genomics.intersect(get_rownames(broad_), get_rownames(loc_))
    #genes = genomics.intersect(genes, list(regulated_tf) + list(regulated_nontf) + list(stable_tf) + list(stable_nontf))
    #total_ = len(genes)
    #print total_
    #print float(len(genomics.intersect(genes, regulated_tf))) / total_
    #print float(len(genomics.intersect(genes, regulated_nontf))) / total_
    #print float(len(genomics.intersect(genes, stable_tf))) / total_
    #print float(len(genomics.intersect(genes, stable_nontf))) / total_       
    #cols = epigenomes
    #r1,r2,r3 = [], [], []
    #ta1,ta2,ta3,ta4 = 0,0,0,0
    #tt1,tt2,tt3,tt4 = 0,0,0,0
    #tb1,tb2,tb3,tb4 = 0,0,0,0
    #tt_a, tt_b, tt_t = 0,0,0    
    #for c in cols:
    #    b1,b2,b3,b4 = 0, 0, 0, 0
    #    t1,t2,t3,t4=0,0,0,0
    #    a1,a2,a3,a4=0,0,0,0    
    #    t_a, t_b, t_t = 0,0,0
    #    for g in genes:            
    #        if broad_[g][c] == float(1) and loc_[g][c] == float(2):
    #            tt_a += 1
    #            t_a += 1
    #            if g in regulated_tf:
    #                a1 += 1
    #                ta1 += 1
    #            elif g in regulated_nontf:
    #                a2 += 1
    #                ta2 += 1
    #            elif g in stable_tf:
    #                a3 += 1
    #                ta3 += 1
    #            elif g in stable_nontf:
    #                a4 += 1
    #                ta4 += 1
    #        elif broad_[g][c] == float(1) and loc_[g][c] != float(2):
    #            tt_b += 1
    #            t_b += 1
    #            if g in regulated_tf:
    #                b1 += 1
    #                tb1 += 1
    #            elif g in regulated_nontf:
    #                b2 += 1
    #                tb2 += 1
    #            elif g in stable_tf:
    #                b3 += 1
    #                tb3 += 1
    #            elif g in stable_nontf:
    #                b4 += 1    
    #                tb4 += 1            
    #        elif loc_[g][c] == float(2) and broad_[g][c] != float(1):  
    #            tt_t += 1
    #            t_t += 1          
    #            if g in regulated_tf:
    #                t1 += 1
    #                tt1 += 1
    #            elif g in regulated_nontf:
    #                t2 += 1
    #                tt2 += 1
    #            elif g in stable_tf:
    #                t3 += 1
    #                tt3 += 1
    #            elif g in stable_nontf:
    #                t4 += 1
    #                tt4 += 1
    #    r1.append([c, float(a1)/t_a, float(a2)/t_a, float(a3)/t_a, float(a4)/t_a])
    #    r2.append([c, float(b1)/t_b, float(b2)/t_b, float(b3)/t_b, float(b4)/t_b])
    #    r3.append([c, float(t1)/t_t, float(t2)/t_t, float(t3)/t_t, float(t4)/t_t])
    #r1.append(['combined', float(ta1)/tt_a, float(ta2)/tt_a, float(ta3)/tt_a, float(ta4)/tt_a])
    #r2.append(['combined', float(tb1)/tt_b, float(tb2)/tt_b, float(tb3)/tt_b, float(tb4)/tt_b])
    #r3.append(['combined', float(tt1)/tt_t, float(tt2)/tt_t, float(tt3)/tt_t, float(tt4)/tt_t])
    #genomics.write_file(r1, '/Users/woojunshim/Research/Data/broad_tss_gene_group_prop.txt')
    #genomics.write_file(r2, '/Users/woojunshim/Research/Data/broad_gene_group_prop.txt')
    #genomics.write_file(r3, '/Users/woojunshim/Research/Data/tss_gene_group_prop.txt')

    ### SUMMARY TABLE FOR COUNTS FOR GENES WITH BROAD AND TSS PEAKS 
    #broad_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_binary.txt')
    #loc_ = read_table1('/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt')
    #genes = genomics.intersect(get_rownames(broad_), get_rownames(loc_))
    #results = []    
    #total_ = len(epigenomes)
    #tt= {}
    #for g in genes:
    #    tt[g] = {}
    #    for c in epigenomes:
    #        tt[g][c] = 0
    # 1. BOTH 
    #for g in genes:
    #    cnt = 0
    #    for c in epigenomes:
    #        if (broad_[g][c] == float(1)) and (loc_[g][c] == float(2)):
    #            cnt += 1
    #            tt[g][c] = 1
    #    if g in regulated_tf:
    #        tag = 1 
    #    elif g in regulated_nontf:
    #        tag = 2
    #    elif g in stable_tf:
    #        tag = 3
    #    elif g in stable_nontf:
    #        tag = 4
    #    else:
    #        tag = 5
    #    results.append([g, cnt, float(cnt+1)/(total_+1), tag])
    #results.insert(0, ['#gene','count','proportion','group'])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/genes_broad_tss_stats.txt')
    #genomics.write_table1(tt, '/Users/woojunshim/Research/Data/genes_broad_tss_table.txt')

    # 2. TSS  
    #for g in genes:
    #    cnt = 0
    #    for c in epigenomes:
    #        if loc_[g][c] == float(2):
    #            cnt += 1
    #    if g in regulated_tf:
    #        tag = 1 
    #    elif g in regulated_nontf:
    #        tag = 2
    #    elif g in stable_tf:
    #        tag = 3
    #    elif g in stable_nontf:
    #        tag = 4
    #    else:
    #        tag = 5
    #    results.append([g, cnt, tag])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/genes_tss_stats.txt')

    # 3. COMBINE BROAD + TSS + CV 
    # SIMPLY MULTIPLYING THE RATIOS 
    #cv_ = read_table1('/Users/woojunshim/Research/Data/cv_genes_.txt')
    #ref_ = genomics.read_file('/Users/woojunshim/Research/Data/genes_broad_tss_stats.txt', [2], rowname='0')
    #results = [['#gene','ratio','group']]
    #genes = []
    #for g1 in cv_:
    #    if g1 in ref_:
    #        genes.append(g1)
    #for g in genes:
    #    value = cv_[g]['value'] * float(ref_[g][0][0])
    #    if g in regulated_tf:
    #        tag = 1 
    #    elif g in regulated_nontf:
    #        tag = 2
    #    elif g in stable_tf:
    #        tag = 3
    #    elif g in stable_nontf:
    #        tag = 4
    #    else:
    #        tag = 5
    #    results.append([g, value, tag])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/genes_broad_tss_cv.txt')


    ### STATISTICAL ANALYSIS BETWEEN GENE GROUPS
    # 1. H3K27ME3 WIDTHS AND GENE GROUPS
    #width_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_widths.txt')
    #width_ = exp_
    #cols = get_colnames(width_)
    #genes = genomics.intersect(get_rownames(width_), get_rownames(broad_))
    #results = []
    #a,b,c,d = 0,0,0,0
    #for col in cols:
    #    a,b,c,d = 0,0,0,0
    #    temp = []
    #    for g in genes:
    #        if width_[g][col] != float(0):
    #            temp.append([g, width_[g][col]])
    #    temp = genomics.sort_(temp, idx=1, reverse_=True)
    #    idx_ = int(len(temp) / 10)
    #    for i in range(len(temp)):
    #        g = temp[i][0]
    #        if i<idx_:
    #            if g in regulated_nontf:
    #                a += 1
    #            else:
    #                b += 1
    #        else:
    #            if g in regulated_nontf:
    #                c += 1
    #            else:
    #                d += 1
    #    s, p = stat.fisher(a,b,c,d)
    
    #    results.append([col, s, p])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/fet_top10_exp_vs_regulated_nontf.txt')
                





    ### ADD GENE GROUPS TO 'genes_broad_h3k27me3_stats_.txt'
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_stats_.txt')
    #for no in range(len(temp)):
    #    if temp[no][0] in regulated_tf:
    #        tag = 1
    #    elif temp[no][0] in regulated_nontf:
    #        tag = 2
    #    elif temp[no][0] in stable_tf:
    #        tag = 3
    #    elif temp[no][0] in stable_nontf:
    #        tag = 4
    #    else:
    #        tag = 5
    #    temp[no].extend([tag])
    #genomics.write_file(temp, '/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_stats_gene_groups.txt')

    ### BINARY TABLE FOR EXPRESSED REGULATED TFS 
    #results = {}
    #cols = get_colnames(exp_)
    #for g in regulated_tf:
    #    results[g] = {}
    #    for c in cols:
    #        if exp_[g][c] > float(1):
    #            results[g][c] = 1
    #        else:
    #            results[g][c] = 0
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/binary_regulated_tf.txt')



    ### DENSITY ANALYSIS FOR (MEDIAN - CURRENT H3K27ME3 WIDTH) FOR 46 CELL TYPES
    #width_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_width_med_minus_current.txt')
    #genes = genomics.intersect(get_rownames(width_), get_rownames(exp_))
    #print len(genes)
    #cols = get_colnames(exp_)
    #groups = ['regulated_tf','regulated_nontf','stable_tf','stable_nontf']
    #for group in groups:
    #    ref_ = set(genomics.read_file_items('/Users/woojunshim/Research/Data/'+group+'.txt'))
    #    results = []
    #    for c in cols:
    #        temp = []
    #        for g in genes:
    #            if exp_[g][c] > float(1):
    #                temp.append([g, width_[g][c]])
    #        temp = genomics.sort_(temp, idx=1, reverse_=True)
    #        temp_ = []
    #        for i in temp:
    #            temp_.append(i[0])
    #        results1, a = density_analysis(temp_, ref_list=ref_, bin_size_=0.01, odd_ratio_=True, background_ratio_=None, accumulative_=False)
    #        results.append([c])
    #        for i in results1:
    #            results[-1].extend([i])
    #    genomics.write_file(results, '/Users/woojunshim/Research/Data/'+group+'_enrichment_H3K27me3_median_minus_current.txt')

    ### CUMULATIVE ANALYSIS FOR (MEDIAN - CURRENT H3K27ME3 WIDTH) FOR 46 CELL TYPES
    #width_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_width_med_minus_current.txt')
    #genes = genomics.intersect(get_rownames(width_), get_rownames(exp_))
    #print len(genes)
    #cols = get_colnames(exp_)
    #groups = ['regulated_tf','regulated_nontf','stable_tf','stable_nontf']
    #for group in groups:
    #    pp = set(genomics.read_file_items('/Users/woojunshim/Research/Data/'+group+'.txt'))
    #    results = []        
    #    for c in cols:
    #        ref_ = []
    #        temp = []
    #        for g in genes:
    #            if exp_[g][c] > float(1):
    #                temp.append([g, width_[g][c]])
    #                if g in pp:
    #                    ref_.append(g)
    #        ref_ = set(ref_)            
    #        temp = genomics.sort_(temp, idx=1, reverse_=True)
    #        yy = (len(temp) / 10) * 10
    #        total_ = len(ref_)
    #        interval = int(yy / 10)
    #        temp_ = []
    #        cnt = 0
    #        cc = 0
    #        for i in temp[0:yy]:
    #            cc += 1
    #            if i[0] in ref_:
    #                cnt += 1
    #            if cc % interval == 0:
    #                value = float(cnt) / total_
    #                temp_.append(value)            
    #        results.append([c])
    #        for i in temp_:
    #            results[-1].extend([i])
    #    genomics.write_file(results, '/Users/woojunshim/Research/Data/'+group+'_cumulative_H3K27me3_median_minus_current.txt')

    ### AVERAGE PROPORTION OF 4 GENE GROUPS (MEDIAN - CURRENT H3K27ME3 WIDTH) FOR ONLY EXPRESSED GENES
    #width_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_width_med_minus_current.txt')
    #width_ = exp_
    #genes = genomics.intersect(get_rownames(width_), get_rownames(exp_))
    #genes = genomics.intersect(genes, list(regulated_tf)+list(regulated_nontf)+list(stable_tf)+list(stable_nontf))
    #print len(genes)
    #cols = get_colnames(exp_)
    #groups = ['regulated_tf','regulated_nontf','stable_tf','stable_nontf']
    #final = []
    #for group in groups:
    #    pp = set(genomics.read_file_items('/Users/woojunshim/Research/Data/'+group+'.txt'))
    #    results = []        
    #    for c in cols:
    #        ref_ = []
    #        temp = []
    #        for g in genes:
    #            if exp_[g][c] > float(1):
    #                temp.append([g, width_[g][c]])
    #                if g in pp:
    #                    ref_.append(g)
    #        ref_ = set(ref_)            
    #        temp = genomics.sort_(temp, idx=1, reverse_=True)
    #        yy = (len(temp) / 100) * 100
    #        total_ = len(ref_)
    #        interval = int(yy / 100)
    #        temp_ = []
    #        cnt = 0
    #        cc = 0
    #        for i in temp[0:yy]:
    #            cc += 1                
    #            if i[0] in ref_:
    #                cnt += 1
    #            if cc % interval == 0:
    #                value = float(cnt) / cc
    #                temp_.append(value)  
    #                cc = 0
    #                cnt = 0
    #        results.append([])
    #        for i in temp_:
    #            results[-1].extend([i])    
    #    print len(results[-1])        
    #    final.append([])
    #    for m in range(100):
    #        final[-1].append(0)        
    #    for m in results:
    #        for n in range(len(m)):                
    #            final[-1][n] += m[n]        
    #    for m in range(len(final[-1])):
    #        final[-1][m] = final[-1][m] / len(results)
    #for m in range(len(final[0])):
    #    to_add = (1 - final[0][m] - final[1][m] - final[2][m] - final[3][m]) / 4
    #    final[0][m] += to_add
    #    final[1][m] += to_add
    #    final[2][m] += to_add
    #    final[3][m] += to_add
    #final[0].insert(0,'Regulated_TF')
    #final[1].insert(0,'Regulated_nonTF')
    #final[2].insert(0,'Stable_TF')
    #final[3].insert(0,'Stable_nonTF')
    #genomics.write_file(final, '/Users/woojunshim/Research/Data/gene_group_prop_expression_percentile_only_expressed.txt')

    ### FOR H3K27ME3 WIDTH
    #width_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_widths.txt')    
    #genes = genomics.intersect(get_rownames(width_), list(regulated_tf)+list(regulated_nontf)+list(stable_tf)+list(stable_nontf))
    #print len(genes)
    #cols = get_colnames(exp_)
    #groups = ['regulated_tf','regulated_nontf','stable_tf','stable_nontf']
    #final = []
    #for group in groups:
    #    pp = set(genomics.read_file_items('/Users/woojunshim/Research/Data/'+group+'.txt'))
    #    results = []        
    #    for c in cols:
    #        ref_ = []
    #        temp = []
    #        for g in genes:                
    #            temp.append([g, width_[g][c]])
    #            if g in pp:
    #                ref_.append(g)
    #        ref_ = set(ref_)            
    #        temp = genomics.sort_(temp, idx=1, reverse_=True)
    #        yy = (len(temp) / 100) * 100
    #        total_ = len(ref_)
    #        interval = int(yy / 100)
    #        temp_ = []
    #        cnt = 0
    #        cc = 0
    #        for i in temp[0:yy]:
    #            cc += 1                
    #            if i[0] in ref_:
    #                cnt += 1
    #            if cc % interval == 0:
    #                value = float(cnt) / cc
    #                temp_.append(value)  
    #                cc = 0
    #                cnt = 0
    #        results.append([])
    #        for i in temp_:
    #            results[-1].extend([i])    
    #    print len(results[-1])        
    #    final.append([])
    #    for m in range(100):
    #        final[-1].append(0)        
    #    for m in results:
    #        for n in range(len(m)):                
    #            final[-1][n] += m[n]        
    #    for m in range(len(final[-1])):
    #        final[-1][m] = final[-1][m] / len(results)
    #for m in range(len(final[0])):
    #    to_add = (1 - final[0][m] - final[1][m] - final[2][m] - final[3][m]) / 4
    #    final[0][m] += to_add
    #    final[1][m] += to_add
    #    final[2][m] += to_add
    #    final[3][m] += to_add
    #final[0].insert(0,'Regulated_TF')
    #final[1].insert(0,'Regulated_nonTF')
    #final[2].insert(0,'Stable_TF')
    #final[3].insert(0,'Stable_nonTF')
    #genomics.write_file(final, '/Users/woojunshim/Research/Data/gene_group_prop_H3K27me3_width_percentile_all.txt')

    ### AVERAGE PROPORTION OF 4 GENE GROUPS (EXPRESSION VALUE) FOR ONLY EXPRESSED GENES
    #width_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_width_med_minus_current.txt')
    #width_ = exp_
    #genes = genomics.intersect(get_rownames(width_), get_rownames(exp_))
    #print len(genes)
    #cols = get_colnames(exp_)
    #groups = ['regulated_tf','regulated_nontf','stable_tf','stable_nontf']
    #final = []
    #for group in groups:
    #    pp = set(genomics.read_file_items('/Users/woojunshim/Research/Data/'+group+'.txt'))
    #    results = []        
    #    for c in cols:
    #        ref_ = []
    #        temp = []
    #        for g in genes:
    #            if exp_[g][c] > float(1):
    #                temp.append([g, width_[g][c]])
    #                if g in pp:
    #                    ref_.append(g)
    #        ref_ = set(ref_)            
    #        temp = genomics.sort_(temp, idx=1, reverse_=True)
    #        yy = (len(temp) / 100) * 100
    #        total_ = len(ref_)
    #        interval = int(yy / 100)
    #        temp_ = []
    #        cnt = 0
    #        cc = 0
    #        for i in temp[0:yy]:
    #            cc += 1                
    #            if i[0] in ref_:
    #                cnt += 1
    #            if cc % interval == 0:
    #                value = float(cnt) / cc
    #                temp_.append(value)  
    #                cc = 0
    #                cnt = 0
    #        results.append([])
    #        for i in temp_:
    #            results[-1].extend([i])    
    #    print len(results[-1])        
        
    #    final.append([])
    #    for m in range(100):
    #        final[-1].append(0)    
        
    #    for m in results:
    #        for n in range(len(m)):                
    #            final[-1][n] += m[n]        
    #    for m in range(len(final[-1])):
    #        final[-1][m] = final[-1][m] / len(results)
    #for m in range(len(final[0])):
    #    to_add = (1 - final[0][m] - final[1][m] - final[2][m] - final[3][m]) / 4
    #    final[0][m] += to_add
    #    final[1][m] += to_add
    #    final[2][m] += to_add
    #    final[3][m] += to_add
    #final[0].insert(0,'Regulated_TF')
    #final[1].insert(0,'Regulated_nonTF')
    #final[2].insert(0,'Stable_TF')
    #final[3].insert(0,'Stable_nonTF')
    #genomics.write_file(final, '/Users/woojunshim/Research/Data/gene_group_prop_expression_percentile.txt')


    ### PROPORTION OF GENE GROUPS BY THE NUMBER OF BROAD PEAKS 
    ### COUNT EVERY 10 
    #ref_ = genomics.read_file1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_stats_gene_groups.txt',sort_by=1)    
    #ref = {}
    #groups = ['regulated_tf','regulated_nontf','stable_tf','stable_nontf']
    #final = []
    #for i in groups:
    #    final.append([])        
    #    for i in range(56):
    #        final[-1].extend([0])   
    #print len(ref_) 
    #for i in ref_:
    #    if int(i[1]) not in ref:
    #        ref[int(i[1])] = []
    #    ref[int(i[1])].append(i[0])
    #print len(ref[0])    
    #temp = []
    #cnt = 0
    #for i in range(111, -1, -1):
    #    if i in ref:        
    #        temp += ref[i]            
    #    if i % 2 == 0:
    #        print len(temp)           
    #        g1 = len(genomics.intersect(temp, regulated_tf))
    #        g2 = len(genomics.intersect(temp, regulated_nontf))
    #        g3 = len(genomics.intersect(temp, stable_tf))
    #        g4 = len(genomics.intersect(temp, stable_nontf))
    #        final[0][cnt] = float(g1) / len(temp)
    #        final[1][cnt] = float(g2) / len(temp)
    #        final[2][cnt] = float(g3) / len(temp)
    #        final[3][cnt] = float(g4) / len(temp)
    #        to_add = (1 - final[0][cnt] - final[1][cnt] - final[2][cnt] - final[3][cnt]) / 4
    #        final[0][cnt] += to_add
    #        final[1][cnt] += to_add
    #        final[2][cnt] += to_add
    #        final[3][cnt] += to_add
    #        temp = []
    #        cnt += 1
    #final[0].insert(0,'Regulated_TF')
    #final[1].insert(0,'Regulated_nonTF')
    #final[2].insert(0,'Stable_TF')
    #final[3].insert(0,'Stable_nonTF')
    #genomics.write_file(final, '/Users/woojunshim/Research/Data/gene_group_prop_no.broad_peaks.txt')

    ### PROPORTION OF GENE GROUPS BY THE NUMBER OF BROAD-TSS PEAKS
    ### COUNT EVERY 4
    #ref_ = genomics.read_file1('/Users/woojunshim/Research/Data/genes_broad_h3k27me3_tss_stats_hg19_new.txt',sort_by=1)    
    #ref = {}
    #groups = ['regulated_tf','regulated_nontf','stable_tf','stable_nontf']
    #final = []    

    #for i in groups:
    #    final.append([])        
    #    for i in range(11):
    #        final[-1].extend([0])    
    #for i in ref_:
    #    if i[0] in all_:
    #        if int(i[1]) not in ref:
    #            ref[int(i[1])] = []
    #        ref[int(i[1])].append(i[0])
     
    #temp = []
    #cnt = 0
    #for i in range(108, -1, -1):
    #    if i in ref:        
    #        temp += ref[i]                  
    #    if i % 10 == 0:
    #        print len(temp)      
    #        g1 = len(genomics.intersect(temp, regulated_tf))
    #        g2 = len(genomics.intersect(temp, regulated_nontf))
    #        g3 = len(genomics.intersect(temp, stable_tf))
    #        g4 = len(genomics.intersect(temp, stable_nontf))
    #        final[0][cnt] = float(g1) / len(temp)
    #        final[1][cnt] = float(g2) / len(temp)
    #        final[2][cnt] = float(g3) / len(temp)
    #        final[3][cnt] = float(g4) / len(temp)
            #to_add = (1 - final[0][cnt] - final[1][cnt] - final[2][cnt] - final[3][cnt]) / 4
            #final[0][cnt] += to_add
            #final[1][cnt] += to_add
            #final[2][cnt] += to_add
            #final[3][cnt] += to_add
    #        temp = []
    #        cnt += 1
    #final[0].insert(0,'Variably_expressed_TF')
    #final[1].insert(0,'Variably_expressed_nonTF')
    #final[2].insert(0,'Stably_expressed_TF')
    #final[3].insert(0,'Stably_expressed_nonTF')
    #genomics.write_file(final, '/Users/woojunshim/Research/Data/gene_group_prop_no.broad_TSS_peaks_new.txt')

    ### PROPORTIONS OF GENE GROUPS FOR NEGATIVE GROUP AND ALL 
    #ref_ = genomics.read_file1('/Users/woojunshim/Research/Data/genes_broad_tss_stats.txt',sort_by=1)    
    #ref = {}
    #groups = ['regulated_tf','regulated_nontf','stable_tf','stable_nontf']
    #final = []
    #for i in groups:
    #    final.append([])        
    #    for i in range(1):
    #        final[-1].extend([0])   
    #print len(ref_) 
    #for i in ref_:
    #    if i[0] in all_:
    #        if int(i[1]) not in ref:
    #            ref[int(i[1])] = []
    #        ref[int(i[1])].append(i[0])
    #print len(ref)    
    #temp = []
    #cnt = 0
    #for i in range(109):
    #    if i in ref:        
    #        temp += ref[i]               
        
    #print len(temp)           
    #g1 = len(genomics.intersect(temp, regulated_tf))
    #g2 = len(genomics.intersect(temp, regulated_nontf))
    #g3 = len(genomics.intersect(temp, stable_tf))
    #g4 = len(genomics.intersect(temp, stable_nontf))
    #final[0][cnt] = float(g1) / len(temp)
    #final[1][cnt] = float(g2) / len(temp)
    #final[2][cnt] = float(g3) / len(temp)
    #final[3][cnt] = float(g4) / len(temp)
    #to_add = (1 - final[0][cnt] - final[1][cnt] - final[2][cnt] - final[3][cnt]) / 4
    #final[0][cnt] += to_add
    #final[1][cnt] += to_add
    #final[2][cnt] += to_add
    #final[3][cnt] += to_add
    #temp = []
    #cnt += 1
    #final[0].insert(0,'Regulated_TF')
    #final[1].insert(0,'Regulated_nonTF')
    #final[2].insert(0,'Stable_TF')
    #final[3].insert(0,'Stable_nonTF')
    #genomics.write_file(final, '/Users/woojunshim/Research/Data/gene_group_prop_no.broad_TSS_peaks_all.txt')

    ### WILCOXON RANK SUM TEST BETWEEN BROAD AND NARROW PEAK GENES 
    #names = ['E038','E082','E095','E104','E105','E070','E071','E037','E047']
    #t1 = read_table1('/Users/woojunshim/Research/Data/jaccard_btw_broad_genes.txt')
    #t2 = read_table1('/Users/woojunshim/Research/Data/jaccard_btw_narrow_genes.txt')
    #g1, g2 = [], []
    #for c1 in names:
    #    for c2 in names:
    #        if c1 != c2:
    #            g1.append(t1[c1][c2])
    #            g2.append(t2[c1][c2])
    #print np.mean(g1)
    #print np.mean(g2)
    #s, p = stat.wilcoxon(g1, g2)
    #print s, p
  

    ### TABLE FOR (MEDIAN - CURRENT H3K27ME3 WIDTH) 
    #width_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_widths.txt')
    #results = initiate_table(width_)
    #for g in width_:
    #    temp = []
    #    for c in width_[g]:
    #        temp.append(width_[g][c])
    #    median_ = np.median(temp)
    #    for c in width_[g]:
    #        value = median_ - width_[g][c]
    #        results[g][c] = value
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_width_med_minus_current.txt')

    ### CALCULATE PROPORTIONS OF [BROAD + REPRESSED] / [REPRESSED] FOR ALL CELL TYPES (FOR BOTH TF AND ALL GENES)
    #broad_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_binary.txt')
    #loc_ = read_table1('/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt')
    #genes = genomics.intersect(get_rownames(broad_), get_rownames(loc_))
    #genes = genomics.intersect(genes, get_rownames(exp_))
    #print len(genes)
    #cols = get_colnames(exp_)
    #results = []
    #for col in cols:
    #    total_tf, total_genes = 0, 0
    #    r_tf, r_genes = 0, 0
    #    for g in genes:            
    #        if exp_[g][col] < float(1):
    #            total_genes += 1
    #            if g in tf_list:
    #                total_tf += 1
    #                if broad_[g][col] == float(1):
    #                    r_tf += 1
    #            else:
    #                if broad_[g][col] == float(1):
    #                    r_genes += 1
    #    results.append([col, float(r_tf)/total_tf, float(r_genes)/total_genes])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/prop_broad_over_repressed_.txt')


    ### PROPORTIONS OF EXPRESSED GENES BETWEEN BROAD AND NARROW PEAKS 
    #broad_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_binary.txt')
    #loc_ = read_table1('/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt')
    #genes = genomics.intersect(get_rownames(exp_), get_rownames(broad_))
    #genes = genomics.intersect(genes, get_rownames(loc_))
    #cols = get_colnames(exp_)
    #results = []
    #for c in cols:
    #    tbc, tnc = 0, 0
    #    bc, nc = 0, 0
    #    for g in genes:
    #        if loc_[g][c] != float(0):
    #            if broad_[g][c] == float(1):
    #                tbc += 1
    #                if exp_[g][c] > float(1):
    #                    bc += 1
    #            else:
    #                tnc += 1
    #                if exp_[g][c] > float(1):
    #                    nc += 1
    #    results.append([c, float(bc)/tbc, float(nc)/tnc])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/prop_exp_vs_broadness.txt')   

    ### JACCARD INDEX BETWEEN BROAD GENES AND NARROW GENES 
    #names = ['E038','E082','E095','E104','E105','E070','E071','E037','E047']
    #broad_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_binary.txt')
    #loc_ = read_table1('/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt')
    #genes = genomics.intersect(get_rownames(loc_), get_rownames(broad_))    
    #cols = epigenomes
    #broad, narrow = {}, {}
    #for c1 in names:
    #    broad[c1] = {}
    #    narrow[c1] = {}
    #    for c2 in names:
    #        broad[c1][c2] = 0.0
    #        narrow[c1][c2] = 0.0
    #ref_b, ref_n = {}, {}
    #for c1 in cols: 
    #    ref_b[c1], ref_n[c1] = [], []       
    #    for g in genes:
    #        if loc_[g][c1] != float(0):
    #            if broad_[g][c1] == float(1):
    #                ref_b[c1].append(g)
    #            elif broad_[g][c1] == float(0):
    #                ref_n[c1].append(g)
    #cnt = 0
    #for c1 in names:
    #    for c2 in names:
    #        bi = jaccard_index(ref_b[c1], ref_b[c2])
    #        ni = jaccard_index(ref_n[c1], ref_n[c2])
    #        broad[c1][c2] = bi
    #        narrow[c1][c2] = ni
    #        print cnt
    #        cnt += 1
    #genomics.write_table1(broad, '/Users/woojunshim/Research/Data/jaccard_btw_broad_genes.txt')
    #genomics.write_table1(narrow, '/Users/woojunshim/Research/Data/jaccard_btw_narrow_genes.txt')


    ### FISHER'S EXACT TEST OF THE TFS BETWEEN BROAD AND NARROW GENES
    ### ENRICHMENT OF TF
    #names = ['E038','E082','E095','E104','E105','E070','E071','E037','E047']
    #broad_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_binary.txt')
    #loc_ = read_table1('/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt')
    #genes = genomics.intersect(get_rownames(loc_), get_rownames(broad_))    
    #cols = epigenomes
    #ref_ = set(tf_list)
    #ref_b, ref_n = {}, {}
    #for c1 in cols: 
    #    ref_b[c1], ref_n[c1] = [], []       
    #    for g in genes:
    #        if loc_[g][c1] != float(0):
    #            if broad_[g][c1] == float(1):
    #                ref_b[c1].append(g)
    #            elif broad_[g][c1] == float(0):
    #                ref_n[c1].append(g)
    #results = []
    #for col in cols:
    #    print col
    #    results.append([col])
    #    a,b,c,d = 0,0,0,0
    #    for g in ref_b[col]:
    #        if g in tf_list:
    #            a += 1
    #        else:
    #            b += 1
    #    for g in ref_n[col]:
    #        if g in tf_list:
    #            c += 1
    #        else:
    #            d += 1
    #    print a,b,c,d
    #    s, p = stat.fisher(a,b,c,d)
    #    results[-1].extend([p])        
        
    #    s, p = stat.fisher(c,d,a,b)
    #    results[-1].extend([p])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/fet_tf_btw_broadness.txt')


    ### CORRELATION BETWEEN RANKS OF GENES (BY EXP. AND H3K27ME3 PEAK WIDTH)
    # 1. ONLY BROADEST H3K27ME3 PEAKS
    #width_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_widths.txt')
    #genes = genomics.intersect(get_rownames(width_), get_rownames(exp_))
    #print len(genes)
    #results = [['#cell','spearman','p_value']]
    #cols = get_colnames(exp_)
    #for c in cols:
    #    t1, t2 = [], {}
    #    for g in genes:
    #        t1.append([g, width_[g][c]])
    #        t2[g] = exp_[g][c]
    #    t1 = genomics.sort_(t1, idx=1, reverse_=True)        
    #    v1, v2 = [], []
    #    for i in range(len(t1)):
    #        g = t1[i][0]
    #        v1.append(t1[i][1])
    #        v2.append(t2[g])
    #    s, p = stat.spearman(v1, v2)
    #    results.append([c, s, p])
    #print v1[:10]
    #print v2[:10]
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/spearman_cor_btw_broadest_width_vs_exp.txt')

    #main('/Volumes/Project/Research/bigdata/roadmap/narrow_peaks/H3K27me3/E129-H3K27me3.narrowPeak', output_='test.txt', tss__='/Users/woojunshim/Research/Data/hg19_TSS_.txt', max_width__=2500, dominant_=False, convert_DS=False, centre_=True, remove_ncrna_=False)

    # 2. WITH ALL H3K27ME3 PEAKS COMBINED 
    #temp = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_widths.txt')
    #genes = get_rownames(temp)
    #results = {}
    #for g in genes:
    #    results[g] = {}
    #    for epi in epigenomes:
    #        results[g][epi] = 0.0
    #cnt = 0
    #for epi in epigenomes:
    #    cnt += 1
    #    print cnt
    #    file_ = '/Users/woojunshim/Research/bigdata/roadmap/broad_peaks/'+epi+'-H3K27me3.broadPeak'
    #    aa = main(file_, output_=None, tss__='/Users/woojunshim/Research/Data/hg19_TSS_.txt', max_width__=2500, dominant_=False, convert_DS=False, centre_=True, remove_ncrna_=False)
    #    for i in aa:
    #        if len(i) == 2:
    #            g = i[0]
    #            if g in genes:
    #                results[g][epi] += float(i[1])
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_widths_sum.txt')

    ### TABLE FOR EXPRESSION PROPORTIONS FOR GENES WHEN CATEGORISED BY BROADNESS OR LOCATION
    #exp_ = read_table1('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.txt')
    #broad_ = read_table1('/Users/woojunshim/Research/Data/broad_binary_46.txt')
    #loc_ = read_table1('/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt')
    #results = []


    ### ADD GENE GROUP CLASS TO 'EXP_BROAD_STAT.TXT'
    #temp = read_table1('/Users/woojunshim/Research/Data/exp_broad_stat.txt')
    #for g in temp:
    #    if g in regulated_tf:
    #        tag = 1
    #    elif g in regulated_nontf:
    #        tag = 2
    #    elif g in stable_tf:
    #        tag = 3
    #    else:
    #        tag = 4
    #    temp[g]['group'] = tag
    #genomics.write_table1(temp, '/Users/woojunshim/Research/Data/exp_broad_stat_.txt')

    ### EXTRACT [EXP_CLASS, BROADNESS, LOCATION, GENE_CLASS] FOR ALL GENES
    #exp_ = read_table1('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.txt')
    #broad_ = read_table1('/Users/woojunshim/Research/Data/broad_binary_46.txt')
    #loc_ = read_table1('/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt')
    #genes = genomics.intersect(get_rownames(exp_), get_rownames(broad_))
    #genes = genomics.intersect(genes, get_rownames(loc_))
    #print len(genes)
    #cols = get_colnames(exp_)
    #for c in cols:   # DISCRETISING THE EXPRESSION DATA
    #    temp = []
    #    for g in exp_:
    #        if exp_[g][c] > float(1):
    #             temp.append([g, exp_[g][c]])
    #        else:
    #            exp_[g][c] = 0
    #    temp = genomics.sort_(temp, idx=1, reverse_=False)
    #    iv = len(temp) / 4
    #    class_ = 1
    #    for j in range(1, len(temp)+1):
    #        if j%iv == 0:
    #            class_ += 1
    #        temp[j-1][1] = class_
    #    for i in temp:
    #        g = i[0]
    #        class__ = i[1]
    #        exp_[g][c] = class__
    #results = {}
    #for g in genes:
    #    results[g] = {}
    #    if g in regulated_tf:
    #        tag = 1
    #    elif g in regulated_nontf:
    #        tag = 2
    #    elif g in stable_tf:
    #        tag = 3
    #    else:
    #        tag = 4
    #    for c in cols:
    #        results[g][c] = str(exp_[g][c])+','+str(int(broad_[g][c]))+','+str(int(loc_[g][c]))+','+str(tag)
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/gene_features_table.txt')


    ### COMBINE EXP AND BROAD_BINARY_46.STAT.TXT
    #t1 = read_table1('/Users/woojunshim/Research/Data/exp_binary_46_stat.txt')
    #t2 = read_table1('/Users/woojunshim/Research/Data/broad_binary_46_stat.txt')
    #genes = genomics.intersect(get_rownames(t1), get_rownames(t2))
    #print len(genes)
    #results = []
    #for g in genes:
    #    results.append([g, t1[g]['value'], t2[g]['value']])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/exp_binary_stat.txt')

    ### ENRICHMENT OF GROUPS OF GENES AMONG GENES RANKED BY NUMBER OF BROAD PEAKS 
    #ref1, ref2, ref3, ref4 = regulated_tf, regulated_nontf, stable_tf, stable_nontf
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_stats_.txt')
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/genes_tss_stats.txt')
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/genes_broad_tss_stats.txt')
    #temp = genomics.sort_(temp, idx=1, reverse_=True)
    #tt = []
    #for i in temp:
    #    if i[0] in all_:
    #        tt.append(i[0])
    #print len(tt)
    #results1, a = density_analysis(tt, ref_list=ref1, bin_size_=0.01, odd_ratio_=True, background_ratio_=None, accumulative_=False)
    #results2, a = density_analysis(tt, ref_list=ref2, bin_size_=0.01, odd_ratio_=True, background_ratio_=None, accumulative_=False)
    #results3, a = density_analysis(tt, ref_list=ref3, bin_size_=0.01, odd_ratio_=True, background_ratio_=None, accumulative_=False)
    #results4, a = density_analysis(tt, ref_list=ref4, bin_size_=0.01, odd_ratio_=True, background_ratio_=None, accumulative_=False)
    #results = [['Regulated_TF']]
    #for i in results1:
    #    results[-1].extend([i])
    #results.append(['Regulated_nonTF'])
    #for i in results2:
    #    results[-1].extend([i])
    #results.append(['Stable_TF'])
    #for i in results3:
    #    results[-1].extend([i])
    #results.append(['Stable_nonTF'])
    #for i in results4:
    #    results[-1].extend([i])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/enrichment_group_genes_by_no.broad_tss_peaks.txt')


    ### CV FOR GROUPS OF GENES (AND NUMBER OF CELL TYPES EXPRESSED)
    #temp = read_table1('/Users/woojunshim/Research/Data/cv_genes.txt')
    #exp_ = read_table1('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.txt')
    #for g in temp:
    #    temp[g]['no.expressed'] = 0
    #    if g in regulated_tf:
    #        tag = 1
    #    elif g in regulated_nontf:
    #        tag = 2
    #    elif g in stable_tf:
    #        tag = 3
    #    else:
    #        tag = 4
    #    for c in exp_[g]:
    #        if exp_[g][c] > float(1):
    #            temp[g]['no.expressed'] += 1
    #    temp[g]['gene_class'] = tag
    #genomics.write_table1(temp, '/Users/woojunshim/Research/Data/cv_genes_.txt')


    ### ENRICHMENT OF 4 GROUPS OF GENES BY BROADNESS AND LOCATION OF PEAKS ACROSS CELL TYPES
    ### LOCATION
    #pathway = '/Users/woojunshim/Research/Data/'
    #subclass = read_table1('/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt')
    #broad = read_table1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_binary.txt')
    #cols = genomics.intersect(get_colnames(subclass), get_colnames(broad))
    #gs = get_rownames(subclass)
    #refs = ['regulated_tf','regulated_nontf','stable_tf','stable_nontf']
    #results = [['#cell','regulated_tf','regulated_nontf','stable_tf','stable_nontf']]
    #location_ = float(1)
    #for col in cols:
    #    results.append([col])
    #    for r in refs:
    #        ref = set(genomics.read_file_items(pathway+r+'.txt'))            
    #        a,b,c,d = 0,0,0,0
    #        for g in gs:
    #            if g in ref:
    #                if subclass[g][col] == location_:
    #                    a += 1
    #                else:
    #                    b += 1
    #            else:
    #                if subclass[g][col] == location_:
    #                    c += 1
    #                else:
    #                    d += 1
    #        s, p = stat.fisher(a,b,c,d)
            #value = -np.log10(p)
            #if value == -float(0):
            #    value = 0.0
    #        results[-1].extend([s])
    #genomics.write_file(results, pathway+'fet_upstream.txt')

    ### ENRICHMENT OF 4 GROUPS OF GENES BY BROADNESS AND LOCATION OF PEAKS ACROSS CELL TYPES
    ### BROADNESS
    #pathway = '/Users/woojunshim/Research/Data/'
    #subclass = read_table1('/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt')
    #broad = read_table1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_binary.txt')
    #cols = genomics.intersect(get_colnames(subclass), get_colnames(broad))
    #gs = get_rownames(broad)
    #refs = ['regulated_tf','regulated_nontf','stable_tf','stable_nontf']
    #results = [['#cell','regulated_tf','regulated_nontf','stable_tf','stable_nontf']]
    #broad_ = float(1)
    #max_ = 0
    #for col in cols:
    #    results.append([col])
    #    for r in refs:
    #        ref = set(genomics.read_file_items(pathway+r+'.txt'))            
    #        a,b,c,d = 0,0,0,0
    #        for g in gs:
    #            if subclass[g][col] != float(0):
    #                if g in ref:
    #                    if broad[g][col] == broad_:
    #                        a += 1
    #                    else:
    #                        b += 1
    #                else:
    #                    if broad[g][col] == broad_:
    #                        c += 1
    #                    else:
    #                        d += 1
    #        s, p = stat.fisher(a,b,c,d)
    #        if s == np.inf:
    #            s = max_
    #        if s > max_:
    #            max_ = s
    #        results[-1].extend([s])
    #genomics.write_file(results, pathway+'fet_broad.txt')
                    







    #colnames = get_colnames(broad)
    #results = {}
    #print len(colnames)
    #print len(subclass)
    #for i in range(1, 4):
    #    results[str(i)] = [0, 0]
    #for gene in subclass:
    #    for col in colnames:
    #        if subclass[gene][col] != 0:
    #            class_ = int(subclass[gene][col])
    #            value_ = int(broad[gene][col])                
    #            if value_ == 1:
    #                results[str(class_)][0] += 1
    #            else:
    #                results[str(class_)][1] += 1
    #output_ = [] 
    #print results   
    #for i in range(1, 4):
    #    fore_ = str(i)
    #    a = results[fore_][0]
    #    b = results[fore_][1]
    #    c,d = 0,0
    #    for m in results:
    #        if fore_ != m:
    #            c += results[m][0]
    #            d += results[m][1]
    #    print a,b,c,d
    #    s, p = stat.fisher(a,b,c,d)
    #    output_.append([fore_, s, p])
    #genomics.write_file(output_, '/Users/woojunshim/Research/Data/fet_location_vs_broad_.txt')    

    ### TEST MUTUAL INFORMATION
    #a = [[1,1],[1,1],[1,1],[1,0],[1,0]]
    #ii = mutual_information(a)


    ### WILCOXON TEST FOR NUMBER OF BROAD PEAKS BETWEEN REGULATED AND STABLE TFS 
    #counts = genomics.read_file1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_stats_.txt')
    #fore_g = set(genomics.read_file_items('/Users/woojunshim/Research/Data/regulated_tf.txt'))
    #back_g = set(genomics.read_file_items('/Users/woojunshim/Research/Data/regulated_nontf.txt'))
    #fore_g = set(tf_list)
    #back_g = set(non_tf_list)
    #fore = []
    #back = []
    #for item in counts:
    #    g = item[0]
    #    value = float(item[1])
    #    if g in fore_g:
    #        fore.append(value)
    #    elif g in back_g:
    #        back.append(value)
    #print len(fore)
    #print len(back)
    #s, p = stat.mann(fore, back)
    #print s, p


    ### FIND MEAN AND SD OF GIVEN EXP. DISTRIBUTION
    #epi = 'E059'
    #broad = float(1)
    #tss = float(1)
    #exp_ = read_table1('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.txt')
    #loc_ = read_table1('/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt')
    #broad_ = read_table1('/Users/woojunshim/Research/Data/broad_binary_46.txt')
    #b_group, t_group = [0.0, 1.0], [0.0, 1.0]
    #results = [['broad','tss','mean','sd']]


    ### STATISTICS FOR PEAKS ACROSS CELL TYPES
    #temp = read_table1('/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt')
    #results = []
    #cols = get_colnames(temp)
    #for col in cols:
    #    results.append([col,0,0,0])
    #    for g in temp:            
    #        v = int(temp[g][col])
    #        if v != 0:
    #            results[-1][v] += 1
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/peak_location_stat.txt')


    ### MUTUAL INFORMATION BETWEEN BROADNESS AND LOCATION
    #broad_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_binary.txt')
    #loc_ = read_table1('/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt')
    #results = []
    #cols = get_colnames(broad_)
    #genes = genomics.intersect(get_rownames(broad_), get_rownames(loc_))
    #total = []
    #for col in cols:
    #    temp = []
    #    for g in genes:
    #        if loc_[g][col] != float(0):
    #            temp.append([loc_[g][col], broad_[g][col]])
    #            total.append([loc_[g][col], broad_[g][col]])
    #    l, b = [], []
    #    for g in genes:
    #        l.append(loc_[g][col])
    #        b.append(broad_[g][col])
    #    results.append([col, mutual_information(temp), entropy(b), entropy(l)])
    #results.append(['all', mutual_information(total)])
    #results.insert(0, ['#cell','MI','entropy(broad)','entropy(location)'])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/mutual_information_broad_location_entropy.txt')




    ### DISTRIBUTION OF TFS (CV > 1) BY EXPRESSION VALUE ACROSS CELL TYPES
    ### DENSITY ANALYSIS
    #all_cv_ = read_table1('/Users/woojunshim/Research/Data/cv_genes.txt')
    #rows = get_rownames(all_cv_)
    #genes = []
    #for g in all_cv_:
    #    if all_cv_[g]['value'] > 1:
    #        genes.append(g)
    #print len(genes)
    #exp_ = read_table1('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols_exp.txt')
    #exp_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_widths.txt')
    #rows = genomics.intersect(rows, get_rownames(exp_))
    #rows = get_rownames(exp_)
    #print len(rows)
    #ref = genomics.read_file_items('/Users/woojunshim/Research/Data/stable_nontf.txt')
    #results = []
    #cols = get_colnames(exp_)    
    #for c in cols:
    #    temp = []
    #    for g in rows:
    #        temp.append([g, exp_[g][c]])
    #    temp = genomics.sort_(temp, idx=1, reverse_=True)
    #    tt = []
    #    for i in temp:
    #        tt.append(i[0])
    #    results1, a = density_analysis(tt, ref_list=ref, bin_size_=0.01, odd_ratio_=True, background_ratio_=None, accumulative_=False)
    #    results.append([c])
    #    for i in results1:
    #        results[-1].extend([i])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/density_stable_nontf_h3k27me3.txt')


    ### STATISTICS OF CV TABLE
    #temp = read_table1('/Users/woojunshim/Research/Data/cv_genes.txt')
    #results = {}
    #rows = ['regulated','constitutive']
    #cols = ['TF','nonTF']
    #tf = []
    #nontf = []
    #s_tf = []
    #s_nontf = []
    #for r in rows:
    #    results[r] = {}
    #    for c in cols:
    #        results[r][c] = 0 
    #for g in temp:
    #    if temp[g]['TF'] == float(1):
    #        if temp[g]['value'] > 1:
    #            results['regulated']['TF'] += 1
    #            tf.append(g)
    #        else:
    #            results['constitutive']['TF'] += 1
    #            s_tf.append(g)
    #    elif temp[g]['TF'] == float(0):
    #        if temp[g]['value'] > 1:
    #           results['regulated']['nonTF'] += 1
    #           nontf.append(g)
    #        else:
    #            results['constitutive']['nonTF'] += 1
    #            s_nontf.append(g)
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/cv_table.txt')
    #genomics.write_file_items(tf, '/Users/woojunshim/Research/Data/regulated_tf.txt')
    #genomics.write_file_items(nontf, '/Users/woojunshim/Research/Data/regulated_nontf.txt')
    #genomics.write_file_items(s_tf, '/Users/woojunshim/Research/Data/stable_tf.txt')
    #genomics.write_file_items(s_nontf, '/Users/woojunshim/Research/Data/stable_nontf.txt')

    ### EXTRACT GENE TABLES WHERE THE EXPRESSION IS OBSERVED IN > 2 CELLS 
    #temp = read_table1('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.txt')
    #cols = get_colnames(temp)
    #genes = []
    #for g in temp:
    #    cnt = 0
    #    for c in cols:
    #        if temp[g][c] > 1:
    #            cnt += 1
    #    if cnt > 2:
    #        genes.append(g)
    #temp_ = subset_table(temp, rows=genes, cols=cols)
    #genomics.write_table1(temp_, '/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols_exp.txt')

    ### ANALYSIS OF BROAD AND TSS GENES ACROSS CELL TYPES
    # 1A. OVERLAP BETWEEN THEM 
    #broad_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_binary.txt')
    #loc_ = read_table1('/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt')
    #genes = genomics.intersect(get_rownames(broad_), get_rownames(loc_))
    #results = []
    #location = 'downstream'
    #broad = 'not_broad'
    #counts = [['#cell', broad, location, 'p('+broad+')', 'p('+location+')', 'p('+broad+'|'+location+')','p('+location+'|'+broad+')']]
    #for epi in epigenomes:
    #    b, l = [], []
    #    b_l = 0
    #    total_ = 0
    #    for g in genes:
    #        if loc_[g][epi] != float(0):
    #            total_ += 1
    #            if broad_[g][epi] == float(0):
    #                b.append(g)
    #            if loc_[g][epi] == float(3):
    #                l.append(g)
    #            if broad_[g][epi] == float(0) and loc_[g][epi] == float(3):
    #                b_l += 1
    #    union_ = genomics.union(b, l)
    #    inter_ = genomics.intersection(b, l)        
    #    results.append([epi, float(len(inter_)) / len(union_)])
    #    counts.append([epi, len(b), len(l), float(len(b))/total_, float(len(l))/total_, float(b_l)/len(l), float(b_l)/len(b)])
    #genomics.write_file(counts, '/Users/woojunshim/Research/Data/'+broad+'_'+location+'_counts.txt')
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/jaccard_broad_tss.txt')

    # 1A. CONDITIONAL PROBABILITIES BETWEEN BROADNESS AND LOCATION OF PEAKS 
    #loc_counts = genomics.read_file('/Users/woojunshim/Research/Data/peak_location_stat.txt', [1,2,3], rowname='0')
    #bro_counts = genomics.read_file('/Users/woojunshim/Research/Data/broad_tss_gene_counts.txt', [1], rowname='0')
    #broad_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_binary.txt')
    #loc_ = read_table1('/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt')
    #genes = genomics.intersect(get_rownames(broad_), get_rownames(loc_))
    #print len(genes)
    #loc_label = ['upstream','TSS','downstream']
    #bro_label = ['not-broad','broad']
    #results = [['#cell']]
    #for i in range(1, 4):
    #    loc = loc_label[i-1]           
    #    for j in range(2):
    #        bro = bro_label[j]
    #        results[-1].extend(['#'+bro+'|'+loc])
    #        results[-1].extend(['#'+loc+'|'+bro])
    #results[-1].extend(['p(broad)','p(upstream)','p(TSS)','p(downstream)'])
    #for epi in epigenomes:
    #    total_peaks = int(loc_counts[epi][0][0]) + int(loc_counts[epi][0][1]) + int(loc_counts[epi][0][2])
    #    loc_c, bro_c, together = 0, 0, 0
    #    results.append([epi])
    #    for i in range(1, 4):
    #        loc = loc_label[i-1]           
    #        for j in range(2):
    #            bro = bro_label[j]
    #            for g in genes:
    #                if loc_[g][epi] == float(i):
    #                    loc_c += 1
    #                if broad_[g][epi] == float(j):
    #                    bro_c += 1
    #                if loc_[g][epi] == float(i) and broad_[g][epi] == float(j):
    #                    together += 1
    #            results[-1].extend([float(together)/loc_c, float(together)/bro_c])
    #    results[-1].extend([float(bro_counts[epi][0][0])/total_peaks, float(loc_counts[epi][0][0])/total_peaks, float(loc_counts[epi][0][1])/total_peaks, float(loc_counts[epi][0][2])/total_peaks])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/cond_probabilities_broad_vs_location.txt')


    # 1B. PROBABILITY ANALYSIS (P(TF|BROAD, TSS), P(EXP|BROAD, TSS))
    #broad_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_binary.txt')
    #loc_ = read_table1('/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt')
    #exp_ = read_table1('/Users/woojunshim/Research/Data/exp_binary_46.txt')
    #epigenomes = get_colnames(exp_)
    #genes = genomics.intersect(get_rownames(broad_), get_rownames(loc_))  
    #genes = genomics.intersect(genes, get_rownames(exp_))  
    #results = [['#cell','p(TF)','p(broad|TF)','p(broad|non-TF)','p(TSS|TF)','p(TSS|non-TF)','p(exp|broad,TSS)','p(exp|non-broad,TSS)','p(exp|broad,not-TSS)','p(exp|not-broad,not_TSS)']]
    #tf_list = set(genomics.read_file_items('/Users/woojunshim/Research/Data/regulated_tf.txt'))
    #print len(tf_list)
    #for epi in epigenomes:        
    #    total_g = 0
    #    total_tf = 0
    #    total_b_t = 0
    #    total_nb_t = 0
    #    total_b_nt = 0
    #    total_nb_nt = 0
    #    total_ntf = 0 
    #    b_tf, t_tf, exp_b_t, exp_nb_t, exp_b_nt, exp_nb_nt, b_ntf, t_ntf = 0,0,0,0,0,0,0,0 
    #    for g in genes:
    #        if loc_[g][epi] != float(0):
    #            total_g += 1
    #            if g in tf_list:
    #                total_tf += 1                    
    #                if broad_[g][epi] == float(1):
    #                    b_tf += 1
    #                if loc_[g][epi] == float(2):
    #                    t_tf += 1
    #            else:
    #                total_ntf += 1
    #                if broad_[g][epi] == float(1):
    #                    b_ntf += 1
    #                if loc_[g][epi] == float(2):
    #                    t_ntf += 1
    #            if (broad_[g][epi] == float(1)) and (loc_[g][epi] == float(2)):
    #                total_b_t += 1
    #                if exp_[g][epi] == float(1):
    #                    exp_b_t += 1
    #            if (broad_[g][epi] == float(0)) and (loc_[g][epi] == float(2)):
    #                total_nb_t += 1
    #                if exp_[g][epi] == float(1):
    #                    exp_nb_t += 1
    #            if (broad_[g][epi] == float(1)) and (loc_[g][epi] != float(2)):
    #                total_b_nt += 1
    #                if exp_[g][epi] == float(1):
    #                    exp_b_nt += 1
    #            if (broad_[g][epi] == float(0)) and (loc_[g][epi] != float(2)):
    #                total_nb_nt += 1
    #                if exp_[g][epi] == float(1):
    #                    exp_nb_nt += 1
    #    results.append([epi, float(total_tf)/total_g, float(b_tf)/total_tf, float(b_ntf)/total_ntf, float(t_tf)/total_tf, float(t_ntf)/total_ntf, float(exp_b_t)/total_b_t, float(exp_nb_t)/total_nb_t, float(exp_b_nt)/total_b_nt, float(exp_nb_nt)/total_nb_nt])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/probabilities_broad_tss_exp_regulated_tf.txt')

    # 1C. PROBABILITY ANALYSIS (WITH CONSTINUOUS VARIABLE FOR EXPRESSION)    
    # REMOVED ALL ZERO VALUES -> LOG10(RPKM) -> NORMALISE USING (X-MIN) / (MAX-MIN)
    #broad_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_binary.txt')
    #loc_ = read_table1('/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt')
    #exp_ = read_table1('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols_exp.txt')
    #epigenomes = get_colnames(exp_)
    #genes = genomics.intersect(get_rownames(broad_), get_rownames(loc_))  
    #genes = genomics.intersect(genes, get_rownames(exp_))  
    #results = [['#cell','p(TF)','p(broad|TF)','p(broad|non-TF)','p(TSS|TF)','p(TSS|non-TF)','p(exp|broad,TSS)','p(exp|non-broad,TSS)','p(exp|broad,not-TSS)','p(exp|not-broad,not_TSS)']]
    #tf_list = set(genomics.read_file_items('/Users/woojunshim/Research/Data/regulated_tf.txt'))
    #print len(tf_list)
    #for epi in epigenomes:        
    #    total_g = 0
    #    total_tf = 0
    #    total_b_t = 0
    #    total_nb_t = 0
    #    total_b_nt = 0
    #    total_nb_nt = 0
    #    total_ntf = 0 
    #    exp_b_t, exp_nb_t, exp_b_nt, exp_nb_nt, all_ = [], [], [], [], []
    #    b_tf, t_tf, b_ntf, t_ntf = 0,0,0,0
    #    for g in genes:
    #        if exp_[g][epi] != float(0): 
    #            if loc_[g][epi] != float(0):
    #                total_g += 1
    #                if g in tf_list:
    #                    total_tf += 1                    
    #                    if broad_[g][epi] == float(1):
    #                        b_tf += 1
    #                    if loc_[g][epi] == float(2):
    #                        t_tf += 1
    #                else:
    #                    total_ntf += 1
    #                    if broad_[g][epi] == float(1):
    #                        b_ntf += 1
    #                    if loc_[g][epi] == float(2):
    #                        t_ntf += 1
    #                if (broad_[g][epi] == float(1)) and (loc_[g][epi] == float(2)):
    #                    total_b_t += 1
    #                    exp_b_t.append(np.log10(exp_[g][epi]))
    #                    all_.append(np.log10(exp_[g][epi]))
    #                if (broad_[g][epi] == float(0)) and (loc_[g][epi] == float(2)):
    #                    total_nb_t += 1
    #                    exp_nb_t.append(np.log10(exp_[g][epi]))
    #                    all_.append(np.log10(exp_[g][epi]))
    #                if (broad_[g][epi] == float(1)) and (loc_[g][epi] != float(2)):
    #                    total_b_nt += 1
    #                    exp_b_nt.append(np.log10(exp_[g][epi]))
    #                    all_.append(np.log10(exp_[g][epi]))
    #                if (broad_[g][epi] == float(0)) and (loc_[g][epi] != float(2)):
    #                    total_nb_nt += 1
    #                    exp_nb_nt.append(np.log10(exp_[g][epi]))
    #                    all_.append(np.log10(exp_[g][epi]))
    #    min_ = np.min(all_)
    #    max_ = np.max(all_)
    #    for no in range(len(exp_b_t)):
    #        exp_b_t[no] = (exp_b_t[no] - min_) / (max_ - min_)
    #    for no in range(len(exp_nb_t)):
    #        exp_nb_t[no] = (exp_nb_t[no] - min_) / (max_ - min_)
    #    for no in range(len(exp_b_nt)):
    #        exp_b_nt[no] = (exp_b_nt[no] - min_) / (max_ - min_)
    #    for no in range(len(exp_nb_nt)):
    #        exp_nb_nt[no] = (exp_nb_nt[no] - min_) / (max_ - min_)
    #    mu_b_t, mu_nb_t, mu_b_nt, mu_nb_nt = np.mean(exp_b_t), np.mean(exp_nb_t), np.mean(exp_b_nt), np.mean(exp_nb_nt)
    #    sig_b_t, sig_nb_t, sig_b_nt, sig_nb_nt = np.std(exp_b_t), np.std(exp_nb_t), np.std(exp_b_nt), np.std(exp_nb_nt)
    #    results.append([epi, float(total_tf)/total_g, float(b_tf)/total_tf, float(b_ntf)/total_ntf, float(t_tf)/total_tf, float(t_ntf)/total_ntf, '['+str(mu_b_t)+','+str(sig_b_t)+']', '['+str(mu_nb_t)+','+str(sig_nb_t)+']', '['+str(mu_b_nt)+','+str(sig_b_nt)+']', '['+str(mu_nb_nt)+','+str(sig_nb_nt)+']'])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/probabilities_broad_tss_exp_regulated_tf_cont_normalised.txt')


    

    ### CREATE A LIST OF BI-VALENT GENES
    #tt = read_table1('/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt')
    #genes = set()
    #for g in tt:
    #    if tt[g]['E003'] == float(2):
    #        genes.add(g)
    #print len(genes)
    #tt = genomics.read_file1('/Users/woojunshim/Research/Data/hg19_TSS_summary.txt')
    #inputs = []
    #names = []
    #results = []
    #bed = read_bed('/Users/woojunshim/Research/Data/E003-H3K4me3.gappedPeak.bed')
    #for i in tt:
    #    if i[0] in genes:
    #        name = i[0]
    #        temp = check_point_overlap([i[1], i[2]], bed[i[1]])
    #        if temp:
    #            results.append(name)
    #genomics.write_file_items(results, '/Users/woojunshim/Research/Data/bi-valent.txt')

    ### CREATE TSS POINT TABLE FOR ALL GENES (LONGEST TRANSCRIPT)
    #results = []
    #tss = {}
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/hg19_TSS_.txt')
    #length = {}
    #for item in temp:
    #    if item[0].startswith('NM'):
    #        if item[-1] not in tss:
    #            length[item[-1]] = 0
    #            length_ = int(item[4]) - int(item[3])
    #            if length_ > length[item[-1]]:
    #                length[item[-1]] = length_
    #                if item[2] == '+':
    #                    tss[item[-1]] = [item[1], int(item[3]), '+']
    #                else:
    #                    tss[item[-1]] = [item[1], int(item[4]), '-']
    #for m in tss:
    #    results.append([tss[m][0], tss[m][1], tss[m][1], m])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/hg19_TSS_summary.txt')

    ### READ H3K27ME3 BEDGRAPH FILE AND EXTRACT ONES (>50, I.E. HEAVILY MARKED BY H3K27ME3 DOMAINS)
    #temp = open('/Volumes/Project/Research/bigdata/roadmap/broad_peaks/bedgraph/h3k27me3_broadest_only.bedgraph', 'r')
    #results = []
    #threshold = 50
    #for line in temp:
    #    line = line.strip().split()
    #    if int(line[3]) > threshold:
    #        results.append(line)
    #genomics.write_file(results, '/Volumes/Project/Research/bigdata/roadmap/broad_peaks/bedgraph/h3k27me3_broadest_only_over50.bedgraph.bed')


    ### CREATE A FILE FOR PROMOTERS FOR ALL TSS 
    #results = []
    #tss = {}
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/hg19_TSS_.txt')
    #length = {}
    #for item in temp:        
    #    if item[0] not in tss:                
    #        if item[2] == '+':
    #            tss[item[0]] = [item[1], int(item[3])-2500, int(item[3]), item[0], item[5]]
    #        else:
    #            tss[item[0]] = [item[1], int(item[4]), int(item[4])+2500, item[0], item[5]]
    #for m in tss:
    #    results.append([tss[m][0], tss[m][1], tss[m][2], tss[m][3], tss[m][4]])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/hg19_TSS_promoters.txt')

    ### CREATE TSS POINT TABLE FOR ALL GENES (LONGEST TRANSCRIPT)
    ### BED FILE FORMAT
    #results = []
    #tss = {}
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/hg19_TSS_.txt')
    #length = {}
    #for item in temp:
    #    if item[0].startswith('NM'):
    #        if item[-1] not in tss:
    #            length[item[-1]] = 0
    #            length_ = int(item[4]) - int(item[3])
    #            if length_ > length[item[-1]]:
    #                length[item[-1]] = length_
    #                if item[2] == '+':
    #                    tss[item[-1]] = [item[1], int(item[3])-2500, int(item[4])]
    #                else:
    #                    tss[item[-1]] = [item[1], int(item[3]), int(item[4])+2500]
    #for m in tss:
    #    results.append([tss[m][0], tss[m][1], tss[m][2], m])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/hg19_longest_TSS.txt')

    #results = []
    #tss = {}
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/hg19_TSS_.txt')
    #length = {}
    #for item in temp:
    #    if item[0].startswith('NM'):
    #        if item[-1] not in tss:
    #            length[item[-1]] = 0
    #            length_ = int(item[4]) - int(item[3])
    #            if length_ > length[item[-1]]:
    #                length[item[-1]] = length_
    #                if item[2] == '+':
    #                    tss[item[-1]] = [item[1], int(item[3])-1000, int(item[3])+1000]
    #                else:
    #                    tss[item[-1]] = [item[1], int(item[4])-1000, int(item[4])+1000]
    #for m in tss:
    #    results.append([tss[m][0], tss[m][1], tss[m][2], m])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/hg19_longest_TSS_1000up_1000down.txt')

    ### TABLE FOR EXPRESSION, LOCATION 2 AND BROAD PEAKS FOR SELECTED TFs 
    #results = {}
    #names = ['E038','E082','E095']
    #temp = read_table1('/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt')
    #exp_ = read_table1('/Users/woojunshim/Research/Data/exp_binary_46.txt')
    #groups = ['GO.0030097','GO.0007420','GO.0007507']
    #for g in groups:
    #            results[g] = {}
    #            for c in names:
    #                results[g][c] = 'NA'
    #for no in range(len(groups)):
    #    g = groups[no]
    #    ref_genes = genomics.intersect(genomics.read_file_items('/Users/woojunshim/Research/Data/'+g+'_genes_9606_.txt'), tf_list)
    #    hh = []
    #    for ll in exp_:
    #        if exp_[ll][names[no]] == float(1):
    #            hh.append(ll)        
    #    genes = genomics.intersect(hh, ref_genes)
    #    print len(genes)        
    #    aa = proportion_in_columns(temp, names, genes, ref_value=float(2))
    #    for n in range(len(names)):
    #        col = names[n]
    #        results[g][col] = aa[n]
    #print results
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/TSS_proportion_selected_tf.txt')


    ### ENRICHMENT ANALYSIS OF TF (RANKED BY COMPLIANCE), WITHOUT CONSIDERING WIDTH
    ### LOCATION & NOT EXPRESSED
    #t = genomics.read_file1('/Users/woojunshim/Research/Data/location_1_notexp_compliance_genes_.txt', sort_by=1)
    #tt = []
    #for i in t:
    #    tt.append(i[4])
    #results1, a = density_analysis(tt, ref_list=['1'], bin_size_=0.01, odd_ratio_=True, background_ratio_=None, accumulative_=False)
    #t = genomics.read_file1('/Users/woojunshim/Research/Data/location_2_notexp_compliance_genes_.txt', sort_by=1)
    #tt = []
    #for i in t:
    #    tt.append(i[4])
    #results2, a = density_analysis(tt, ref_list=['1'], bin_size_=0.01, odd_ratio_=True, background_ratio_=None, accumulative_=False)
    #t = genomics.read_file1('/Users/woojunshim/Research/Data/location_3_notexp_compliance_genes_.txt', sort_by=1)
    #tt = []
    #for i in t:
    #    tt.append(i[4])
    #results3, a = density_analysis(tt, ref_list=['1'], bin_size_=0.01, odd_ratio_=True, background_ratio_=None, accumulative_=False)
    #results = [['upstream'],['TSS'],['downstream']]
    #for i in range(len(results1)):
    #    results[0].extend([results1[i]])
    #    results[1].extend([results2[i]])
    #    results[2].extend([results3[i]])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/enrichment_tf_location_exp_compliance_.txt')

    ### LOCATION & NOT EXPRESSED
    ### COMPLIANCE FOR 4 GROUPS OF GENES
    #t = genomics.read_file1('/Users/woojunshim/Research/Data/location_1_notexp_compliance_genes_.txt', sort_by=1)
    #tt = []
    #for i in t:
    #    tt.append(i[4])
    #results1, a = density_analysis(tt, ref_list=['1'], bin_size_=0.01, odd_ratio_=True, background_ratio_=None, accumulative_=False)
    #t = genomics.read_file1('/Users/woojunshim/Research/Data/location_2_notexp_compliance_genes_.txt', sort_by=1)
    #tt = []
    #for i in t:
    #    tt.append(i[4])
    #results2, a = density_analysis(tt, ref_list=['1'], bin_size_=0.01, odd_ratio_=True, background_ratio_=None, accumulative_=False)
    #t = genomics.read_file1('/Users/woojunshim/Research/Data/location_3_notexp_compliance_genes_.txt', sort_by=1)
    #tt = []
    #for i in t:
    #    tt.append(i[4])
    #results3, a = density_analysis(tt, ref_list=['1'], bin_size_=0.01, odd_ratio_=True, background_ratio_=None, accumulative_=False)
    #results = [['upstream'],['TSS'],['downstream']]
    #for i in range(len(results1)):
    #    results[0].extend([results1[i]])
    #    results[1].extend([results2[i]])
    #    results[2].extend([results3[i]])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/enrichment_tf_location_exp_compliance_.txt')

    ### BROADNESS & NOT EXPRESSED
    #t = genomics.read_file1('/Users/woojunshim/Research/Data/broad_notexp_compliance_genes.txt', sort_by=1)
    #tt = []
    #for i in t:
    #    tt.append(i[4])
    #results1, a = density_analysis(tt, ref_list=['1'], bin_size_=0.01, odd_ratio_=True, background_ratio_=None, accumulative_=False)
    #t = genomics.read_file1('/Users/woojunshim/Research/Data/notbroad_notexp_compliance_genes.txt', sort_by=1)
    #tt = []
    #for i in t:
    #    tt.append(i[4])
    #results2, a = density_analysis(tt, ref_list=['1'], bin_size_=0.01, odd_ratio_=True, background_ratio_=None, accumulative_=False)
    #results = [['broad'],['not-broad']]
    #for i in range(len(results1)):
    #    results[0].extend([results1[i]])
    #    results[1].extend([results2[i]])   
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/enrichment_tf_broadness_exp_compliance.txt')

    ### ADD LABELS OF GROUP OF GENES 
    #t = genomics.read_file1('/Users/woojunshim/Research/Data/broad_notexp_compliance_genes.txt', sort_by=1)
    #for n in range(len(t)):
    #    g = t[n][0]
    #    if g in regulated_tf:
    #        tag = 1
    #    elif g in regulated_nontf:
    #        tag = 2
    #    elif g in stable_tf:
    #        tag = 3
    #    elif g in stable_nontf:
    #        tag = 4
    #    else:
    #        tag = 5
    #    t[n].extend([tag])
    #genomics.write_file(t, '/Users/woojunshim/Research/Data/broad_notexp_compliance_genes_.txt')

    #t = genomics.read_file1('/Users/woojunshim/Research/Data/notbroad_notexp_compliance_genes.txt', sort_by=1)
    #for n in range(len(t)):
    #    g = t[n][0]
    #    if g in regulated_tf:
    #        tag = 1
    #    elif g in regulated_nontf:
    #        tag = 2
    #    elif g in stable_tf:
    #        tag = 3
    #    elif g in stable_nontf:            
    #        tag = 4
    #    else:
    #        tag = 5
    #    t[n].extend([tag])
    #genomics.write_file(t, '/Users/woojunshim/Research/Data/notbroad_notexp_compliance_genes_.txt')

    ### BROADNESS & NOT EXPRESSED
    ### COMPLIANCE FOR 4 GROUPS OF GENES
    #t = genomics.read_file1('/Users/woojunshim/Research/Data/broad_notexp_compliance_genes_.txt', sort_by=1)
    #tt = []
    #for i in t:
    #    tt.append(i[5])
    #results1, a = density_analysis(tt, ref_list=['1'], bin_size_=0.01, odd_ratio_=True, background_ratio_=None, accumulative_=False)
    #t = genomics.read_file1('/Users/woojunshim/Research/Data/notbroad_notexp_compliance_genes_.txt', sort_by=1)
    #tt = []
    #for i in t:
    #    tt.append(i[5])
    #results2, a = density_analysis(tt, ref_list=['1'], bin_size_=0.01, odd_ratio_=True, background_ratio_=None, accumulative_=False)
    #results = [['broad'],['not-broad']]
    #for i in range(len(results1)):
    #    results[0].extend([results1[i]])
    #    results[1].extend([results2[i]])   
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/enrichment_regulated_tf_broadness_exp_compliance.txt')

    ### SUMMARY TABLE TO SHOW COMPLIANCE OF LOCATION OF PEAKS AND EXPRESSION OUTCOME FOR ALL GENES    
    #results = []
    #location = float(1)        
    #expression = float(0)
    #loc = read_table1('/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt') 
    #exp = read_table1('/Users/woojunshim/Research/Data/exp_binary_46.txt')
    #colnames = get_colnames(exp)
    #genes = common_names(['/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt', '/Users/woojunshim/Research/Data/exp_binary_46.txt'])   
    #results = [['#gene','positive','negative','compliance','TF']]    
    #for g in genes:
    #    a, b, c = 0, 0, 0
    #    for col in colnames:
    #        if loc[g][col] != float(0):
    #            if loc[g][col] == location:
    #                c += 1
    #                if exp[g][col] == expression:
    #                    a += 1
                #elif (loc[g][col] != location) and (exp[g][col] != expression):
                #    a += 1
    #                else:
    #                    b += 1
    #    if g in tf_list:
    #        tag = 1
    #    else:
    #        tag = 0
    #    if c != 0:
    #        results.append([g, a, b, float(a)/c, tag])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/location_1_notexp_compliance_genes_.txt')

    ### SUMMARY TABLE TO SHOW COMPLIANCE OF BROADNESS OF PEAKS AND EXPRESSION OUTCOME FOR ALL GENES    
    #results = []
    #b_ = float(0)        
    #expression = float(0)
    #loc = read_table1('/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt') 
    #exp = read_table1('/Users/woojunshim/Research/Data/exp_binary_46.txt')
    #broad = read_table1('/Users/woojunshim/Research/Data/broad_binary_46.txt')
    #colnames = get_colnames(exp)
    #genes = common_names(['/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt', '/Users/woojunshim/Research/Data/exp_binary_46.txt','/Users/woojunshim/Research/Data/broad_binary_46.txt'])   
    #print len(genes)
    #results = [['#gene','positive','negative','compliance','TF']]    
    #for g in genes:
    #    a, b, c = 0, 0, 0
    #    for col in colnames:
    #        if loc[g][col] != float(0):
    #            if broad[g][col] == b_:
    #                c += 1
    #                if exp[g][col] == expression:
    #                    a += 1
                #elif (loc[g][col] != location) and (exp[g][col] != expression):
                #    a += 1
    #                else:
    #                    b += 1
    #    if g in tf_list:
    #        tag = 1
    #    else:
    #        tag = 0
    #    if c != 0:
    #        results.append([g, a, b, float(a)/c, tag])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/notbroad_exp_compliance_genes.txt')


    ### SUMMARY TABLE FOR LOCATIONS FOR ALL GENES
    #temp = read_table1('/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt')    
    #results = {}
    #for g in temp:
    #    results[g] = {}
    #    for i in range(0,4):
    #        results[g][str(i)] = 0
    #for g in temp:
    #    for c in epigenomes:
    #        class_ = int(temp[g][c])
    #        results[g][str(class_)] += 1
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/summary_gene_locations.txt')


    ### MERGE FILES 
    #pathway = '/Users/woojunshim/Research/Data/pileup_100bp_'
    #labels = ['Broad','Not_broad']    
    #epis = ['E038','E082','E095']   
    #for epi in epis:
    #    files = [] 
    #    for l in labels:
    #        files.append(pathway+l+'_peaks_'+epi+'.txt')
    #    results = merge_files(files, labels)
    #    genomics.write_table1(results, pathway+'peaks_'+epi+'_combined.txt')

    ### CORRELATION BETWEEN BROADNESS OF PEAKS AND EXPRESSION FOR ALL GENES ACROSS ALL CELL TYPES
    ### GENERATE PROPORTIONS OF 3 CATEGORIES (I.E. 1: MATCH, 2: BROAD BUT EXPRESSED, 3: NOT BROAD BUT NOT EXPRESSED)
    #exp_ = read_table1('/Users/woojunshim/Research/Data/exp_binary_46.txt')
    #broad_ = read_table1('/Users/woojunshim/Research/Data/broad_binary_46.txt')
    #genes = genomics.intersect(get_rownames(exp_), get_rownames(broad_))
    #cols = get_colnames(exp_)
    #cn = len(cols)
    #results = []
    #for gene in genes:
    #    a,b,c = 0,0,0
    #    for col in cols:
    #        if (exp_[gene][col] == float(1) and broad_[gene][col] == float(0)) or (exp_[gene][col] == float(0) and broad_[gene][col] == float(1)):
    #            a += 1  # match
    #        elif (exp_[gene][col] == float(1) and broad_[gene][col] == float(1)):
    #            b += 1  
    #        elif (exp_[gene][col] == float(0) and broad_[gene][col] == float(0)):
    #            c += 1
    #    a = round(float(a) / cn, 4)
    #    b = round(float(b) / cn, 4)
    #    c = round(float(c) / cn, 4)
    #    results.append([gene, a, b, c])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/broadness_vs_exp_all_genes_all_cell_types.txt')


    ### FISHER'S EXACT TEST ON GENES OF THE NOT_BROAD GROUP
    #temp = read_table1('/Users/woojunshim/Research/Data/combined_binary_46_stat.txt', as_list=True)
    #a,b,c,d = 0,0,0,0  
    #tf_list =set(tf_list)    
    #for gene in temp:
    #    item = temp[gene]
    #    if item[2][1] != 46.0:
    #        if item[1][1] == 0.0:
    #            if gene in tf_list:
    #                a += 1
    #            else:
    #                b += 1
    #        else:
    #            if gene in tf_list:
    #                c += 1
    #            else:
    #                d += 1
    #print a,b,c,d
    #s, p = stat.fisher(a,b,c,d)
    #print s,p

    ### CREATE 46epigenomes.RPKM.symbols.txt
    #cols = get_colnames(exp_)
    #colnames = genomics.intersect(cols, epigenomes)
    #print len(colnames)
    #print len(colnames)
    #results = {}
    #for gene in all_exp_genes:
    #    results[gene] = {}
    #    for col in colnames:
    #        results[gene][col] = exp_[gene][col]
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/47epigenomes.RPKM.symbols.txt')

    ### CREAT A LIST OF CONSTITUTIVELY EXPRESSED GENES OR GENES WITHOUT A BROAD PEAK
    #temp = read_table1('/Users/woojunshim/Research/Data/combined_binary_46_stat.txt')
    #results = []
    #for g in temp:
    #    if temp[g]['broad'] == float(0):
    #        results.append(g)
    #genomics.write_file_items(results, '/Users/woojunshim/Research/Data/not_broad_genes.txt')

    ### CREATE A LIST OF CELL-TYPE SPECIFIC TF 
    #temp = genomics.read_file_items('/Users/woojunshim/Research/Data/GO.0030097_genes_9606_.txt')
    #results = []
    #tf_list = set(tf_list)
    #for i in temp:
    #    if i in tf_list:
    #        results.append(i)
    #genomics.write_file_items(results, '/Users/woojunshim/Research/Data/GO.0030097_tf_9606_.txt')

    ### COMBINE 'broad_binary_46_stat.txt' & 'exp_binary_46_stat.txt' into A SINGLE TABLE
    #pathway = '/Users/woojunshim/Research/Data/'
    #files = [pathway+'broad_binary_46_stat.txt', pathway+'exp_binary_46_stat.txt']
    #labels = ['broad','exp']
    #results = combine_tables(files, labels)
    #for gene in results:        
    #    if gene in tf_list:
    #        tag = 1
    #    else:
    #        tag = 0
    #    results[gene]['TF'] = tag
    #genomics.write_table1(results, pathway+'combined_binary_46_stat.txt')

    ### COMBINE EXP_PROPORTION AND BROAD_PEAK PROPORTION FOR ALL GENES (FOR 46 CELL TYPES)
    #f1 = read_table1('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.txt')
    #f2 = genomics.read_file1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_stats_.txt')    
    #g1 = get_rownames(f1)
    #g2 = set()
    #for i in f2:
    #    g2.add(i[0])
    #genes = genomics.intersect(g1, g2)
    #print len(genes)

    ### CREATE A EXPRESSION BINARY TABLE
    #exp = create_binary_table('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.txt')
    #exp = subset_table(exp, rows=genes, cols=colnames)
    #broad = subset_table('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_binary.txt', rows=genes, cols=colnames, numerical=False)
    #genomics.write_table1(exp, '/Users/woojunshim/Research/Data/exp_binary_46.txt')
    #genomics.write_table1(broad, '/Users/woojunshim/Research/Data/broad_binary_46.txt')

    ### EXTRACT EXPRESSION BINARY TABLE FOR NOT-BROAD GENES
    #temp = read_table1('/Users/woojunshim/Research/Data/exp_binary_all.txt')
    #all_ = get_rownames(temp)
    #broad = read_table1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_binary_at_least_one_broad.txt')
    #broad_ = get_rownames(broad)
    #not_broad = [x for x in all_ if x not in set(broad_)]
    #results = extract_rows(temp, broad)
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/exp_binary_broad.txt')


    ### PILEUP ANALYSIS
    ### FOR GENES 
    #pathway = '/Users/woojunshim/Research/Data/'    
    #non_tf_list = [x for x in all_exp_genes if x not in set(tf_list)]    
    #temp = read_table1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_binary_at_least_one_broad.txt')
    #genes = get_rownames(temp)    
    #epi = get_colnames(temp)
    #not_broad = [x for x in all_exp_genes if x not in set(genes)]  
    #epis =['E095','E082','E038']      
    #for e in epi:           
    #    results = pileup1(pathway+'dist_to_tss_min.txt', pathway+'dist_to_tss_max.txt', tf_list, colnames=[e], range_=[-50000, 50000], normalise_=False)    
    #    genomics.write_file(results, pathway+'/pileup/pileup_100bp_tf_'+e+'.txt')

    ### MERGE INTO A SINGLE FILE
    #pathway = '/Users/woojunshim/Research/Data/pileup/'
    #files = []
    #for e in epi:
    #    files.append(pathway+'pileup_100bp_tf_'+e+'.txt')
    #results = merge_files(files, epi)
    #genomics.write_table1(results, pathway+'pileup_100bp_tf_combined_count.txt')



    ### PILEUP ANALYSIS
    ### FOR PEAKS
    #pathway = '/Users/woojunshim/Research/Data/'    
    #non_tf_list = [x for x in all_exp_genes if x not in set(tf_list)]    
    #temp = read_table1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_binary_at_least_one_broad.txt')    
    #genes = get_rownames(temp)    
    #epis = get_colnames(temp)
    #pp = read_table1(pathway+'dist_to_tss_min.txt', numerical=False)
    #all_exp_genes = get_rownames(pp)
    #not_broad = [x for x in all_exp_genes if x not in set(genes)]    
    #for e in epis:
    #    epi = [e]         
    #    results = pileup2(pathway+'dist_to_tss_min.txt', pathway+'dist_to_tss_max.txt', pathway+'/broadPeaks/genes_broad_h3k27me3_binary.txt', all_exp_genes, binary_value=1, colnames=epi, range_=[-50000, 50000])    
    #    genomics.write_file(results, pathway+'/pileup/pileup_100bp_broad_peaks_'+e+'.txt')

    ### MERGE INTO A SINGLE FILE
    #pathway = '/Users/woojunshim/Research/Data/pileup/'
    #files = []
    #for e in epis:
    #    files.append(pathway+'pileup_100bp_broad_peaks_'+e+'.txt')
    #results = merge_files(files, epis)
    #genomics.write_table1(results, pathway+'pileup_100bp_broad_peaks_combined.txt')

    
    ### COUNT BROAD AND NON-BROAD GENES (TFS)
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_stats_.txt', sort_by=1)
    #results = [0, 0, 0 ,0]    
    #for item in temp:
    #    if float(item[1]) != float(0):
    #        if item[3] == '1':
    #            results[0] += 1
    #        else:
    #            results[1] += 1
    #    else:
    #        if item[3] == '1':
    #            results[2] += 1
    #        else:
    #            results[3] += 1
    #genomics.write_file_items(results, '/Users/woojunshim/Research/Data/broadPeaks/gene_stat.txt')


    ### FET TO SEE IF CELL-TYPE SPECIFIC FUNCTIONAL GENES ARE PREFERENTIALLY LOCATED WITHIN A GIVEN CELL TYPE OF INEREST
    #epi = 'E095'
    #term = 'GO.0007507'
    #ref_genes_ = genomics.read_file_items('/Users/woojunshim/Research/Data/'+term+'_genes_9606_.txt')
    #exp_ = read_table1('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.txt')
    #exp = []
    #for gene in exp_:
    #    if exp_[gene][epi] > float(1):
    #        exp.append(gene)
    #print len(exp)
    #ref_genes_ = genomics.intersect(ref_genes_, tf_list)
    #ref_genes_ = genomics.intersect(ref_genes_,exp)    
    #ref_genes = ref_genes_
    #print len(ref_genes)
    #location = read_table1('/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt')
    #results = {}
    #for i in range(1,4):
    #    results[str(i)] = [0, 0]
    #genes = set()
    #for gene in location:
    #    if location[gene][epi] != 0:
    #        genes.add(gene)
    #print len(genes)
    #for gene in genes:
    #    class_ = int(location[gene][epi])
    #    if gene in ref_genes:
    #        results[str(class_)][0] += 1
    #    else:
    #        results[str(class_)][1] += 1
    #output_ = []
    #for i in range(1,4):
    #    a,b,c,d = 0,0,0,0
    #    for j in range(1,4):
    #        if i==j:
    #            a = results[str(j)][0]
    #            b = results[str(j)][1]
    #        else:
    #            c += results[str(j)][0]
    #            d += results[str(j)][1]
    #    print a,b,c,d
    #    s, p = stat.fisher(a,b,c,d)
    #    output_.append([i, s, p])
    #genomics.write_file(output_, '/Users/woojunshim/Research/Data/fet_location_'+term+'_'+epi+'_tf.txt') 





    ### ANALYSE ASSOCIATION OF TFS WITH SELECTED GO TERMS 
    ### FIRST RANK TFS BY PROPORTION OF BROAD H3K27ME3 PEAKS
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_stats_.txt', sort_by=2)
    #results = []
    #names = ['GO.0007507','GO.0007420','GO.0002520']
    #ref = {}
    #for name in names:
    #    mm = set(genomics.read_file_items('/Users/woojunshim/Research/Data/'+name+'_genes_9606_.txt'))
    #    ref[name] = mm
    #for item in temp:
    #    if item[3] != '2':
    #        gene = item[0]
    #        prop = item[2]
    #        results.append([gene, prop])
    #        for name in names:
    #            if gene in ref[name]:
    #                results[-1].extend([1])
    #            else:
    #                results[-1].extend([0])
    #names[0] = '#'+names[0]
    #results.insert(0, names)
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/presence_go_terms_all_.txt')

    ### ENRICHMENT OF SELECTED GO TERMS AMONG BROAD TFS     
    #input_ = genomics.read_file1('/Users/woojunshim/Research/Data/presence_go_terms_all.txt')
    #names = ['GO.0007507','GO.0007420','GO.0030097'] 
    #results = []     
    #for i in range(2, 5):
    #    tt = []
    #    name = names[i-2]
    #    for item in input_:
            #if float(item[1]) > 0.00892857142857:
    #        tt.append(item[i])   
    #    print len(tt)     
    #    results1, a = density_analysis(tt, ref_list=['1'], bin_size_=0.01, odd_ratio_=True, background_ratio_=None, accumulative_=False)
    #    results.append([name])
    #    for item in results1:
    #        results[-1].extend([item])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/go_enrichment_all.txt')    

    ### ENRICHMENT OF TFs   
    #input_ = genomics.read_file1('/Users/woojunshim/Research/Data/presence_go_terms_all.txt')     
    #results = []        
    #tt = []
    #for item in input_:
    #    tt.append(item[0])
    #results1, a = density_analysis(tt, ref_list=tf_list, bin_size_=0.01, odd_ratio_=True, background_ratio_=None, accumulative_=False)
    #results.append(['TF'])
    #for item in results1:
    #    results[-1].extend([item])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/tf_enrichment_all.txt')    


    ### WILCOXON RANK SUM TEST (EXPRESSED BROAD TFS VS EXPRESSED NON-BROAD TFS)
    #exp_ = read_table1('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.txt')
    #names = ['E038','E082','E095','E104','E105','E070','E071','E037','E047']
    #results = []
    #fore = []
    #back = []
    #for name in names:
    #    temp = genomics.read_file1('/Users/woojunshim/Research/Data/'+name+'_expressed_broad_vs_narrow_genes.txt')
    #    for item in temp:
    #        if item[2]=='0':
    #            if item[1]=='1':
    #                fore.append(exp_[item[0]][name])
    #            else:
    #                back.append(exp_[item[0]][name])
    #print len(fore), len(back)        
    #s, p = stat.mann(fore, back, alternative_='less')
    #print s, p 


    ### EXTRACT SELECTED GO ELEMENTS FROM R SCRIPT OUTPUT
    #pathway = '/Users/woojunshim/Research/Data/'
    #labels = ['broad','non-broad']
    #epi = 'E082'
    #files = [pathway+epi+'_expressed_broad_tf_GO.txt',pathway+epi+'_expressed_narrow_tf_GO.txt']
    #ids = ['hemopoiesis','T_cell_differentiation','immune_system_development','lymphocyte_differentiation','regulation_of_myeloid_cell_differentiation']  # E038
    #ids = ['cardiac_chamber_morphogenesis','cardiac_ventricle_development','heart_development','heart_morphogenesis','cardiovascular_system_development'] # E095
    #ids = ['central_nervous_system_development','neurogenesis','brain_development','forebrain_generation_of_neurons','neuron_fate_commitment'] # E082
    #results = extract_elements(files, labels, ids, id_idx=2, value_idx=3)
    #genomics.write_table1(results, pathway+'extracted_go_table_tf_'+epi+'.txt')
    

    ### OVERLAP ANALYSIS for GENES (TFS) BETWEEN CELL TYPES
    #broad = '1' 
    #tf = '0'
    #names = ['E037','E038','E047','E070','E071','E082','E095','E104','E105']
    #d = []
    #g = []
    #for i in range(len(names)):
    #    temp = genomics.read_file1('/Users/woojunshim/Research/Data/'+names[i]+'_expressed_broad_vs_narrow_genes.txt')
    #    d.append(temp)
    #    g.append(set())
    #for i in range(len(d)):
    #    for item in d[i]:
    #        if (item[1] == broad) and (item[2] == tf):
    #            g[i].add(item[0])

    #for item in d1:
    #    if (item[1] == broad) and (item[2] == tf):
    #        g[0].add(item[0])
    #for item in d2:
    #    if (item[1] == broad) and (item[2] == tf):
    #        g[1].add(item[0])
    #for item in d3:
    #    if (item[1] == broad) and (item[2] == tf):
    #        g[2].add(item[0])
    #names = ['E038','E095','E082']

    #results = {}
    #for i in range(len(g)):
    #    results[names[i]] = {}
    #    for j in range(len(g)):
    #        total = len(genomics.union(g[i],g[j]))
    #        ov = len(genomics.intersect(g[i],g[j]))
    #        results[names[i]][names[j]] = float(ov) / float(total)
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/overlap_prop_broad_nontf_.txt')


    
    

    ### IDENTIFY EXPRESSED GENES THAT HAVE EITHER BROAD PEAK(S) OR NOT
    #exp_ = read_table1('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.txt')
    #broad = read_table1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_binary_at_least_one_broad.txt')
    #broad_genes = get_rownames(broad)
    #epi = 'E037'
    #broad_ = set()
    #narrow_ = set()
    #for gene in exp_:        
    #    if exp_[gene][epi] > float(1):
    #        if gene in broad_genes:
    #            broad_.add(gene)
    #        else:
    #            narrow_.add(gene)
    #results = []
    #for gene in broad_:        
    #    if gene in tf_list:
    #        tag = 1
    #    else:
    #        tag = 0
    #    results.append([gene, 1, tag])
    #for gene in narrow_:
    #    if gene in tf_list:
    #        tag = 1
    #    else:
    #        tag = 0
    #    results.append([gene, 0, tag])    
    #results.insert(0, ['#gene','broad','TF'])    
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/'+epi+'_expressed_broad_vs_narrow_genes.txt')

    ### FISHER'S EXACT TEST FOR ASSOCIATION BETWEEN BEING EXPRESSED (BINARY) AND LOCATION OF PEAKS
    ### BACKGROUND IS THE REST OF SUBCLASSES
    #subclass = read_table1('/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt')
    #exp_ = read_table1('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.txt')
    #colnames = get_colnames(exp_)
    #results = {}
    #for i in range(1, 4):
    #    results[str(i)] = [0, 0]
    #cnt = 0
    #for gene in subclass:
    #    if gene in exp_:
    #        cnt += 1
    #        for col in colnames:
    #            if subclass[gene][col] != 0:
    #                class_ = int(subclass[gene][col])
    #                value_ = float(exp_[gene][col])                
    #                if value_ > float(1):
    #                    results[str(class_)][0] += 1
    #                else:
    #                    results[str(class_)][1] += 1
    #print cnt
    #output_ = []
    #for i in range(1, 4):
    #    fore_ = str(i)
    #    a = results[fore_][1]
    #    b = results[fore_][0]
    #    c,d = 0,0
    #    for m in results:
    #        if fore_ != m:
    #            c += results[m][1]
    #            d += results[m][0]
    #    print a,b,c,d
    #    s, p = stat.fisher(a,b,c,d)
    #    output_.append([fore_, s, p])
    #genomics.write_file(output_, '/Users/woojunshim/Research/Data/fet_location_vs_exp.txt')

    ### TABLE FOR PROPORTIONS OF EXPRESSED GENES CATEGORISED BY THE LOCATION (ACROSS THE 46 CELL TYPES)
    #subclass = read_table1('/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt')
    #exp_ = read_table1('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.txt')
    #colnames = get_colnames(exp_)
    #genes = genomics.intersect(subclass, exp_)    
    #tf_ = genomics.intersect(genes, tf_list)
    #nontf_ = [x for x in genes if x not in set(tf_)] 
    #results = []  
    #for col in colnames:
    #    temp = {}
    #    cnt = {}
    #    for i in range(1,4):  # 3 locational preferences
    #        temp[i] = [0, 0]  # exp, not expressed
    #        cnt[i] = 0  # number of genes with a locational preference
    #    for g in nontf_:
    #        if subclass[g][col] != float(0):
    #            i = int(subclass[g][col])
    #            cnt[i] += 1
    #            if exp_[g][col] < float(1):
    #                temp[i][1] += 1
    #            else:
    #                temp[i][0] += 1
    #    results.append([col])
    #    for i in range(1,4):
    #        results[-1].extend([float(temp[i][0])/cnt[i]])
    #    print cnt
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/exp_location_prop_nontf.txt')

    ### TABLE FOR PROPORTIONS OF EXPRESSED GENES CATEGORISED BY BROADNESS (ACROSS THE 46 CELL TYPES)
    #broad = read_table1('/Users/woojunshim/Research/Data/broad_binary_46.txt')
    #subclass = read_table1('/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt')
    #exp_ = read_table1('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.txt')
    #colnames = get_colnames(exp_)
    #genes = genomics.intersect(broad, exp_)
    #genes = genomics.intersect(genes, subclass)   
    #print len(genes) 
    #tf_ = genomics.intersect(genes, tf_list)
    #nontf_ = [x for x in genes if x not in set(tf_)] 
    #results = []  
    #for col in colnames:
    #    temp = {}
    #    cnt = {}
    #    for i in range(2):  # 3 locational preferences
    #        temp[i] = [0, 0]  # exp, not expressed
    #        cnt[i] = 0  # number of genes with a locational preference
    #    for g in tf_:
    #        if subclass[g][col] != float(0):
    #            i = int(broad[g][col])
    #            cnt[i] += 1
    #            if exp_[g][col] < float(1):
    #                temp[i][1] += 1
    #            else:
    #                temp[i][0] += 1
    #    results.append([col])
    #    for i in range(2):
    #        results[-1].extend([float(temp[i][0])/cnt[i]])
    #    print cnt
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/exp_broad_prop_tf.txt')

    ### TABLE FOR PROPORTIONS OF EXPRESSED GENES CATEGORISED BY THE LOCATION (ACROSS THE 46 CELL TYPES)
    ### FOR 4 GROUPS OF GENES
    #subclass = read_table1('/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt')
    #exp_ = read_table1('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.txt')
    #colnames = get_colnames(exp_)
    #genes = genomics.intersect(subclass, exp_)    
    #genes = genomics.intersect(genes, stable_tf)
    #print len(genes)
    #tf_ = genomics.intersect(genes, tf_list)
    #nontf_ = [x for x in genes if x not in set(tf_)] 
    #results = []  
    #for col in colnames:
    #    temp = {}
    #    cnt = {}
    #    for i in range(1,4):  # 3 locational preferences
    #        temp[i] = [0, 0]  # exp, not expressed
    #        cnt[i] = 0  # number of genes with a locational preference
    #    for g in genes:
    #        if subclass[g][col] != float(0):
    #            i = int(subclass[g][col])
    #            cnt[i] += 1
    #            if exp_[g][col] < float(1):
    #                temp[i][1] += 1
    #            else:
    #                temp[i][0] += 1
    #    results.append([col])        
    #    for i in range(1,4):
    #        if cnt[1]==0 or cnt[2]==0 or cnt[3]==0:
    #            continue
    #        else:                
    #            results[-1].extend([float(temp[i][0])/cnt[i]])        
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/exp_location_prop_stable_tf.txt')

    ### TABLE FOR PROPORTIONS OF EXPRESSED GENES CATEGORISED BY BROADNESS (ACROSS THE 46 CELL TYPES)
    ### FOR 4 GROUPS OF GENES
    #broad = read_table1('/Users/woojunshim/Research/Data/broad_binary_46.txt')
    #subclass = read_table1('/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt')
    #exp_ = read_table1('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.txt')
    #colnames = get_colnames(exp_)
    #genes = genomics.intersect(broad, exp_)
    #genes = genomics.intersect(genes, subclass)   
    #genes = genomics.intersect(genes, stable_tf)
    #print len(genes) 
    #tf_ = genomics.intersect(genes, tf_list)
    #nontf_ = [x for x in genes if x not in set(tf_)] 
    #results = []  
    #for col in colnames:
    #    temp = {}
    #    cnt = {}
    #    for i in range(2):  # 3 locational preferences
    #        temp[i] = [0, 0]  # exp, not expressed
    #        cnt[i] = 0  # number of genes with a locational preference
    #    for g in genes:
    #        if subclass[g][col] != float(0):
    #            i = int(broad[g][col])
    #            cnt[i] += 1
    #            if exp_[g][col] < float(1):
    #                temp[i][1] += 1
    #            else:
    #                temp[i][0] += 1
    #    results.append([col])
    #    print cnt
    #    if cnt[1] < 10:  # remove if less than 10 counts
    #        del results[-1]
    #    else:
    #        for i in range(2):
    #            results[-1].extend([float(temp[i][0])/cnt[i]])        
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/exp_broad_prop_stable_tf_removed.txt')

    ### CREATE A TABLE FOR ALL GENES FOR EXPRESSED PROPORTIONS ACROSS CELL TYPES
    #exp_ = read_table1('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.txt')
    #labels = ['Regulated_TF','Regulated_nonTF','Stable_TF','Stable_nonTF']
    #results = [labels]
    #cols = get_colnames(exp_)
    #for c in cols:
    #    results.append([c])
    #    cnt = 0
    #    for g in regulated_tf:
    #        if exp_[g][c] > float(1):
    #            cnt += 1
    #    results[-1].extend([float(cnt)/len(regulated_tf)])
    #    cnt = 0
    #    for g in regulated_nontf:
    #        if exp_[g][c] > float(1):
    #            cnt += 1
    #    results[-1].extend([float(cnt)/len(regulated_nontf)])
    #    cnt = 0
    #    for g in stable_tf:
    #        if exp_[g][c] > float(1):
    #            cnt += 1
    #    results[-1].extend([float(cnt)/len(stable_tf)])
    #    cnt = 0
    #    for g in stable_nontf:
    #        if exp_[g][c] > float(1):
    #            cnt += 1
    #    results[-1].extend([float(cnt)/len(stable_nontf)])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/exp_prop_group_genes.txt')







    
    ### FISHER'S EXACT TEST FOR ASSOCIATION BETWEEN BROAD PEAKS (BINARY) AND LOCATION OF PEAKS
    ### BACKGROUND IS THE REST OF SUBCLASSES
    #subclass = read_table1('/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt')
    #broad = read_table1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_binary.txt')
    #colnames = get_colnames(broad)
    #results = {}
    #print len(colnames)
    #print len(subclass)
    #for i in range(1, 4):
    #    results[str(i)] = [0, 0]
    #for gene in subclass:
    #    for col in colnames:
    #        if subclass[gene][col] != 0:
    #            class_ = int(subclass[gene][col])
    #            value_ = int(broad[gene][col])                
    #            if value_ == 1:
    #                results[str(class_)][0] += 1
    #            else:
    #                results[str(class_)][1] += 1
    #output_ = [] 
    #print results   
    #for i in range(1, 4):
    #    fore_ = str(i)
    #    a = results[fore_][0]
    #    b = results[fore_][1]
    #    c,d = 0,0
    #    for m in results:
    #        if fore_ != m:
    #            c += results[m][0]
    #            d += results[m][1]
    #    print a,b,c,d
    #    s, p = stat.fisher(a,b,c,d)
    #    output_.append([fore_, s, p])
    #genomics.write_file(output_, '/Users/woojunshim/Research/Data/fet_location_vs_broad_.txt')

    ### FISHER'S EXACT TEST FOR ASSOCIATION BETWEEN BROAD GENES AND LOCATION OF PEAKS
    #subclass = read_table1('/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt')
    #broad = read_table1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_binary_at_least_one_broad.txt')
    #bg = set(get_rownames(broad))
    #colnames = get_colnames(broad)
    #results = {}
    #print len(colnames)
    #print len(subclass)
    #for i in range(1, 4):
    #    results[str(i)] = [0, 0]
    #for gene in subclass:
    #    for col in colnames:
    #        if subclass[gene][col] != 0:
    #            class_ = int(subclass[gene][col])                             
    #            if gene in bg:
    #                results[str(class_)][0] += 1
    #            else:
    #                results[str(class_)][1] += 1
    #output_ = [] 
    #print results   
    #for i in range(1, 4):
    #    fore_ = str(i)
    #    a = results[fore_][0]
    #    b = results[fore_][1]
    #    c,d = 0,0
    #    for m in results:
    #        if fore_ != m:
    #            c += results[m][0]
    #            d += results[m][1]
    #    print a,b,c,d
    #    s, p = stat.fisher(a,b,c,d)
    #    output_.append([fore_, s, p])
    #genomics.write_file(output_, '/Users/woojunshim/Research/Data/fet_location_vs_broad_genes.txt')


    ### FISHER'S EXACT TEST COMPARING ASSOCIATION BETWEEN TFS AND LOCATIONAL SUBCLASSES OF PEAKS
    ### BACKGROUND IS THE REST OF SUBCLASSES  
    #subclass = read_table1('/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt')    
    #colnames = get_colnames(subclass)
    #results = {}
    #all_exp_genes = set(all_exp_genes)
    #for i in range(1, 4):
    #    results[str(i)] = [0, 0]
    #for gene in subclass:
    #    for col in colnames:
    #        if subclass[gene][col] != 0:
    #            class_ = int(subclass[gene][col])                               
    #            if (gene in all_exp_genes) and (gene not in tf_list):
    #                results[str(class_)][1] += 1
    #            else:
    #                results[str(class_)][0] += 1
    #output_ = []
    #for i in range(1, 4):
    #    fore_ = str(i)
    #    a = results[fore_][1]
    #    b = results[fore_][0]
    #    c,d = 0,0
    #    for m in results:
    #        if fore_ != m:
    #            c += results[m][1]
    #            d += results[m][0]
    #    print a,b,c,d
    #    s, p = stat.fisher(a,b,c,d)
    #    output_.append([fore_, s, p])
    #genomics.write_file(output_, '/Users/woojunshim/Research/Data/fet_location_vs_nontf.txt')

    ### FISHER'S EXACT TEST COMPARING ASSOCIATION BETWEEN TFS (WITH/WITHOUT A BROAD PEAK) AND LOCATIONAL SUBCLASSES OF PEAKS
    ### BACKGROUND IS THE REST OF SUBCLASSES  
    #subclass = read_table1('/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt')  
    #binary = read_table1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_binary_at_least_one_broad.txt')  
    #broad_genes = get_rownames(binary)
    #all_exp_genes = set(all_exp_genes)
    #colnames = get_colnames(binary)
    #results = {}    
    #for i in range(1, 4):
    #    results[str(i)] = [0, 0]    
    #for gene in subclass:
    #    for col in colnames:
    #        if subclass[gene][col] != 0:
    #            class_ = int(subclass[gene][col])                               
    #            if (gene not in tf_list) and (gene in broad_genes) and (gene in all_exp_genes):
    #                results[str(class_)][1] += 1                    
    #            else:
    #                results[str(class_)][0] += 1    
    #output_ = []
    #for i in range(1, 4):
    #    fore_ = str(i)
    #    a = results[fore_][1]
    #    b = results[fore_][0]
    #    c,d = 0,0
    #    for m in results:
    #        if fore_ != m:
    #            c += results[m][1]
    #            d += results[m][0]
    #    print a,b,c,d
    #    s, p = stat.fisher(a,b,c,d)
    #    output_.append([fore_, s, p])
    #genomics.write_file(output_, '/Users/woojunshim/Research/Data/fet_location_vs_nontf_at_lease_one_broad.txt')

    ### SUMMARY OF PEAK LOCATIONS 
    #temp = read_table1('/Users/woojunshim/Research/Data/location_to_tss_broadpeaks.txt')
    #results = []
    #for gene in temp:
    #    a,b,c,d = 0,0,0,0
    #    for col in temp[gene]:
    #        if temp[gene][col] ==0:
    #            a += 1
    #        elif temp[gene][col] ==1:
    #            b += 1
    #        elif temp[gene][col] ==2:
    #            c += 1
    #        else:
    #            d += 1
    #    results.append([gene, round(float(a)/len(temp[gene]), 3), round(float(b)/len(temp[gene]), 3), round(float(c)/len(temp[gene]), 3), round(float(d)/len(temp[gene]), 3)])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/gene_location_summary.txt')



    ### SUBSET 'gene_broad_h3k27me3_binary' table to only TFs
    ### OR AT LEAST ONE BROAD H3K27ME3 PEAKS
    #temp = read_table1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_binary.txt', numerical=False)
    #colnames = get_colnames(temp)
    #genes = get_rownames(temp)
    #names = []
    #for gene in genes:
    #    for col in colnames:
    #        if temp[gene][col] == '1':
    #            names.append(gene)
    #            break
    #print len(names)
    #rownames = genomics.intersection(genes,tf_list)
    #results = subset_table('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_binary.txt', names, colnames)    
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_binary_at_least_one_broad.txt')


    ### CUMULATIVE PROPORTIONS OF TFS AND NON-TFS BY NUMBER OF BROAD PEAKS
    ### USING A SLIDING POINT 
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_stats_.txt')
    #for no in range(len(temp)):
    #    temp[no][1] = float(temp[no][1])
    #temp = genomics.sort_(temp, idx=1, reverse_=True)
    #results = []

    ### CREATE A SUMMARY TABLE 
    #gb = gene_body_size('/Users/woojunshim/Research/Data/hg19_TSS.txt', id_idx=5, start=3, end=4)
    #width_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_widths.txt', as_list=True)    
    #broad_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_binary_at_least_one_broad.txt')
    #broad = get_rownames(broad_)
    #stat_ = genomics.read_file('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_stats_.txt', [1], rowname='0')    
    #results = []
    #genes = []
    #for g in stat_:
    #    genes.append(g)
    #genes = genomics.intersect(genes, get_rownames(width_))
    #pp = []
    #for g in gb:
    #    pp.append(g)
    #genes = genomics.intersect(genes, pp)
    #print len(genes)
    #for g in genes:
    #    temp = []
    #    for m in width_[g]:
    #        temp.append(m[1])
    #    med_ = get_median(temp)
    #    if g in tf_list:
    #        tag = 1
    #    else:
    #        tag = 0
    #    results.append([g, stat_[g][0][0], med_, gb[g][2], tag])
    #results.insert(0, ['#gene', 'broad_peaks','median','gene_body','TF'])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/genes_summary.txt')

    ### DENSITY TABLE FOR TFS FROM 'GENES_SUMMARY.TXT'
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/genes_summary.txt')
    #results = []
    #for no in range(len(temp)):
    #    temp[no][2] = float(temp[no][2])
    #    temp[no][3] = float(temp[no][3])
    #    temp[no].extend([temp[no][2] / temp[no][3]])
    #temp = genomics.sort_(temp, idx=2, reverse_=True)
    #tt = []
    #for i in temp:
    #    tt.append(i[4])
    #results1, a = density_analysis(tt, ref_list=['1'], bin_size_=0.01, odd_ratio_=True, background_ratio_=None, accumulative_=False)

    #temp = genomics.sort_(temp, idx=3, reverse_=True)
    #tt = []
    #for i in temp:
    #    tt.append(i[4])
    #results2, a = density_analysis(tt, ref_list=['1'], bin_size_=0.01, odd_ratio_=True, background_ratio_=None, accumulative_=False)

    #temp = genomics.sort_(temp, idx=5, reverse_=True)
    #tt = []
    #for i in temp:
    #   tt.append(i[4])
    #results3, a = density_analysis(tt, ref_list=['1'], bin_size_=0.01, odd_ratio_=True, background_ratio_=None, accumulative_=False)

    #results.append(['median'])
    #for i in results1:
    #    results[-1].extend([i])
    #results.append(['gene_body'])
    #for i in results2:
    #    results[-1].extend([i])
    #results.append(['median/gene_body'])
    #for i in results3:
    #    results[-1].extend([i])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/genes_density_table.txt')

    




    ### FIND SIZE OF GENE BODY FROM TSS FILES
    ### CALCULATE SPEARMAN'S CORRELATION BETWEEN 
    #results = gene_body_size('/Users/woojunshim/Research/Data/hg19_TSS.txt', id_idx=5, start=3, end=4)
    #output_ = []
    #width_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_widths.txt')
    #genes = get_rownames(width_)
    #for epi in tissue_groups_:
    #    temp = []
    #    widths = []
    #    sizes = []
    #    for gene in genes:
    #        temp.append([gene, width_[gene][epi]])
    #        widths.append(width_[gene][epi])
    #    temp = genomics.sort_(temp, idx=1, reverse_=True)
    #    widths.sort(reverse=True)
    #    for item in temp:
    #        gene = item[0]
    #        sizes.append(results[gene][2])
    #    a,b = stat.spearman(widths, sizes)
    #    output_.append([epi, a, b])        
    #genomics.write_file(output_, '/Users/woojunshim/Research/Data/broadPeaks/spearman_gene_size_and_broadness.txt')

    ### WHITNEY MANN TEST COMPARING GENE BODY SIZE BETWEEN 'BROAD' GENES VS THE REST
    ### OR COMPARING BETWEEN TF AND NON-TF GENES
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_stats_.txt')
    #broad_genes = set()
    #rest_genes = set()
    #sizes = gene_body_size('/Users/woojunshim/Research/Data/hg19_TSS.txt', id_idx=5, start=3, end=4)
    #for item in temp:
    #    gene = item[0]
    #    if gene in tf_list:
        #if float(item[1])==float(0):
    #    if gene not in tf_list:
    #        rest_genes.add(gene)
    #    else:
    #        broad_genes.add(gene)
    #fore = []
    #back = []
    #print len(broad_genes)
    #print len(rest_genes)
    #for gene in sizes:
    #    if gene in broad_genes:
    #        fore.append(sizes[gene][2])
    #    elif gene in rest_genes:
    #        back.append(sizes[gene][2])
    #s, p = stat.mann(fore, back, alternative_='less')
    #print s, p
 

    ### DISTANCE BETWEEN CENTRE OF ASSIGNED PEAKS TO THE TSS AND WHETHER OVERLAP
    #dist = {}
    #overlap = {}
    #tss = {}
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/hg19_TSS_.txt')
    #for item in temp:
    #    if item[-1] not in tss:
    #        if item[2] == '+':
    #            tss[item[-1]] = [item[1], float(item[3]), '+']
    #        else:
    #            tss[item[-1]] = [item[1], float(item[4]), '-']
    #for epi in tissue_groups_:
    #    temp = genomics.read_file1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/'+epi+'_H3K27me3_genes.txt')
    #    for item in temp:
    #        gene = item[1]
    #        coordinate_ = [item[4], item[5]]
    #        centre = int((float(item[4]) + float(item[5])) / 2)
    #        dist_ = centre - tss[gene][1]
    #        if tss[gene][2] == '-':
    #            dist_ = -dist_
    #        if is_within(centre, coordinate_):
    #            tag_ = '1'
    #        else:
    #            tag_ = '0'
    #        if gene not in dist:
    #            dist[gene] = {}
    #            for col in tissue_groups_:
    #                dist[gene][col] = 'NA'
    #        dist[gene][epi] = dist_
    #        if gene not in overlap:
    #            overlap[gene] = {}
    #            for col in tissue_groups_:
    #                overlap[gene][col] = '0'
    #        overlap[gene][epi] = tag_
    #genomics.write_table1(dist, '/Users/woojunshim/Research/Data/dist_to_tss.txt')
    #genomics.write_table1(overlap, '/Users/woojunshim/Research/Data/overlap_tss_binary.txt')

    ### DISTANCE BETWEEN PEAKS TO THE TSS 
    ### GENERATES TWO NUMBERS (I.E. MAX AND MIN)
    #dist1 = {}   
    #dist2 = {} 
    #tss = {}
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/hg19_TSS_.txt')
    #for item in temp:
    #    if item[-1] not in tss:
    #        if item[2] == '+':
    #            tss[item[-1]] = [item[1], float(item[3]), '+']
    #        else:
    #            tss[item[-1]] = [item[1], float(item[3]), '-']
    #for epi in tissue_groups_:
    #    temp = genomics.read_file1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/'+epi+'_H3K27me3_genes.txt')
    #    for item in temp:
    #        gene = item[1]
    #        coordinate_ = [float(item[4]), float(item[5])]            
    #        dist1_ = coordinate_[0] - tss[gene][1]
    #        dist2_ = coordinate_[1] - tss[gene][1]
    #        if gene not in dist1:
    #            dist1[gene] = {}
    #            for col in tissue_groups_:
    #                dist1[gene][col] = 'NA'
    #        dist1[gene][epi] = dist1_
    #        if gene not in dist2:
    #            dist2[gene] = {}
    #            for col in tissue_groups_:
    #                dist2[gene][col] = 'NA'
    #        dist2[gene][epi] = dist2_            
    #genomics.write_table1(dist1, '/Users/woojunshim/Research/Data/dist_to_tss_min.txt')
    #genomics.write_table1(dist2, '/Users/woojunshim/Research/Data/dist_to_tss_max.txt')


    ### CREATE A TABLE FOR KENDALL'S CORRELATION CALCULATION (BROAD AND NARROW H3K27ME3 PEAKS)
    #narrow = genomics.read_file('/Users/woojunshim/Research/Data/genes_broad_h3k27me3_binary_narrowpeaks_stats_.txt', [1], rowname='0')
    #broad = genomics.read_file('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_stats_.txt', [1], rowname='0')
    #g1 = get_rownames(narrow)
    #g2 = get_rownames(broad)
    #genes = genomics.intersection(g1, g2)
    #results = {}
    #for g in genes:
    #    results[g] = {}
    #    results[g]['broad'] = float(broad[g][0][0])
    #    results[g]['narrow'] = float(narrow[g][0][0])
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/prop_table_broad_narrow.txt')

    ### 

    ### CALCULATE CORRELATION BETWEEN BINARY TABLES OF BROAD AND NARROW H3K27ME3 PEAKS FOR ALL GENES
    #results = []
    #narrow_ = read_table1('/Users/woojunshim/Research/Data/genes_broad_h3k27me3_binary_narrowpeaks.txt')
    #broad_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_binary.txt')
    #width_n = read_table1('/Users/woojunshim/Research/Data/H3K27me3_widths_all_narrow.txt')
    #width_b = read_table1('/Users/woojunshim/Research/Data/H3K27me3_widths_all_broad.txt')
    #g1 = get_rownames(narrow_)
    #g2 = get_rownames(broad_)
    #genes = genomics.intersection(g1, g2)
    #cols = get_colnames(narrow_)    
    #for g in genes:                
    #    l1 = []
    #    l2 = []
    #    for col in cols:
    #        if (width_n[g][col] != float(0)) and (width_b[g][col] != float(0)):
    #            l1.append(narrow_[g][col])
    #            l2.append(broad_[g][col])
    #    if len(l1) > 1:
    #        s, p = stat.spearman(l1, l2)
    #        results.append([g, s, p])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/gene_cor_broadpeaks_vs_narrowpeaks_.txt')


    ### CALCULATE CORRELATION BETWEEN NARROW AND BROAD H3K27ME3 PEAKS FOR ALL 111 CELL TYPES
    #results = []
    #for epi in tissue_groups_:
    #    broad_ = genomics.read_file1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/'+epi+'_H3K27me3_genes.txt')
    #    narrow_ = read_table1('/Volumes/Project/Research/bigdata/roadmap/narrow_peaks/H3K27me3/assigned/'+epi+'_H3K27me3_narrow_assigned.txt')
    #    broad = []
    #    narrow = []
    #    b, n, genes = [], [], []
    #    b_ = {}
    #    for i in broad_:
    #        if float(i[2]) != float(0):
    #            b.append(i[1])
    #            b_[i[1]] = float(i[2])
    #    for i in narrow_:
    #        if narrow_[i]['width'] != float(0):
    #            n.append(i)
    #    genes = genomics.intersect(b, n)
    #    print len(genes)

    #    for g in genes:
    #        broad.append([g, b_[g]])
    #    for g in genes:
    #        narrow.append([g, narrow_[g]['width']])
    #    s, p = cor_btw_lists(broad, narrow)
    #    results.append([epi, s, p])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/broadPeaks/cor_btw_broad_narrow_.txt')


    ### CREATE TEXT FILE TO DOWNLOAD NARROW H3K4ME3 PEAKS
    #temp = genomics.read_file_items('/Users/woojunshim/Research/Data/Roadmap/narrowpeak_list.txt')
    #results = []    
    #for i in temp:
    #    if 'H3K27me3' in i:
    #        results.append('http://egg2.wustl.edu/roadmap/data/byFileType/peaks/consolidated/narrowPeak/'+i)
    #genomics.write_file_items(results, '/Users/woojunshim/Research/Data/Roadmap/narrowpeak_list_.txt')

    ### EXTRACT MRNA GENES FOR MM10
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/mm10_tss_.txt')
    #results = set()
    #for item in temp:
    #    if item[1].startswith('NM'):
    #        results.add(item[-4])
    #genomics.write_file_items(list(results), '/Users/woojunshim/Research/Data/mm10_mrna.txt')

    ### REMOVE - IN TSANKOV EXP DATA
    #temp = read_table1('/Users/woojunshim/Research/Data/Tsankov/expression_dMS.txt')
    #del temp['-']
    #print len(temp)
    #genomics.write_table1(temp, '/Users/woojunshim/Research/Data/Tsankov/exp_MS.txt')

    ### FILLING GAPS IN H3K4ME3 TABLE
    #temp = read_table1('/Users/woojunshim/Research/Data/ENCODE/hindbrain_e10.5_mouse/product_hindbrain_e10.5_mm10.txt')
    #ref_ = get_rownames(temp)
    #results = fill_gaps('/Users/woojunshim/Research/Data/ENCODE/hindbrain_e10.5_mouse/H3K4me3_hindbrain_e10.5_mm10.txt', ref_)
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/ENCODE/hindbrain_e10.5_mouse/H3K4me3_hindbrain_e10.5_mm10.txt')

    ### COUNT NUMBER OF GENES WITH BROAD H3K27ME3 COUNTS
    #input_genes = genomics.read_file1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_stats.txt')      
    #input_genes = convert_to_num(input_genes, idx=1)
    #input_genes = genomics.sort_(input_genes, idx=1, reverse_=True)
    #input_ = []
    #for item in input_genes:
    #    input_.append(item[0])    
    #results = []
    #prev = 0
    #total_tf = 0
    #tf_cnt = 0
    #prev_tf = 0
    #for item in input_:
    #    if item in tf_list:
    #        total_tf += 1    
    #for i in range(111, -1, -1):        
    #    cnt = 0
    #    tf_cnt = 0
    #    for item in input_genes:
    #        if item[1] >= float(i):
    #            cnt += 1
    #            if item[0] in tf_list:
    #                tf_cnt += 1                    
    #        else:
    #            break
    #    print tf_cnt
    #    results.append([i, cnt-prev, tf_cnt-prev_tf, cnt, tf_cnt, float(cnt) / len(input_genes), float(tf_cnt) / total_tf, float(tf_cnt) / cnt])
    #    prev = cnt       
    #    prev_tf = tf_cnt 
    #results.insert(0, ['#cell','cnt_genes_bin','cnt_tf_bin','cumulative_cnt','cumulative_tf_cnt','cumulative_gene_proportion', 'cumulative_tf_proportion','cumulative_tf_proportion_bin'])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/broadPeaks/fet_broad_gene_count_.txt')

    ### ENRICHMENT SCORE FOR TFS AMONG GENES SORTED BY NUMBER OF BROAD H3K27ME3 PEAKS  
    #input_genes = genomics.read_file1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_stats.txt')
    #ref_list = genomics.read_file_items('/Users/woojunshim/Research/Data/GO.0003677_genes_9606_.txt')    
    #input_genes = convert_to_num(input_genes, idx=1)
    #input_genes = genomics.sort_(input_genes, idx=1, reverse_=True)
    #input_ = []
    #total_tf = 0
    #total_non = 0
    #for item in input_genes:
    #    input_.append(item[0])    
    #    if item[0] in tf_list:
    #        total_tf += 1
    #    else:
    #        total_non += 1  
    #total_tf = float(total_tf) / len(input_genes)
    #total_non = float(total_non) / len(input_genes)   
    #results_tf = ['TF']
    #results_non = ['nonTF']    
    #for i in range(111, -1, -1):
    #    cnt = 0
    #    tf = 0
    #    non = 0        
    #    for item in input_genes:
    #        if item[1] == float(i):
    #            cnt += 1
    #            if item[0] in tf_list:
    #                tf += 1
    #            else:
    #                non += 1
    #    if cnt != 0:            
    #        value1 = (float(tf) / cnt) / total_tf
    #        value2 = (float(non) / cnt) / total_non
    #    results_tf.append(value1)
    #    results_non.append(value2)        
    #results = [results_tf, results_non]
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/broadPeaks/tf_density_broad_h3k27me3.txt')



    ### FET for TFs or GO:003677 (DNA binding) term sorted by number of broad H3K27me3 peak occurrences
    ### FOR COUNTS
    #input_genes = genomics.read_file1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_stats_.txt')
    #ref_list = genomics.read_file_items('/Users/woojunshim/Research/Data/GO.0003677_genes_9606_.txt')    
    #print len(znf_list)
    #ref_list = znf_list
    #input_genes = convert_to_num(input_genes, idx=1)
    #input_genes = genomics.sort_(input_genes, idx=1, reverse_=True)
    #input_ = []
    #for item in input_genes:
    #    input_.append(item[0])    
    #results = []
    #for i in range(111, -1, -1):
    #    cnt = 0
    #    for item in input_genes:
    #        if item[1] >= float(i):
    #            cnt += 1
    #        else:
    #            break
    #    print cnt
    #    result = point_fet(input_, tf_list, cut_off_=cnt)
    #    results.append(result)
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/broadPeaks/fet_broad_count_tf.txt')

    ### FOR PERCENTILE
    #input_genes = genomics.read_file1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_stats_.txt')
    #ref_list = genomics.read_file_items('/Users/woojunshim/Research/Data/GO.0003677_genes_9606_.txt')    
    #print len(znf_list)
    #ref_ = znf_list
    #input_genes = convert_to_num(input_genes, idx=1)
    #input_genes = genomics.sort_(input_genes, idx=1, reverse_=True)
    #input_ = []
    #for item in input_genes:
    #    input_.append(item[0])        
    #p = sliding_fet(input_, ref_, output_='p-value', convert_to_percentile=True, percentile_bin = 0.01)
    #genomics.write_file_items(p, '/Users/woojunshim/Research/Data/broadPeaks/fet_znf.txt')


    ### CALCULATE CELL TYPE SCORES 
    #a, b = cell_type_scores('/Users/woojunshim/Research/Data/Palpant/product_palpant.txt', '/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_widths_inverse.txt', obtain_rank=True)
    #print a[0:10]
    #genomics.write_file(b[a[0][0]], '/Users/woojunshim/Research/Data/Palpant/combined_.txt')

    ### COMBINE MELANOMA DATA INTO ONE TABLE
    #pathway = '/Users/woojunshim/Research/melanoma/'
    #files = []
    #labels = []
    #for i in range(217, 228):
    #    files.append(pathway+'new_product_FPKM.'+str(i)+'.txt')
    #    if i==221 or i==225:
    #        labels.append('Invasive.'+str(i))
    #    else:
    #        labels.append('Proliferative.'+str(i))
    #results = combine_into_table(files, labels)
    #genomics.write_table1(results, pathway+'score_table_melanoma.txt')

    ### REMOVE DUPLICATE ROWNAMES
    #temp = read_table1('/Users/woojunshim/Research/melanoma/score_table_melanoma.txt')    
    #results = {}
    #colnames = get_colnames(temp)
    #print colnames
    #for gene in temp:
    #    results[gene] = {}
    #    for col in colnames:
    #        results[gene][col] = temp[gene][col]
    #genomics.write_table1(results, '/Users/woojunshim/Research/melanoma/score_table_melanoma_.txt')



    ### TEST TO EXTRACT NO. OF COUNTS OF CELL TYPES
    #bt = read_table1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_binary.txt') 
    #output_ = read_table1('/Users/woojunshim/Research/Data/Paige/product_paige.txt')
    #genes = []
    #for g in output_:
    #    if output_[g]['score'] > float(0):
    #        genes.append(g)
    #print len(genes)
    #results = find_colnames_summary(bt, genes, value_=0)    
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/Paige/cell_type_prop.txt')

    ### FISHER'S EXACT TEST TO SHOW THAT GENES WITH BROAD H3K27ME3 PEAKS ARE ASSOCIATED WITH REPRESSED EXPRESSION
    ### WILCOXON TEST TO COMPARE EXPRESSION VALUES BETWEEN TWO GROUPS
    ### CALCULATION DONE ACROSS ALL 46 CELL TYPES
    #wid_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_widths.txt')
    #colnames = get_colnames(wid_)
    #g1 = get_rownames(exp_)
    #g2 = get_rownames(wid_)
    #genes = genomics.intersection(g1, g2)
    #results1 = []
    #results2 = []
    #for col in colnames:        
    #    value_ = []
    #    input_ = []
    #    a,b,c,d = 0,0,0,0
    #    broad = []
    #    non_broad = []
    #    for gene in genes:            
    #        value_.append(wid_[gene][col])
    #        input_.append([gene, wid_[gene][col]])
    #    value_.sort(reverse=True)
    #    input_ = genomics.sort_(input_, idx=1, reverse_=True)
    #    elbow = find_elbow(value_)
    #    results1.append([col, elbow, float(elbow)/len(input_)])
    #genomics.write_file(results1, '/Users/woojunshim/Research/Data/roadmap_elbow.txt')
    #    for i in range(elbow):
    #        g = input_[i][0]
    #        v = exp_[g][col]
    #        broad.append(v)          
    #        if v > float(1): ## if expressed
    #            a += 1
    #        else:
    #            b += 1
    #    for i in range(elbow, len(genes)):
    #        g = input_[i][0]
    #        v = exp_[g][col]
    #        non_broad.append(v)          
    #        if v > float(1): ## if expressed
    #            c += 1
    #        else:
    #            d += 1
    #    s, p = stat.mann(broad, non_broad, alternative_='less')
    #    results2.append([col, s, p])
    #    s, p = stat.fisher(a,b,c,d, alternative_='less')
    #    results1.append([col, s, p])
    #genomics.write_file(results1, '/Users/woojunshim/Research/Data/broadPeaks/fet_exp_broad_vs_non_broad.txt')
    #genomics.write_file(results2, '/Users/woojunshim/Research/Data/broadPeaks/wilcoxon_exp_broad_vs_non_broad.txt')






    ### FIND CELL TYPES 
    #genes = ['GATA4','GATA6','MEIS2','MEIS1','EOMES','TBX5','TBX20']
    #for gene in genes:
    #    print gene
    #    results = find_colnames('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_binary.txt', id_=gene, value_=0)
    #    print results
    #    print

    ### SPEARMAN'S CORRELATION BETWEEN HUMAN AND MOUSE DATA
    #mouse = genomics.read_file1('/Users/woojunshim/Research/Data/mm10/h3k27me3/genes_broad_h3k27me3_stats_mm10.txt')
    #gm = []
    #gm_ = {}
    #for item in mouse:
    #    gm.append(item[0].upper())    
    #    gm_[item[0].upper()] = float(item[2])
    #human = genomics.read_file1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_stats.txt')
    #gh = []
    #gh_ = {}
    #for item in human:
    #    gh.append(item[0].upper())
    #    gh_[item[0].upper()] = float(item[2])
    #common = genomics.intersection(gm, gh)
    #print len(common)
    #vh = []
    #vm = []
    #for g in common:
    #    vm.append(gm_[g])
    #    vh.append(gh_[g])
    #r, p = stat.spearman(vh,vm)
    #print r, p

    ### ANALYSIS ON MIKE'S DATA SET (DE GENES)
    #temp = read_table1('/Users/woojunshim/Research/melanoma/MITF_de.txt')
    #direction = {}
    #for gene in temp:        
    #    if temp[gene]['fc'] > 0:
    #        direction[gene] = 'up'
    #    else:
    #        direction[gene] = 'down'            
    #    temp[gene]['fc'] = np.abs(temp[gene]['fc'])
    #results = product_analysis1(temp, 'fc', '/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_stats.txt', 2, exp_filter=0.0)
    #for no in range(len(results)):
    #    if results[no][0] != '\t':
    #        gene = results[no][0]
    #        results[no].extend([direction[gene]])
    #genomics.write_file(results, '/Users/woojunshim/Research/melanoma/scores_MITF_de.txt')  



    ### PRODUCT OF EXPRESSION VALUE & PROPORTION OF BROAD H3K27ME3 PEAKS   
    #pathway = '/Users/woojunshim/Research/Data/ENCODE/hindbrain_e10.5_mouse/'  
    #suffix = 'hindbrain_e10.5_mm10'
    #results = product_analysis1(pathway+'exp_'+suffix+'.txt', 'FPKM', '/Users/woojunshim/Research/Data/mm10/h3k27me3/genes_broad_h3k27me3_stats_mm10_.txt', 2)
    #genomics.write_file(results, pathway+'product_'+suffix+'.txt')  

    ### For multiple runs
    #temp = read_table1('/Users/woojunshim/Research/melanoma/verf_exp.csv')
    #colnames = get_colnames(temp)
    #for col in colnames:
    #    results = product_analysis1('/Users/woojunshim/Research/melanoma/verf_exp.csv', col, '/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_stats_.txt', 2)
    #    genomics.write_file(results, '/Users/woojunshim/Research/melanoma/scores_'+col+'.txt')  
    
    #temp = read_table1('/Users/woojunshim/Research/Data/H3K4me3_widths_narrow.txt')
    #a = extract_rows(temp, all_exp_genes)
    #genomics.write_table1(a, '/Users/woojunshim/Research/Data/H3K4me3_widths_narrow_.txt')
    #print len(a)

    ### PRODUCT ANAYLSIS FOR ROADMAP EXPRESSION DATA


   
    ### CHECK WHETHER GENES HAVE BROAD H3K27ME3 PEAKS ACROSS CELL TYPES
    ### GIVE 1 FOR GENE THAT HAVE BROAD PEAK, 0 FOR NOT (AS DEFINED BY ELBOW POINT)
    #temp = read_table1('/Users/woojunshim/Research/Data/H3K4me3_widths_narrow_.txt')
    #colnames = get_colnames(temp)
    #genes = get_rownames(temp)
    #results = initiate_table(temp)
    #for col in colnames:
    #    data_ = []
    #    m_ = []
    #    for gene in genes:            
    #        data_.append(temp[gene][col])
    #        m_.append([gene, temp[gene][col]])
    #    m_ = genomics.sort_(m_, idx=1, reverse_=True)        
    #    data_.sort(reverse=True)        
    #    elbow = find_elbow(data_)
    #    members = []
    #    for i in range(elbow):
    #        members.append(m_[i][0])
    #    tt = check_membership(genes, members)        
    #    for no in range(len(data_)):
    #        gene = genes[no]            
    #        results[gene][col] = tt[no]
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/genes_broad_h3k27me3_binary_narrowpeaks.txt')

    ### CREATE A SUMMARY FOR 'genes_broad_h3k27me3_binary.txt'
    ### THIS INCLUDES SUM OF OCCURRENCES, WHETHER TFS OR NOT
    #tf_list = genomics.read_file_items('/Users/woojunshim/Research/Data/TF_list_mm10_symbol.txt')
    #temp = read_table1('/Users/woojunshim/Research/Data/mm10/h3k27me3/genes_broad_h3k27me3_binary_mm10.txt')
    #temp = read_table1('/Users/woojunshim/Research/Data/genes_broad_h3k27me3_binary_narrowpeaks.txt')
    #genes = get_rownames(temp)
    #colnames = get_colnames(temp)
    #results = [['#gene','occurrence','proportion','TF']]    
    #for gene in genes:        
    #    cnt = 0
    #    for col in temp[gene]:
    #        cnt += temp[gene][col]
    #    prop = (float(cnt)+1) / (len(colnames)+1)
    #    if gene in tf_list:
    #        t = 1
    #    else:
    #        t=0
    #    results.append([gene, cnt, prop, t])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/genes_broad_h3k27me3_binary_narrowpeaks_stats_.txt')
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/mm10/h3k27me3/genes_broad_h3k27me3_stats_mm10_.txt')


    ### SPEARMAN'S CORRELATION FOR 47 CELL TYPES BETWEEN H3K27ME3 WIDTHS AND RPKM
    #results = cor_btw_tables('/Users/woojunshim/Research/Data/57epigenomes.RPKM.symbols.txt', '/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_widths.txt')
    #genomics.write_file(results, '/Users/woojunshim/Research/papers/H3K27me3/Data/spearman_cor_h3k27me3_rpkm.txt')

    ### ENRICHMENT ANALYSIS ON H3K27ME3 MEAN WIDTH TABLE
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_mean_table.txt')
    #input_ = []
    #ref_ = genomics.read_file_items('/Users/woojunshim/Research/Data/GO.0003677_genes_9606_.txt')
    #for item in temp:
    #    input_.append(item[0])
    #    if item[2] == '1':
    #        ref_.append(item[0])
    #p_ = sliding_fet(input_, ref_, output_='p-value', convert_to_percentile=True, percentile_bin = 0.01)
    #genomics.write_file_items(p_, '/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_mean_fet_GO.0003677.txt')


    ### EXTRACTING TOP 5% (EMPIRICAL P-VALUE) H3K27ME3 AVE WIDTHS GENES
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_mean_table.txt')
    #values = []
    #idx = int(len(temp) * 0.05)
    #for i in range(idx):
    #    value = temp[i][1]
    #    gene = temp[i][0]
    #    values.append([gene, np.log10(float(value))])
    #genomics.write_file(values, '/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_mean_selected.txt')



    ### PERFORMANCE ANALYSIS ###
    #temp = genomics.read_file_items('/Users/woojunshim/Research/Data/mm10_mrna.txt')  # For mouse
    #all_exp_genes = temp
    

    #pathway = '/Users/woojunshim/Research/Data/Palpant/'  
    #pathway = '/Users/woojunshim/Research/Data/Tsankov/' 
    #pathway = '/Users/woojunshim/Research/Data/ENCODE/keratinocyte_human/'  
    #pathway = '/Users/woojunshim/Research/Data/ENCODE/thymus_p0_mouse/'
    #pathway = '/Users/woojunshim/Research/Data/ENCODE/hindbrain_e10.5_mouse/'    
    #labels = ['exp','H3K4me3','product']
    #files = []
    #cell = 'MS'
    #cell = 'hindbrain_e10.5_mm10'
    #for label in labels:
    #    temp = pathway+label+'_'+cell+'.txt'
    #    files.append(temp)
    #temp = read_table1(files[0])
    #genes = get_rownames(temp)
    #genes = genomics.intersection(genes, all_exp_genes)
    #performance_analysis1(files, positives=pathway+'mesendoderm_positives.txt', output=pathway+'_new_ROC', order_='descending', labels=labels, calculate_auc_=True, all_genes=genes)

    ### EXTRACT MEAN FPKM VALUES FOR ENCODE DATA (CEREBELLUM)
    #pathway = '/Users/woojunshim/Research/Data/ENCODE/cerebellum_human/'
    #pathway = '/Users/woojunshim/Research/Data/ENCODE/keratinocyte_human/'
    #pathway = '/Users/woojunshim/Research/Data/ENCODE/thymus_p0_mouse/'
    #l1 = extract_lines(pathway+'ENCFF319WZT.tsv', prefix='ENSMUSG')  # human = ENSG, mouse = ENSMUSG
    #l2 = extract_lines(pathway+'ENCFF356QFG.tsv', prefix='ENSMUSG')
    #l = combine_lists(l1,l2,idx=6)  #FPKM
    #con_table = conversion_table('/Users/woojunshim/Research/Data/mm10_ensembl_symbols.txt', 1, 2)
    #results = []
    #for no in range(len(l)):
    #    name = l[no][0].split('.')[0]
    #    if name in con_table:
    #        results.append([con_table[name], l[no][1]])
    #results.insert(0, ['\t','FPKM'])
    #genomics.write_file(results, pathway+'exp_thymus_p0_mm10.txt')


    ### H3K27ME3 20KB CUTOFF APPROACH
    #aa = restrict_elements('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_mean_table.txt', idx=1, cutoff=20000)
    #aa = set(aa)
    #results = read_table1('/Users/woojunshim/Research/Data/Palpant/TPM_CPC.txt')
    #results = read_table1('/Users/woojunshim/Research/Data/ENCODE/keratinocyte_human/exp_keratinocyte_hg19.txt') 
    #col_ = 'CPC_RNAseq'
    #col_ = 'FPKM'
    #for item in results:        
    #    results[item][col_] = float(results[item][col_])
    #    if item not in aa:
    #        results[item][col_] = 0
    #results_ = []
    #for item in results:
    #    results_.append([item, results[item][col_]])
    #results_ = genomics.sort_(results_, idx=1, reverse_=True)
    #genomics.write_file(results_, '/Users/woojunshim/Research/Data/ENCODE/keratinocyte_human/20kb_keratinocyte_hg19.txt')


    ### SORT FILES IN ORDER
    #files = ['pre-defined_paige_d14.txt','skipped_paige_d14.txt','seed_paige_d14.txt']
    #pathway = '/Users/woojunshim/Research/Data/Paige/'
    #for file in files:
    #    temp = genomics.read_file1(pathway+file)
    #    temp = temp[1:]
    #    for no in range(len(temp)):
    #        temp[no][1] = float(temp[no][1])
    #    temp = genomics.sort_(temp, idx=1, reverse_=True)
    #    temp.insert(0,['day14'])
    #    genomics.write_file(temp, pathway+file)




    ### EXTRACT KNOWN TFS (MM10)
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/TF_list_mm10.txt', fill_gap=False)
    #table_ = conversion_table('/Users/woojunshim/Research/Data/mm10_ensembl_symbols.txt', 1, 2)
    #tf_ = []
    #for item in temp:
    #    tf_.append(item[0])
    #results = []
    #for item in tf_:
    #    if item in table_:
    #        results.append(table_[item])
    #genomics.write_file_items(results, '/Users/woojunshim/Research/Data/TF_list_mm10_symbol.txt')


    ### EXTRACT UNIQUE MM10 POSITIVE GENES
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/GO.0030902_genes_10090_.txt', fill_gap=False)
    #tf_ = genomics.read_file_items('/Users/woojunshim/Research/Data/TF_list_mm10_symbol.txt')
    #tf_ = set(tf_)
    #results = []
    #for item in temp:
    #    if item[0] not in results:
    #        if item[0] in tf_:
    #            results.append(item[0])
    #genomics.write_file_items(results, '/Users/woojunshim/Research/Data/GO.0030902_genes_mm10.txt')


    ### EXTRACT GENES FOR A GIVEN GO TERM
    ### taxa=9606 (homo sapiens), 10090(mus musculus)
    #term_ = 'GO:0007492'
    #taxa_ = 9606
    #extract_go_genes(term_, '/Users/woojunshim/Research/Data/GO.'+term_[3:]+'_genes_'+str(taxa_)+'.txt', taxa=taxa_, annotation_file='gene_association_goa_ref_human')

    ### COMBINE MESODERM AND ENDODERM TERMS
    #a = genomics.read_file_items('/Users/woojunshim/Research/Data/GO.0007498_genes_9606.txt')
    #b = genomics.read_file_items('/Users/woojunshim/Research/Data/GO.0007492_genes_9606.txt')
    #c = []
    #for i in a:
    #    if i not in c:
    #        c.append(i)
    #for i in b:
    #    if i not in c:
    #        c.append(i)
    #genomics.write_file_items(c, '/Users/woojunshim/Research/Data/mes_endo_genes.txt')



    ### MGI GENES
    #t = genomics.read_file1('/Users/woojunshim/Research/Data/GO.0048538_genes_10090.tab', fill_gap=False)
    #results = []
    #for item in t:
    #    if item[1] not in results:
    #        results.append(item[1])
    #genomics.write_file_items(results,'/Users/woojunshim/Research/Data/ENCODE/thymus_p0_mouse/thymus_p0_GO.0048538_positives_.txt')
    #tf_list = genomics.read_file_items('/Users/woojunshim/Research/Data/TF_list_mm10_symbol.txt')
    

    ### IDENTIFY POSITIVE GENES 
    #tf_list = genomics.read_file_items('/Users/woojunshim/Research/Data/TF_list_mm10_symbol.txt')  # ADD FOR MOUSE 
    #pathway = '/Users/woojunshim/Research/Data/ENCODE/thymus_p0_mouse/'
    #pathway = '/Users/woojunshim/Research/Data/Tsankov/'
    #results = identify_positive_genes(pathway+'exp_MS.txt', '/Users/woojunshim/Research/Data/mes_endo_genes_.txt', qualifiers=set(tf_list))
    #genomics.write_file_items(results, pathway+'mesendoderm_positives.txt')

    ### EXTRACT CPC TFS BY EXPRESSION VALUE
    #temp = read_table1('/Users/woojunshim/Research/Data/Palpant/TPM_CPC.txt')
    #input_ = []
    #for gene in temp:
    #    if gene in tf_list:
    #        if temp[gene]['CPC_RNAseq'] > float(1.0):
    #            input_.append([gene, temp[gene]['CPC_RNAseq']])
    #input_ = genomics.sort_(input_, idx=1, reverse_=True)
    #genomics.write_file(input_, '/Users/woojunshim/Research/Data/Palpant/TPM_CPC_tf.txt')

    ### COMPARE COUNTS OF POSITIVES
    #cnt = count_positives('/Users/woojunshim/Research/Data/Palpant/TPM_CPC_tf.txt', '/Users/woojunshim/Research/Data/Palpant/CPC_positive.txt', cut_off=133)
    #print cnt

    ### EXTRACT ALL EXPRESSED TFS WITH MAD FEATURE
    #temp = read_table1('/Users/woojunshim/Research/Data/Palpant/TPM_CPC.txt')
    #input_ = []
    #for gene in temp:
    #    if temp[gene]['CPC_RNAseq'] > float(1.0):
    #        input_.append([gene, temp[gene]['CPC_RNAseq']])
    #results = find_potential_genes(input_, '/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_mad_table.txt', tf_list)
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/Palpant/mad_tf_CPC.txt')


    ### ASNALYSE CPC_POSITIVES
    #positives = genomics.read_file_items('/Users/woojunshim/Research/Data/Palpant/CPC_positive.txt')
    #table = subset_table('/Users/woojunshim/Research/Data/broadPeaks/svd/H3K27me3_cor.txt', positives, positives)
    #genomics.write_table1(table, '/Users/woojunshim/Research/Data/Palpant/CPC_positives_table.txt')

    ### MELANOMA DATA
    ### CONVERT FILTERING ANALYSIS RESULTS TO RANK TABLE
    #results = convert_to_rank('/Users/woojunshim/Research/melanoma/combined_genes_filtered_verf.txt', rank_limit=1500)
    #genomics.write_table1(results, '/Users/woojunshim/Research/melanoma/results_rank.txt')

    # CALCULATE AVERAGE RANKS FOR GENES BETWEEN TWO STATES AND DIFFERENCE (INVASIVE - PROLIFERATIVE)
    #temp = read_table1('/Users/woojunshim/Research/melanoma/results_rank.txt')
    #inv_state = ['FPKM.221','FPKM.225']
    #genes = get_rownames(temp)
    #results = [['#gene','invasive','proliferative','diff.','TF']]
    #for gene in genes:
    #    pro = []
    #    inv = []
    #    for col in temp[gene]:
    #        value = temp[gene][col]
    #        if col in inv_state:
    #            inv.append(value)
    #        else:
    #            pro.append(value)
    #    inv_ = np.mean(inv)
    #    pro_ = np.mean(pro)
    #    dif_ = inv_ - pro_
    #    if gene in tf_list:
    #        tf_ = 1
    #    else:
    #        tf_ = 0
    #    results.append([gene, inv_, pro_, dif_, tf_])
    #genomics.write_file(results,'/Users/woojunshim/Research/melanoma/ave.rank_dif.txt')

    # OR BINARY TABLE TO SHOW WHETHER GENES ARE RANKED WITHIN A THRESHOLD (E.G. WITHIN TOP 1000)
    #temp = read_table1('/Users/woojunshim/Research/melanoma/results_rank.txt')
    #inv_state = ['FPKM.221','FPKM.225']
    #genes = get_rownames(temp)
    #results = [['#gene','invasive','proliferative','TF']]
    #thre_ = 1000
    #for gene in genes:
    #    pro = 0
    #    inv = 0
    #    for col in temp[gene]:
    #        value = temp[gene][col]
    #        if value < thre_:
    #            if col in inv_state:
    #                inv += 1
    #            else:
    #                pro += 1
    #    if gene in tf_list:
    #        tf_ = 1
    #    else:
    #        tf_ = 0
    #    results.append([gene, float(inv)/2, float(pro)/9, tf_])
    #genomics.write_file(results,'/Users/woojunshim/Research/melanoma/reg_prop_genes.txt')




    ### CALCULATE PROPORTIONS (VERFAILLIE)
    #temp = read_table1('/Users/woojunshim/Research/melanoma/combined_genes_filtered_verf.txt')
    #inv_state = ['FPKM.221','FPKM.225']
    #results = [['#gene','proliferative','invasive']]
    #for gene in temp:        
    #    results.append([gene])
    #    pro = 0
    #    inv = 0
    #    for col in temp[gene]:
    #        if temp[gene][col] >= float(1):
    #            if col in inv_state:
    #                inv += 1
    #            else:
    #                pro += 1
    #    results[-1].extend([round(float(pro)/9, 3), round(float(inv)/2, 3)])
    #genomics.write_file(results, '/Users/woojunshim/Research/melanoma/prop_table.txt')

    ### EXTRACTING A POSITIVE GENE SET
    #temp = genomics.read_file_items('/Users/woojunshim/Research/Data/GO.0007507_genes.txt')
    #temp = set(temp)
    #exp_ = read_table1('/Users/woojunshim/Research/Data/Palpant/TPM_ave.txt')
    #col = 'CPC_RNAseq'
    #results = []
    #for g in exp_:
    #    if g in tf_list:
    #        if exp_[g][col] > float(1):
    #            if g in temp:
    #                results.append(g)
    #genomics.write_file_items(results, '/Users/woojunshim/Research/Data/Palpant/CPC_positive_7507.txt')

    ### EXTRACT GO TERMS FOR ALL GENES
    ### FOR CONVERTING ID, USE WEBSITE http://www.uniprot.org/uploadlists/
    ### POSITIVE GENES 
    #import godata
    #import webservice
    #term = 'GO:0030900'    
    #texon = 9606
    #texon = 10090
    #pathway = '/Users/woojunshim/Research/Data/NCC/'    
    #pathway = '/Users/woojunshim/Research/Data/Pax6/'
    #go = godata.GO('gene_association_goa_ref_human', 'go-basic.obo')
    #go = godata.GO('gene_association.mgi', 'go-basic.obo')
    #t_ = go.getGenes(terms_or_term=term, evid = None, taxa = texon, rel = None, include_more_specific = True)
    #results = []
    #for item in t_:
    #    results.append(item)
    #genomics.write_file_items(results, pathway+'GO.'+term[3:]+'_genes_'+str(texon)+'.txt')    

    ### NATHAN'S THIRD APPROACH (BY SETTING A THRESHOLD ON MAD VALUE)
    ### FROM THE PLOT, GENES WITH MAD ABOVE TOP 7% VALUES WERE FIRST IDENTIFIED 
    ### THEN GIVEN INPUT DATA, ONLY GENES WITH THIS FEATURE ARE RANKED BY EXPRESSION VALUE
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_mad_table.txt')
    #idx = int(len(temp) * 0.07)
    #for no in range(len(temp)):
    #    temp[no][1] = float(temp[no][1])
    #temp = genomics.sort_(temp, idx=1, reverse_=True)
    #selected = set()
    #for no in range(idx):
    #    selected.add(temp[no][0])
    #exp_ = read_table1('/Users/woojunshim/Research/Data/Paige/expression/expression_data_ave_symbol.txt')
    #for gene in exp_:
    #    if gene not in selected:
    #        for col in exp_[gene]:
    #            exp_[gene][col] = 0
    #    if exp_[gene][col] < 1.0:
    #        exp_[gene][col] = 0
    #genomics.write_table1(exp_, '/Users/woojunshim/Research/Data/Paige/expression/paige_pre-defined_4.txt')


    ### COUNT NUMBERS OF CELL TYPES A GIVEN TF IS EXPRESSED (USING ROADMAP)
    #temp = read_table1('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.txt')
    #results = []
    #for gene in temp:
    #    cnt = 0 
    #    if gene in tf_list:
    #        for col in temp[gene]:
    #            if temp[gene][col] > float(1):
    #                cnt += 1
    #        results.append([gene, cnt])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/TF_occurrences.txt')




    ### CREATE A BACKGROUND ROC
    #background = background_roc_curve(18089)
    #genomics.write_file(background, '/Users/woojunshim/Research/Data/Palpant/ROC_background_CPC_genes.txt')

    ### TRANSFORM ROC TO CROC
    ### USING MAGNIFICATION FACTOR = 14, (i.e. f[0.05]=0.5)
    #files = ['skipped_CPC_genes','filtering_CPC_genes', 'TPM_CPC_genes', 'DEG_p_CPC_genes', 'background_CPC_genes']
    #files = ['pre-defined_CPC_genes']
    #pathway = '/Users/woojunshim/Research/Data/Palpant/'
    #for file in files:
    #    temp = genomics.read_file1(pathway+'ROC_'+file+'.txt')
    #    new = transform_to_croc(temp, mag_par=14)
    #    genomics.write_file(new, pathway+'CROC_'+file+'.txt')



    ### ANALYSE NUMBER OF FILTERED GENES ACROSS CELLS 
    #results = count_filtered_genes('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.txt', '/Users/woojunshim/Research/Data/selected_genes_roadmap_filtered_TF.txt')
    #genomics.write_file_items(results, '/Users/woojunshim/Research/Data/filtered_genes_count_roadmap.txt')

    ### ASSIGN PEAKS 
    #main('/Users/woojunshim/Research/Data/ENCODE/hindbrain_e10.5_mouse/ENCFF432UHX.bed', output_='/Users/woojunshim/Research/Data/ENCODE/hindbrain_e10.5_mouse/H3K4me3_hindbrain_e10.5_mouse', tss__='/Users/woojunshim/Research/Data/mm10_TSS_NCBI.txt', max_width__=2500, dominant_=True, convert_DS=False, centre_=True, remove_ncrna_=False)

    ### ASSIGN PEAKS (MULTIPLE FILES)
    #pathway = '/Volumes/Project/Research/bigdata/roadmap/narrow_peaks/H3K27me3/'
    #for epi in tissue_groups_:
    #    print epi
    #    input_ = pathway+epi+'-H3K27me3.narrowPeak'
    #    output_ = pathway+'assigned/'+epi+'_H3K27me3_narrow_assigned.txt'
    #    main(input_, output_=output_, tss__='/Users/woojunshim/Research/Data/hg19_TSS_.txt', max_width__=2500, dominant_=True, convert_DS=False, centre_=True, remove_ncrna_=False)



    ### CALCULATE AUC
    #pathway = '/Users/woojunshim/Research/Data/Palpant/'
    #pathway = '/Users/woojunshim/Research/Data/Paige/'
    #files = ['ROC_seed_set_palpant__18tf.txt','ROC_skipped_seed_palpant__18tf.txt','ROC_TPM_ave_18tf.txt','ROC_pre-defined_palpant__18tf.txt','ROC_20kb_palpant__18tf.txt']
    #files = ['ROC_exp_d14_18tf.txt','ROC_20kb_paige_d14_18tf.txt','ROC_pre-defined_paige_d14_18tf.txt','ROC_skipped_paige_d14_18tf.txt','ROC_seed_paige_d14_18tf.txt']
    #for file in files:
    #    temp = genomics.read_file1(pathway+file)
    #    y_ = []   
    #    for item in temp:
    #        y_.append(float(item[0]))
    #    area = calculate_auc(y_)
    #    print
    #    print file
    #    print area    

    ### CALCULATE ROC
    ### PAIGE DATA
    #exp_ = read_table1('/Users/woojunshim/Research/Data/57epigenomes.RPKM.symbols.txt')
    #genes = get_rownames(exp_)
    #files = ['seed_set_palpant_','pre-defined_palpant_','skipped_seed_palpant_','TPM_ave']
    #files = ['seed_paige_d14','pre-defined_paige_d14','skipped_paige_d14','20kb_paige_d14']
    #files = ['20kb_palpant_']   # for DEG
    #files = ['exp_d14']
    #pathway = '/Users/woojunshim/Research/Data/Palpant/'
    #pathway = '/Users/woojunshim/Research/Data/Paige/'
    #positives_ = '/Users/woojunshim/Research/Data/Palpant/CPC_positives_18tf.txt'
    #for file in files:
    #    temp = read_table1('/Users/woojunshim/Research/Data/Palpant/'+file+'.txt', numerical=True)
    #    temp = read_table1(pathway+file+'.txt', numerical=True)
    #    temp = read_table1('/Users/woojunshim/Research/Data/Palpant/DEG/CPC/'+file+'.txt', numerical=False)    # DEG
    #    temp = extract_rows(temp, genes)    
    #    cpc = extract_values(temp, '"p-value"', members=None)  # for DEG
    #    cpc = extract_values(temp, 'CPC_RNAseq', members=None)    
    #    cpc = extract_values(temp, 'day14', members=None)    
    #    for no in range(len(cpc)):
    #        cpc[no][1] = float(cpc[no][1])
    #    cpc = genomics.sort_(cpc, idx=1, reverse_=True)    
    #    cpc = genomics.sort_(cpc, idx=1, reverse_=False)  # for p-value (DEG)
    #    print cpc[0:10]
    #    positives = genomics.read_file_items(positives_)
    #    results = roc_stat(cpc, positives)
    #    results.insert(0, ['#TPR','FPR'])
    #    genomics.write_file(results, pathway+'ROC_'+file+'_18tf.txt')

    ### CALCULATE ROC
    ### ROADMAP DATA
    ### POSITIVES = EXPRESSED TFS (RPKM > 1.0)
    # DEFINE POSITIVES
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/TF_occurrences.txt')
    #t = []
    #for item in temp:
    #    if int(item[1]) != 46:  # remove constitutively expressed TFs 
    #        t.append(item[0])
    #t = set(t)
    #exp_ = read_table1('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.txt')
    #members = {}
    #cols = get_colnames(exp_)
    #for col in cols:
    #    members[col] = []
    #    temp = []
    #    for gene in exp_:
    #        if (exp_[gene][col] > float(1)) and (gene in t):
    #            temp.append([gene, exp_[gene][col]])
    #    temp = genomics.sort_(temp, idx=1, reverse_=True)
    #    for i in range(20):  # top 20 highly expressed TFs 
    #        members[col].append(temp[i][0])

    #genes = get_rownames(exp_)
    #groups = ['combined_results_roadmap_filtered_TF']
    #groups = ['46epigenomes.RPKM.symbols']
    #for group in groups:
    #    temp = read_table1('/Users/woojunshim/Research/Data/'+group+'.txt', numerical=True)    
    #    temp = extract_rows(temp, genes)          
    #    for col in cols:
    #        positives = members[col]       
    #        print len(positives)        
    #        cpc = extract_values(temp, col, members=None)
    #        cpc = genomics.sort_(cpc, idx=1, reverse_=False)            
    #        results = roc_stat(cpc, positives)
    #        results.insert(0, ['#TPR','FPR'])
    #        genomics.write_file(results, '/Users/woojunshim/Research/Data/ROC/ROC_'+group+'_'+col+'_filtered_TF.txt')   


    ### CALCULATE PRC (WE DON'T HAVE NEGATIVES)
    ### PAIGE DATA
    #temp = read_table1('/Users/woojunshim/Research/Data/Palpant/combined_results_20tf_palpant.txt')
    #cpc = extract_values(temp, 'CPC_RNAseq', members=None)
    #cpc = genomics.sort_(cpc, idx=1, reverse_=True)    
    #positives = genomics.read_file_items('/Users/woojunshim/Research/Data/Palpant/selected_cardiac_genes.txt')
    #results, baseline = prc_stat(cpc, positives)
    #results.insert(0, ['#precision','recall'])
    #results.insert(0, ['#baseline='+str(baseline)])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/Palpant/PRC_filtering_CPC_genes.txt')


    ### ADD TISSUE GROUPS TO OUTPUT TABLE
    #temp = read_table1('/Users/woojunshim/Research/Data/combined_results_roadmap.txt')
    #temp = transpose_table(temp)
    #del temp['colnames']
    #print temp
    #temp = add_tissue_groups(temp)
    #genomics.write_table1(temp, '/Users/woojunshim/Research/Data/combined_results_roadmap_.txt')


    ### IDENTIFY HIGHLY CORRELATED GENES (PALPANT DATA SET)
    ### FILTERING ANALYSIS
    #input_ = '/Users/woojunshim/Research/Data/ENCODE/keratinocyte_human/exp_keratinocyte_hg19.txt'
    #output_ = '/Users/woojunshim/Research/Data/ENCODE/keratinocyte_human/skipped_keratinocyte_hg19.txt'
    #tt = genomics.read_file1(input_)
    #print len(tt)
    #filtering_analysis(exp_table=input_, feature_table='/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_mad_table.txt', cor_table='/Users/woojunshim/Research/Data/broadPeaks/svd/H3K27me3_cor.txt', no_seed='filter', output_file=output_, exp_filter=1.0, output_seed_set=False, skip_seed_analysis=True, combine_result=True)
    #aa = sort_table(output_)
    #genomics.write_file(aa, output_)
    #ranking_analysis(exp_table='/Users/woojunshim/Research/Data/Palpant/TPM_CPC.txt', feature_table='/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_mad_table.txt', cor_table='/Users/woojunshim/Research/Data/broadPeaks/svd/H3K27me3_cor.txt', no_seed=20, output_file='/Users/woojunshim/Research/Data/Palpant/ranking_seed_palpant.txt', exp_filter=1.0, output_seed_set=False)

    ### FIND EMPIRICAL P-VALUE 
    #temp = read_table1('/Users/woojunshim/Research/Data/Palpant/jaccard_index_CPC_RNAseq.txt')
    #input_ = []
    #for g1 in temp:
    #    for g2 in temp[g1]:
    #        input_.append(temp[g1][g2]) 
    #print empirical_p(input_)


    ### COMBINE FILTERING ANALYSIS OUTCOME WITH EXPRESSION DATA SET
    #results = combine_filtering_analysis('/Users/woojunshim/Research/Data/Palpant/TPM_ave.txt','/Users/woojunshim/Research/Data/Palpant/selected_genes_20tf_palpant.txt')
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/Palpant/combined_results_20tf_palpant.txt')
    

    ### EXTRACT GENES WITH MAD FEATURE (ROADMAP)    
    #temp_ = read_table1('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.txt') 
    #temp_ = read_table1('/Users/woojunshim/Research/Data/Palpant/TPM_ave.txt')
    #genes = get_rownames(temp_)
    #epis = get_colnames(temp_)
    #results1 = {}
    #results2 = {}
    #for gene in genes:
    #    results1[gene] = {}
    #    results2[gene] = {}
    #    for epi in epis:
    #        results1[gene][epi] = 0
    #        results2[gene][epi] = 0
    #for colname in epis:
    #    input_genes = []  # only gene symbols
    #    input_ = []  # [[gene, exp], ..., ]
    #    for gene in genes:
    #        if temp_[gene][colname] > 1.0:
    #            input_genes.append(gene)
    #            input_.append([gene, temp_[gene][colname]])    
    #    print 'Input =', colname
    #    print 'No. expressed genes =', len(input_genes)

        # CALCULATE CUMULATIVE MAD / SUM OF MADS FOR GENES 
    #    mad_list = cul_mad(input_genes, '/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_mad_table.txt')

        # FIND ELBOW POINT
    #    data_points = []
    #    for item in mad_list:
    #        data_points.append(item[1])      
    #    elbow_point = find_elbow(data_points)
        #print 'Elbow point =', elbow_point

        # EXTRACT GENES WITH ABOVE THE ELBOW POINT 
    #    cnt = 0           
    #    for no in range(elbow_point):
    #        gene = mad_list[no][0]
    #        results1[gene][colname] = no+1
    #        if gene in tf_list:            
    #            results2[gene][colname] = cnt+1
    #            cnt += 1
        #print 'No. TFs above the elbow point =', len(tfs)
    #genomics.write_table1(results1, '/Users/woojunshim/Research/Data/Palpant/MAD_genes_palpant.txt')
    #genomics.write_table1(results2, '/Users/woojunshim/Research/Data/Palpant/MAD_tfs_palpant.txt')

    
    ### CALCULATE OVERLAP COEFFICIENTS OF MAD-SELECTED TFS FOR ALL PAIRWISE CELL TYPES
    #temp = read_table1('/Users/woojunshim/Research/Data/Palpant/MAD_genes_palpant.txt') 
    #epis = get_colnames(temp)
    #ref = {}
    #for epi in epis:
    #    ref[epi] = []
    #    for gene in temp:
    #        if temp[gene][epi] == 1:
    #            ref[epi].append(gene)
    #results = {}
    #for e1 in epis:
    #    results[e1] = {}        
    #    for e2 in epis:
    #        results[e1][e2] = overlap_coefficient(ref[e1], ref[e2])
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/Palpant/MAD_genes_overlap_coefficient_palpant.txt')


    ### ANALYSING ENCODE DATA SETS
    #conversion_table(input_file, from_idx, to_idx)

    ### EXAMPLE RUN FOR CELL REPORTS DATA SET
    #filtering_analysis(exp_table='/Users/woojunshim/Research/Data/57epigenomes.RPKM.symbols.txt', feature_table='/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_mad_table.txt', cor_table='/Users/woojunshim/Research/Data/broadPeaks/svd/H3K27me3_cor.txt', no_seed='filter', output_file='/Users/woojunshim/Research/Data/selected_genes_roadmap_filtered_TF.txt')


    ### FILTERING ANALYSIS
    # READ IN AN INPUT AND REMOVE GENES (< TPM 1.0)
    #colname = 'C-EC_RNAseq'
    #temp_ = read_table1('/Users/woojunshim/Research/Data/Palpant/TPM_ave.txt') 
    #genes = get_rownames(temp_)
    #input_genes = []  # only gene symbols
    #input_ = []  # [[gene, exp], ..., ]
    #for gene in genes:
    #    if temp_[gene][colname] > 1.0:
    #        input_genes.append(gene)
    #        input_.append([gene, temp_[gene][colname]])    
    #print 'Input =', colname
    #print 'No. genes (>1.0 TPM) =', len(input_genes)

    # CALCULATE CUMULATIVE MAD / SUM OF MADS FOR GENES 
    #mad_list = cul_mad(input_genes, '/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_mad_table.txt')

    # FIND ELBOW POINT
    #data_points = []
    #for item in mad_list:
    #    data_points.append(item[1])      
    #elbow_point = find_elbow(data_points)
    #print 'Elbow point =', elbow_point

    # EXTRACT GENES WITH ABOVE THE ELBOW POINT    
    #genes_above_elbow = []  # Genes that are above the elbow point
    #tfs = []  # TFs that are above the elbow point
    #for no in range(elbow_point):
    #    gene = mad_list[no][0]
    #    genes_above_elbow.append(gene)
    #    if gene in tf_list:            
    #        tfs.append(gene)
    #print 'No. TFs above the elbow point =', len(tfs)

    # INTEGRATE WITH INPUT DATA AND FIND SEED SET GENE
    #seed_no = 20 # Number of seed set genes
    #input_ = genomics.sort_(input_, idx=1, reverse_=True)
    #seed_set = []  # Seed set gene
    #cnt = 0
    #for no in range(len(input_)):
    #    gene = input_[no][0]
    #    if gene in tfs:
    #        seed_set.append(gene)
    #        cnt += 1
    #    if cnt == seed_no:
    #        break
    
    # CALCULATE SIMILARITY FOR ALL GENES WITH THE SEED SET    
    # EXTRACT GENES THAT ARE SIGNIFICANTLY POSITIVELY (BH-ADJUSTED P<0.05) TO THE SEED SET
    #cor__ = '/Users/woojunshim/Research/Data/broadPeaks/svd/H3K27me3_cor.txt'  # H3K27me3 dynamics correlation matrix
    #cor_ = subset_table(cor__, rows=input_genes, cols=input_genes, numerical=True)    
    #results = seed_analysis(candidate_=seed_set, background_=input_genes, cor_file=cor_, output_=None, multiple_correction=True)
    #correlated_genes = set()   # gene set that are significantly positively (BH-adjusted p<0.05) to the seed set
    #for no in range(1, len(results)):
    #    if (results[no][1] > 0) and (results[no][3] < 0.05):   
    #        correlated_genes.add(results[no][0])
    #print 'No. genes that are sig. pos. to the seed set =', len(correlated_genes)

    # GET OUTPUT
    #output_ = []
    #tf_tag = 0  # tag to indicate whether the given is a TF or not
    #for item in input_:
    #    if item[0] in correlated_genes:
    #        if item[0] in tf_list:
    #            output_.append([item[0], item[1], 1])
    #        else:
    #            output_.append([item[0], item[1], 0])
    #output_ = genomics.sort_(output_, idx=2, reverse_=True)
    #output_.insert(0, ['#gene','TPM','TF'])
    #genomics.write_file(output_, '/Users/woojunshim/Research/Data/Palpant/'+colname+'.txt')


    ### CREATE A DENSITY TABLE FOR H3K27ME3 MAD TABLE (TF AND NON-TF)
    #input_ = genomics.read_file1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_median_table.txt')
    #input_ = genomics.read_file1('/Users/woojunshim/Research/Data/H3K27me3_mad_table_mm10.txt')
    #input_ = genomics.read_file1('/Users/woojunshim/Research/Data/broadPeaks/genes_broad_h3k27me3_stats.txt')
    #tt = []
    #for no in range(len(input_)):
    #    item = input_[no]       
    #    input_[no][2] = float(input_[no][2])
    #input_ = genomics.sort_(input_, idx=2, reverse_=True)
    #for item in input_:
    #    tt.append(item[3])
    #results1, a = density_analysis(tt, ref_list=['1'], bin_size_=0.05, odd_ratio_=True, background_ratio_=None, accumulative_=False)
    #results2, b = density_analysis(tt, ref_list=['0'], bin_size_=0.05, odd_ratio_=True, background_ratio_=None, accumulative_=False)
    #print results1
    #results1.insert(0, 'TF')
    #results2.insert(0, 'Non-TF')
    #results = [results1, results2]
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/broadPeaks/tf_density_broad_h3k27me3.txt') 


    ### CREATE A TABLE FOR TFS (WHETHER REMOVED OR KEPT) BY TPM AFTER THE NEW ANALYSIS 
    #exp_ = read_table1('/Users/woojunshim/Research/Data/Palpant/TPM_ave.txt')
    #groups = ['CPC','C-EC','H-EC']
    #for group in groups:
    #    col = group+'_RNAseq'
    #    temp = genomics.read_file1('/Users/woojunshim/Research/Data/Palpant/'+group+'_combined.txt')
    #    selected = set()
    #    for item in temp:
    #        if float(item[2]) == float(1.0):
    #            selected.add(item[0])
    #    results = []
    #    pp = []
    #    for gene in exp_:
    #        pp.append([gene, exp_[gene][col]])
    #    pp = genomics.sort_(pp, idx=1, reverse_=True)
    #    for item in pp:
    #        gene = item[0]
    #        if gene in tf_list:
    #            if gene in selected:
    #                results.append([gene, item[1], 1])
    #            else:
    #                results.append([gene, item[1], 0])
    #    results.insert(0, ['#gene','TPM','selected'])
    #    genomics.write_file(results, '/Users/woojunshim/Research/Data/Palpant/'+group+'_TF_results.txt')


    ### COMBINE CPC_all_broad_genes.txt + CPC_similar_to_top20_tf.txt 
    ### ONLY SELECT ONES THAT ARE POSITIVELY SIGNIFICANT
    ### THEN RANK BY RPKM
    #broad = genomics.read_file1('/Users/woojunshim/Research/Data/Palpant/C.EC_all_broad_genes.txt')
    #similar = genomics.read_file('/Users/woojunshim/Research/Data/Palpant/C-EC_similar_to_top20_tf.txt', [1,3], rowname='0')
    #results = []
    #for item in broad:
    #    if item[0] in similar:
    #        if (float(similar[item[0]][0][0]) > 0) and (float(similar[item[0]][0][1]) < 0.05):
    #            results.append([item[0], item[1]])
    #            if item[0] in tf_list:
    #                results[-1].extend([1])
    #            else:
    #                results[-1].extend([0])
    #results = genomics.sort_(results, idx=2, reverse_=True)
    #results.insert(0, ['#gene','TPM','TF'])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/Palpant/C.EC_combined.txt')


    

    ### Identify highly similar genes with TOP 20 TFS (AMONG SELECTED GENES) PALPANT DATA
    #files = ['H-EC','C-EC','CPC']    
    #pathway = '/Users/woojunshim/Research/Data/Palpant/'
    #exp_table = read_table1(pathway+'TPM_ave.txt')
    #all_genes = get_rownames(exp_table)
    #cor_ = '/Users/woojunshim/Research/Data/broadPeaks/svd/H3K27me3_cor.txt'
    #for file in files:
    #    print file
    #    class_ = file+'_RNAseq'
    #    output__ = pathway+file+'_similar_to_top20_tf.txt'
    #    temp_ = genomics.read_file1(pathway+file+'_results.txt')
    #    fore = []
    #    back = []
    #    for i in range(20):
    #        fore.append(temp_[i][0])
    #    for gene in all_genes:
    #        if exp_table[gene][class_] > 1.0:
    #            back.append(gene) 
    #    print fore
    #    rescue_analysis1(candidate_=fore, background_=back, cor_file=cor_, output_=output__, threshold_=0.05, multiple_correction=True, pair_analysis_=False)


    ### Cor analysis on E095
    ### TOP 100 EXPRESSED TFS BY SD 
    #uu = genomics.read_file1('/Users/woojunshim/Research/Data/broadPeaks/E095_high_sd_expressed_genes.txt')
    #background = []
    #candidate = []
    #for i in uu:
    #    background.append(i[1])
    #for i in range(20):
    #    candidate.append(uu[i][1])
    #cor_ = '/Users/woojunshim/Research/Data/broadPeaks/svd/H3K27me3_cor.txt'
    #cor_analysis(candidate, background, cor_file=cor_, output_='/Users/woojunshim/Research/Data/broadPeaks/E095_candidate.txt', pair_analysis_=False) 

    ### RANK PRODUCT OF PRE-FILTERED LIST AND R>0.9 COUNTS
    #temp1 = genomics.read_file('/Users/woojunshim/Research/Data/Palpant/pre-filtering_CPC_RNA-seq.txt',[1], rowname='0')
    #temp2 = genomics.read_file('/Users/woojunshim/Research/Data/Palpant/CPC_r0.9_counts_pre-filtering.txt',[1],rowname='0')
    #input_ = []
    #for item in temp1:
    #    if float(temp1[item][0][0]) > 1.0:
    #        input_.append([item, temp1[item][0][0], temp2[item][0][0]])
    #results = rank_product(input_, id_idx=0, indexs=[1,2], order_='descending')
    #results = genomics.sort_(results, idx=1, reverse_=False)
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/Palpant/rp_pre-filtering_r0.9_counts.txt')
    



    ### FIND CORRELATED GENES (PALPANT DATA SET)
    #cor_ = '/Users/woojunshim/Research/Data/broadPeaks/svd/H3K27me3_cor.txt'
    #exp_ = read_table1('/Users/woojunshim/Research/Data/Palpant/TPM_ave.txt')

    #k27_ = genomics.read_file1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_median_summary.txt')    
    #input_ = []
    #for i in k27_:
    #    if float(i[1]) > 20000:
    #        input_.append(i[0])

    #input_ = []
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/Palpant/pre-filtering_CPC_RNA-seq.txt')
    #for i in temp:
    #    input_.append(i[0])

    #background_ = []
    #for gene in exp_:
    #    if exp_[gene]['CPC_RNA-seq'] > 1.0:
    #        background_.append(gene)
    #print len(input_)
    #print len(background_)
    #results = get_correlated_genes(input_, background_, cor_, r_=0.9)
    #gg = count_genes(results)
    #print gg
    #genomics.write_file(gg, '/Users/woojunshim/Research/Data/Palpant/CPC_r0.9_counts_pre-filtering.txt')


    ### CREATE A TABLE FOR ALL GENES, H3K4ME3, H3K27ME3, RPKM MEDIAN VALUE
    #marks = ['H3K27me3','H3K4me3','RPKM']
    #pathway = '/Users/woojunshim/Research/Data/broadPeaks/'  
    #results = {}
    #file1 = genomics.read_file(pathway+'H3K27me3_median_summary.txt', [1,3], rowname='0')
    #file2 = genomics.read_file(pathway+'H3K4me3_median_summary.txt', [1], rowname='0')
    #file3 = genomics.read_file(pathway+'RPKM_median_summary.txt', [1], rowname='0')
    #for gene in file1:
    #    if (gene in file2) and (gene in file3):
    #        results[gene] = {}
    #        results[gene]['H3K27me3'] = file1[gene][0][0]
    #        results[gene]['H3K4me3'] = file2[gene][0][0]
    #        results[gene]['RPKM'] = file3[gene][0][0]
    #        results[gene]['TF'] = file1[gene][0][1]
    #genomics.write_table1(results, pathway+'all_genes_k4_k27_rpkm.txt')





    ### CALCULATE MEDIAN WIDTH VALUES FOR ALL GENES 
    #marks = ['H3K27me3','H3K4me3','H3K9me3','H3K27ac','H3K36me3','H3K4me1']
    #marks = ['RPKM']
    #pathway = '/Users/woojunshim/Research/Data/broadPeaks/'   
    
    #for no in range(len(marks)):
    #    mark = marks[no]        
    #    temp = read_table1(pathway+mark+'_widths.txt')
    #    results = []        
    #    genes = get_rownames(temp)
    #    for gene in genes:
    #        pp = []
    #        count = 0
    #        for col in temp[gene]:
    #            pp.append(temp[gene][col]+1)  #pseudo-count
    #            if temp[gene][col] != 0:
    #                count += 1
    #        pp.sort(reverse=True)
    #        med_ = len(pp) / 2
    #        if gene in tf_list:
    #            tag = '1'
    #        else:
    #            tag = '0'
    #        results.append([gene, pp[med_], count, tag])   
    #    results = genomics.sort_(results, idx=1, reverse_=True) 
    #    results.insert(0,['#gene','median_width','no_cells','TF'])
    #    genomics.write_file(results, pathway+mark+'_median_summary.txt')

    ### CALCULATE PROPORTIONS OF TFS IN EACH BIN (E.G. 100 GENES)   

    #marks = ['H3K27me3','H3K4me3','H3K9me3','H3K27ac','H3K36me3','H3K4me1']
    #pathway = '/Users/woojunshim/Research/Data/broadPeaks/'   
    
    #for mark in marks:
    #    cnt = 0
    #    bin_no = 0
    #    tf_ = 0
    #    znf_ = 0
    #    temp = genomics.read_file1(pathway+mark+'_median_summary.txt')       
    #    total = len(temp)
    #    total_tf = 0
    #    bin_size = int(total * 0.01)
    #    znt_count = 0
    #    for item in temp:
    #        if item[3]=='1':
    #            total_tf += 1
    #            if item[0] in znf_list:
    #                znt_count += 1
    #    rate = float(total_tf) / total
    #    znf_rate = float(znt_count) / total
    #    results = [['#bin_no','enrichment_TF','FET','proportion_ZNF']]
    #    for no in range(len(temp)):
    #        cnt += 1
    #        tf_ += int(temp[no][3])
    #        if temp[no][0] in znf_list:                
    #            znf_ += int(temp[no][3])
    #        if cnt % bin_size == 0:
    #            bin_no += 1
    #            a=tf_
    #            b=bin_size - a
    #            c=total_tf - tf_
    #            d=total-bin_size
    #            o,p = stat.fisher(a,b,c,d)                
    #            results.append([bin_no, (float(tf_)/bin_size)/rate, p, (float(znf_)/bin_size)/znf_rate])
    #            tf_ = 0
    #            znf_ = 0

    #    genomics.write_file(results, pathway+mark+'_TF_enrichment_percentile.txt')

    ### COMBINE TF PROPORTION FILES INTO A TABLE
    #marks = ['H3K27me3','H3K4me3','H3K9me3','H3K27ac','H3K36me3','H3K4me1']
    #pathway = '/Users/woojunshim/Research/Data/broadPeaks/'      
    #results = {}
    #for no in range(1,101):
    #    results[str(no)] = {}
    #    for mark in marks:
    #        results[str(no)][mark] = 0.00
    #for mark in marks:
    #    temp = genomics.read_file1(pathway+mark+'_TF_enrichment_percentile.txt')
    #    for item in temp:
    #        results[item[0]][mark] = item[2]
    #final = [[]]
    #for mark in marks:
    #    final[-1].extend([mark])
    #for no in range(1,101):
    #    final.append([no])
    #    for mark in marks:
    #        final[-1].extend([results[str(no)][mark]])
    
    #genomics.write_file(final, pathway+'Combined_FET_percentile.txt')

    ### CALCULATE CUMULATIVE FISHER'S EXACT TEST

    #marks = ['H3K27me3','H3K4me3','H3K9me3','H3K27ac','H3K36me3','H3K4me1']
    #pathway = '/Users/woojunshim/Research/Data/broadPeaks/'   
    #results = []
    #for mark in marks:
    #    results.append([mark])
    #    temp = genomics.read_file1(pathway+mark+'_median_summary.txt')
    #    input_ = []
    #    ref_ = []
    #    for item in temp:
    #        if item[3]=='1':
    #            ref_.append(item[3])
    #        input_.append(item[3])
    #    p = sliding_fet(input_, ref_, output_='p-value', convert_to_percentile=True, percentile_bin = 0.01)
    #    for m in p:
    #        results[-1].extend([m])
    #genomics.write_file(results, pathway+'FET_TF_excl.txt')


    ### EXTRACT H3K4ME3, H3K27ME3 AND EXPRESSION VALUES FOR A CELL TYPE
    #epi = 'E095'
    #k27me3 = convert_to_z('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_widths.txt')
    #g1 = get_rownames(k27me3)    
    #k4me3 = convert_to_z('/Users/woojunshim/Research/Data/broadPeaks/H3K4me3_widths.txt')
    #exp = convert_to_z('/Users/woojunshim/Research/Data/57epigenomes.RPKM.symbols.txt')
    #results = [['K27me3','K4me3','Exp']]
    #for g in g1:        
    #    if g in k4me3:
    #        if g in exp:
    #            results.append([g])
    #            results[-1].extend([k27me3[g][epi],k4me3[g][epi],exp[g][epi]])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/broadPeaks/'+epi+'_g.txt')

    ### CALCULATE STATISTICS BETWEEN TF AND NON-TF ACROSS CELL TYPES
    #genes = ['NKX2-5','TBX5','GATA4','GATA6','ISL1','HAND1','HAND2','MEIS1','MEIS2','TAL1','MYH6','MYH7','TNNI3']    
    #genes = ['TNNI3']    
    #tf_ = genomics.read_file1('/Users/woojunshim/Research/Data/TF/TF_combined.txt')
    #tf_list = []
    #for line in tf_:
    #    tf_list.append(line[0])    
    #tf_list = set(tf_list)
    #pathway = '/Users/woojunshim/Research/Data/broadPeaks/'
    #hm = ['H3K4me3','H3K27me3','H3K9me3','H3K27ac','H3K4me1']    
    #files = []
    #for h in hm:
    #    files.append(pathway+h+'_widths.txt')
    #files.append('/Users/woojunshim/Research/Data/57epigenomes.RPKM.symbols.txt')
    #genes = get_common_genes(files)
    #print len(genes)
    #pp = genomics.read_file1('/Users/woojunshim/Research/Data/common_epigenomes.txt')
    #colnames = []
    #for p in pp:
    #    colnames.append(p[0])
    #results = [['feature']]
    #for col in colnames:
    #    results[-1].extend([col])
    #for no in range(len(hm)):
    #    file = files[no]
    #    h = hm[no]    
    #    results.append([h])
    #    input_ = convert_to_z(file)
    #    for col in colnames:
    #        tf = []
    #        nontf = []
    #        for g in genes:
    #            if g in tf_list:
    #                tf.append(input_[g][col])
    #            else:
    #                nontf.append(input_[g][col])
    #        s, p = stat.t_test(tf, nontf)
    #        results[-1].extend([s])
    #genomics.write_file(results, pathway+'tf_nontf_diff_t_s.txt')


    ### FIND OVERLAPPING EPIGENOMES
    #temp1 = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K27ac_widths.txt')
    #temp2 = read_table1('/Users/woojunshim/Research/Data/57epigenomes.RPKM.symbols.txt')
    #col1 = get_colnames(temp1)
    #col2 = get_colnames(temp2)
    #over = genomics.intersection(col1, col2)
    #genomics.write_file(over, '/Users/woojunshim/Research/Data/common_epigenomes.txt')


    ### TAG GENES 
    #pathway = '/Users/woojunshim/Research/Data/Paige/'
    #days = ['day2','day5','day9','day14']
    #exp = read_table1(pathway+'expression/expression_data_ave_symbol.txt')
    #genes = get_rownames(exp)
    #for day in days:
    #    temp = []
    #    for gene in genes:
    #        temp.append([gene, exp[gene][day]])
    #    temp = genomics.sort_(temp, idx=1, reverse_=True)
    #    input_ = []
    #    for item in temp:
    #        input_.append(item[0])
    #    ref = []
    #    yy = genomics.read_file1(pathway+'H3K27me3_'+day+'_new.txt')
    #    for item in yy:
    #        if (float(item[3]) < 0.05) and (float(item[1]) > 0):
    #            ref.append(item[0])
    #    results = tag_genes(input_, ref)
    #    genomics.write_file(results, pathway+'H3K27me3_'+day+'_simple_filter.txt')


    ### EXTRACT WIDTHS FOR A GIVEN GENE
    #genes = ['NKX2-5','TBX5','GATA4','GATA6','ISL1','HAND1','HAND2','MEIS1','MEIS2','TAL1','MYH6','MYH7','TNNI3','TNNI1']    
    #genes = ['ZNF567','ZNF678','ZNF345','ZNF595','ZNF382','ZNF544']
    #pathway = '/Users/woojunshim/Research/Data/broadPeaks/'
    #hm = ['H3K4me3','H3K27me3','H3K9me3','H3K27ac','H3K4me1']
    #files = []
    #for h in hm:
    #    files.append(pathway+h+'_widths.txt')
    #files.append('/Users/woojunshim/Research/Data/57epigenomes.RPKM.symbols.txt')
    #pp = genomics.read_file1('/Users/woojunshim/Research/Data/common_epigenomes.txt')
    #colnames = []
    #for p in pp:
    #    colnames.append(p[0])
    #print colnames
    #for gene in genes:
    #    results = extract_features(files,gene,colnames, normalise_=True)
    #    genomics.write_file(results, pathway+gene+'_features_raw.txt')
    

    ### EXTRACT H3K4ME3 AND H3K27ME3 MEDIAN VALUES FOR SELECTED GENES      
    #genes = ['NKX2-5','TBX5','GATA4','GATA6','ISL1','HAND1','HAND2','MEIS1','MEIS2','TAL1','MYH6','MYH7','TNNI3','TNNI1'] 
    #colnames = ['H3K27me3','H3K4me3']
    #pathway = '/Users/woojunshim/Research/Data/broadPeaks/'
    #results = {}
    #for gene in genes:
    #    results[gene] = {}
    #    for col in colnames:
    #        results[gene][col] = 0.0
    #for col in colnames:
    #    temp_ = genomics.read_file(pathway+col+'_median_summary.txt', [1], rowname='0')
    #    for gene in genes:
    #        results[gene][col] = temp_[gene][0][0]
    #genomics.write_table1(results, pathway+'cardiac_k27_k4_median.txt')


    ### CREATE A SUMMARY TABLE FOR DAY 9 AND DAY 14 (PAIGE DATA)
    #top = 200
    #day = 'day9'
    #mark='H3K27me3'
    #genes_ = genomics.read_file1('/Users/woojunshim/Research/Data/cardiac_regulators__.txt')
    #genes = []
    #for line in genes_:
    #    genes.append(line[0])
    #results = {}
    #cols = ['Exp.','H3K4me3','H3K27me3']
    #for gene in genes:
    #    results[gene] = {}
    #    for col in cols:            
    #        results[gene][col] = 0
    #exp_ = read_table1('/Users/woojunshim/Research/Data/Paige/expression/expression_data_ave_symbol.txt')
    #gs = get_rownames(exp_)    
    #exp = set()
    #temp = []
    #temp_k4 = genomics.read_file1('/Users/woojunshim/Research/Data/Paige/H3K4me3_'+day+'_new.txt_.txt')
    #temp_k27 = genomics.read_file1('/Users/woojunshim/Research/Data/Paige/H3K27me3_'+day+'_new.txt_.txt')
    #ts4 = set()
    #ts27 = set()
    #for g in gs:
    #    temp.append([g, exp_[g][day]])
    #temp = genomics.sort_(temp, idx=1, reverse_=True)
    #for i in range(top):
    #    exp.add(temp[i][0])
    #    ts4.add(temp_k4[i][0])
    #    ts27.add(temp_k27[i][0])
    #for gene in genes:
    #    if gene in exp:
    #        results[gene]['Exp.'] = 1
    #    if gene in ts4:
    #        results[gene]['H3K4me3'] = 1
    #    if gene in ts27:
    #        results[gene]['H3K27me3'] = 1
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/Paige/Paige_'+day+'.txt')


    ### CONVERT WIDTHS TO BINS (DISCRETISATION)
    #files = ['H3K27me3','H3K4me3','H3K9me3']    
    #genes1 = set()
    #genes2 = set()
    #genes3 = set()
    #temp = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K4me3_widths.txt')
    #genes1 = get_rownames(temp)
    #temp = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_widths.txt')
    #genes2 = get_rownames(temp)
    #temp = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K9me3_widths.txt')
    #genes3 = get_rownames(temp)
    #aa = genomics.intersection(genes1, genes2)
    #bb = genomics.intersection(aa, genes3)
    #results1= {}
    #for bb in results1:
    #    results1[bb] = {}
    #    for file in files:
    #        results1[bb][file] = 0
    #for file in files:
    #    temp = read_table1('/Users/woojunshim/Research/Data/broadPeaks/'+file+'_widths.txt')
    #    results = convert_to_bins('/Users/woojunshim/Research/Data/broadPeaks/'+file+'_widths.txt', bins_=10, genes_=bb)
    #    for gene in bb:
    #        results1[gene][file] = results[gene]['E095']
    #    genomics.write_table1(results, '/Users/woojunshim/Research/Data/broadPeaks/'+file+'_widths_disc.txt')
    #genomics.write_file1(results1, '/Users/woojunshim/Research/Data/broadPeaks/E095_combined.txt')


    ### ADD COL IDS TO BEDGRAPH
    ### CALCULATE CHIP-SEQ SIGNALS AT A GIVEN LOCUS
    #results = [['#cell','sum_ChIP-seq']]
    #pathway = '/Users/woojunshim/Research/Data/Palpant/bw/'
    #files = ['C-EC_H3K4me3','C-EC_H3K27me3','H-EC_H3K4me3','H-EC_H3K27me3','CPC_H3K4me3','CPC_H3K27me3']
    #for file in files:
    #    results = add_id_col(pathway+file, col_idx=3)
    #    genomics.write_file(results, pathway+file+'.bed')

    #    results = extract_bed_entry(pathway+file+'.bed', ['chr4',57514153,57547872])
    #    genomics.write_file(results,pathway+'HOPX_'+file+'.txt')

    #    temp = genomics.read_file1(pathway+'HOPX_GSE97080_'+file+'.bedgraph.txt')
    #    sum_ = 0
    #    for item in temp:
    #        sum_ += float(item[4])
    #    results.append([file, sum_])
    #genomics.write_file(results, pathway+'chip-seq-signal.txt')

    ### Maximum likelihood est.
    #input= []
    #temp = genomics.read_file1('/Users/woojunshim/Research/Data/Paige/H3K27me3_stats.txt')
    #for item in temp:
    #    input.append([item[0], float(item[2])])
    #max_likelihood(input, tf_list)

    ### CALCULATE AVERAGE AND MEDIAN WIDTHS FOR H3K4ME3 WIDTHS
    #table_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_widths.txt')
    #results = []
    #epigenomes = get_colnames(table_)
    #for gene in table_:
    #    temp = []
    #    for col in epigenomes:
    #        if table_[gene][col] != float(0):
    #            temp.append(table_[gene][col])            
    #    
    #    results.append([gene, np.mean(temp)])
    #results.insert(0, ['#gene','average'])
    #genomics.write_file(results,'/Users/woojunshim/Research/Data/Paige/H3K27me3_stats_new.txt')


    ### RUN ANALYSIS ON PAIGE DATA 
    ### 1. GIVEN A GENE LIST RANKED BY RAW EXPRESSION VALUE
    ### 2. SELECTED TOP 30 GENES FROM THE TOP OF THE LIST (IF WITHIN THE LIST BY MEAN H3K27ME3 WIDTH, set by ref_threshold)    
    ### 3. USE THIS AS A MAGNET GENE SET AND IDENTIFY GENES THAT ARE HIGHLY CORRELATED
    ### 4. GO BACK TO THE ORIGINAL LIST AND REMOVE ONES THAT ARE NOT HIGHLY CORRELATED TO THE REFERERENCE GENE SET
    ### 5. CALCULATE (EXPRESSION / P-VALUE) FOR EACH GENE & RANK 
    #pathway = '/Users/woojunshim/Research/Data/Paige/'
    #days = ['day2','day5','day9','day14'] 
    #days = ['day14']
    #ref_file = pathway+'H3K27me3_stats.txt'  
    #type__ = 'H3K27me3'
    #for day in days:
    #    output_ = pathway+type__+'_'+day+'_new__.txt'
    #    temp = genomics.read_file1(pathway+'H3K27me3_'+day+'.txt')
    #    input_ = []
    #    for item in temp:
    #        input_.append([item[0], float(item[1])])        
    #    analysis_(input_, ref_file, ref_idx=2, ref_threshold=1490 , output_file = output_, type_=type__)  # threshold=1490 based on Max likelihood estimation

    ### RUN THE ANALYSIS ON TSANKAV DATA SET
    #pathway = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Analysis_results/Tsankov/'
    #temp = genomics.read_file1(pathway+'expression_FPKM_dMS.txt')
    #input_ = []
    #ref_file = '/Users/woojunshim/Research/Data/Paige/H3K27me3_stats.txt'  
    #for item in temp:
    #    if item[0] != '-':
    #        if float(item[-1]) != float(0):
    #            input_.append([item[0], float(item[-1])])
    #print input_[0:10]
    #analysis_(input_, ref_file, ref_idx=1, ref_threshold=1490 , output_file = pathway+'Tsankov_MS_results.txt', include_tf=False)

    ### CALCULATE RANK PRODUCTS OF H3K4ME3 AND H3K27ME3 RESULTS (PAIGE)
    #pathway = '/Users/woojunshim/Research/Data/Paige/'
    #days = ['day2','day5','day9','day14']       
    #for day in days:
    #    input_ = []
    #    k4me3 = genomics.read_file1(pathway+'H3K4me3_'+day+'_summary.txt')
    #    k27me3 = genomics.read_file1(pathway+'H3K27me3_'+day+'_summary.txt')
    #    for no in range(len(k4me3)):
    #        k4me3[no][1] = float(k4me3[no][1])
    #    for no in range(len(k27me3)):
    #        k27me3[no][1] = float(k27me3[no][1])
    #    k4me3 = genomics.sort_(k4me3, idx=1, reverse_=True)
    #    k4me3_ = {}
    #    for no in range(len(k4me3)):
    #        gene = k4me3[no][0]
    #        k4me3_[gene] = no+1
    #    k27me3 = genomics.sort_(k27me3, idx=1, reverse_=True)
    #    k27me3_ = {}
    #    for no in range(len(k27me3)):
    #        gene = k27me3[no][0]
    #        k27me3_[gene] = no+1
    #    for gene in k4me3_:
    #        input_.append([gene, k4me3_[gene], k27me3_[gene]])
    #    rp_list = rank_product(input_, 0, [1,2])
    #    genomics.write_file(rp_list, pathway+'rp_'+day+'.txt')


    ### TEST ON ENCODE DATA
    #pathway='/Users/woojunshim/Research/Data/Paige/'
    #epi = 'E120'    
    #ref_file = pathway+'H3K27me3_stats.txt'  
    #output_ = pathway+epi+'_H3K27me3.txt'
    #table_ = read_table1('/Users/woojunshim/Research/Data/57epigenomes.RPKM.symbols.txt')
    #input_ = []
    #for gene in table_:
    #    if table_[gene][epi] != 0:
    #        input_.append([gene,table_[gene][epi]])     
    #print input_[0:10]
    #analysis_(input_, ref_file, ref_idx=1, ref_threshold=1490 , output_file = output_, type_='H3K27me3', include_tf=True)  # threshold=1490 based on Max likelihood estimation

    ### CALCULATE RANK PRODUCTS OF H3K4ME3 AND H3K27ME3 RESULTS (ENCODE)
    #pathway='/Users/woojunshim/Research/Data/Paige/'
    #epi = 'E119'       
    #input_ = []
    #k4me3 = genomics.read_file1(pathway+epi+'_H3K4me3_summary.txt')
    #k27me3 = genomics.read_file1(pathway+epi+'_H3K27me3_summary.txt')
    #for no in range(len(k4me3)):
    #    k4me3[no][1] = float(k4me3[no][1])
    #for no in range(len(k27me3)):
    #    k27me3[no][1] = float(k27me3[no][1])
    #k4me3 = genomics.sort_(k4me3, idx=1, reverse_=True)
    #k4me3_ = {}
    #for no in range(len(k4me3)):
    #    gene = k4me3[no][0]
    #    k4me3_[gene] = no+1
    #k27me3 = genomics.sort_(k27me3, idx=1, reverse_=True)
    #k27me3_ = {}
    #for no in range(len(k27me3)):
    #    gene = k27me3[no][0]
    #    k27me3_[gene] = no+1
    #for gene in k4me3_:
    #    input_.append([gene, k4me3_[gene], k27me3_[gene]])
    #rp_list = rank_product(input_, 0, [1,2])
    #genomics.write_file(rp_list, pathway+'rp_'+epi+'.txt')


    ### TEST ON PALPANT DATA
    ### FIRST GET AVERAGE TPM FOR EACH TIME-POINTS
    #pathway = '/Users/woojunshim/Research/Data/Palpant/'
    #results = {}
    #table_ = read_table1(pathway+'GSE97080_RNAseq_samples_TPM.txt', numerical=False)
    #genes = get_rownames(table_)
    #colnames = get_colnames(table_)
    #groups = ['H-EC_RNAseq','C-EC_RNAseq','CPC_RNA-seq']
    #for gene in genes:
    #    results[gene] = {}
    #    for group in groups:
    #        ave_ = (float(table_[gene][group+'_rep1']) + float(table_[gene][group+'_rep2'])) / 2
    #        results[gene][group] = ave_
    #genomics.write_table1(results, pathway+'TPM_ave.txt')


    # NATHAN'S METHOD
    #pathway = '/Users/woojunshim/Research/Data/Palpant/'
    #groups = ['H-EC_RNAseq','C-EC_RNAseq','CPC_RNA-seq']    
    #table_ = read_table1('/Users/woojunshim/Research/Data/Palpant/TPM_ave.txt')
    #ref_table = genomics.read_file1('/Users/woojunshim/Research/Data/Paige/H3K27me3_stats.txt')
    #genes = get_rownames(table_)
    #ref = []
    #for no in range(len(ref_table)):
    #    ref.append([ref_table[no][0], float(ref_table[no][1])])
    #for group in groups:
    #    temp_ = []
    #    for gene in genes:
    #        temp_.append([gene, table_[gene][group]])
    #    temp_ = genomics.sort_(temp_, idx=1, reverse_=True)
    #    results = simple_analysis(temp_, ref, threshold_=20000)
    #    results.insert(0, ['#gene','TPM'])
    #    genomics.write_file(results, pathway+'pre-filtering_'+group+'.txt')

    # H3K27me3 & H3K4me3  
    #marks = ['H3K27me3','H3K4me3']
    #marks = ['H3K4me3']
    #for mark in marks:
    #    ref_file = '/Users/woojunshim/Research/Data/Paige/H3K27me3_stats.txt' 
    #    for group in groups:            
    #        output_ = pathway+'seed_'+mark+'_'+group+'_.txt'            
    #        input_ = []
    #        for gene in table_:
    #            if table_[gene][group] > 1:
    #                input_.append([gene,table_[gene][group]])     
    #        print input_[0:10]
    #        analysis_(input_, ref_file, ref_idx=1, ref_threshold=1000 , output_file = output_, type_=mark, include_tf=True)  # threshold=1490 based on Max likelihood estimation    

    # RANK PRODUCT
    #days = ['H-EC_RNAseq','C-EC_RNAseq','CPC_RNA-seq']         
    #for day in days:
    #    input_ = []
    #    k4me3 = genomics.read_file1(pathway+'seed_H3K4me3_'+day+'_summary.txt')
    #    k27me3 = genomics.read_file1(pathway+'seed_H3K27me3_'+day+'_summary.txt')
    #    for no in range(len(k4me3)):
    #        k4me3[no][1] = float(k4me3[no][1])
    #    for no in range(len(k27me3)):
    #        k27me3[no][1] = float(k27me3[no][1])
    #    k4me3 = genomics.sort_(k4me3, idx=1, reverse_=True)
    #    k4me3_ = {}
    #    for no in range(len(k4me3)):
    #        gene = k4me3[no][0]
    #        k4me3_[gene] = no+1
    #    k27me3 = genomics.sort_(k27me3, idx=1, reverse_=True)
    #    k27me3_ = {}
    #    for no in range(len(k27me3)):
    #        gene = k27me3[no][0]
    #        k27me3_[gene] = no+1
    #    for gene in k4me3_:
    #        input_.append([gene, k4me3_[gene], k27me3_[gene]])
    #    rp_list = rank_product(input_, 0, [1,2])
    #    rp_list = genomics.sort_(rp_list, idx=1, reverse_=False)
    #    genomics.write_file(rp_list, pathway+'rp_'+day+'.txt')


    #tf_ = genomics.read_file1('/Users/woojunshim/Research/Data/TF/TF_combined.txt')
    #tf_list = []
    #for line in tf_:
    #    tf_list.append(line[0])    
    #tf_list = set(tf_list)
    #pathway = '/Users/woojunshim/Research/Data/Paige/1/'
    #days = ['day0','day2','day5','day9','day14']  
    #marks = ['H3K4me3','H3K27me3']
    #for mark in marks:
    #    cor_ = '/Users/woojunshim/Research/Data/broadPeaks/svd/'+mark+'_cor.txt'  
    #    for day in days:
    #        fore = []
    #        back = []
    #        cnt = 0
    #        temp = genomics.read_file1(pathway+'h3k4me3_'+day+'_assigned_all.bed')
    #        for line in temp:
    #            if cnt < 20:
    #                if line[1] in tf_list:
    #                    fore.append(line[1])
    #                    cnt += 1
    #            back.append(line[1])
    #        print len(fore)
    #        print len(back)
    #        print fore
    #        rescue_analysis(candidate_=fore, background_=back, cor_file=cor_, output_=pathway+day+'_analysis_results_by_'+mark+'.txt', threshold_=0.05, multiple_correction=True, pair_analysis_=False)   






    ### FIND OVERLAPPED SIGNIFICANT GENES 
    #days = ['day2','day5','day9']
    #for day in days:
    #    results = find_common_genes('/Users/woojunshim/Research/Data/Paige/expression/'+day+'_analysis_results_by_H3K4me3_exp_20tf.txt','/Users/woojunshim/Research/Data/Paige/expression/'+day+'_analysis_results_by_H3K27me3_exp_20tf.txt')
    #    genomics.write_file(results, '/Users/woojunshim/Research/Data/Paige/expression/'+day+'_common_exp_20tf.txt')


    ### 
    #tf__ = read_table1('/Users/woojunshim/Research/Data/Paige/expression/tf_ranked_by_expression.txt')
    #file_ = read_table1('/Users/woojunshim/Research/Data/Paige/expression/expression_data_ave_symbol.txt')   
    #genes = get_rownames(file_) 
    #pathway = '/Users/woojunshim/Research/Data/Paige/expression/'
    #pathway = '/Users/woojunshim/Research/Data/Paige/1/'
    #days = ['day2','day5','day9','day14']  
    #marks = ['H3K4me3','H3K27me3']
    #tf_ = genomics.read_file1('/Users/woojunshim/Research/Data/TF/TF_combined.txt')
    #tf_list = []
    #for line in tf_:
    #    tf_list.append(line[0])    
    #tf_list = set(tf_list)
    #for mark in marks:
    #    cor_ = '/Users/woojunshim/Research/Data/broadPeaks/svd/'+mark+'_cor.txt'  
    #    for day in days:
    #        fore = []
    #        back = []
    #        cnt = 0
    #        tf_mm = []
    #        for gene in genes:
    #            if tf__[gene][day] < 99999:
    #                tf_mm.append([gene, tf__[gene][day]])
    #            back.append(gene)
    #        tf_mm = genomics.sort_(tf_mm, idx=1, reverse_=False)           
    #        for no in range(20):
    #            fore.append(tf_mm[no][0])                 
    #        print len(fore)
    #        print len(back)
    #        print fore
    #        rescue_analysis(candidate_=fore, background_=back, cor_file=cor_, output_=pathway+day+'_analysis_results_by_'+mark+'_exp_10tf.txt', threshold_=0.05, multiple_correction=True, pair_analysis_=False)   


    ### ANALYSIS USING TOP 20 HIGHLY EXPRESSED TFS FROM PAIGE DATA
    #tf__ = read_table1('/Users/woojunshim/Research/Data/Paige/expression/tf_ranked_by_expression.txt')
    #file_ = read_table1('/Users/woojunshim/Research/Data/Paige/expression/expression_data_ave_symbol.txt')   
    #genes = get_rownames(file_) 
    #pathway = '/Users/woojunshim/Research/Data/Paige/expression/'
    #pathway = '/Users/woojunshim/Research/Data/Paige/1/'
    #days = ['day2','day5','day9','day14']  
    #marks = ['H3K4me3','H3K27me3']
    #tf_ = genomics.read_file1('/Users/woojunshim/Research/Data/TF/TF_combined.txt')
    #tf_list = []
    #for line in tf_:
    #    tf_list.append(line[0])    
    #tf_list = set(tf_list)
    #for mark in marks:
    #    cor_ = '/Users/woojunshim/Research/Data/broadPeaks/svd/'+mark+'_cor.txt'  
    #    for day in days:
    #        fore = []
    #        back = []
    #        cnt = 0
    #        tf_mm = []
    #        for gene in genes:
    #            if tf__[gene][day] < 99999:
    #                tf_mm.append([gene, tf__[gene][day]])
    #            back.append(gene)
    #        tf_mm = genomics.sort_(tf_mm, idx=1, reverse_=False)
    #        tf_m = []
    #        for item in tf_mm:
    #            tf_m.append(item[0])
    #        yy = subset_table(cor_, rows=tf_m, cols=tf_m)
    #        fore = identify_correlated_genes(yy, tf_m, threshold_=0.6, no_=10)                       
    #        print len(fore)
    #        print len(back)
    #        print fore
    #        rescue_analysis(candidate_=fore, background_=back, cor_file=cor_, output_=pathway+day+'_analysis_results_by_'+mark+'_exp_10tf.txt', threshold_=0.05, multiple_correction=True, pair_analysis_=False)   

    

    ### ASSIGN PEAKS TO PAIGE DATA
    #pathway = '/Users/woojunshim/Research/Data/Paige/1/'
    #days = ['day0','day2','day5','day9','day14']
    #tss_ = '/Users/woojunshim/Research/Data/hg19_TSS_.txt'
    #output_pathway = pathway    
    #max_width_= 2500
    #cnt = 0    
    #for day in days:
    #    mm = 1
    #    temp = genomics.read_file1(pathway+day+'_all.bed')
    #    for no in range(len(temp)):
    #        temp[no].extend(['peak_'+str(mm)])
    #        mm += 1
    #    genomics.write_file(temp, pathway+day+'_all_.bed')

    #for epi in days:
    #    cnt += 1
    #    print cnt
    #    print epi
    #    print
    #    file_ = pathway+epi+'_all_.bed'    
    #    main(file_, output_=output_pathway+epi+'_H3K4me3_genes.txt', max_width__=max_width_, tss__=tss_, dominant_=True, convert_DS=False, centre_=True)

    ### ANALYSIS ON PAIGE DATA
    ### USING TOP 10 TFS FROM WIDTH OF H3K4ME3
    #tf_ = genomics.read_file1('/Users/woojunshim/Research/Data/TF/TF_combined.txt')
    #tf_list = []
    #for line in tf_:
    #    tf_list.append(line[0])    
    #tf_list = set(tf_list)
    #pathway = '/Users/woojunshim/Research/Data/Paige/1/'
    #days = ['day0','day2','day5','day9','day14']  
    #marks = ['H3K4me3','H3K27me3']
    #for mark in marks:
    #    cor_ = '/Users/woojunshim/Research/Data/broadPeaks/svd/'+mark+'_cor.txt'  
    #    for day in days:
    #        fore = []
    #        back = []
    #        cnt = 0
    #        temp = genomics.read_file1(pathway+'h3k4me3_'+day+'_assigned_all.bed')
    #        for line in temp:
    #            if cnt < 20:
    #                if line[1] in tf_list:
    #                    fore.append(line[1])
    #                    cnt += 1
    #            back.append(line[1])
    #        print len(fore)
    #        print len(back)
    #        print fore
    #        rescue_analysis(candidate_=fore, background_=back, cor_file=cor_, output_=pathway+day+'_analysis_results_by_'+mark+'.txt', threshold_=0.05, multiple_correction=True, pair_analysis_=False)   

    ### CONVERT PAIGE EXPRESSION DATA ID TO GENE SYMBOLS
    #data_ = read_table1('/Users/woojunshim/Research/Data/Paige/expression/expression_data_ave.txt')
    #days = get_colnames(data_)
    #genes = get_rownames(data_)
    #input_file = []
    #for gene in genes:
    #    input_file.append([gene])
    #conversion = convert_id(input_file, '/Users/woojunshim/Research/Data/Paige/expression/affy_annotation_table.txt', col_idx1=1, col_idx2=2)  
    #print conversion[0]
    #print input_file[0]
    #results = {}
    #for no in range(len(input_file)):
    #    gene = conversion[no] 
    #    results[gene] = {}
    #    for day in days:
    #        results[gene][day] = data_[input_file[no][0]][day]
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/Paige/expression/expression_data_ave_symbol.txt')

    ### EXTRACT TFS FROM PAIGE EXPRESSION DATA
    #file_ = read_table1('/Users/woojunshim/Research/Data/Paige/expression/expression_data_ave_symbol.txt')
    #file_ = read_table1('/Users/woojunshim/Research/Data/57epigenomes.RPKM.symbols.txt')
    #tf_ = genomics.read_file1('/Users/woojunshim/Research/Data/TF/TF_combined.txt')
    #tf_list = []
    #for line in tf_:
    #    tf_list.append(line[0])  
    #tf_list = set(tf_list)
    #results = {}
    #days = get_colnames(file_)
    #genes = get_rownames(file_)
    #for gene in genes:
    #    results[gene] = {}
    #    for day in days:
    #        results[gene][day] = 99999
    #for day in days:
    #    temp = []
    #    for gene in genes:
    #        if gene in tf_list:
    #            temp.append([gene, file_[gene][day]])
    #    temp = genomics.sort_(temp, idx=1, reverse_=True)
    #    for i in range(len(temp)):
    #        results[temp[i][0]][day] = i+1
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/tf_ranked_RPKM.txt')

    ### USING THE TOP 20 TF RESULTS, EXTRACT TOP 200 GENES BEFORE AND AFTER THE FILTERING
    ### FOR EXPRESSION DATA (RAW EXPRESSION DATA)
    #pathway = '/Users/woojunshim/Research/Data/Paige/expression/'
    #days = ['day2','day5','day9','day14'] 
    #marks = ['H3K4me3','H3K27me3']
    #before_ = read_table1('/Users/woojunshim/Research/Data/Paige/expression/expression_data_ave_symbol.txt')
    #for mark in marks:
    #    for day in days:            
    #        yes = set()
    #        results = []
    #        after = genomics.read_file1(pathway+day+'_analysis_results_by_'+mark+'_exp_20tf.txt')
    #        for line in after:
    #            if float(line[1]) > float(0):
    #                if float(line[3]) < 0.05:
    #                    yes.add(line[0])
    #        temp = []
    #        for gene in before_:
    #            temp.append([gene, before_[gene][day]])
    #        temp = genomics.sort_(temp, idx=1, reverse_=True)
    #        for i in range(200):
    #            results.append([temp[i][0]])            
    #        cnt = 0            
    #        for line in temp:
    #            if line[0] in yes:
    #                results[cnt].extend([line[0]])
    #                cnt += 1                    
    #            if cnt==200:
    #                break
    #        genomics.write_file(results,pathway+mark+'_'+day+'_top200_exp.txt')



    ### USING THE TOP 20 TF RESULTS, EXTRACT TOP 200 GENES BEFORE AND AFTER THE FILTERING
    #pathway = '/Users/woojunshim/Research/Data/Paige/1/'
    #days = ['day0','day2','day5','day9','day14'] 
    #marks = ['H3K4me3','H3K27me3']
    #for mark in marks:
    #    for day in days:
    #        yes = set()
    #        results = []
    #        after = genomics.read_file1(pathway+day+'_analysis_results_by_'+mark+'.txt')
    #        for line in after:
    #            if float(line[1]) > float(0):
    #                if float(line[3]) < 0.05:
    #                    yes.add(line[0])
    #        before = genomics.read_file1(pathway+'h3k4me3_'+day+'_assigned_all.bed')
    #        for i in range(200):
    #            results.append([before[i][1]])            
    #        cnt = 0            
    #        for line in before:
    #            if line[1] in yes:
    #                results[cnt].extend([line[1]])
    #                cnt += 1                    
    #            if cnt==200:
    #                break
    #        genomics.write_file(results,pathway+mark+'_'+day+'_top200.txt')







    #print len(fore)
    #print len(back)
    #print fore[0:10]
    #cor_ = '/Users/woojunshim/Research/Data/broadPeaks/svd/H3K4me3_cor.txt'
    #rescue_analysis(candidate_=fore, background_=back, cor_file=cor_, output_='/Users/woojunshim/Research/Data/broadPeaks/svd/E095_H3K4me3_results.txt', threshold_=0.05, multiple_correction=True, pair_analysis_=False)   



    ### ANALYSIS USING SVD REDUCED H3K4ME3 & H3K27MES ON E095
    ### DE_TF USED AS THE FOREGROUND, DEG USED AS THE BACKGROUND    
    #file1 = read_table1('/Users/woojunshim/Research/Data/highly_expressed_genes/DEG/new/DE_genes_table.txt')
    #file2 = read_table1('/Users/woojunshim/Research/Data/highly_expressed_genes/DEG/new/DE_TF_table.txt')
    #fore = []
    #back = []
    #epi = 'E095'
    #for gene in file2:
    #    if file2[gene][epi] != 0:
    #        fore.append(gene)
    #for gene in file1:
    #    if file1[gene][epi] != 0:
    #        back.append(gene)
    #print len(fore)
    #print len(back)
    #print fore[0:10]
    #cor_ = '/Users/woojunshim/Research/Data/broadPeaks/svd/H3K4me3_cor.txt'
    #rescue_analysis(candidate_=fore, background_=back, cor_file=cor_, output_='/Users/woojunshim/Research/Data/broadPeaks/svd/E095_H3K4me3_results.txt', threshold_=0.05, multiple_correction=True, pair_analysis_=False)   

    ### FILTERING OUT NOT SIGNIFICANTLY CORRELATED GENES MM10
    #data_ = genomics.read_file1('/Users/woojunshim/Research/Data/mm10/h3k4me3/genes/ENCFF827DGB_genes.txt')
    #genes = set()
    #ref_ = genomics.read_file1('/Users/woojunshim/Research/Data/mm10/h3k4me3/mm10_results.txt')
    #for item in ref_:        
    #    if float(item[1]) > 0:
    #        if float(item[-1]) < 0.05:
    #            genes.add(item[0])
    #results = [['#gene','H3K4me3']]
    #for item in data_:
    #    if item[1] in genes:
    #        results.append([item[1],item[2]])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/mm10/h3k4me3/mm10_results_.txt')

    ### MM10 analysis for Mike
    #file_ = genomics.read_file1('/Users/woojunshim/Research/Data/mm10/h3k4me3/genes/ENCFF827DGB_genes.txt')
    #fore = []
    #back = []
    #cnt = 0
    #for item in file_:        
    #    if cnt <200:
    #        fore.append(item[1])
    #    back.append(item[1])
    #    cnt +=1
    #print len(fore)
    #print len(back)
    #print fore[0:10]
    #cor_ = '/Users/woojunshim/Research/Data/mm10/h3k4me3/mm10_cor.txt'
    #rescue_analysis(candidate_=fore, background_=back, cor_file=cor_, output_='/Users/woojunshim/Research/Data/mm10/h3k4me3/mm10_results.txt', threshold_=0.05, multiple_correction=True, pair_analysis_=False)

    ### CALCULATE DISTANCE TO CLOESEST TSS FOR GENES AND WRITE A SUMMARY TABLE
    #tss = {}
    #tss_ = open('/Users/woojunshim/Research/Data/hg19_TSS_.txt', 'r')
    #for line in tss_:
    #    line = line.strip().split()
    #    if line[5] not in tss:
    #        tss[line[5]] = []
    #    if line[2] == '+':
    #        tss[line[5]].append(line)
    #groups = ['H3K4me1','H3K9me3','H3K36me3','H3K27ac','H3K4me3','H3K27me3']      
    
    #pathway = '/Users/woojunshim/Research/Data/broadPeaks/'    
    #for group in groups:
    #    results = {}
    #    tissue_groups__ = []
    #    for epi in tissue_groups_:
    #        try:
    #            file_ = genomics.read_file1(pathway+group+'/'+epi+'_'+group+'_genes.txt')
    #            tissue_groups__.append(epi)                

    #        except:
    #            pass
    #    for epi in tissue_groups__:
    #        try:
    #            file_ = genomics.read_file1(pathway+group+'/'+epi+'_'+group+'_genes.txt')

    #            for item in file_:
    #                if item[1] not in results:
    #                    results[item[1]] = {}
    #                    for m in tissue_groups__:
    #                        results[item[1]][m] = 0.0
    #                results[item[1]][epi] += float(item[2])
    #        except:
    #            pass
    #    genomics.write_table1(results, pathway+group+'_widths.txt')    


    ### CREATE A MATRIX FOR NORMALISED EXPRESSION VALUES (PAIGE)
    #pathway = '/Users/woojunshim/Research/Data/Paige/expression/'
    #colnames = ['d1','d2','d5','d14']
    #results = {}
    #genes = set()
    #for col in colnames:
    #    data_ = genomics.read_file1(pathway+col+'.txt')
    #    for item in data_:
    #        if item[0] not in genes:
    #            genes.add(item[0])
    #for gene in genes:
    #    results[gene] = {}
    #    for col in colnames:
    #        results[gene][col] = 0.0
    #for col in colnames:
    #    data_ = genomics.read_file1(pathway+col+'.txt')
    #    for item in data_:
    #        gene = item[0]
    #        results[gene][col] = item[1]
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/Paige/expression/noramlised_combined_rep1.txt')

    ### Maximum likelihhod extimation 
    #tf_list_ = genomics.read_file1('/Users/woojunshim/Research/Data/TF/TF_combined.txt')
    #mrna_list_ = genomics.read_file1('/Users/woojunshim/Research/Data/mRNA_genes.txt')
    #tf_list = set()
    #mrna_list = set()
    #for item in tf_list_:
    #    tf_list.add(item[0])


    ### 
    #table_ = read_table1('/Users/woojunshim/Research/Data/57epigenomes.RPKM.symbols.txt')
    #colnames = get_colnames(table_)
    #epigenomes_ = colnames
    #for col in colnames:
    #    if col in tissue_groups_:
    #        epigenomes_.append(col)
    #print len(epigenomes_)
    #exp_median = {}
    #genes = get_rownames(table_)
    #for gene in genes:
    #    temp = []
    #    for col in epigenomes_:
                     
    #        temp.append(table_[gene][col])
    #    mean_ = np.mean(temp)        
    #    exp_median[gene] = mean_   
    
    #data_ = read_table1('/Users/woojunshim/Research/Data/Paige/expression/expression_data_ave.txt')
    #days = get_colnames(data_)
    #genes = get_rownames(data_)
    #input_file = []
    #for gene in genes:
    #    input_file.append([gene])
    #conversion = convert_id(input_file, '/Users/woojunshim/Research/Data/Paige/expression/affy_annotation_table.txt', col_idx1=1, col_idx2=2)   
    #width_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_widths.txt')   
    #dd = open('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_broad_genes.txt','r')    
    #epigenomes = get_colnames(width_)
    #ref_genes = set()
    #combined = {}
    #for line in dd:
    #    line=line.strip().split()
    #    ref_genes.add(line[0])
    #for day in days:
    #    results = []        
    #    for no in range(len(genes)):
    #        gene = conversion[no]            
    #        if gene in ref_genes:
    #            results.append([gene, data_[genes[no]][day]])
    #    results = genomics.sort_(results, idx=1, reverse_=True)
    #    for no in range(len(results)):
    #        item = results[no]
    #        gene = item[0]
    #        temp = []
    #        for col in epigenomes:
    #            if width_[gene][col] != 0:
    #                temp.append(width_[gene][col])
    #        mean_ = np.mean(temp)
    #        sd_ = np.std(temp)
    #        temp.sort(reverse=True)
    #        med_ = temp[len(temp)/2]
    #        #results[no].extend([mean_,med_,sd_])
    #        if gene in exp_median:
    #            results[no].extend([mean_, np.log2(mean_), exp_median[gene], np.log2(exp_median[gene])])
    #        if gene not in combined:
    #            if gene in exp_median:
    #                combined[gene] = [gene, mean_, np.log2(mean_), exp_median[gene], np.log2(exp_median[gene]), mean_/exp_median[gene], np.log2(mean_)/np.log2(exp_median[gene])]    

    #    results.insert(0, ['#gene','Exp.value','Mean_h3k27me3','log2(mean_h3k27me3)','Mean_exp','log2(mean_hexp)'])
    #    genomics.write_file(results, '/Users/woojunshim/Research/Data/Paige/H3K27me3_'+day+'_.txt')
    #combined_ = [['#gene','Mean_h3k27me3','log2(mean_h3k27me3)','Mean_exp','log2(mean_hexp)','h3k27me3/exp','log2(h3k27me3/exp)']]
    #for gene in combined:                
    #    combined_.append(combined[gene])
    #genomics.write_file(combined_, '/Users/woojunshim/Research/Data/Paige/H3K27me3_stats_.txt')

    ### APPLY THESE GENE SETS TO PAIGE DATA SETS    
    #data_ = read_table1('/Users/woojunshim/Research/Data/Paige/expression/expression_data_ave.txt')
    #days = get_colnames(data_)
    #genes = get_rownames(data_)
    #input_file = []
    #for gene in genes:
    #    input_file.append([gene])
    #conversion = convert_id(input_file, '/Users/woojunshim/Research/Data/Paige/expression/affy_annotation_table.txt', col_idx1=1, col_idx2=2)   
    #width_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_widths.txt')   
    #dd = open('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_broad_genes.txt','r')    
    #epigenomes = get_colnames(width_)
    #ref_genes = set()
    #combined = {}
    #for line in dd:
    #    line=line.strip().split()
    #    ref_genes.add(line[0])
    #for day in days:
    #    results = []        
    #    for no in range(len(genes)):
    #        gene = conversion[no]            
    #        if gene in ref_genes:
    #            results.append([gene, data_[genes[no]][day]])
    #    results = genomics.sort_(results, idx=1, reverse_=True)
    #    for no in range(len(results)):
    #        item = results[no]
    #        gene = item[0]
    #        temp = []
    #        for col in epigenomes:
    #            if width_[gene][col] != 0:
    #                temp.append(width_[gene][col])
    #        mean_ = np.mean(temp)
    #        sd_ = np.std(temp)
    #        temp.sort(reverse=True)
    #        med_ = temp[len(temp)/2]
    #        #results[no].extend([mean_,med_,sd_])
    #        if gene in exp_median:
    #            results[no].extend([mean_, np.log2(mean_), exp_median[gene], np.log2(exp_median[gene])])
    #        if gene not in combined:
    #            if gene in exp_median:
    #                combined[gene] = [gene, mean_, np.log2(mean_), exp_median[gene], np.log2(exp_median[gene]), mean_/exp_median[gene], np.log2(mean_)/np.log2(exp_median[gene])]    

    #    results.insert(0, ['#gene','Exp.value','Mean_h3k27me3','log2(mean_h3k27me3)','Mean_exp','log2(mean_hexp)'])
    #    genomics.write_file(results, '/Users/woojunshim/Research/Data/Paige/H3K27me3_'+day+'_.txt')
    #combined_ = [['#gene','Mean_h3k27me3','log2(mean_h3k27me3)','Mean_exp','log2(mean_hexp)','h3k27me3/exp','log2(h3k27me3/exp)']]
    #for gene in combined:                
    #    combined_.append(combined[gene])
    #genomics.write_file(combined_, '/Users/woojunshim/Research/Data/Paige/H3K27me3_stats_.txt')


    ### EXTRACT COMBINED SETS OF GENES WITH BROAD H3K27ME3 OR H3K9ME3 
    #file_ = genomics.read_file1('/Users/woojunshim/Research/Data/broadPeaks/elbow_points_H3K9me3.txt')    
    #data_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K9me3_widths.txt')
    #genes = get_rownames(data_)
    #results = set()
    #for no in range(1, len(file_)):        
    #    epi = file_[no][0]
    #    if epi in tissue_groups_:
    #        temp = []
    #        for gene in genes:
    #            if data_[gene][epi] != 0:
    #                temp.append([gene, data_[gene][epi]])
    #        temp = genomics.sort_(temp, idx=1, reverse_=True)
    #        for m in range(int(file_[no][1])):
    #            if temp[m][0] not in results:
    #                results.add(temp[m][0])
    #outcome = []
    #for item in results:
    #    outcome.append([item])
    #genomics.write_file(outcome, '/Users/woojunshim/Research/Data/broadPeaks/H3K9me3_broad_genes.txt')


    ### AND FILTER GENES (PAIGE DATA)
    #data_ = read_table1('/Users/woojunshim/Research/Data/Paige/expression/expression_data_ave.txt')


    ### FIND ELBOW POINTS FOR H3K9ME3
    #file_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K9me3_widths.txt')
    #genes = get_rownames(file_)
    #results = []
    #for epi in epigenomes:
    #    temp = []
    #    for gene in genes:
    #        if file_[gene][epi] != 0:
    #            temp.append(file_[gene][epi])
    #    temp.sort(reverse=True)
    #    el = find_elbow(temp)
    #    results.append([epi, el])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/broadPeaks/elbow_points_H3K9me3.txt')



    ### CALCULATE OVERLAP OF TOP 500 GENES RANKED BY A RANGE OF HMS 
    #pathway = '/Users/woojunshim/Research/Data/broadPeaks/'
    #epi ='E013'
    #marks = ['H3K4me3','H3K27me3','H3K36me3','H3K9me3','H3K4me1','H3K27ac']
    #results = {}
    #data_ = {}
    #top_no = 500
    #for mark in marks:
    #    data_[mark] = []
    #    file_ = read_table1(pathway+mark+'_widths.txt')
    #    temp_ = []        
    #    genes = get_rownames(file_)
    #    for gene in genes:
    #        if file_[gene][epi] != float(0):
    #            temp_.append([gene, file_[gene][epi]])
    #    temp_ = genomics.sort_(temp_, idx=1, reverse_=True)
    #    for i in range(top_no):
    #        data_[mark].append(temp_[i][0])    
    #for m1 in marks:
    #    results[m1] = {}
    #    for m2 in marks:
    #        tt = len(genomics.intersection(data_[m1], data_[m2]))
    #        results[m1][m2] = float(tt) / top_no
    #genomics.write_table1(results, pathway+'hm_top500_overlap_'+epi+'.txt')

    ### Average overlap
    #pathway = '/Users/woojunshim/Research/Data/broadPeaks/'    
    #marks = ['H3K4me3','H3K27me3','H3K36me3','H3K9me3','H3K4me1','H3K27ac']
    #temp = read_table1(pathway+'H3K27ac_widths.txt')
    #epigenomes = get_colnames(temp)
    #results = {}
    #data_ = {}
    #top_no = 500
    #print len(epigenomes)    
    #for m1 in marks:
    #    results[m1] = {}
    #    for m2 in marks:
    #        results[m1][m2] = 0.0            
    #for epi in epigenomes:
    #    print epi
    #    for mark in marks:
    #        data_[mark] = []
    #        file_ = read_table1(pathway+mark+'_widths.txt')
    #        temp_ = []        
    #        genes = get_rownames(file_)
    #        for gene in genes:
    #            if file_[gene][epi] != float(0):
    #                temp_.append([gene, file_[gene][epi]])
    #        temp_ = genomics.sort_(temp_, idx=1, reverse_=True)
    #        for i in range(top_no):
    #            data_[mark].append(temp_[i][0])    
    #    for m1 in marks:            
    #        for m2 in marks:
    #            tt = len(genomics.intersection(data_[m1], data_[m2]))
    #            results[m1][m2] += float(tt) / top_no                
    #for m1 in marks:
    #    for m2 in marks:
    #        results[m1][m2] = results[m1][m2] / len(epigenomes)
    #genomics.write_table1(results, pathway+'hm_top500_overlap_average.txt')







    ### COMBINE BOTH H3K4ME3 AND H3K27ME3 CORRELATION TABLES
    #pathway = '/Users/woojunshim/Research/Data/broadPeaks/svd/'
    #threshold_ = 1.8 # for sum of the two correlation values
    #h3k4me3 = read_table1(pathway+'D30_filtered_genes_H3K4me3_cor.txt')
    #h3k27me3 = read_table1(pathway+'D30_filtered_genes_H3K27me3_cor.txt')
    #genes1 = get_rownames(h3k4me3)
    #genes2 = get_rownames(h3k27me3)
    #genes = genomics.intersection(genes1, genes2)
    #results = {}
    #for gene in genes:
    #    results[gene] = {}
    #    for g in genes:
    #        temp = h3k4me3[gene][g] + h3k27me3[gene][g]
    #        if temp > threshold_:
    #            results[gene][g] = 1
    #        else:
    #            results[gene][g] = 0
    #genomics.write_table1(results, pathway+'D30_filtered_genes_combined_binary.txt')

    # FINDING A THRESHOLD FOR BEST COVERAGE WITH MINIMAL OVERLAP
    #pathway = '/Users/woojunshim/Research/Data/broadPeaks/svd/'
    #threshold_ = 1.9 # for sum of the two correlation values
    #h3k4me3 = read_table1(pathway+'D30_filtered_genes_H3K4me3_cor.txt')
    #h3k27me3 = read_table1(pathway+'D30_filtered_genes_H3K27me3_cor.txt')
    #genes1 = get_rownames(h3k4me3)
    #genes2 = get_rownames(h3k27me3)
    #genes = genomics.intersection(genes1, genes2)
    #results = {}
    #current = set(genes[0])
    #stat_ = []
    #for i in range(10):
    #    covered = set()
    #    diff = set()        
    #    threshold_ = threshold_ - 0.1*i
    #    for gene in genes:
    #        results[gene] = {}
    #        for g in genes:
    #            temp = h3k4me3[gene][g] + h3k27me3[gene][g]
    #            if temp > threshold_:
    #                results[gene][g] = 1   
    #                if g != gene:                 
    #                    covered.add(g)
    #                    if g not in current:
    #                        diff.add(g)                   
    #            else:
    #                results[gene][g] = 0
    #    overlap_ = genomics.intersection(list(covered), list(current))
    #    yy = float(len(diff))/len(overlap_)
    #    stat_.append([threshold_, yy])
    #    if yy < 1.0:
    #        break    
    #    current = covered

    #genomics.write_file(stat_, pathway+'D30_filtered_genes_stat.txt')  


    #genomics.write_table1(results, pathway+'D30_filtered_genes_combined_binary.txt')






    ### ANALYSIS FOR MM10
    #groups = ['H3K4me1','H3K9me3','H3K36me3','H3K27ac']  
    #groups = ['H3K27ac']
    #groups = ['H3K4me3']
    #output_pathway = '/Users/woojunshim/Research/Data/mm10/h3k4me3/genes/'
    #pathway = '/Users/woojunshim/Research/Data/mm10/h3k4me3/bed/'
    #meta_ = genomics.read_file1('/Users/woojunshim/Research/Data/mm10/h3k4me3/selected_metadata.txt')
    #cnt = 0
    #tss_ = genomics.read_file('/Users/woojunshim/Research/Data/mm10_tss_.txt',[12,2,4,5,3])
    #tss = genomics.tss(tss_, chr_idx=1, position_list=[2, 3], strand_idx=4, id_idx=0)
    
    #for item in meta_:
    #    group = item[0]
    #    print group         
    #    max_width_= 2500             
        
    #    cnt += 1
    #    print cnt
    #    print group
    #    print
    #    file_ = pathway+group+'.bed'   
    #    main(file_, output_=output_pathway+group+'_genes.txt', tss__='/Users/woojunshim/Research/Data/mm10_tss_.txt', max_width__=max_width_, dominant_=True, convert_DS=False, centre_=True, remove_ncrna_=False)
    
    #pathway = '/Users/woojunshim/Research/Data/mm10/h3k4me3/genes/'
    #for group in groups:
    #    results = {}
    #    tissue_groups__ = []
    #    for item in meta_:
    #        tissue_groups__.append(item[0])
    #    for item in meta_:
    #        epi = item[0]
    #        try:
    #            file_ = genomics.read_file1(pathway+epi+'_genes.txt')
    #            for item in file_:
    #                if item[1] not in results:
    #                    results[item[1]] = {}
    #                    for m in tissue_groups__:
    #                        results[item[1]][m] = 0.0
    #                results[item[1]][epi] += float(item[2])
    #        except:
    #            pass
    #    genomics.write_table1(results, pathway+group+'_widths.txt')


    ### EXTRACT SAMPLE METADATA FOR MM10
    #file_ = open('/Users/woojunshim/Research/Data/mm10/h3k4me3/metadata.txt', 'r')
    #results = []
    #ids = set()
    #for line in file_:
    #    line = line.replace(' ', '_')
    #    line = line.strip().split()        
    #    if line[0].startswith('EN'):
    #        if line[3] not in ids:                
    #            if '_' in line[19]:
    #                ids.add(line[3])
    #                results.append([line[0], line[3], line[6], line[10]])

    #file_ = open('/Users/woojunshim/Research/Data/mm10/h3k4me3/metadata.txt', 'r')    
    #for line in file_:
    #    line = line.replace(' ', '_')
    #    line = line.strip().split()
    #    if line[0].startswith('EN'):
    #        if line[3] not in ids:                
    #            ids.add(line[3])
    #            results.append([line[0], line[3], line[6], line[10]])

    #genomics.write_file(results, '/Users/woojunshim/Research/Data/mm10/h3k4me3/selected_metadata.txt')



    ### SATURATION ANALYSIS FOR ALL EPIGENETIC MARKS FOR EXPRESSED GENES
    #rpkm = read_table1('/Users/woojunshim/Research/Data/57epigenomes.RPKM.symbols.txt')
    #epigenomes_ = get_colnames(rpkm)    
    #epigenomes = []
    #for epi in epigenomes_:
    #    if epi in tissue_groups_:
    #        epigenomes.append(epi)
    #groups = ['H3K4me3','H3K27me3','H3K36me3','H3K9me3','H3K4me1','H3K27ac']    
    #for group in groups:
    #    results = []
    #    ref_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/'+group+'_widths.txt')
    #    cols = get_colnames(ref_)        
    #    for epi in epigenomes:  
    #        if epi in cols:          
    #            ref_list_ = []
    #            for gene in ref_:
    #                if ref_[gene][epi] != 0:
    #                    ref_list_.append([gene, ref_[gene][epi]])
    #            ref_list_ = genomics.sort_(ref_list_, idx=1, reverse_=True)
    #            ref_list = []
    #            for item in ref_list_:
    #                ref_list.append(item[0])            
    #            tt = mean_values('/Users/woojunshim/Research/Data/57epigenomes.RPKM.symbols.txt', colname=epi, order_list=ref_list, cumulative_=True)
    #            results.append([epi])
    #            for item in tt:
    #                results[-1].extend([item])
    #    genomics.write_file(results, '/Users/woojunshim/Research/Data/broadPeaks/'+group+'_expression_mean_cumulative.txt')



    ### CALCULATE MEDIAN VALUE FOR EACH GENE
    #results = calculate_('/Users/woojunshim/Research/Data/broadPeaks/H3K4me3_widths.txt')
    #genomics.write_table1(dic_to_list(results), '/Users/woojunshim/Research/Data/broadPeaks/H3K4me3_median.txt')

    #results_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K4me3_widths.txt')
    #genes = get_rownames(results_)
    #colnames = get_colnames(results_)
    #for gene in genes:
    #    thre = results[gene]
    #    for col in colnames:
    #        if results_[gene][col] <= thre:
    #            results_[gene][col] = 0.0
    #genomics.write_table1(results_,'/Users/woojunshim/Research/Data/broadPeaks/H3K4me3_width_median.txt' )




    ### CREATE A TABLE FOR SUM OF WIDTHS 
    #groups = ['H3K4me1','H3K9me3','H3K36me3','H3K27ac','H3K4me3','H3K27me3']  
    #groups = ['H3K4me1','H3K9me3','H3K36me3','H3K27ac']  
    
    #pathway = '/Users/woojunshim/Research/Data/broadPeaks/'    
    #for group in groups:
    #    results = {}
    #    tissue_groups__ = []
    #    for epi in tissue_groups_:
    #        try:
    #            file_ = genomics.read_file1(pathway+group+'/'+epi+'_'+group+'_genes.txt')
    #            tissue_groups__.append(epi)
    #        except:
    #            pass
    #    for epi in tissue_groups__:
    #        try:
    #            file_ = genomics.read_file1(pathway+group+'/'+epi+'_'+group+'_genes.txt')
    #            for item in file_:
    #                if item[1] not in results:
    #                    results[item[1]] = {}
    #                    for m in tissue_groups__:
    #                        results[item[1]][m] = 0.0
    #                results[item[1]][epi] += float(item[2])
    #        except:
    #            pass
    #    genomics.write_table1(results, pathway+group+'_widths.txt')



    ### CREATE A TABLE FOR TF
    #tf_list = read_line('/Users/woojunshim/Research/Data/TF/TF_combined.txt', col_idx=0)
    #tf_list = set(tf_list)
    #results = []
    #table_ = read_table1('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.txt')
    #genes = get_rownames(table_)
    #epigenomes = get_colnames(table_)
    #for epi in epigenomes:
    #    results.append([epi])
    #    for gene in genes:
    #        if gene in tf_list:
    #            if table_[gene][epi] > 1.0:
    #                results[-1].extend([gene])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/highly_expressed_genes/DEG/new/All_expressed_TF.txt')


    ### CREATE A NEW LIST OF DEG_TF_list.txt    
    #de_table = read_table1('/Users/woojunshim/Research/Data/highly_expressed_genes/DEG/new/DE_genes_table.txt')
    #epigenomes = get_colnames(de_table)
    #genes = get_rownames(de_table)
    #results = []
    #for epi in epigenomes:
    #    results.append([epi])
    #    for gene in genes:
    #        if de_table[gene][epi] != float(0):
    #            results[-1].extend([gene])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/highly_expressed_genes/DEG/new/DEG_genes_list.txt')
        




    ### IDENTIFY HIGHLY CORRELATED GENE SETS FOR EACH GENE
    #results = get_clusters('/Users/woojunshim/Research/Data/broadPeaks/svd/cor_genes_d30_c2_cell1_10.txt', low_threshold_=0.9)
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/broadPeaks/svd/d30_c2_cell1_10.txt')

    ### CREATE A EXPRESSION TABLE WITHOUT ENCODE
    #table_ = read_table1('/Users/woojunshim/Research/Data/57epigenomes.RPKM.symbols.txt', del_colnames=True)
    #colnames_ = get_colnames(table_)
    #colnames = []
    #for col in colnames_:
    #    if col in tissue_groups_:
    #        colnames.append(col)
    #rownames_ = get_rownames(table_)
    #results = {}
    #for row in rownames_:
    #    results[row] = {}
    #    for col in colnames:
    #        results[row][col] = table_[row][col]
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.txt')


    ### FINDING FUNCTIONS (SATURATION ANALYSIS)    
    #results = saturation_analysis('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.txt', '/Users/woojunshim/Research/Data/highly_expressed_genes/DEG/new/DE_TF_table.txt', random_=False)
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/broadPeaks/saturation_expression.txt')

    ### CREATE A DE TF TABLE
    #epi_list_ = read_table1('/Users/woojunshim/Research/Data/57epigenomes.RPKM.symbols.txt', del_colnames=True)
    #epi_list__ = get_colnames(epi_list_)
    #print len(epi_list__)
    #epi_list = []    
    #for epi in epi_list__:
    #    if epi in epigenomes:
    #        epi_list.append(epi)    
    #genes = get_rownames(epi_list_)
    #pathway = '/Users/woojunshim/Research/Data/highly_expressed_genes/DEG/new/'
    #tf_list = read_line('/Users/woojunshim/Research/Data/TF/TF_combined.txt', col_idx=0)
    #tf_list = set(tf_list)
    #results = {}
    #for row in genes:
    #    results[row] = {}
    #    for epi in epi_list:
    #        results[row][epi] = 0


    #for epi in epi_list:
    #    back = []
    #    fore = []
    #    de_tf = []
    #    temp_ = open(pathway+epi+'/output_score.txt', 'r')
    #    for line in temp_:
    #        line = line.strip().split()
    #        if not line[0].startswith('"'):
    #            if line[4] != 'NA':
    #                if float(line[4]) > 0.0:
    #                    if line[-1] == 'TRUE':
    #                        back.append([line[0], float(line[4])])
    #    back = genomics.sort_(back, idx=1, reverse_=True)        
    #    cnt = 1
    #    for i in range(len(back)):
    #        line = back[i]            
    #        if line[0] in tf_list:
    #            results[line[0]][epi] = cnt
    #            cnt += 1
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/highly_expressed_genes/DEG/new/DE_genes_table.txt')

    ### CREATE ENSG TO SYMBOL TABLE FROM HOMO_SAPIENS.GRCH37.87.GTF
    #file_ = open('/Users/woojunshim/Research/Data/Homo_sapiens.GRCh37.87.gtf', 'r')
    #results = {}


    ### COMBINE GENE IDS TO EXON_LENGTHS.TXT
    #conversion = genomics.read_file('/Users/woojunshim/Research/Data/U_gene_conversion_table_.txt', [2, -1], rowname='3')
    #exon = genomics.read_file1('/Users/woojunshim/Research/Data/exon_lengths.txt')    
    #for no in range(len(exon)):
    #    item = exon[no]
    #    if len(item) > 2:
    #        if item[1] in conversion:
    #            exon[no].extend([conversion[item[1]][0][0],conversion[item[1]][0][1]])
    #        else:
    #            exon[no].extend(['NA','NA'])
    #genomics.write_file(exon, '/Users/woojunshim/Research/Data/exon_lengths_.txt')

    ### CREATE universal GENE ID CONVERSION TABLE
    #ensembl_ = genomics.read_file1('/Users/woojunshim/Research/Data/gene2ensembl.txt')
    #table_ = {}
    #file_ = open('/Users/woojunshim/Research/Data/Ensembl_gene_symbols_conversion_.txt', 'r')
    #for line in file_:
    #    line = line.strip().split()
    #    if len(line) > 2:
    #        table_[line[1]] = line[2]

    #ensembl = genomics.find_entry(ensembl_, feature='9606', idx_=0)
    #for no in range(len(ensembl)):
    #    id = ensembl[no][2]
    #    if id in table_:
    #        ensembl[no].extend([table_[id]])
    #    else:
    #        ensembl[no].extend(['NA'])
    #genomics.write_file(ensembl, '/Users/woojunshim/Research/Data/U_gene_conversion_table.txt')
    #for no in range(len(ensembl)):
    #    id = ensembl[no][3].split('.')[0]
    #    ensembl[no][3] = id
    #genomics.write_file(ensembl, '/Users/woojunshim/Research/Data/U_gene_conversion_table_.txt')


    ### EXTRACT GENE DATA FROM SINGLE CELL 
    #pathway = '/Users/woojunshim/Research/scRNA/'
    #file_ = read_table1(pathway+'MeanExpression_by_Clusters_Separate5Day_new.txt', del_colnames=True)
    #input_ = []
    #for gene in file_:
    #    if file_[gene]['Day_30_C2'] > float(0):
    #        input_.append(gene) 
    #results = subset_table('/Users/woojunshim/Research/Data/broadPeaks/combined_table.txt', rows = input_, cols=None)
    #genomics.write_table1(results,'/Users/woojunshim/Research/Data/broadPeaks/Test_day30_c2.txt')

    
    ### CALCULATE VARIANCE FOR EACH GENE IN U MATRIX
    #result = row_operation('/Users/woojunshim/Research/Data/broadPeaks/svd/U_10.txt')
    #result_ = dic_to_list(result)
    #genomics.write_file(result_, '/Users/woojunshim/Research/Data/broadPeaks/svd/var_U_10.txt')

    ### CONVERT 'COMBINED_TABLE.TXT' TO PROPORTIONS
    #results = convert_to_proportion_t('/Users/woojunshim/Research/Data/broadPeaks/combined_table.txt')
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/broadPeaks/combined_table_prop.txt')

    ### TEST FOR SCRNA-DATA
    #pathway = '/Users/woojunshim/Research/scRNA/'
    #file_ = read_table1(pathway+'MeanExpression_by_Clusters_Separate5Day_new.txt', del_colnames=True)
    #input_ = []
    #for gene in file_:
    #    if file_[gene]['Day_30_C2'] != float(0):
    #        input_.append([gene, file_[gene]['Day_30_C2']])    
    #combined = read_table1('/Users/woojunshim/Research/Data/broadPeaks/combined_table.txt')
    #results_ = multiply_elements(input_, combined)
    #results = {}
    #colnames = get_colnames(results_)
    #for item in input_:
    #    gene = item[0]
    #    if gene in results_:
    #        results[gene] = {}
    #        for col in colnames:
    #            results[gene][col] = results_[gene][col]
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/broadPeaks/Test_Day30_C2.txt')

    ### CREATE RANK TABLES 
    # 1. BY H3K4ME3 WIDTH
    #pathway='/Users/woojunshim/Research/Data/broadPeaks/H3K4me3/'
    #table_ = add_pseudo(pathway+'All_widths_H3K4me3.txt', count_=1.0)    
    #results = rank_genes(table_)
    #genomics.write_table1(results, pathway+'H3K4me3_rank.txt')

    # 2. BY H3K27ME3 WIDTH
    #pathway='/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/'
    #table_ = add_pseudo(pathway+'All_widths_H3K27me3.txt', count_=1.0)    
    #results = rank_genes(table_)
    #genomics.write_table1(results, pathway+'H3K27me3_rank.txt')

    # BY (H3K4ME3+1) * LOG2(H3K27ME3 + 2)
    #pathway = '/Users/woojunshim/Research/Data/broadPeaks/'
    #table_ = read_table1(pathway+'combined_log10.txt')
    #results = rank_genes(table_)
    #genomics.write_table1(results, pathway+'combined_log10_rank.txt')

    # BY EXPRESSION DATA
    #pathway = '/Users/woojunshim/Research/Data/broadPeaks/'
    #table_ = read_table1(pathway+'combined_log10.txt')
    #results = rank_genes(table_)
    #genomics.write_table1(results, pathway+'combined_log10_rank.txt')


    # 3. BY 
    #pathway='/Users/woojunshim/Research/Data/broadPeaks/H3K4me3/'
    #table1 = add_pseudo(pathway+'All_widths_H3K4me3.txt', count_=1.0)    
    #pathway='/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/'
    #table2 = add_pseudo(pathway+'All_widths_H3K27me3.txt', count_=1.0)    
    
    #first = table_operation(table1, table2, operator_='divide')
    #first = single_table_operation(table2, operator_='log10')

    #second = table_operation(first, table1, operator_='multiply')
    #final = single_table_operation(second, null_value_=1.0) 
    #final = single_table_operation(first, operator_='log2')
    #genomics.write_table1(first, '/Users/woojunshim/Research/Data/broadPeaks/combined_.txt')

    #pathway='/Users/woojunshim/Research/Data/broadPeaks/H3K4me3/'
    #table1 = add_pseudo(pathway+'All_widths_H3K4me3.txt', count_=1.0)    
    #pathway='/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/'
    #table2 = add_pseudo(pathway+'All_widths_H3K27me3.txt', count_=1.0)    
    #results = table_operation(table1, table2, operator_='divide')
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/broadPeaks/division.txt')



    #3. CALCULATE RANK PRODUCT OF 1 AND 2
    #pathway='/Users/woojunshim/Research/Data/broadPeaks/'
    #results = rank_product_tables(pathway+'/H3K4me3/H3K4me3_rank.txt', pathway+'/H3K27me3/H3K27me3_rank.txt')
    #genomics.write_table1(results, pathway+'H3K4me3_H3K27me3_rp.txt')

    # CREATE BINARY TABLES
    #threshold = read_table1('/Users/woojunshim/Research/Data/broadPeaks/rank_points.txt', del_colnames=True)    
    #table = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K4me3/H3K4me3_rank.txt', del_colnames=True)
    #colnames = get_colnames(table)
    #results = {}
    #for gene in table:
    #    results[gene] = {}
    #    for col in colnames:
    #        results[gene][col] = 0
    #for col in colnames:
    #    thre_ = threshold[col]['H3K4me3']
    #    for gene in table:
    #        if table[gene][col] <= thre_:
    #            results[gene][col] = 1
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/broadPeaks/H3K4me3/H3K4me3_binary.txt')


    # 4. PERFORM ANALYSIS
    #input_ = read_table1('/Users/woojunshim/Research/scRNA/MeanExpression_by_Clusters_Separate5Day_new.txt', del_colnames=True)
    #days = ['Day_0','Day_2','Day_5','Day_15','Day_30']
    #clusters = ['C1','C2']
    #for day in days:
    #    for clu in clusters:
    #        temp = []
    #        value = day+'_'+clu
    #        print value
    #        for gene in input_:
    #            if input_[gene][value] != float(0):
    #                temp.append([gene, input_[gene][value]])
    #        temp = genomics.sort_(temp, idx=1, reverse_=True)
    #        input_list = []
    #        for item in temp:
    #            input_list.append(item[0])
    #        print len(input_list)
    #        print
    #        perform_analysis_(input_list, h3k4me3_rank_='/Users/woojunshim/Research/Data/broadPeaks/H3K4me3/H3K4me3_binary.txt', h3k27me3_rank_='/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/H3K27me3_rank.txt', output_file='/Users/woojunshim/Research/scRNA/results_/'+value+'.txt', back_itr=10, threshold_=0.0001)







    ### TEST WILCOXON SIGNED-RANK TEST
    #file_ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K4me3/All_widths_H3K4me3.txt', del_colnames=True)
    #input1 = []
    #for gene in file_:        
    #    input1.append(file_[gene]['E095'])
    #input1.sort(reverse=True)
    #sum_ = np.sum(input1)
    #input1_ = input1[0:1000]
    #input2 = genomics.random_sample(input1_)
    #print input2[0:10]
    #for no in range(len(input1_)):
    #    input1_[no] = input1_[no]*(no+1)
    #    input2[no] = input2[no]*(no+1)
    #print input1_[0:10]
    #print input2[0:10]        
    #s, p = stat.mann(input1_, input2, alternative_='greater')
    #print s, p
    


    ### CALCULATE RANK RATIOS BETWEEN H3K4ME3 AND H3K27ME3 
    #results = calculate_rank_ratios(table1='/Users/woojunshim/Research/Data/broadPeaks/H3K4me3/All_widths_H3K4me3.txt', table2='/Users/woojunshim/Research/Data/broadPeaks/H3K27me3/All_widths_H3K27me3.txt', use_value_=True)
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/broadPeaks/rank_ratios_width.txt')

    ### GET ELBOW POINTS FOR H3K4ME3 AND H3K27ME3 ACROSS CELL TYPES
    #types = ['H3K4me3','H3K27me3']
    #pathway = '/Users/woojunshim/Research/Data/broadPeaks/'
    #results = [types]    
    #for epi in tissue_groups_:
    #    file_ = genomics.read_file(pathway+'H3K4me3/'+epi+'_H3K4me3_genes.txt', [1,2])
    #    total = len(file_)
    #    coord = []
    #    for no in range(len(file_)):
    #        coord.append(float(file_[no][1]))        
    #    elbow1 = find_elbow(coord)
    #    file_ = genomics.read_file(pathway+'H3K27me3/'+epi+'_H3K27me3_genes.txt', [1,2])
    #    total = len(file_)
    #    coord = []
    #    for no in range(len(file_)):
    #        coord.append(float(file_[no][1]))        
    #    elbow2 = find_elbow(coord)
    #    results.append([epi, elbow1, elbow2])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/broadPeaks/elbow_points.txt')


    ### TRY SCRNA-SEQ DATA
    #cor_ = '/Users/woojunshim/Research/Data/broadPeaks/H3K4me3/width_pearson_H3K4me3.txt'
    #sig_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/significant_cell_types_table_sorted1.txt'
    #colnames = ['Day_30_C1','Day_30_C2']
    #genes = find_genes_in_cluster('/Users/woojunshim/Research/scRNA/MeanExpression_by_Clusters_Separate5Day_new.txt', colnames=colnames, ignore_zero=True)    
    #pathway = '/Users/woojunshim/Research/scRNA/'
    #for no in range(len(colnames)):
    #    input_genes = []
    #    for item in genes[no]:
    #        input_genes.append(item[0])
    #    perform_analysis(input_genes, sig_table_=sig_, cor_table_=cor_, output_file=pathway+colnames[no]+'_results.txt', threshold_=0.05, back_itr=10, high_cor_=0.5)

    ### TRIM MEAN EXPRESSION BY CLUSTER FILE
    #file_ = open('/Users/woojunshim/Research/scRNA/MeanExpression_by_Clusters_Separate5Day.txt', 'r')
    #genes = set()
    #for line in file_:
    #    line = line.strip().split()
    #    if line[0] not in genes:
    #        genes.add(line[0])
    #    else:
    #        print line[0]

    ### REPLACE 'NA' TO 0
    #file_ = read_table1('/Users/woojunshim/Research/scRNA/MeanExpression_by_Clusters_Separate5Day_.txt', numerical=False)
    #colnames = file_['colnames']
    #del file_['colnames']    
    #print colnames
    #for gene in file_:
    #    for time in file_[gene:
    #        if file_[gene][time]=='NA':
    #            file_[gene][time] = 0.0
    #genomics.write_table1(file_, '/Users/woojunshim/Research/scRNA/MeanExpression_by_Clusters_Separate5Day_new.txt')

    ### TEST OVER-EXPRESSED GENES IN CLUSTER
    #file_ = read_table1('/Users/woojunshim/Research/scRNA/MeanExpression_by_Clusters_Separate5Day_new.txt', del_colnames=True)
    #total = len(file_)
    #results = [0,0,0,0]    
    #colnames = ['Day_5_C1','Day_5_C2','Day_5_C3','Day_5_C4']
    #for gene in file_:
    #    sum_ = 0.0
    #    for col in colnames:
    #        sum_ += file_[gene][col]
    #    ave_ = sum_ / len(colnames)
    #    for no in range(len(colnames)):
    #        if file_[gene][colnames[no]] > ave_:
    #            results[no] += 1
    #print results


    ### HYPOTHESIS : CELL IDENTITY GENES WILL SHARE HIGH CORRELATIONS OF H3K4ME3 & H3K27MES 
    ### INPUTS: 

    ### CREATES ALL_WIDTHS.TXT
    #pathway = '/Volumes/Project/Research/bigdata/roadmap/narrow_peaks/H3K27me3/assigned/'
    #results = {}
    #for epi in tissue_groups_:
        #file_ = genomics.read_file1(pathway+epi+'_H3K27me3_narrow_assigned.txt')
    #    file_ = read_table1(pathway+epi+'_H3K27me3_narrow_assigned.txt')
    #    for item in file_:            
    #        if item not in results:
    #            results[item] = {}
    #            for epi1 in tissue_groups_:
    #                results[item][epi1] = 0.0
    #        results[item][epi] = file_[item]['width']
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/H3K4me3_widths_narrow.txt')





    ### ASSIGN GENES TO H3K27ME3 PEAKS    
    
    #output_pathway = '/Users/woojunshim/Research/Data/broadPeaks/H3K4me3/'
    #pathway = '/Users/woojunshim/Research/bigdata/roadmap/'
    #max_width_= 2500
    #cnt = 0
    #for epi in tissue_groups_:
    #    cnt += 1
    #    print cnt
    #    print epi
    #    print
    #    file_ = pathway+epi+'-H3K4me3.broadPeak'    
    #    main(file_, output_=output_pathway+epi+'_H3K4me3_genes.txt', max_width__=max_width_, dominant_=True, convert_DS=False, centre_=True)


    ### ASSIGN GENES TO OTHER TYPES OF HISTONE PEAKS 

    #groups = ['H3K4me1','H3K9me3','H3K36me3','H3K27ac']  
    #groups = ['H3K27ac']
     
    #for group in groups:
    #    print group
    #    output_pathway = '/Users/woojunshim/Research/Data/broadPeaks/'+group+'/'
    #    pathway = '/Users/woojunshim/Research/bigdata/roadmap/'
    #    max_width_= 2500
    #    cnt = 0
    #    for epi in tissue_groups_:
    #        try:
    #            cnt += 1
    #            print cnt
    #            print epi
    #            print
    #            file_ = pathway+epi+'-'+group+'.broadPeak'    
    #            main(file_, output_=output_pathway+epi+'_'+group+'_genes.txt', max_width__=max_width_, dominant_=True, convert_DS=False, centre_=True)
    #        except:
    #            pass





    ### ASSIGN GENES TO ALL H3K4ME3 PEAKS (NOT ONLY DOMINANT PEAKS)    
    
    #groups = ['H3K4me1','H3K9me3','H3K36me3','H3K27ac','H3K4me3','H3K27me3']  
    #groups = ['H3K27ac', 'H3K27me3','H3K4me3']
      
    #for group in groups:
    #    print group
    #    output_pathway = '/Users/woojunshim/Research/Data/broadPeaks/sum/'+group+'/'
    #    pathway = '/Users/woojunshim/Research/bigdata/roadmap/'
    #    max_width_= 2500
    #    cnt = 0
    #    for epi in tissue_groups_:    
    #       try:            
    #            cnt += 1
    #            print cnt
    #            print epi
    #            print
    #            file_ = pathway+epi+'-'+group+'.broadPeak'    
    #            main(file_, output_=output_pathway+epi+'_'+group+'_genes.txt', max_width__=max_width_, dominant_=False, convert_DS=False, centre_=True)
    #        except:
    #            pass
    

    # TSANKOV 
    #cor_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/gene_pearson_short_sorted1.txt'
    #sig_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/significant_cell_types_table_sorted1.txt'
    #file_ = genomics.read_file1('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Analysis_results/Tsankov/expression_FPKM_dMS.txt')    
    #input_genes_ = []
    #for item in file_:
    #    print item[0]
    #    if item[0] != '-':
    #        if float(item[1]) > 1.0:
    #            input_genes_.append([item[0], float(item[1])])
    #input_genes_ = genomics.sort_(input_genes_, idx=1, reverse_=True)
    #input_genes = []
    #for item in input_genes_:
    #    input_genes.append(item[0])
    #print input_genes[0:10]
    #perform_analysis(input_genes, sig_, cor_, output_file='/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Analysis_results/Tsankov/trankov_results.txt', threshold_=0.05, back_itr=100)

    # Test
    #file_ = '/Users/woojunshim/Research/Data/57epigenomes.RPKM.symbols.txt'
    #cor_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/gene_pearson_short_sorted1.txt'
    #cor_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/gene_pearson_short.txt'
    #sig_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/significant_cell_types_table_sorted1.txt'
    #epi = 'E095'
    #pathway = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/'
    #input_genes = extract_genes(file_, col_name=epi, sort_='descending', min_threshold_=1.0, max_threshold_=None)    
    #background = read_table1(file_, del_colnames=True)
    #input_genes_ = []
    #for item in input_genes:
    #    if float(background[item][epi]) - float(background[item]['E000']) > 0:
    #        input_genes_.append(item)
    #print len(input_genes)
    #print len(input_genes_)
    #rescue_analysis(input_genes_, input_genes, cor_, output_=pathway+epi+'_test.txt', threshold_=0.05, multiple_correction=True, pair_analysis_=False)


    # Single test

    #file_ = '/Users/woojunshim/Research/Data/57epigenomes.RPKM.symbols.txt'
    #cor_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/gene_pearson_short_sorted1.txt'
    #cor_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/width_pearson_cor.txt'
    #sig_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/significant_cell_types_table_sorted1.txt'
    #epi = 'E070'
    #pathway = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/'
    #input_genes = extract_genes(file_, col_name=epi, sort_='descending', min_threshold_=1.0, max_threshold_=None)
    #perform_analysis(input_genes, sig_, cor_, output_file=pathway+epi+'_analysis_results_width.txt', threshold_=0.0001, back_itr=100)

    # Single test2
    
    #cor_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/gene_pearson_short_sorted1.txt'
    #sig_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/significant_cell_types_table_sorted1.txt'    
    #pathway = '/Users/woojunshim/Research/Data/scRNA/'
    #file_ = pathway+'day5_c2_.txt'
    #input_genes = extract_genes(file_, col_name='baseMeanB', sort_='descending', min_threshold_=1.0, max_threshold_=None)
    #perform_analysis(input_genes, sig_, cor_, output_file=pathway+'test_.txt', threshold_=0.05, back_itr=100)

    # TEST RUNS FOR ENCODE DATA SETS
    #file_ = '/Users/woojunshim/Research/Data/57epigenomes.RPKM.symbols.txt'
    #cor_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/width_pearson_cor.txt'
    #sig_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/significant_cell_types_table_sorted1.txt'    
    #pathway = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/test/'
    #data_ = read_table1(file_)
    #colnames = data_['colnames']    
    #for epi in tissue_groups_:
    #    if epi in colnames:
    #        print epi
    #        input_genes = extract_genes(file_, col_name=epi, sort_='descending', min_threshold_=1.0, max_threshold_=None)
    #        perform_analysis(input_genes, sig_, cor_, output_file=pathway+epi+'_results_width.txt', threshold_=0.05, back_itr=100)

    # Multiple tests

    #pathway = '/Users/woojunshim/Research/Data/scRNA/'
    #days = ['day0','day5']
    #clusters = ['c1','c2','c3','c4']

    #file_ = '/Users/woojunshim/Research/Data/57epigenomes.RPKM.symbols.txt'
    #cor_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/gene_pearson_short_sorted1.txt'
    #sig_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/significant_cell_types_table_sorted1.txt'
    #epi = 'E070'
    #pathway = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/'
    #pathway = '/Users/woojunshim/Research/Data/scRNA/'
    #days = ['day5']
    #clusters = ['c1','c2','c3','c4']
    #for day in days:        
    #    print day
    #    for clu in clusters: 
    #        print
    #        print clu   
    #        file_ = pathway+day+'_'+clu+'_.txt'   
    #        test = read_table1(file_, numerical=False)           
            
    #        input_genes = extract_genes(file_, col_name='baseMeanA', sort_='descending', min_threshold_=1.0, max_threshold_=None)
    #        print len(input_genes)

    #        perform_analysis(input_genes, sig_, cor_, output_file=pathway+'new/'+day+'_'+clu+'_'+'_analysis_results.txt', threshold_=0.05, back_itr=100)

    ### CHECK SIGNIFICANT CELL TYPES FOR GENES
    #genes = ['HAND2','NKX2-5','GATA4','MYH6','PAX6','ZZZ']
    #sig_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/significant_cell_types_table_sorted1.txt'
    #sig_ = read_table1(sig_)
    #colnames = sig_['colnames']
    #del sig_['colnames']    
    #t1= get_cols(genes, sig_)
    #t2= extract_intersection(t1, ['E083','E095','E065','E003','E070'])
    #print t2

    ### IDENTIFY CELL TYPES (SIGNIFICANTLY HIGHLY RANKED CELL TYPES)

    # 
    # 1. extract_genes
    #file_ = read_table1('/Users/woojunshim/Research/Data/57epigenomes.RPKM.symbols.txt', del_colnames=True)
    #cor_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/gene_pearson_short_sorted1.txt'
    #sig_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/significant_cell_types_table_sorted1.txt'
    #candidates__ = []
    #epi = 'E004'
    #temp = []
    #for gene in file_:
    #    if float(file_[gene][epi]) > 1:
    #        candidates__.append([gene, float(file_[gene][epi])])
    #candidates__ = genomics.sort_(candidates__, idx=1, reverse_=True)
    #candidates_ = []
    #for item in candidates__:
    #    candidates_.append(item[0])   
    #sig_table = read_table1(sig_)
    #colnames = sig_table['colnames']
    #del sig_table['colnames']
    #input_ = []
    #for gene in candidates_:
    #    if gene in sig_table:
    #        input_.append([])
    #        for col in colnames:
    #            input_[-1].append(sig_table[gene][col])
    #fore = mean_idx(input_)

    #back = []
    #for m in colnames:
    #    back.append([])

    # Now background calculation
    #no_itr = 10
    #for no in range(no_itr):
    #    print no
    #    new_ = genomics.random_sample(candidates_)
    #    input_ = []
    #    for gene in new_:
    #        if gene in sig_table:
    #            input_.append([])
    #            for col in colnames:
    #                input_[-1].append(sig_table[gene][col])  
    #    back_ = mean_idx(input_)
    #    for m in range(len(back_)):
    #        back[m].append(back_[m])
    #results = []
    #for no in range(len(fore)):
    #    mean_ = np.mean(back[no])
    #    sd_ = np.std(back[no])
    #    z_ = stat.z_score(fore[no], mean_=mean_, sd_=sd_)
    #    p_ = stat.p_value(z_, side='lower')
    #    results.append([colnames[no], fore[no], mean_, p_])
    #results = genomics.sort_(results, idx=1, reverse_=True)
    #final = []
    #for item in results:        
    #    if item[3] < 0.0001:
    #        final.append([item[0], item[1], item[2], item[3]])
    #genomics.write_file(final, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/'+epi+'_sig_cell_types.txt')
    



    ### NEW CORRELATION ANALYSIS 
    #file_ = read_table1('/Users/woojunshim/Research/Data/57epigenomes.RPKM.symbols.txt', del_colnames=True)
    #cor_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/gene_pearson_short_sorted1.txt'
    #candidates__ = []
    #epi = 'E095'
    #temp = []
    #for gene in file_:
    #    if float(file_[gene][epi]) > 1:
    #        candidates__.append([gene, float(file_[gene][epi])])
    #candidates__ = genomics.sort_(candidates__, idx=1, reverse_=True)
    #candidates_ = []
    #for item in candidates__:
    #    candidates_.append(item[0])   
    #results, stat_ = cor_analysis2(candidates_, cor_, cor_ave=True, group_number=1, p_threshold_=0.0001)
    #output_ = []
    #for item in results:
    #    output_.append([item])
    #    for m in results[item]:
    #        output_[-1].append(m)
    #genomics.write_file(output_, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/'+epi+'_correlated_genes.txt')
    #genomics.write_file(stat_, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/'+epi+'_correlated_genes_stat.txt')

    ### TESTING RUN FOR E095 TO IDENTIFY REPRESENTATIVE GENE SET (I.E. CANDIDATES)
    #file_ = read_table1('/Users/woojunshim/Research/Data/57epigenomes.RPKM.symbols.txt', del_colnames=True)
    #cor_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/gene_pearson_short_sorted1.txt'
    #candidates__ = []
    #epi = 'E095'
    #temp = []
    #for gene in file_:
    #    if float(file_[gene][epi]) > 1:
    #        candidates__.append([gene, float(file_[gene][epi])])
    #candidates__ = genomics.sort_(candidates__, idx=1, reverse_=True)
    #candidates_ = []
    #for item in candidates__:
    #    candidates_.append(item[0])
    #print len(candidates_)        
    #candidates = identify_rep1(candidates_, cor_)
    #print len(candidates)


    ### CALCULATE FISHER'S EXACT TEST (FET) FOR EXPRESSION DATA (8.17)
    ### FIRST COMPARE BETWEEN DEGS VS. HIGHLY CORRELATED GENES
    #epi_list = read_line('/Users/woojunshim/Research/Data/expression_data_epi_list.txt', col_idx=0)
    #pathway = '/Users/woojunshim/Research/Data/highly_expressed_genes/DEG/'
    #tf_list = read_line('/Users/woojunshim/Research/Data/TF/TF_combined.txt', col_idx=0)
    #tf_list = set(tf_list)
    #results_p = []
    #results_o = []
    #for epi in epi_list:
    #    back = []
    #    fore = []
    #    de_tf = []
    #    temp_ = open(pathway+epi+'/output_score.txt', 'r')
    #    for line in temp_:
    #        line = line.strip().split()
    #        if not line[0].startswith('"'):
    #            if line[4] != 'NA':
    #                if float(line[4]) > 0.0:
    #                    if line[-1] == 'TRUE':
    #                        back.append(line[0])
    #                        if line[0] in tf_list:
    #                            de_tf.append(line[0])
    #    temp_ = genomics.read_file1(pathway+epi+'/'+epi+'_results.txt')
    #    for item in temp_:            
    #        if (float(item[1]) > 0.0) and (float(item[3]) < 0.05):
    #            fore.append(item[0]) 
    #    a,b,c,d = prepare_fet(fore, back, de_tf)
    #    o, p = stat.fisher(a,b,c,d)
    #    results_p.append([epi, p])
    #    results_o.append([epi, o])
    #results_p.insert(0, ['#gene','FET(p)'])
    #results_o.insert(0, ['#gene','Odds.ratio'])
    #genomics.write_file(results_p, pathway+'results_p_deg_vs_cor.txt')
    #genomics.write_file(results_o, pathway+'results_o_deg_vs_cor.txt')
    
    ### SECOND COMPARE DEG OR CORRELATED GENES VS. ALL BACKGROUND
    #epi_list = read_line('/Users/woojunshim/Research/Data/expression_data_epi_list.txt', col_idx=0)
    #pathway = '/Users/woojunshim/Research/Data/highly_expressed_genes/DEG/'
    #tf_list = read_line('/Users/woojunshim/Research/Data/TF/TF_combined.txt', col_idx=0)
    #tf_list = set(tf_list)
    #results_p = []
    #results_o = []
    #for epi in epi_list:
    #    back = []
    #    fore1 = []
    #    fore2 = []
    #    de_tf = []
    #    temp_ = open(pathway+epi+'/output_score.txt', 'r')
    #    for line in temp_:
    #        line = line.strip().split()
    #        if not line[0].startswith('"'):
    #            if line[1] != 'NA':
    #                if float(line[1]) > 1.0:                        
    #                    back.append(line[0])
    #                    if line[0] in tf_list:
    #                        de_tf.append(line[0])
    #            if line[4] != 'NA':
    #                if float(line[4]) > 1:
    #                    if line[-1] =='TRUE':
    #                        fore1.append(line[0])
    #    temp_ = genomics.read_file1(pathway+epi+'/'+epi+'_results.txt')
    #    for item in temp_:            
    #        if (float(item[1]) > 0.0) and (float(item[3]) < 0.05):
    #            fore2.append(item[0]) 
    #    a,b,c,d = prepare_fet(fore1, back, de_tf)
    #    o1, p1 = stat.fisher(a,b,c,d)
    #    a,b,c,d = prepare_fet(fore2, back, de_tf)
    #    o2, p2 = stat.fisher(a,b,c,d)
    #    results_p.append([epi, p1, p2])
    #    results_o.append([epi, o1, o2])
    #results_p.insert(0, ['#gene','before','after'])
    #results_o.insert(0, ['#gene','before','after'])
    #genomics.write_file(results_p, pathway+'results_p_vs_background.txt')
    #genomics.write_file(results_o, pathway+'results_o_vs_background.txt')




    ### CORRECT p_table with s_table after running gene_cor analysis
    ### CORRECT FOR ONE-SIDE TEST
    #p_table = read_table1('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/cardiac_genes_p_new_sorted1_nontf.txt', del_colnames=True)
    #s_table = read_table1('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/cardiac_genes_s_new_sorted1_nontf.txt', del_colnames=True)

    # 1. FISRT DIVIDE EACH ENTRY BY 2 
    #for gene in p_table:
    #    for epi in p_table[gene]:
    #        p_table[gene][epi] = p_table[gene][epi] / 2
    # 2. COMPARE WITH T.STATISTICS AND CONVERT P-VALUES 
    #for gene in p_table:
    #    for epi in p_table[gene]:
    #        if s_table[gene][epi] < float(0):
    #            p_table[gene][epi] = 1 - p_table[gene][epi]
    #genomics.write_table1(p_table, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/cardiac_genes_one_side_p_nontf.txt')


    ### CORRELATIVE ANALYSIS BY SEEDING A PRE-DEFINED REFERENCE GENE SET    
    #data_ = genomics.read_file('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/summary_results_dominant_1.0_broadpeak_mrna_.txt', [0,3], rowname='1')
    #cor_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/gene_pearson_short_sorted1.txt'
    #ref_genes = []    
    #tt = genomics.read_file1('/Users/woojunshim/Research/Data/cardiac_regulators_modified_structural.txt')
    #for item in tt:
    #    ref_genes.append(item[0])
    #print len(ref_genes)
    #for tissue in tissue_groups:
    #    for epi in tissue_groups[tissue]:
    #        print epi
    #        genes = []
    #        temp = data_[epi]
    #        for item in temp:
    #            genes.append(item[0])
    #        print len(genes)
    #        rescue_analysis(ref_genes, genes, cor_file=cor_, output_='/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/test/roadmap/'+epi+'_cardiac', pair_analysis_=False)

    ### COR ANALYSIS 
    #data_ = read_table1('/Users/woojunshim/Research/Data/57epigenomes.RPKM.symbols.txt', del_colnames=True)
    #cor_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/gene_pearson_short_sorted1.txt'
    #genes = []
    #ii = []
    #epis = ['E095','E071','E119']
    #for epi in epis:
    #    genes = []
    #    ii = []
    #    for gene in data_:
    #        if data_[gene][epi] > 1.0:
    #            ii.append([gene, data_[gene][epi]])
    #        ii = genomics.sort_(ii, idx=1, reverse_=True)       
    #    for item in ii:
    #        genes.append(item[0])  
    #    print genes[0:10]        
    #    rescue_analysis(genes[0:500], genes, cor_file=cor_, output_='/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/test/roadmap/'+epi, pair_analysis_=False)

    ### IDENTIFY REFERENCE GENE SET
    #data_ = read_table1('/Users/woojunshim/Research/Data/57epigenomes.RPKM.symbols.txt', del_colnames=True)
    #genes = []
    #ii = []
    #for gene in data_:
    #    ii.append([gene, data_[gene]['E095']])
    #ii = genomics.sort_(ii, idx=1, reverse_=True)       
    #for item in ii:
    #    genes.append(item[0])      
    #results = identify_rep(genes[0:3000], '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/gene_pearson_short_sorted1.txt')
    #r = []
    #for pp in results:
    #    r.append([pp])
    #genomics.write_file(r, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/test_e095_ref.txt')

    ### EXTRACT SIGNIFICANT CELL TYPES FROM PSEUDOOCUNT-ADDED MATRIX
    #pathway='/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/'
    #results = find_broad_peaks(p_table_file=pathway+'specificity_p_table.txt', width_file=pathway+'All_widths.txt', threshold_=0.0001, elbow_point=True)
    #genomics.write_table1(results, pathway+'significant_cell_types_table_0.0001.txt')

    ### GET MIN AND MAX FOR GROUPS OF GENES WITH DIFFERENT NUMBERS OF CELL TYPES
    #results_z = {}
    #results_a = {}
    #final_z = []
    #final_a = []
    #for i in range(1,112):
    #    results_z[str(i)] = []
    #    results_a[str(i)] = []
    #file_ = read_table1('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/All_widths.txt', del_colnames=True)
    #for gene in file_:
    #    cnt = 0
    #    min_ = 999999
    #    max_ = 0
    #    for item in file_[gene]:
    #        if file_[gene][item] == float(0):
    #            continue
    #        else:
    #            if file_[gene][item] < min_:
    #                min_ = file_[gene][item]
    #                cnt += 1
    #            elif file_[gene][item] > max_:
    #                max_ = file_[gene][item]
    #                cnt += 1
    #    results_z[str(cnt)].append(max_)
    #    results_a[str(cnt)].append(min_)
    #for i in results_z:
    #    mean_ = np.mean(results_z[i])
    #    std_  = np.std(results_z[i])
    #    final_z.append([i, mean_, std_])

    #for i in results_a:
    #    mean_ = np.mean(results_a[i])
    #    std_  = np.std(results_a[i])
    #    final_a.append([i, mean_, std_])
    #genomics.write_file(final_z, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/max_values.txt')
    #genomics.write_file(final_a, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/min_values.txt')

    ### ADD MINIMUM WIDTH TO ALL DATA POINTS
    #results = add_pseudo('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/All_widths.txt')
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/All_widths_pseudo.txt')

    ### CREATE A GENE CORRELATION & T-TEST FOR A SELECTED SET OF GENES
    ### CAN MODIFY 'caridac_genes_' IF WANT TO INCLUDE IRRELEVANT GENES
    #epi = 'E055'
    #cardiac_genes_ = genomics.read_file1('/Users/woojunshim/Research/Data/cardiac_regulators_modified_.txt')
    #cor_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/gene_pearson_short_new.txt'
    #all_genes_ = genomics.read_file('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/summary_results_dominant_1.0_broadpeak_mrna_.txt', [0,3], rowname='1')
    #temp = all_genes_[epi]
    #for no in range(len(temp)):
    #    temp[no][1] = float(temp[no][1])
    #temp = genomics.sort_(temp, idx=1, reverse_=True)
    #all_genes = set()
    #for item in temp:
    #    all_genes.add(item[0])
    #cardiac_genes = set()
    #for item in cardiac_genes_:
    #    cardiac_genes.add(item[0])
    #    all_genes.add(item[0])
    #count = int(len(temp) * 0.05)
    #temp = temp[0:count]
    #for item in temp:
    #    cardiac_genes.add(item[0])
    #    all_genes.add(item[0])
    #results = []

    #cor_table = subset_table(cor_, all_genes, cols=None)

    #for gene in cardiac_genes:
    #    s_, p_, ave_f, ave_b = gene_cor(gene, cardiac_genes, cor_table)
    #    results.append([gene, ave_f, ave_b, s_, p_])
    #results.insert(0, ['#gene','ave.candidates','ave.all','t.statistics','p-value'])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/example_cardiac_genes_'+epi+'.txt')

    #cor_table_f = subset_table(cor_, cardiac_genes, cardiac_genes)
    #genomics.write_table1(cor_table_f, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/example_cardiac_genes_table.txt')

    #cardiac_genes_ = genomics.read_file1('/Users/woojunshim/Research/Data/cardiac_regulators_modified_.txt')
    #epi__ = ['E083','E100','E034','E070']
    #results = {}
    #cardiac_genes = set()
    #for item in cardiac_genes_:
    #    cardiac_genes.add(item[0])
    #for no in range(len(epi__)):
    #    epi = epi__[no]
    #    temp = genomics.read_file('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/example_cardiac_genes_'+epi+'.txt', [3,4], rowname='0')
    #    for gene in cardiac_genes:
    #        if gene not in results:
    #            results[gene] = [[]]
    #       if gene in temp:
    #            if float(temp[gene][0][0]) > 0.0:
    #                if float(temp[gene][0][1]) < 0.0001:
    #                    results[gene][0].append(1)
    #                else:
    #                    results[gene][0].append(0)
    #            else:
    #                results[gene][0].append(0)
    #results.insert(0,epi__)
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/cardiac_genes_selected_summary.txt')




    #pathway = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/'

    ### IDENTIFY CELL CONTEXTS OF SIGNIFICANCE
    #results = identify_cell_types(input_spec=pathway+'entropy/gene_specificity_table.txt', p_table=pathway+'specificity_p_table.txt', threshold_=0.0001)
    #genomics.write_table1(results, pathway+'significant_cell_types_table.txt')

    ### CREATE BACKGROUND ENTROPY AND SPECIFICITY TABLE FOR ALL GENES, ASSUMING THE WIDTH GROWS STEADILY
    #pathway = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/'
    #file_ = read_table1(pathway+'All_widths_pseudo.txt', del_colnames=True)
    #colnames = []
    #for item in file_:
    #    if len(colnames) == 0:
    #        for m in file_[item]:
    #            colnames.append(m)
    #    else:
    #        break
    #results = {}
    #for gene in file_:
    #    results[gene] = {}
    #    temp = []
    #    max_ = 0.0
    #    min_ = 100000
    #    cnt = 0
    #    for col in colnames:
    #        results[gene][col] = 0.0
    #        temp.append([col, file_[gene][col]])
    #        if file_[gene][col] > max_:
    #            max_ = file_[gene][col]
    #        if file_[gene][col] < min_:
    #            if file_[gene][col] != 0.0:
    #                min_= file_[gene][col]
    #        if file_[gene][col] != float(0):
    #            cnt += 1
    #    temp = genomics.sort_(temp, idx=1, reverse_=True)
    #    interval = (float(max_) - float(min_)) / (cnt-1)
    #    for no in range(cnt):
    #        results[gene][temp[no][0]] = round(max_ - (interval * no))
    #genomics.write_table1(results, pathway+'background_widths_pseudo.txt')

    ### CALCULATE ENTROPY AND SPECIFICITY FROM A TABLE FILE
    #file_ = read_table1(pathway+'All_widths_pseudo.txt', del_colnames=True)
    #results = {}
    #epi_ = []
    #for gene in file_:
    #    results[gene] = {}
    #    for epi in file_[gene]:
    #        results[gene][epi] = 'NA'
    #    if len(epi_) == 0:
    #        for epi in file_[gene]:
    #            epi_.append(epi)
    #for gene in results:
    #    temp = []
    #    input_ = []
    #    for epi in epi_:
    #        if file_[gene][epi] != float(0):
    #            input_.append(file_[gene][epi])
    #            temp.append([epi, file_[gene][epi]])
    #    ent = entropy(input_)
    #    spe = specificity(input_, ent)
    #    for no in range(len(temp)):
    #        item = temp[no][0]
    #        results[gene][item] = spe[no]
    #genomics.write_table1(results, pathway+'gene_specificity_pseudo.txt')

    ### CALCULATE P-VALUES FOR EACH SPECIFICITY
    ### THIS SHOULD BE RUN AFTER OBTAINING SPECIFICITY SCORES FOR ALL GENES TO IDENTIFY CELL CONTEXTS
    ##counts = genomics.read_file(pathway + 'cell_type_counts.txt', [0], rowname='1')
    #data_ = read_table1('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/gene_specificity_pseudo.txt', del_colnames=True, numerical=False)
    #colnames = []
    #results = {}
    #results_z = {}
    #for gene in data_:
    #    if len(colnames) == 0:
    #        for item in data_[gene]:
    #            colnames.append(item)
    #    else:
    #        break

    #for gene in data_:
    #    results[gene] = {}
    #    results_z[gene] = {}
    #    for col in colnames:
    #        results[gene][col] = 'NA'
    #        results_z[gene][col] = 'NA'

    #cnt = 0
    #for gene in data_:
    #    cnt +=1
    #    print cnt
    #    temp = []
    #    idx = []
    #    for no in range(len(colnames)):
    #        col = colnames[no]
    #        if data_[gene][col] != 'NA':
    #            temp.append(float(data_[gene][col]))
    #            idx.append([no, float(data_[gene][col])])
    #    idx = genomics.sort_(idx, 1, reverse_=False)
        #print len(idx)

    #    zz, pp = specificity_p(temp, background_file=counts, background_specificity_=pathway+'background_specificity_pseudo.txt')
    #    for no in range(len(pp)):
    #        col = colnames[idx[no][0]]
    #        results[gene][col] = pp[no]
    #        results_z[gene][col] = zz[no]
        #if gene =='UBE2Q1':
        #    print results[gene]
        #    print results_z[gene]
    #genomics.write_table1(results, pathway+'specificity_p_table_pseudo.txt')
    #genomics.write_table1(results_z, pathway + 'specificity_z_table_pseudo.txt')




    ### ANALYSIS OF BACKGROUND SPECIFICITY
    #counts = genomics.read_file(pathway+'cell_type_counts.txt', [0], rowname='1')
    #list_ = set()
    #for item in counts['111']:
    #    list_.add(item[0])
    #test = extract_lines(pathway+'background_specificity.txt', list_)
    #test = sort_elements(test)
    #test = sort_by_position(test)







    ### COUNT NUMBERS OF GENES (FOR CELL TYPES WHERE THEY ARE PRESENT)
    #pathway = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/'
    #file_ = read_table1(pathway+'background_specificity.txt', del_colnames=True, numerical=False)
    #results = {}
    #for gene in file_:
    #    results[gene] = 0
    #    for epi in file_[gene]:
    #        if file_[gene][epi] != 'NA':
    #            results[gene] += 1
    #genomics.write_file(results, pathway+'cell_type_counts.txt')


    ### ANNOTATE AFFY MATRIX PROBESET IDS
    ### AND IDENTIFY CANDIDATE SETS AND PERFORM CORRELATION ANALYSIS
    #cor_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/gene_pearson_short_new.txt'
    #pathway = '/Users/woojunshim/Research/Data/Paige/expression/DEG/'
    #days = ['day2','day5','day9','day14']
    #for day in days:
    #    print day
    #    data_ = []
    #    ids = []
    #    file_ = open(pathway+day+'/output_score.txt', 'r')
    #    for line in file_:
    #        line = line.strip().split()
    #        if not line[0].startswith('"Gene'):
    #            data_.append([line[0], float(line[4])])
    #            ids.append([line[0]])
    #    symbols = convert_id(ids, ref_file='/Users/woojunshim/Research/Data/Paige/expression/affy_annotation_table.txt', col_idx1=1, col_idx2=2)
    #    for no in range(len(data_)):
    #        data_[no].extend([symbols[no]])
    #    candidate = []
    #    background = []
    #    data_ = genomics.sort_(data_, idx=1, reverse_=True)
    #    cnt = 0
    #    no_candidate = 1000
    #    for item in data_:
    #        if item[-1] != 'NA':
    #            if cnt < no_candidate:
    #                candidate.append(item[-1])
    #                background.append(item[-1])
    #                cnt += 1
    #            else:
    #                background.append(item[-1])
    #    print len(candidate)
    #    print len(background)

    #   cor_analysis(candidate, background, cor_file=cor_, output_=pathway + day+'/'+day+'_new', pair_analysis_=False)
    #   rescue_analysis(candidate, background, cor_file=cor_, output_=pathway + day + '/' + day, pair_analysis_=False)

    ### SAME ANALYSIS FOR ROADMAP DATA
    #cor_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/gene_pearson_short_sorted1.txt'
    #pathway = '/Users/woojunshim/Research/Data/Paige/expression/DEG/'
    #pathway = '/Users/woojunshim/Research/Data/highly_expressed_genes/DEG/'
    #gg = genomics.read_file1('/Users/woojunshim/Research/Data/highly_expressed_genes/filtering_specificity_combined.txt')
    #epi_ = []
    #for item in gg:
    #    if item[0].startswith('E'):
    #        epi_.append(item[0])    
    #days = epi_
    #stat_ = []
    #for day in days:
    #    print day
    #    data_ = []
    #    file_ = open(pathway + day + '/output_score.txt', 'r')
    #    for line in file_:
    #        line = line.strip().split()
    #        if not line[0].startswith('"Gene'):
    #            if line[1] != 'NA':
    #                if (line[4]=='NA') and (float(line[1]) == 0):
    #                    data_.append([line[0], -999, line[-1]])
    #                elif (line[4]=='NA') and (float(line[1]) > 0):
    #                    data_.append([line[0], 999, line[-1]])
    #                else:
    #                    data_.append([line[0], float(line[4]), line[-1]])
    #    candidate = []
    #    background = []
    #    data_ = genomics.sort_(data_, idx=1, reverse_=True)        
    #    for item in data_:
    #        if (item[-1] == 'TRUE') and (item[1] > 0.0):
    #            candidate.append(item[0])
    #            background.append(item[0])
    #        else:
    #            background.append(item[0])
    #    print len(candidate)
    #    print len(background)
    #    stat_.append([day, len(candidate), len(background)])
        #cor_analysis(candidate, background, cor_file=cor_, output_=pathway + day + '/' + day, pair_analysis_=False)
    #stat_.insert(0, ['#gene','candidates','all'])
    #genomics.write_file(stat_, pathway+'cor_analysis_summary.txt')


    


    ### FIND ELBOW FOR ALL GENES AND CREATE A BINARY TABLE FOR H3K4ME3 DYNAMICS
    #pathway = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/'
    #file_ = read_table1(pathway+'gene_specificity_table.txt', del_colnames=True, numerical=False)
    #colnames = []
    #results = {}
    #for line in file_:
    #    if len(colnames) != 0:
    #        break
    #    else:
    #        for item in file_[line]:
    #            colnames.append(item)
    #for gene in file_:
    #    results[gene] = {}
    #    for col in colnames:
    #        results[gene][col] = 0
    #for gene in file_:
    #    temp = []
    #    for no in range(len(colnames)):
    #        epi = colnames[no]
    #        if file_[gene][epi] != 'NA':
    #            temp.append([float(file_[gene][epi]), epi])
    #    temp = genomics.sort_(temp, idx=0, reverse_=True)
    #    input_ = []
    #    for item in temp:
    #        input_.append(item[0])
    #    idx = find_elbow(input_)
    #    for no in range(idx):
    #        epi = temp[no][1]
    #        results[gene][epi] = 1
    #genomics.write_table1(results, pathway+'gene_dynamics_elbow.txt')






    ### SATURATION ANALYSIS
    #1. CALCULATE SHANNON ENTROPY AND SPECIFICITY FOR GENES AND ACROSS CELL TYPES
    #pathway = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/'
    #file__ = genomics.read_file(pathway+'summary_results_dominant_1.0_broadpeak_mrna_.txt', [0,3],rowname='1')
    #results = {}
    #file_ = {}
    #genes = set()
    #selected_epi_ = subsample_epi(epigenomes)
    #selected_epi = subsample_epi3(tissue_groups, selected_epi_[0], 3)

    #for no in range(len(selected_epi)):
    #    epi_ = set(selected_epi[no])
    #    print len(epi_)
    #    for epi__ in epi_:
    #        f = file__[epi__]
    #        for item in f:
    #            if item[0] not in file_:
    #                file_[item[0]] = []
    #            file_[item[0]].append([epi__, item[1]])
    #    entropy_ = []
    #    for gene in file_:
    #        if gene not in genes:
    #            genes.add(gene)
    #    for gene in genes:
    #        for no in range(len(file_[gene])):
    #            file_[gene][no][1] = float(file_[gene][no][1])
    #    for gene in genes:
    #        results[gene] = {}
    #        for epi in epi_:
    #            results[gene][epi] = 'NA'
    #    for gene in genes:
    #        temp = file_[gene]
    #        input_ = []
    #        for item in temp:
    #            input_.append(item[1])
    #        ent = entropy(input_)
    #        spe = specificity(input_, ent)
    #        entropy_.append([gene, ent])
    #        for no in range(len(temp)):
    #            item = temp[no]
    #            results[gene][item[0]] = spe[no]

        #2. CALCULATE Z-SCORES FOR SPECIFICITY FOR GENES

    #    results_z = {}
    #    for gene in genes:
    #        results_z[gene] = {}
    #        for epi__ in epi_:
    #            results_z[gene][epi__] = 'NA'
    #    for gene in genes:
    #        epi = []
    #        i = []
    #        z_results = []

    #        for e in results[gene]:
    #            if results[gene][e] != 'NA':
    #                epi.append(e)
    #                i.append(float(results[gene][e]))
    #        mean_ = np.mean(i)
    #        sd_ = np.std(i)
    #        for item in i:
    #            z_ = stat.z_score(item, mean_=mean_, sd_=sd_)
    #            z_results.append(z_)
    #        for no in range(len(epi)):
    #            e_ = epi[no]
    #            results_z[gene][e_] = z_results[no]
    #    genomics.write_table1(results_z,pathway+'entropy/saturation/'+str(len(epi_))+'_z.txt')

    ### IDENTIFY MOST AND LEAST CORRELATED GENE PAIRS
    #most = []
    #least = []
    #most_value = 0.0
    #least_value = 1.0
    #no_pairs = 500
    #cor_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/gene_pearson_short.txt'
    #file_ = open(cor_, 'r')

    #3. CONVERT THE Z-SCORE TABLE TO BINARY TABLE
    #4. CALCULATE PEARSON'S CORRELATION FOR SHARED GENES ACROSS ITERATIONS & CALCULATE SUM OF DIFFERENCES BETWEEN TWO ITERATIONS
    #file_ = read_table1(pathway+'entropy/saturation/18_z.txt', numerical=False, del_colnames=True)
    #genes = set()
    #for gene in file_:
    #    genes.add(gene)  # 17,489 genes commonly present in all iterations
    #genes_list = list(genes)
    #genes = genes_list[:5]
    #output_ = {}
    #for no in range(len(selected_epi)-1):
    #    print str(no)+'-th iteration'
    #    set1_name = str(len(selected_epi[no]))
    #    set2_name = str(len(selected_epi[no+1]))
    #    output_[str(set2_name) + '_' + str(set1_name)] = {}
    #    set1_ = binary_table(pathway+'entropy/'+set1_name+'_z.txt', threshold_=-1.0, restricted_list=genes)
    #    set2_ = binary_table(pathway+'entropy/'+set2_name+'_z.txt', threshold_=-1.0, restricted_list=genes)

    #    cnt = 0
    #    for g1 in genes:
    #        output_[str(set2_name) + '_' + str(set1_name)][g1] = 0.0
    #        cnt += 1
    #        for g2 in genes:
    #            if g1==g2:
    #                continue
    #            else:
    #                cor2_ = stat.pearson(set2_[g1], set2_[g2])
    #                cor1_ = stat.pearson(set1_[g1], set1_[g2])
    #                if no == 1 and g1=='UBE2Q1':
    #                    print set2_['UBE2Q1']
    #                    print cor2_

    #                output_[str(set2_name) + '_' + str(set1_name)][g1] += cor2_ - cor1_
    #genomics.write_table1(output_, pathway+'entropy/'+'cor_differences.txt')



    # CONVERT Z-SCORE TABLES TO BINARY TABLES
    #genes_to_remove = set()
    #for epi_ in selected_epi:
    #    table_ = read_table1(pathway+'entropy/saturation/'+str(len(epi_))+'_z.txt', del_colnames=True, numerical=False)
    #    for item in table_:
    #        temp = 0
    #        for m in table_[item]:
    #            if table_[item][m] =='NA':
    #                continue
    #            else:
    #                if float(table_[item][m]) < -1.0:
    #                    temp = 1
    #        if temp == 0:
    #            genes_to_remove.add(item)
    #
    #file_ = read_table1(pathway + 'entropy/saturation/18_z.txt', numerical=False, del_colnames=True)
    #genes = set()
    #for gene in file_:
    #    genes.add(gene)
    #for m in genes_to_remove:
    #    genes.discard(m)
    #print len(genes)
    #for epi_ in selected_epi:
    #    print len(epi_)
    #    table_ = binary_table(pathway+'entropy/saturation/'+str(len(epi_))+'_z.txt', threshold_=-1.0, restricted_list=genes)
    #    genomics.write_table1(table_, pathway+'entropy/saturation/'+str(len(epi_))+'_z_binary_.txt')



    ### SUBSET CORRELATION TABLE & CALCULATE CORRELATIONS FOR SELECTED GENES ACROSS THE EPIGENOMES
    ### TAKES TOP 5% OF GENES BY H3K4ME3 PEAKS TO DEFINE GOOD CANDIDATE GENES
    #cardiac_genes_ = genomics.read_file1('/Users/woojunshim/Research/Data/cardiac_regulators_modified.txt')
    #cor_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/gene_pearson_short_sorted1.txt'
    #cardiac_genes = set()
    #results = {}
    #results_s = {}
    #results_a = {}

    #for item in cardiac_genes_:
    #    if item[0] != 'ATP2A2':
    #        cardiac_genes.add(item[0])
    #        results[item[0]] = {}
    #        results_s[item[0]] = {}
    #        results_a[item[0]] = {}
    #for item in cardiac_genes:
    #    for epi in epigenomes:
    #        results[item][epi] = 'NA'
    #        results_s[item][epi] = 'NA'
    #        results_a[item][epi] = 'NA'
    #for epi in epigenomes:
    #    print epi
    #    file_ = genomics.read_file1('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/new_ds/'+epi+'_new_ds.txt')
    #    background_total = len(file_)
    #    candidate = []
    #    background = []
    #    for no in range(len(file_)):
    #        file_[no][2] = float(file_[no][2])
    #        background.append(file_[no][0])
    #    file_ = genomics.sort_(file_, idx=2, reverse_=True)
    #    candidate_total = int(background_total * 0.05)
    #    for no in range(candidate_total):
    #        candidate.append(file_[no][0])
    #    table_ = subset_table(cor_, cardiac_genes, background)
    #    print len(candidate)
    #    print len(background)
    #    print
    #    for g1 in cardiac_genes:
    #        s_, p_, ave_ = gene_cor(g1, candidate, table_)
    #        results[g1][epi] = p_
    #        results_s[g1][epi] = s_
    #        results_a[g1][epi] = ave_

    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/cardiac_genes_p_new.txt')
    #genomics.write_table1(results_s, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/cardiac_genes_s_new.txt')
    #genomics.write_table1(results_a, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/cardiac_genes_a_new.txt')

    #results = subset_table(cor_, cardiac_genes, cardiac_genes)
    #backgrounds = subset_table(cor_, cardiac_genes, cols=None)
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/cardiac_genes_cor_new.txt')


    ### TESTING CORRELATION ANALYSIS FOR SELECTED CARDIAC GENES 
    ### IT INSERTS A SELECTED SET OF CARDIAC SPECIFIC GENES INTO PRE-DEFINED DEGS FROM BOTH HEART- AND BRAIN-RELATED CELL TYPES.

    #cardiac_genes_ = genomics.read_file1('/Users/woojunshim/Research/Data/cardiac_regulators_modified_nontf.txt')
    #cor_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/gene_pearson_short_sorted1.txt'
    #cardiac_genes = set()
    #results = {}
    #results_s = {}
    #results_a = {}

    #for item in cardiac_genes_:
    #    if item[0] != 'ATP2A2':
    #        cardiac_genes.add(item[0])
    #        results[item[0]] = {}
    #        results_s[item[0]] = {}
    #        results_a[item[0]] = {}

    #gg = genomics.read_file1('/Users/woojunshim/Research/Data/highly_expressed_genes/filtering_specificity_combined.txt')
    #epi_ = []
    #for item in gg:
    #    if item[0].startswith('E'):
    #        if item[0] in tissue_groups_:   #only heart and brain tissue groups
    #            epi_.append(item[0])
    #days = epi_    
    #stat_ = []    
    #for item in cardiac_genes:
    #    for epi in days:
    #        results[item][epi] = 'NA'
    #        results_s[item][epi] = 'NA'
    #        results_a[item][epi] = 'NA'
    #pathway = '/Users/woojunshim/Research/Data/highly_expressed_genes/DEG/'
    #for day in days:
    #    print day
    #    data_ = []
    #    file_ = open(pathway + day + '/output_score.txt', 'r')
    #    for line in file_:
    #        line = line.strip().split()
    #        if not line[0].startswith('"Gene'):
    #            if line[1] != 'NA':
    #                if (line[4]=='NA') and (float(line[1]) == 0):
    #                    data_.append([line[0], -999, line[-1]])
    #                elif (line[4]=='NA') and (float(line[1]) > 0):
    #                    data_.append([line[0], 999, line[-1]])
    #                else:
    #                    data_.append([line[0], float(line[4]), line[-1]])
    #    candidate = []
    #    background = []
    #    data_ = genomics.sort_(data_, idx=1, reverse_=True)        
    #    for item in data_:
    #        if (item[-1] == 'TRUE') and (item[1] > 0.0):
    #            candidate.append(item[0])
    #            background.append(item[0])
    #        else:
    #            background.append(item[0])
    #    for gene in cardiac_genes:
    #        if gene not in candidate:
    #            candidate.append(gene)

        #stat_.append([day, len(candidate), len(background)])
        #cor_analysis(candidate, background, cor_file=cor_, output_=pathway + day + '/' + day, pair_analysis_=False)


    #    table_ = subset_table(cor_, candidate, background)
    #    print len(candidate)
    #    print len(background)
    #    print
    #    for g1 in cardiac_genes:
    #        s_, p_, ave_f, ave_b  = gene_cor(g1, candidate, table_)
    #        results[g1][day] = p_
    #        results_s[g1][day] = s_
    #        results_a[g1][day] = ave_f

    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/cardiac_genes_p_new_sorted1_nontf.txt')
    #genomics.write_table1(results_s, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/cardiac_genes_s_new_sorted1_nontf.txt')
    #genomics.write_table1(results_a, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/cardiac_genes_a_new_sorted1_nontf.txt')

    #results = subset_table(cor_, cardiac_genes, cardiac_genes)
    #backgrounds = subset_table(cor_, cardiac_genes, cols=None)
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/cardiac_genes_cor_new.txt')

    # CALCULATE P-VALUES FOR EACH SELECTED GENE
    #output_ = []
    #for gene in results:
    #    pf = []
    #    pb = []
    #    for g2 in results[gene]:
    #        if g2==gene:
    #            continue
    #        else:
    #            pf.append(results[gene][g2])
    #    for g2 in backgrounds[gene]:
    #        if g2==gene:
    #            continue
    #        else:
    #            pb.append(backgrounds[gene][g2])
    #    s_, p_ = stat.t_test(pf, pb, output_=None)
    #    output_.append([gene, round(np.mean(pf), 4), round(np.mean(pb),4) , p_, round(s_,4)])
    #output_.insert(0, ['#gene','Mean(within_candidate)','Mean(with_all)','p-value(t.test)','t.statistic'])
    #genomics.write_file(output_, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/cardiac_genes_analysis_new.txt')


    ### SUBSET CORRELATION TABLE
    #cardiac_genes_ = genomics.read_file1('/Users/woojunshim/Research/Data/cardiac_regulators_modified.txt')
    #cor_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/gene_pearson_short_new.txt'
    #cardiac_genes = set()
    #for item in cardiac_genes_:
    #    cardiac_genes.add(item[0])
    #results = subset_table(cor_, cardiac_genes, cardiac_genes)
    #backgrounds = subset_table(cor_, cardiac_genes, cols=None)
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/cardiac_genes_cor_new.txt')

    # CALCULATE P-VALUES FOR EACH SELECTED GENE
    #output_ = []
    #for gene in results:
    #    pf = []
    #    pb = []
    #    for g2 in results[gene]:
    #        if g2==gene:
    #            continue
    #        else:
    #            pf.append(results[gene][g2])
    #    for g2 in backgrounds[gene]:
    #        if g2==gene:
    #            continue
    #        else:
    #            pb.append(backgrounds[gene][g2])
    #    s_, p_ = stat.t_test(pf, pb, output_=None)
    #    output_.append([gene, round(np.mean(pf), 4), round(np.mean(pb),4) , p_, round(s_,4)])
    #output_.insert(0, ['#gene','Mean(within_candidate)','Mean(with_all)','p-value(t.test)','t.statistic'])
    #genomics.write_file(output_, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/cardiac_genes_analysis.txt')


    ### SCRNA-SEQ DATA
    #pathway = '/Users/woojunshim/Research/Data/scRNA/'
    #days = ['day15','day30']
    #clusters = ['c1']
    #cor_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/gene_pearson_short.txt'
    #for day in days:
    #    background_ = genomics.read_file1(pathway+day+'_background.txt')
    #    background = []
    #    for item in background_:
    #        background.append(item[0])
    #    for cluster in clusters:
    #        candidate = []
    #        file_ = genomics.read_file1(pathway+day+'_'+cluster+'.txt')
    #        for item in file_:
    #            candidate.append(item[8])
    #        print day, cluster
    #        print len(candidate)
    #        print len(background)
    #        print
    #        cor_analysis(candidate, background, cor_file=cor_, output_=pathway + day +'_'+cluster, pair_analysis_=False)

    ### FDR (MULTIPLE TESTING CORRECTION)
    #pathway = '/Users/woojunshim/Research/Data/scRNA/'
    #days = ['day15','day30']
    #clusters = ['c1']
    #for day in days:
    #    for cluster in clusters:
    #        file_ = genomics.read_file1(pathway+day+'_'+cluster+'_results.txt')
    #        temp = []
    #        for item in file_:
    #            temp.append(float(item[1]))
    #        bh = stat.corrected_p(temp, method_='fdr_bh')
    #        for no in range(len(file_)):
    #            file_[no].extend([bh[no]])
    #        bo = stat.corrected_p(temp, method_='bonferroni')
    #        for no in range(len(file_)):
    #            file_[no].extend([bo[no]])
    #        file_.insert(0, ['#gene','p-value','FDR(BH)','Bonferroni'])
    #        genomics.write_file(file_, pathway+day+'_'+cluster+'_results.txt')




    ### EXTRACT GENE NAMES THAT ARE WITHIN TOP 5% BY H3K4ME3 WIDTHS
    #file_ = genomics.read_file('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/summary_results_dominant_1.0_broadpeak_mrna_.txt', [0,3], rowname='1')
    #genes = set()
    #top_genes = 0.05
    #for epi in epigenomes:
    #    temp = file_[epi]
    #    for no in range(len(temp)):
    #        temp[no][1] = float(temp[no][1])
    #    temp = genomics.sort_(temp, idx=1, reverse_=True)
    #    no_genes = int(len(temp) * 0.05)
    #    for no in range(no_genes):
    #        gene = temp[no][0]
    #        if gene not in genes:
    #            genes.add(gene)
    #results = []
    #for gene in genes:
    #    results.append([gene])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/top5_genes_h3k4me3.txt')
    #epi = []
    #print len(epigenomes)
    #for m in tissue_groups:
    #    for l in tissue_groups[m]:
    #        epi.append([l])
    #genomics.write_file(epi, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/selected_epigenomes.txt')

    ### CORRELATION SCORES
    ### RUN CORRELATION ANALYSIS
    #count = 500  # 500 genes as the candidate genes
    #pathway = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/'
    #pathway1 = '/Users/woojunshim/Research/Data/Paige/1/'
    #pathway1 = '/Users/woojunshim/Research/Data/ENCODE/'
    #output_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/test/encode/'
    #files = ['E114','E115','E116','E117','E118','E119','E120','E121','E122','E123','E124','E125','E126','E127','E128','E129']
    #files = ['day0','day2','day5','day9','day14']
    #cor_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/gene_pearson_short.txt'
    #for file in files:
    #    print file
    #    tt_ = pathway1+'h3k4me3_'+file+'_assigned_.txt'
    #    tt_ = pathway1+file+'-H3K4me3_result'
    #    tt = genomics.read_file1(tt_)
    #    candidate = []
    #    background = []
    #    for no in range(len(tt)):
    #        item = tt[no]
    #        if no<count:
    #            candidate.append(item[1])
    #        background.append(item[1])
    #    cor_analysis(candidate, background, cor_file=cor_, output_=output_+file, pair_analysis_=False)

    # MULTIPLE TEST CORRECTION
    #days = ['day0','day2','day5','day9','day14']
    #for day in days:
    #    file_ = genomics.read_file1(pathway+day+'_results.txt')
    #    temp = []
    #    for item in file_:
    #        temp.append(float(item[1]))
    #    bh = stat.corrected_p(temp, method_='fdr_bh')
    #    for no in range(len(file_)):
    #        file_[no].extend([bh[no]])
    #    file_.insert(0, ['#gene','p-value','t.statistics','FDR(BH)'])
    #    genomics.write_file(file_, pathway+day+'_'+cluster+'_results.txt')


    #pathway1 = '/Users/woojunshim/Research/Data/ENCODE/'
    #output_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/test/encode/'
    #files = ['E114', 'E115', 'E116', 'E117', 'E118', 'E119', 'E120', 'E121', 'E122', 'E123', 'E124', 'E125', 'E126','E127', 'E128', 'E129']

    #cor_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/gene_pearson_short.txt'
    #for file in files:
    #    print file
    #    tt_ = pathway1 + file + '-H3K4me3_result'
    #    tt = genomics.read_file1(tt_)
    #    candidate = []
    #    background = []
    #    for no in range(len(tt)):
    #        item = tt[no]
    #        if no < count:
    #            candidate.append(item[1])
    #        background.append(item[1])
    #    cor_analysis(candidate, background, cor_file=cor_, output_=output_ + file, pair_analysis=False)

    ### CALCULATE P-VALUES FOR SPECIFICITY FOR GENES
    #pathway = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/'
    #input_ = read_table1(pathway+'gene_specificity_table.txt', numerical=False, del_colnames=True)
    #results_z = {}
    #results_p = {}
    #genes = set()
    #for gene in input_:
    #    genes.add(gene)
    #for gene in genes:
    #    results_z[gene] = {}
    #    results_p[gene] = {}
    #    for epi in epigenomes:
    #        results_z[gene][epi] = 'NA'
    #        results_p[gene][epi] = 'NA'
    #for gene in genes:
    #    epi = []
    #    i = []
    #    z_results = []
    #    p_results = []
    #    for e in input_[gene]:
    #        if input_[gene][e] != 'NA':
    #            epi.append(e)
    #            i.append(float(input_[gene][e]))
    #    mean_ = np.mean(i)
    #    sd_ = np.std(i)
    #    for item in i:
    #        z_ = stat.z_score(item, mean_=mean_, sd_=sd_)
    #        p_ = stat.p_value(z_, side='lower')
    #        z_results.append(z_)
    #        p_results.append(p_)
    #    temp = stat.corrected_p(p_results)
    #    for no in range(len(epi)):
    #        e_ = epi[no]
    #        results_z[gene][e_] = z_results[no]
    #        results_p[gene][e_] = temp[no]
    #genomics.write_table1(results_z, pathway+'gene_specificity_z.txt')
    #genomics.write_table1(results_p, pathway + 'gene_specificity_p_corrected.txt')



    ### CALCULATE SHANNON ENTROPY AND SPECIFICITY FOR GENES AND ACROSS CELL TYPES
    #pathway = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/'
    #file_ = genomics.read_file(pathway+'summary_results_dominant_1.0_broadpeak_mrna_.txt', [1,3],rowname='0')
    #results = {}
    #genes = set()
    #entropy_ = []
    #for gene in file_:
    #    if gene not in genes:
    #        genes.add(gene)
    #for gene in genes:
    #    for no in range(len(file_[gene])):
    #        file_[gene][no][1] = float(file_[gene][no][1])
    #for gene in genes:
    #    results[gene] = {}
    #    for epi in epigenomes:
    #        results[gene][epi] = 'NA'
    #for gene in genes:
    #    temp = file_[gene]
    #    input_ = []
    #    for item in temp:
    #        input_.append(item[1])
    #    ent = entropy(input_)
    #    spe = specificity(input_, ent)
    #    entropy_.append([gene, ent])
    #    for no in range(len(temp)):
    #        item = temp[no]
    #        results[gene][item[0]] = spe[no]
    #genomics.write_table1(results, pathway+'gene_specificity_table.txt')
    #genomics.write_file(entropy_,pathway+'gene_entropy.txt')


    ### FIND SIGNIFICANT PAIRS FROM TABLE INSTANCE
    #p,n = find_significant_pairs('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/hclust/FET/clusters/cluster_dependence.txt', threshold_=0.1)
    #genomics.write_file(p, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/hclust/FET/clusters/positive_clusters.txt')
    #genomics.write_file(n, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/hclust/FET/clusters/negative_clusters.txt')

    ### CREATE  BINARY TABLE FOR ENTROPY (BASED ON THRESHOLD)
    #pathway = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/'
    #table_ = read_table1(pathway+'gene_specificity_z.txt', del_colnames=True, numerical=False)
    #gene_ = set()
    #threshold_ = -1.0
    #for item in table_:
    #    gene_.add(item)
    #results = {}
    #for gene in gene_:
    #    results[gene] = {}
    #    for col in table_[gene]:
    #        results[gene][col] = 0
    #for gene in gene_:
    #    for col in table_[gene]:
    #        if table_[gene][col] != 'NA':
    #            if float(table_[gene][col]) < threshold_:
    #                results[gene][col] = 1
    #genomics.write_table1(results, pathway+'gene_entropy_table_z.txt')

    ### REMOVE GENES WITH NO SUBSTANTIAL H3K4ME3 DYNAMICS FROM 'gene_entropy_table.txt'
    #pathway = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/'
    #table_ = read_table1(pathway + 'significant_cell_types_table_0.0001.txt', del_colnames=True, numerical=False)
    #genes = set()
    #removed_genes = []
    #for item in table_:
    #    for col in table_[item]:
    #        if int(table_[item][col]) == 1:
    #            genes.add(item)
    #            break
    #    if item not in genes:
    #        removed_genes.append([item])
    #results = {}
    #for gene in genes:
    #    results[gene] = {}
    #    for col in table_[gene]:
    #        results[gene][col] = table_[gene][col]
    #genomics.write_table1(results, pathway+'significant_cell_types_table_sorted0.0001.txt')
    #genomics.write_file(removed_genes, pathway+'genes_without_specificity_0.0001.txt')





    ### CREATE TRIMMED TABLE FOR NEW 2.0 TABLE
    #pathway = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/'
    #table_ = read_table1(pathway+'broadpeak_combined_foreground_counts_intra.txt', del_colnames=True)
    #gene__ = open(pathway+'all_genes_within_threshold.txt', 'r')
    #gene_ = set()
    #for line in gene__:
    #    line = line.strip().split()
    #    if not line[0].startswith('#'):
    #        gene_.add(line[0])
    #results = {}
    #for gene in gene_:
    #    results[gene] = {}
    #    for col in table_[gene]:
    #        results[gene][col] = 0
    #for gene in gene_:
    #    for col in table_[gene]:
    #        results[gene][col] = int(table_[gene][col])
    #genomics.write_table1(results, pathway+'new_broadpeak_genes_counts_intra.txt')


    #new_analysis(input_file='/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/new_ds/E083_new_ds.txt', ref_file='/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/broadpeak_combined_foreground_counts_intra.txt', threshold_=1, input_gene_idx=0, input_value_idx=2)

    ### CREATE A TABLE FILE (INTRA-THRESHOLD FOR ALL 111 EPIGENOMES)
    #file_ = genomics.read_file('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/summary_results_dominant_1.0_broadpeak_mrna_.txt', [1,4], rowname='0')
    #cut_off = genomics.read_file('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/hclust/Roadmap_cutoff_positions.txt', [1], rowname='0')
    #results = {}
    #genes = set()
    #for gene in file_:
    #    if gene in mrna:
    #        if gene not in results:
    #            results[gene] = {}
    #for gene in file_:
    #    for tissue in tissue_groups:
    #        for epi in tissue_groups[tissue]:
    #            results[gene][epi] = 0
    #file_ = genomics.read_file('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/summary_results_dominant_1.0_broadpeak_mrna_.txt',[0, 4], rowname='1')
    #for epi in file_:
    #    temp = file_[epi]
    #    for no in range(len(temp)):
    #        temp[no][1] = float(temp[no][1])
    #    temp = genomics.sort_(temp, idx=1, reverse_=True)
    #    for no in range(int(cut_off[epi][0][0])):
    #        item = temp[no]
    #        gene = item[0]
    #        genes.add(gene)
    #        results[gene][epi] = 1
    #results = []
    #for item in genes:
    #    results.append([item])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/all_genes_within_threshold.txt')

    ### CREATE A TABLE FILE (ALL DS SCORES FROM 111 EPIGENOMES)
    #file_ = genomics.read_file('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/summary_results_dominant_1.0_broadpeak_mrna_.txt', [1,4], rowname='0')
    #results = {}
    #for gene in file_:
    #    if gene in mrna:
    #        if gene not in results:
    #            results[gene] = {}
    #for gene in file_:
    #    for tissue in tissue_groups:
    #        for epi in tissue_groups[tissue]:
    #            results[gene][epi] = 0.0
    #for gene in file_:
    #    temp = file_[gene]
    #    for item in temp:
    #        results[gene][item[0]] = item[1]
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/All_DS.txt')


    ### CREATE A TABLE FILE FROM _summary.txt
    #pathway='/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/new_ds/mle/epigenomes/'
    #results = {}
    #for epi in epigenomes:
    #    file_ = genomics.read_file1(pathway+epi+'_results_summary.txt')
    #    results[epi] = {}
    #    for tissue in tissue_groups:
    #        results[epi][tissue] = 0.0
    #    for item in file_:
    #        results[epi][item[0]] = item[1]
    #genomics.write_table1(results, pathway+'Roadmap_summary.txt')


    ### EXPORT EPIGENOMES AS TEXT FILE
    #output_ = open('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/epigenomes_list.txt','w')
    #for epi in epigenomes:
    #    output_.write(epi+'\t'+tissue_groups_[epi]+'\n')


    ### CONTRIBUTION ANALYSIS
    #pathway = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/new_ds/'
    #pathway1 = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/new_ds/mle/epigenomes/'
    #ref_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/broadpeak_tissue_enrichment_pvalues__.txt'
    #contribution_analysis(pathway+'E113_new_ds.txt', ref_, summary_file=pathway1+'E113_results_summary.txt', contribution_file=pathway1+'E113_results_contribution_scores.txt', gene_idx=0, value_idx=2, threshold=0.05, output_=pathway1+'E113_gene_significance.txt')

    ### FIND MISSING GENES FROM TABLE
    #results = []
    #a = read_table1('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/broadpeak_combined_foreground_counts_.txt')
    #b = read_table1('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/broadpeak_combined_foreground_tissue_counts_.txt')
    #for gene in a:
    #    if gene not in b:
    #        results.append([gene])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/missing_genes_in_table.txt')


    ### FIND THE BEST THETA (I.E. DS THRESHOLD) FOR EACH CELL TYPE
    ### AND CALCULATE CONTRIBUTION SCORE FOR TISSUE TYPES
    ### PRODUCE LISTS OF GENE TABLES WITH CONTRIBUTION SCORES FOR TISSUE TYPES
    #pathway = '/Users/woojunshim/Research/Data/Paige/1/'
    #pathway = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/new_ds/'
    #days = ['E114','E115','E116','E117','E118','E119','E120','E121','E122','E123','E124','E125','E126','E127','E128','E129']
    #pathway = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/new_ds/'
    #pathway = '/Users/woojunshim/Research/Data/ENCODE/'
    #pathway = '/Users/woojunshim/Research/Data/'
    #days = ['day0','day2','day5','day9','day14']
    #ref_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/broadpeak_tissue_enrichment_pvalues__.txt'
    #for day in days:
        #input_file = pathway+'H3K4me3_'+day+'_assigned_.txt'
    #    output_file_ = pathway+'H3K4me3_'+day+'_result'
    #    input_file = pathway+'h3k4me3_'+day+'_assigned_.txt'
        #output_file_ = pathway+'h3k4me3_'+day+'_mle_'
    #    print day
        #input_file = pathway+day+'-H3K4me3_result'
        #output_file_ = pathway+day+'-H3K4me3_result'
        #input_file = pathway+'ENCFF'+day+'.bed'
        #output_file_ = pathway+'ENCFF'+day+'_result'
        #input_file = pathway+day+'-H3K4me3.broadPeak'
        #output_file_ = pathway+day+'-H3K4me3_result'
        #main(input_file, output_file_, max_width__=2500, dominant_=True, convert_DS=True)
    #    prop, tissue_, thetha_ = scan(input_file, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/broadpeak_tissue_enrichment_pvalues__.txt',gene_idx=1, difference_idx=2, value_idx=2, theta=[5.0, 7.5, 0.1], threshold=0.05)
    #    contribution_scores(input_file, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/broadpeak_tissue_enrichment_pvalues__.txt',gene_idx=1, value_idx=2, threshold=0.05, proportions=prop, theta_=thetha_, output_file=output_file_, test='/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/summary_results_dominant_1.0_broadpeak_mrna_.txt', test_type='empirical')
    #for day in days:
    #    input_file = pathway + 'h3k4me3_' + day + '_assigned_.txt'
    #    input_file1 = pathway+'H3K4me3_'+day+'_result'
    #    contribution_analysis(input_file, ref_, summary_file=input_file1+'_summary.txt',
    #                          contribution_file=input_file1+'_contribution_scores.txt', gene_idx=1,
    #                          value_idx=2, threshold=0.05, output_=pathway+'H3K4me3_'+day+'_gene_significance.txt')

    ### PERFORMS MAXIMUM LIKELIHOOD ESTIMATION FOR THE DIFFERENCE FROM THE THRESHOLD
    #pathway = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/new_ds/'
    #for tissue in tissue_groups:
    #    files = []
    #    for epi in tissue_groups[tissue]:
    #        files.append(pathway+epi+'_new_ds.txt')
    #    output_, theta_choice, max_ = mle(files, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/broadpeak_tissue_enrichment_pvalues__.txt', gene_idx=0, difference_idx=2, value_idx=2, tissue_group_=tissue)
    #    genomics.write_file(output_, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/new_ds/mle/'+tissue+'_mle.txt')



    ### PERFORM TISSUE COMPOSITION ANALYSIS
    #results = composition_analysis1('/Users/woojunshim/Research/Data/Paige/1/h3k4me3_day14_assigned_.txt', '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/new_broadpeak_genes_counts_intra.txt',gene_idx=1, difference_idx=2, value_idx=2, cutoff_=675)


    ### CONTRIBUTION SCORES
    #contribution_scores1('/Users/woojunshim/Research/Data/Paige/1/h3k4me3_day14_assigned_.txt',
    #                    '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/new_broadpeak_genes_counts_intra.txt',
    #                    gene_idx=1, value_idx=2, threshold=0.05, proportions=results, cutoff_=675,
    #                    output_file='/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/test.txt',
    #                    test='/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/summary_results_dominant_1.0_broadpeak_mrna_.txt',
    #                    test_type='empirical')
    ### READ IN ALL 'E***_new_ds.txt' AND CREATES A TABLE OF FILTERED OR INCLUDED GENES
    #print epigenomes
    #genes_excluded = {}
    #genes_included = {}
    #temp1 = {}
    #temp2 = {}
    #cut_off = 0.05  #empirical p-value cut-off
    #for epi in epigenomes:
    #    temp1[epi] = set()
    #    temp2[epi] = set()
    #    no_genes = 0
    #    file_ = genomics.read_file1('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/new_ds/' + epi + '_new_ds.txt')
    #    for no in range(len(file_)):
    #        file_[no][2] = float(file_[no][2])
    #        file_[no][4] = float(file_[no][4])
    #    file_ = genomics.sort_(file_, idx=4, reverse_=False)
    #    for item in file_:
    #        if float(item[4]) < cut_off:
    #            temp1[epi].add(item[0])
    #            no_genes += 1
    #        else:
    #            break
    #    file_ = genomics.sort_(file_, idx=2, reverse_=True)
    #    for no in range(no_genes):
    #        item = file_[no]
    #        temp2[epi].add(item[0])
    #    for item in temp1[epi]:
    #        if item not in temp2[epi]:
    #            if item not in genes_included:
    #                genes_included[item] = {}
    #                for epi_ in epigenomes:
    #                    genes_included[item][epi_] = 0
    #            genes_included[item][epi] = 1
    #    for item in temp2[epi]:
    #        if item not in temp1[epi]:
    #            if item not in genes_excluded:
    #                genes_excluded[item] = {}
    #                for epi_ in epigenomes:
    #                    genes_excluded[item][epi_] = 0
    #            genes_excluded[item][epi] = 1
    #    if epi=='E065':
    #        print no_genes

    #genomics.write_table1(genes_included, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/new_ds/included_genes_table.txt')
    #genomics.write_table1(genes_excluded, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/new_ds/excluded_genes_table.txt')


    ### READ IN ALL 'E***_new_ds.txt' AND CREATES A TABLE OF DESIGNATED VALUE
    #results = {}
    #lowest = {}
    #for epi in epigenomes:
    #    lowest[epi] = 0.0
    #    current_lowest = 9999
    #    file_ = genomics.read_file1('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/new_ds/'+epi+'_new_ds.txt')
    #    for item in file_:
    #        if item[0] not in results:
    #            results[item[0]] = {}
    #        if float(item[3]) < current_lowest:
    #            current_lowest = float(item[3])
    #    lowest[epi] = current_lowest
    #for epi in epigenomes:
    #    for gene in results:
    #        results[gene][epi] = 'NA'
    #for epi in epigenomes:
    #    file_ = genomics.read_file1('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/new_ds/'+epi+'_new_ds.txt')
    #    for item in file_:
    #        results[item[0]][epi] = item[3]
    #for gene in results:
    #    for epi in epigenomes:
    #        if results[gene][epi] == 'NA':
    #            results[gene][epi] = lowest[epi]   # Replace 'NA' values with the lowest in the given epigenome
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/new_ds/DS_change_table.txt')

    ### GET RID OF ALL VALUES OF 'Not_observed' or '999999'
    #pathway = '/Users/woojunshim/Research/Data/Paige/1/'
    #days = ['day0', 'day2', 'day5', 'day9', 'day14']
    #for day in days:
    #    results = []
    #    input_ = genomics.read_file1(pathway + 'h3k4me3_' + day + '_assigned.txt')
    #    for no in range(len(input_)):
    #        if (input_[no][-1] != 'Not_observed') and (input_[no][-1] != '999999'):
    #            results.append(input_[no])
    #    genomics.write_file(results, pathway+'h3k4me3_' + day + '_assigned_.txt')

    ### POPULATION ANALYSIS FOR DS CHANGE (PAIGE DATA)
    #pathway= '/Users/woojunshim/Research/Data/Paige/1/'
    #days = ['day0','day2','day5','day9','day14']
    #for day in days:
    #    input_ = genomics.read_file1(pathway+'h3k4me3_'+day+'_assigned_.txt')
    #    for no in range(len(input_)):
    #        input_[no][-1] = float(input_[no][-1])
    #    input_ = genomics.sort_(input_, idx=-1,reverse_=True)
    #    temp = []
    #    for no in range(len(input_)):
    #        if (input_[no][-1] != 'Not_observed') and (input_[no][-1] != '999999'):
    #            temp.append(float(input_[no][-1]))
    #    results = population_analysis(temp, output_='empirical', multiple_correction=False)
    #    for no in range(len(input_)):
    #        input_[no].extend([results[no]])
    #    input_.insert(0, ['#Peak_ID','Gene_symbol','DS','Chr','Start','End','Difference_from_threshold','p-value(empirical)'])
    #    genomics.write_file(input_, pathway+'h3k4me3_'+day+'_assigned__.txt')



    ### Tsankov data analysis
    #results = []
    #results = chip_enrichment('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Analysis_results/Tsankov/results.txt',sort_by=2, col_no=7, bin_size=1)
    #print results[0:9]

    ### EXTRACT ENTRIES WITH ONLY SIGNIFICANT P-VALUES IN ANY OF TISSUE COLUMNS(FROM E.G. broadpeak_tissue_enrichment_pvalues.txt)
    #file_ = open('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/broadpeak_tissue_enrichment_pvalues.txt', 'r')
    #results = []
    #cnt = 0
    #header = []
    #threshold_ = 0.05
    #for line in file_:
    #    line = line.strip().split()
    #    if cnt == 0:
    #        for m in line:
    #            header.append(m)
    #        cnt = 1
    #    else:
    #        pass_ = False
    #        for no in range(1, len(line)):
    #            if float(line[no]) <= threshold_:
    #                pass_ = True
    #        if pass_ == True:
    #            results.append(line)
    #results.insert(0, header)
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/broadpeak_tissue_enrichment_pvalues_sig.txt')


    ### READS 'hotspots_distances.txt' AND 1.REMOVE NCRNAS AND 2.CREATES INTERVALS AS DEFINED
    #results = create_intervals('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/hotspots_distances.txt', col_idx=6, range_=[-1000000, 1000000], interval_size=1000)
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/hotspots_distances_.txt')

    ### FILTER OUT ELEMENTARY INTERVALS WITH IRRELEVANT VALUES
    ### CATEGORISE INTO PRE-DEFINED BINS
    #input_ = genomics.read_file1('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/hotspots_distances_.txt')
    #results = {}
    #for i in range(2000):
    #    results[str(i+1)] = [0,0,0]
    #for item in input_:
    #    if len(item) > 7:
    #        if (int(item[3]) != 0) and (item[-1]!='NA'):
    #            if int(item[3]) > 50:
    #                results[item[-1]][0] += 1
    #            elif (int(item[3]) > 10) and (int(item[3]) <= 50):
    #                results[item[-1]][1] += 1
    #            else:
    #                results[item[-1]][2] += 1
    #final = []
    #for item in results:
    #    final.append([int(item)-1000])
    #    for m in results[item]:
    #        final[-1].extend([str(m)])
    #final = genomics.sort_(final, idx=0, reverse_=False)
    #final.insert(0, ['#bin','cat1(>50)','cat2(10<x<=50)','cat3(x<=10)'])
    #genomics.write_file(final, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/hotspots_category_counts.txt')








    ### LOCATIONAL ANALYSIS OF DOMINANT PEAKS (BROAD-PEAKS)
    #tss_ = '/Users/woojunshim/Research/Data/hg19_TSS_.txt'
    #tss_data = genomics.read_file(tss_, [1, 3, 4, 2, 5, 0])
    #tss_human19 = genomics.tss(tss_data, chr_idx=0, position_list=[1, 2], strand_idx=3, id_idx=4)
    #bed_data_ = []
    #bed_data = genomics.read_file1('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/elementary_intervals_counts_broadpeak.txt')
    #mrna_ = genomics.read_file1('/Users/woojunshim/Research/Data/mRNA_genes.txt')
    #mrna = set()
    #for item in mrna_:
    #    if item[0] not in mrna:
    #        mrna.add(item[0])
    #for no in range(len(bed_data)):
    #    bed_data[no].extend([no+1])
    #    bed_data_.append([bed_data[no][0],bed_data[no][1],bed_data[no][2],bed_data[no][4]])
    #max_width_ = 2500
    #temp = genomics.assign_gene(bed_data_, tss_human19, min_distance=0, max_distance=max_width_, centre=True, width=True,
    #                   gene_include=True)
    #final = []
    #for no in range(len(temp)):
    #    item = temp[no]
    #    if item[1]!='':
    #        if item[1] in mrna:
    #            final.append([bed_data[no][0],bed_data[no][1],bed_data[no][2],bed_data[no][3],bed_data[no][4]])
    #            final[-1].extend([item[1], item[2]])
    #genomics.write_file(final, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/hotspots_distances.txt')

    ### EXTRACT GENOMIC COORDINATES OF PEAKS
    #pathway = '/volumes/Project/Research/bigdata/roadmap/broad_peaks/'
    #pathway1 = '/Users/woojunshim/Research/Data/broadPeaks/'
    #output_ = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/'
    #data_ = genomics.read_file(output_+'summary_results_dominant_1.0_broadpeak.txt', [0,2,3,4,-2,-1], rowname='1')
    #for tissue in tissue_groups:
    #    for epi in tissue_groups[tissue]:
    #        temp_ = open(pathway+epi+'-H3K4me3.broadPeak', 'r')
    #        temp = {}
    #        for line in temp_:
    #            line = line.strip().split()
    #            temp[line[3]] = [line[0], line[1], line[2]]
    #        for no in range(len(data_[epi])):
    #            id = data_[epi][no][1]
    #            data_[epi][no].extend([temp[id][0],temp[id][1],temp[id][2]])
    #results = []
    #for epi in data_:
    #    for item in data_[epi]:
    #        results.append([epi])
    #        for m in item:
    #            results[-1].extend([m])
    #genomics.write_file(results, output_+'summary_dominant_broadpeak.txt')
    #        output_ = open(pathway1+epi+'_coordinates.broadPeaks.bed','w')
    #        for item in temp:
    #            output_.write(item[0]+'\t'+item[1]+'\t'+item[2]+'\n')




    ### CREATE ELEMENTARY INTERVALS
    #results = el_points('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/collaped_dominant_broadpeak.txt', chr_idx=0, start_idx=1, end_idx=2)
    #output_ = []
    #for chr in results:
    #    for no in range(len(results[chr])-1):
    #        output_.append([chr, results[chr][no], results[chr][no+1]])
    #genomics.write_file(output_, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/elementary_intervals_broadpeak.bed')

    ### EXPORT GENOMIC COORDINATES OF DOMINANT PEAKS FOR SELECTED GENES
    #times = ['day0', 'day2', 'day5', 'day9', 'day14']
    #pathway = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/'
    #output_ = pathway+'igv/'
    #for time in times:
    #temp = genomics.read_file1(pathway+'summary_dominant_broadpeak.txt')
    #results = genomics.extract_elements(temp, feature_idx=[-3,-2,-1])
    #genomics.write_file(results, pathway+'collaped_dominant_broadpeak.txt')

    ### COMPARE TWO TIME-POINTS (E.G. PAIGE_DAY9 & DAY14)
    #pathway = '/Users/woojunshim/Research/Data/Paige/1/'
    #pairs = [['day0','day5'],['day5','day14'],['day0','day14'],['day0','day2'],['day2','day5'],['day5','day9'],['day9','day14']]
    #pairs = [['day0','day14']]
    #times = ['day0','day2','day5','day9','day14']
    #output_pathway = pathway+'analysis/'
    #for pair in pairs:
    #    compare_two_states(pathway+'h3k4me3_'+pair[0]+'_assigned.txt',pathway+'h3k4me3_'+pair[1]+'_assigned.txt', value_idx1=2, value_idx2=2,gene_idx1=1, gene_idx2=1, output_=pathway+pair[0]+'_'+pair[1]+'_.txt', write_extra=True)

    ### COMBINE TWO TIME-POINTS INTO ONE FILE
    #pathway = '/Users/woojunshim/Research/Data/Paige/'
    #file1 = trim_txt(pathway+'Day5_vs_day9.txt', cols=[0,1], col_names=['#gene','change1'])
    #file2 = trim_txt(pathway + 'Day9_vs_day14.txt', cols=[0, 1], col_names=['#gene','change2'])
    #file1 = genomics.read_file1(pathway+'Paige_K4me3_day14_assigned_.txt')
    #file2 = genomics.read_file1(pathway+'Day9_vs_day14.txt')
    #combined_change = add_column(file1, file2, 1, 0, 3)
    #file1 = trim_txt(pathway+'Day5_vs_day9.txt', cols=[0,2], col_names=['#gene','z-score1'])
    #file2 = trim_txt(pathway + 'Day9_vs_day14.txt', cols=[0, 2], col_names=['#gene','z-score2'])
    #combined_z = add_column(file1, file2, 0, 0, 1)
    #combined_change.insert(0, ['#Ensembl_ID','Gene_symbol','DS','Chr','Start','End','p-value','Pass_threshold','DS_change_rank'])
    #genomics.write_file(combined_change, pathway+'DS_changes_added_day14.txt')
    #genomics.write_file(combined_z, pathway+'z-socre_changes.txt')

    ### ADD A COLUMN TO INDICATE WHETHER THE DS CHANGE IS > 1SD (TRUE)
    #pathway = '/Users/woojunshim/Research/Data/Paige/1/'
    #for pair in pairs:
    #    value_list = {}
    #    a_list = set()
    #    temp = genomics.read_file1(pathway+pair[0]+'_'+pair[1]+'.txt_appeared')
    #    for item in temp:
    #        value_list[item[0]] = float(item[1])
    #        if float(item[1]) > 1.0:
    #            a_list.add(item[0])
    #    temp = genomics.read_file1(pathway+pair[0]+'_'+pair[1]+'.txt')
    #    for item in temp:
    #        value_list[item[0]] = float(item[1])
    #        if float(item[1]) > 1.0:
    #            a_list.add(item[0])
    #    file_ = genomics.read_file1(pathway+'h3k4me3_'+pair[1]+'_assigned.txt')
    #    for no in range(len(file_)):
    #        item = file_[no]
    #        gene = item[1]
    #        if gene in a_list:
    #            file_[no].extend([str(value_list[gene]), 'True'])
    #        else:
    #            file_[no].extend([str(value_list[gene]), 'False'])
    #    file_.insert(0, ['#Peak_ID','Gene_symbol','DS','Chr','Start','End','p-value','Difference_from_threshold','DS_change('+pair[0]+'_'+pair[1]+')','Up-regulated'])
    #    genomics.write_file(file_, output_pathway+pair[0]+'_'+pair[1]+'_summary.txt')

    ### CREATE A DS CHANGE TABLE (FROM DAY0 TO DAY14)
    #genes = {}
    #results = []
    #first_point = 'h3k4me3_day0_assigned.txt'
    #for time in times:
    #    temp = genomics.read_file1(pathway+'h3k4me3_'+time+'_assigned.txt')
    #    for item in temp:
    #        if item[1] not in genes:
    #            genes[item[1]] = []
    #temp = genomics.read_file1(pathway+first_point)
    #positives = {}
    #for item in temp:
    #    positives[item[1]] = item[2]
    #for gene in genes:
    #    if gene in positives:
    #        genes[gene].append(positives[gene])
    #    else:
    #        genes[gene].append('NA')

    #for pair in pairs:
    #    positives = {}
    #    temp = genomics.read_file1(pathway+pair[0]+'_'+pair[1]+'.txt')
    #    for item in temp:
    #        positives[item[0]] = item[1]
    #    for gene in genes:
    #        if gene in positives:
    #            genes[gene].append(positives[gene])
    #        else:
    #            genes[gene].append('NA')
    #for gene in genes:
    #    results.append([gene])
    #    for m in genes[gene]:
    #        results[-1].extend([m])
    #results.insert(0, ['#gene', times[0], times[0]+'_'+times[1], times[1]+'_'+times[2], times[2]+'_'+times[3], times[3]+'_'+times[4]])
    #genomics.write_file(results, output_pathway+'ds_change_table.txt')

    ### CREATE A DS TABLE (FROM DAY0 TO DAY14)
    #genes = {}
    #results = []
    #first_point = 'h3k4me3_day0_assigned.txt'
    #pathway = '/Users/woojunshim/Research/Data/Paige/1/analysis/'
    #for time in times:
    #    temp = genomics.read_file1(pathway+'h3k4me3_'+time+'_assigned.txt')
    #    for item in temp:
    #        if item[1] not in genes:
    #            genes[item[1]] = []
    #for time in times:
    #    temp = genomics.read_file1(pathway + 'h3k4me3_' + time + '_assigned.txt')
    #    positives = {}
    #    for item in temp:
    #        positives[item[1]] = item[2]
    #    for gene in genes:
    #        if gene in positives:
    #            genes[gene].append(positives[gene])
    #        else:
    #            genes[gene].append(0) # If peak is not observed, assign value of 0
    #for gene in genes:
    #    results.append([gene])
    #    for m in genes[gene]:
    #        results[-1].extend([m])
    #results.insert(0, ['#gene', times[0], times[1], times[2], times[3], times[4]])
    #genomics.write_file(results, pathway+'ds_table_.txt')

    ### REPLACE A SPACE GAP WITH '_'
    #file_ = replace('/Users/woojunshim/Research/Data/GO_Terms/GO_table_.txt', from_="'", to_='')
    #genomics.write_file(file_, '/Users/woojunshim/Research/Data/GO_Terms/GO_table_.txt')







    ### SLIDING FET
    #top_genes = 'top30'
    #deg_list_ = genomics.read_file1('/Users/woojunshim/Research/Data/highly_expressed_genes/DEG_list_'+top_genes+'.txt')
    #results1 = [['#cell_type','Broadest','RP','Difference_from_threshold']]
    #results2 = [['#cell_type','Broadest','RP','Difference_from_threshold']]
    #cell_types = []
    #for item in deg_list_:
    #    cell_types.append(item[0])
    #for epi in cell_types:
    #    print epi
    #    ref_genes = []
    #    for item in deg_list_:
    #        if item[0] == epi:
    #            for m in range(1, len(item)):
    #                ref_genes.append(item[m])
    #    print len(ref_genes)
    #    temp = genomics.read_file1('/Users/woojunshim/Research/Data/rp/Roadmap/'+epi+'_assigned.txt')
    #    input_list = []
    #    for n in range(len(temp)):
    #        temp[n][2] = float(temp[n][2])
    #        temp[n][8] = float(temp[n][8])
    #        temp[n][7] = float(temp[n][7])
    #    temp = genomics.sort_(temp, idx=2, reverse_=True)
    #    for n in range(len(temp)):
    #        input_list.append(temp[n][1])
    #    fet1 = sliding_fet(input_list, ref_genes, convert_to_percentile=True)

    #   temp = genomics.sort_(temp, idx=8, reverse_=True)
    #   for n in range(len(temp)):
    #       input_list.append(temp[n][1])
    #    fet2 = sliding_fet(input_list, ref_genes, convert_to_percentile=True)

    #    temp = genomics.sort_(temp, idx=7, reverse_=True)
    #    for n in range(len(temp)):
    #        input_list.append(temp[n][1])
    #    fet3 = sliding_fet(input_list, ref_genes, convert_to_percentile=True)

    #    results1.append([epi, min(fet1), min(fet2), min(fet3)])
    #    results2.append([epi, 100-(fet1.index(min(fet1))+1), 100-(fet2.index(min(fet2))+1), 100-(fet3.index(min(fet3))+1)])
    #    genomics.write_file([fet1, fet2, fet3], '/Users/woojunshim/Research/Data/rp/Roadmap/results/'+epi+'_performance_fet_'+top_genes+'.txt')
    #genomics.write_file(results1, '/Users/woojunshim/Research/Data/rp/Roadmap/results/best_pvalues_'+top_genes+'.txt')
    #genomics.write_file(results2, '/Users/woojunshim/Research/Data/rp/Roadmap/results/best_percentiles_'+top_genes+'.txt')


    ### TRIMMING BROAD PEAK FILES
    #pathway = '/Users/woojunshim/Research/bigdata/paige/h3k4me3/peaks/'
    #days = ['day0', 'day2', 'day5', 'day9', 'day14']
    #for epi in days:
    #    temp = genomics.read_file1(pathway+'h3k4me3_'+epi+'.broadPeak')
    #    for no in range(len(temp)):
    #        short_ = temp[no][3].split("bam_")
    #        name = short_[1]+'_'+str(no+1)
    #        temp[no][3] = name
    #    genomics.write_file(temp, pathway+'h3k4me3_'+epi+'_.broadPeak')


    ### RUN ANALYSIS
    #pathway = '/Users/woojunshim/Research/bigdata/paige/h3k4me3/peaks/'
    #pathway = '/Users/woojunshim/Research/bigdata/roadmap/'
    #output_pathway = '/Users/woojunshim/Research/Data/ENCODE/'
    #pathway = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/'
    #files = ['GSE96290_ENCFF682XDY_peaks_hg19_fetal_cardiac_muscle_invitro.bed','GSE96290_ENCFF382BJH_replicated_peaks_hg19_fetal_cardiac_muscle_invitro.bed','CVP_K4.bed']
    #files = ['CVP_K4.bed']
    #days = ['day0','day2','day5', 'day9', 'day14']
    #days = ['day14']
    #files = ['E124','E125','E126','E127','E128','E129']
    #width = 2500
    #for epi in files:
    #    print epi
    #    filename_ = output_pathway+'h3k4me3_'+epi+'_assigned_all.bed'
    #    temp = genomics.read_file1(filename_)
    #    genes = set()
    #    results = []
    #    for item in temp:
    #        if item[1] not in genes:
    #            genes.add(item[1])
    #            results.append(item)
    #    results.insert(0, ['#peak','gene','width','chr','start','end'])
    #    genomics.write_file(results, output_pathway+'h3k4me3_'+epi+'_assigned_broadest.bed')
    #    filename_ = output_pathway+epi+'_H3K4me3_assigned.txt'
    #    filename__ = output_pathway+epi+'_H3K4me3_assigned_.txt'
    #    main(pathway+epi+'-H3K4me3.broadPeak', filename_, max_width__=width, dominant_=True)
    #    inter_cell_type_analysis(filename_, 2, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/summary_results_dominant_1.0_broadpeak.txt', 4, output_=filename__)
    #    check_dynamic_ranges(filename__, filename__, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/combined_broadpeak_cut_off_list__.txt', col_idx=2, gene_idx=1)
    #    final = select_lines(filename__, '/Users/woojunshim/Research/Data/mRNA_genes.txt', id_idx=1)
    #    genomics.write_file(final, filename__)

    ### TRIMMING TEXT FILES (E.G. Paige_K4Me3_day9_assigned.txt')
    #pathway = '/Users/woojunshim/Nathan/Results/'
    #days = ['day5', 'day9']
    #days = ['day14']
    #widths = [2500]
    #for epi in days:
    #    filename_ = output_pathway+'h3k4me3_'+epi+'_assigned.txt'
    #    for width in widths:
    #    results = trim_txt(filename_, [0,1,2,3,4,5,-1], ['#Peak_ID','Gene_symbol','DS','Chr','Start','End','Difference_from_threshold'])
    #    genomics.write_file(results, filename_)


    ### CALCULATE RANK PRODUCT
    #pathway = '/Users/woojunshim/Nathan/Results/'
    #days = ['day5','day9','day14']
    #widths = [2500]
    #for epi in epigenomes:
    #    for width in widths:
    #    input__ = genomics.read_file1(ourput_pathway+epi+'_assigned.txt')
    #    input_ = []
    #    for item in input__:
    #        if item[-1] != 'NA' and item[-1] != 'Not_observed':
    #            input_.append(item)
    #    rp_list = rank_product(input_, id_idx=1, indexs=[2,7])
    #    results = add_column(input_, add_list=rp_list, input_idx=1, add_idx=0, value_idx=1)
    #    results.insert(0, ['#Ensembl_ID','Gene_symbol','DS','Chr','Star','End','p-value','Difference_from_threshold','RP'])
    #    genomics.write_file(results, ourput_pathway+epi+'_assigned.txt')


    ### CALCULATE DISTANCES FROM REFERENCE PEAKS
    #results = calculate_distances('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/summary_results_pdf_dominant_2.5kb_FINAL.txt','/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/Ref_peaks.txt', input_id_idx=0, input_coord=[-3,-2,-1], ref_id_idx=0, ref_coord=[4,5,6])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/outcome.txt')

    ### EXTRACT GENOMIC COORDINATES FOR REFERENCE PEAKS
    #results = extract_cols('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/Ref_peaks.txt', prefix_idx=1, id_idx=2, filename='-H3K4me3.gappedPeak.bed', id_idx_=3, cols=[0,1,2], col_names=['#gene','cell_type','domain_id','DS','chr','start','end'])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/Ref_peaks.txt')

    ### IDENTIFY REFERENCE PEAKS FOR GENES
    #results = identify_ref_peaks('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/summary_results_pdf_dominant_2.5kb_standard.txt_1.0', gene_idx='0', epi_idx=1, value_idx=4, id_idx=2)
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/Ref_peaks.txt')

    ### TRIMMING TEXT FILES (E.G. Paige_K4Me3_day9_assigned.txt')
    #pathway = '/Users/woojunshim/Nathan/Results/'
    #days = ['day5', 'day9', 'day14']
    #days = ['day14']
    #widths = [None, 1000, 2500, 5000]
    #for day in days:
    #    for width in widths:
    #        results = trim_txt(pathway+'Paige_K4me3_'+day+'/'+'Paige_K4me3_'+day+'_assigned_'+str(width)+'.txt', [0,1,2,3,4,5,-2,-1], ['#Ensembl_ID','Gene_symbol','DS','Chr','Start','End','p-value','Difference_from_threshold'])
    #        genomics.write_file(results, pathway+'Paige_K4me3_'+day+'/'+'Paige_K4me3_'+day+'_assigned_'+str(width)+'.txt')

    ### 'BROADEST PEAKS ARE INFORMATIVE TO CAPTURE KEY REGULATORY GENES'
    #data_ = {}
    #input_data = {}
    #pathway = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Assigned_genes/all_peaks_2.5kb/'
    #deg_list_ = genomics.read_file1('/Users/woojunshim/Research/Data/highly_expressed_genes/DEG_list_top150.txt')
    #cardiac_genes_ = genomics.read_file1('/Users/woojunshim/Research/Data/cardiac_tf.txt')
    #mrna_list_ = genomics.read_file1('/Users/woojunshim/Research/Data/mRNA_genes.txt')
    #mrna_list = set()
    #deg_list = []
    #cardiac_genes = []
    #name_ = 'cardiac_genes'
    #for item in mrna_list_:
    #    mrna_list.add(item[0])
    #for group in tissue_groups:
    #    for epi in tissue_groups[group]:
    #        data_[epi] = {}
    #        input_data[epi] = []
    #        temp = open(pathway+epi+'_all_peaks_assigned.txt', 'r')
    #        for line in temp:
    #            line = line.strip().split()
    #            if not line[0].startswith('#'):
    #                if line[1] not in data_[epi]:
    #                    if line[1] in mrna_list:
    #                        data_[epi][line[1]] = []
    #                if line[1] in mrna_list:
    #                    data_[epi][line[1]].append(float(line[2]))
    #        for gene in data_[epi]:
    #            dominant = np.max(data_[epi][gene])
    #            average = np.mean(data_[epi][gene])
    #            sum_ = np.sum(data_[epi][gene])
    #            input_data[epi].append([gene, dominant, average, sum_])

    # You can mask this section
    #epigenomes = ['E069']
    #for epi in epigenomes:
    #    temp = input_data[epi]
    #    temp.insert(0, ['#dominant','average','sum'])
    #    genomics.write_file(temp, pathway+epi+'_ranked_genes.txt')

    #dominant1__ = []
    #average1__ = []
    #sum1__ = []
    #dominant2__ = []
    #average2__ = []
    #sum2__ = []
    #epigenomes = []
    #for epi in deg_list_:
    #    epigenomes.append(epi[0])
    #for epi in epigenomes:
    #    deg_list = []
    #    for item in deg_list_:
    #        if item[0] == epi:
    #            for no in range(1, len(item)):
    #                deg_list.append(item[no])
    #    temp = input_data[epi]
    #   temp = genomics.sort_(temp, idx=1, reverse_=True)
    #    temp_ = []
    #    for item in temp:
    #        temp_.append(item[0])
    #    a = sliding_fet(temp_, deg_list, convert_to_percentile=True)
    #    dominant1__.append([epi])
    #    dominant1__[-1].extend([np.min(a)])
    #    dominant2__.append([epi])
    #    dominant2__[-1].extend([100-(a.index(np.min(a))+1)])
    #    temp = genomics.sort_(temp, idx=2, reverse_=True)
    #    temp_ = []
    #    for item in temp:
    #        temp_.append(item[0])
    #    b = sliding_fet(temp_, deg_list, convert_to_percentile=True)
    #    average1__.append([epi])
    #    average1__[-1].extend([np.min(b)])
    #    average2__.append([epi])
    #    average2__[-1].extend([100-(b.index(np.min(b))+1)])
    #    temp = genomics.sort_(temp, idx=3, reverse_=True)
    #    temp_ = []
    #    for item in temp:
    #        temp_.append(item[0])
    #    c = sliding_fet(temp_, deg_list, convert_to_percentile=True)
    #    sum1__.append([epi])
    #    sum1__[-1].extend([np.min(c)])
    #    sum2__.append([epi])
    #    sum2__[-1].extend([100-(c.index(np.min(c))+1)])

    #    file_ = [a,b,c]
    #    genomics.write_file(file_, pathway+'performance_fet/'+epi+'_performance_fet_'+name_+'.txt')


    #genomics.write_file(dominant1__, pathway+'Dominant_best_p-values_'+name_+'.txt')
    #genomics.write_file(average1__, pathway + 'Average_best_p-values_'+name_+'.txt')
    #genomics.write_file(sum1__, pathway + 'Sum_best_p-values_'+name_+'.txt')
    #genomics.write_file(dominant2__, pathway + 'Dominant_best_positions_'+name_+'.txt')
    #genomics.write_file(average2__, pathway + 'Average_best_positions_'+name_+'.txt')
    #genomics.write_file(sum2__, pathway + 'Sum_best_positions_'+name_+'.txt')








    ### COUNT NUMBERS OF PEAKS (ALL & ASSIGNED & AVERAGE / GENE)
    #pathway1='/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Assigned_genes/all_peaks_2.5kb/'
    #pathway2='/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/'
    #tf_list_ = genomics.read_file1('/Users/woojunshim/Research/Data/TF/TF_combined.txt')
    #mrna_list_ = genomics.read_file1('/Users/woojunshim/Research/Data/mRNA_genes.txt')
    #tf_list = set()
    #mrna_list = set()
    #for item in tf_list_:
    #    tf_list.add(item[0])
    #for item in mrna_list_:
    #    mrna_list.add(item[0])
    #results = [['#cell_type','Total_peaks(gapped)','Assigned_peaks','Assigned_genes','Assigned_peaks/genes(Ave.)','Assigned_peak_width(Ave.)','Assigned_peak_width(Max.)']]
    #results1 = [['#cell_type','Assigned_peaks(TF)','SD(TF)','Assigned_peaks(nonTF)','SD(nonTF)','p-value(Wilcoxon)']]
    #count_table = read_table1(pathway1+'Peak_count_table.txt', del_colnames=True)
    #ave_width_table = read_table1(pathway1+'Ave.width_table.txt', del_colnames=True)
    #max_width_table = read_table1(pathway1+'Max.width_table.txt', del_colnames=True)
    #for group in tissue_groups:
    #    for epi in tissue_groups[group]:
    #        results.append([epi])
    #        results1.append([epi])
    #        total_cnt = 0
    #        total_genes = 0
    #        sum_peaks_no = 0
    #        peaks_width_ave = []
    #        peaks_width_max = []
    #        tf_count = []
    #        nontf_count = []
    #        data_ = open(pathway2+epi+'-H3K4me3.gappedPeak.bed', 'r')
    #        for line in data_:
    #            line = line.strip().split()
    #            if len(line) != 0:
    #                total_cnt += 1
    #        for gene in count_table:
    #            if (str(count_table[gene][epi]) != '0.0') and (gene in mrna_list):
    #                total_genes += 1
    #                sum_peaks_no += float(count_table[gene][epi])
    #                peaks_width_ave.append(float(ave_width_table[gene][epi]))
    #                peaks_width_max.append(float(max_width_table[gene][epi]))
    #                if gene in tf_list:
    #                    tf_count.append(float(count_table[gene][epi]))
    #                else:
    #                    nontf_count.append(float(count_table[gene][epi]))
    #        ave_peak = np.mean(peaks_width_ave)
    #        ave_peak_sd = np.std(peaks_width_ave)
    #        max_peak = np.mean(peaks_width_max)
    #        max_peak_sd = np.std(peaks_width_max)
    #        tf_ave = np.mean(tf_count)
    #        tf_ave_sd = np.std(tf_count)
    #        nontf_ave = np.mean(nontf_count)
    #        nontf_ave_sd = np.std(nontf_count)
    #        s, p = stat.ranksum(tf_count, nontf_count)
    #        results[-1].extend([total_cnt, sum_peaks_no, total_genes, float(sum_peaks_no)/total_genes, str(ave_peak)+'+/-'+str(ave_peak_sd), str(max_peak)+'+/-'+str(max_peak_sd)])
    #        results1[-1].extend([str(tf_ave), str(tf_ave_sd), str(nontf_ave), str(nontf_ave_sd), str(p)])
    #genomics.write_file(results, pathway1+'supplementary_table1.txt')
    #genomics.write_file(results1, pathway1+'ranksum_peak_count_mrna.txt')







    ### DENSITY ANALYSIS OF SINGLE PROMOTER USE
    #results = []
    #data_ = genomics.read_file('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/summary_results_pdf_dominant_2.5kb_standard.txt_1.0_.txt', [0,4], rowname='1')
    #table_ = read_table1('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Assigned_genes/all_peaks_2.5kb/Peak_count_table.txt')
    #epigenomes = []
    #for epi in data_:
    #    epigenomes.append(epi)
    #for epi in epigenomes:
    #    temp = data_[epi]
    #    for no in range(len(temp)):
    #        temp[no][1] = float(temp[no][1])
    #    temp = genomics.sort_(temp, idx=1, reverse_=True)
    #    input_list = []
    #    cat_list = []
    #    for item in temp:
    #        input_list.append(item[0])
    #    for gene in input_list:
    #        cat_list.append(str(table_[gene][epi]))
    #    a,b = density_analysis(cat_list, ['1.0'])
    #    results.append([epi])
    #    for item in a:
    #        results[-1].extend([item])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Assigned_genes/all_peaks_2.5kb/Single_peak_enrichment.txt')

    ### FET COMPARING TOP 30 DIFFERENTIALLY EXPRESSED TFS (SEE IF THEY HAVE A SINGLE PEAK)
    #deg_list = genomics.read_file1('/Users/woojunshim/Research/Data/highly_expressed_genes/DEG_list_top150.txt')
    #epigenomes = []
    #results = [['#cell_type','statistics','p-value']]
    #for item in deg_list:
    #    epigenomes.append(item[0])
    #table_ = read_table1('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Assigned_genes/all_peaks_2.5kb/Peak_count_table.txt')
    #del table_['colnames']
    #genes = []
    #for item in table_:
    #    genes.append(item)

    #for epi in epigenomes:
    #    a,b,c,d = 0, 0, 0, 0
    #    total = 0
    #    ref_list= []
    #    for i in range(len(deg_list)):
    #        item = deg_list[i]
    #        if item[0] == epi:
    #            for no in range(1, len(item)):
    #                ref_list.append(item[no])

    #    for gene in genes:
    #        if str(table_[gene][epi]) != '0.0':
    #            if gene in ref_list:
    #                if str(table_[gene][epi]) == '1.0':
    #                    a += 1
    #                elif str(table_[gene][epi]) != '1.0':
    #                    c += 1
    #            else:
    #                if str(table_[gene][epi]) == '1.0':
    #                    b += 1
    #                if str(table_[gene][epi]) != '1.0':
    #                    d += 1
    #    s, p = stat.fisher(a,b,c,d)
    #    results.append([epi, s, p])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Assigned_genes/all_peaks_2.5kb/Single_peak_enrichment_top150.txt')



    ### CREATE A LIST OF MRNA GENES FROM 'SUMMARY_RESULTS_PDF....TXT'
    #data_ = genomics.read_file1('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/summary_results_pdf_dominant_2.5kb_standard.txt_1.0_.txt')
    #results = set()
    #for item in data_:
    #    if item[0] not in results:
    #        results.add(item[0])
    #results = list(results)
    #genomics.write_file(results,'/Users/woojunshim/Research/Data/mRNA_genes.txt')



    ### REMOVE ALL NON-CODING RNA GENES IN 'SUMMARY_RESULTS_PDF....TXT'
    #data_ = genomics.read_file1('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/summary_results_pdf_dominant_2.5kb_standard.txt_1.0')
    #results = [['#gene','cell_type','domain','width','width/SD','..1','..2','..3','TF','mRNA','dynamic_range']]
    #for item in data_:
    #    if item[-2] == 'True':
    #        results.append(item)
    #genomics.write_file(results,'/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/summary_results_pdf_dominant_2.5kb_standard.txt_1.0_')



    ### CALCULATE STATISTICS COMPARING TWO GROUPS
    #pathway = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Assigned_genes/all_peaks_2.5kb/'
    #results = group_comparison(pathway+'Max.width_table.txt', pathway+'Peak_count_table.txt')
    #genomics.write_file(results, pathway+'Single_vs_multiple_peaks_expression_t-test.txt')

    ### ASSIGN GENES TO PEAKS (ALL OF PEAKS)
    #pathway='/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/'
    #tss_data = genomics.read_file('/Users/woojunshim/Research/Data/hg19_TSS_.txt',[1, 3, 4, 2, 5, 0])  # Numbers as column index in the input text file
    #tss_human19 = genomics.tss(tss_data, chr_idx=0, position_list=[1, 2], strand_idx=3, id_idx=4)
    #mrna_ = genomics.read_file1('/Users/woojunshim/Research/Data/mRNA_genes.txt')
    #mrna_list = set()
    #for item in mrna_:
    #    mrna_list.add(item[0])
    #assigned_genes = {}
    #test_groups = ['IMR90','Heart']
    #statistics_ = {}
    #print '1.Assigning genes..'
    #for group in tissue_groups:
    #    for epi in tissue_groups[group]:
    #        statistics_[epi] = [0.0, 100000.0]  # keep max. & min. values for each cell type
    #        print epi
    #        H3K4me3 = []
    #        assigned_genes[epi] = {}
    #        ii = open(pathway+epi + '-H3K4me3.gappedPeak.bed', 'r')
    #        genes_ = {}
    #        for line in ii:
    #            line = line.replace(' ', '_')
    #            line = line.strip().split()
    #            H3K4me3.append([line[0], line[1], line[2], line[3]])
    #            genes_[line[3]] = [line[0], line[1], line[2]]
    #        temp = genomics.assign_gene(H3K4me3, tss_human19, min_distance=0, max_distance=2500, centre=False, width=True, gene_include=True)
    #        results = []
    #        for item in temp:
    #            if (int(item[2]) < 9999999999) and (item[1] in mrna_list):
    #                results.append([item[0], item[1], genes_[item[0]][0],genes_[item[0]][1],genes_[item[0]][2], int(item[-1]), item[2]])
    #                if len(item[3]) != 0:
    #                    results[-1].extend([item[3][0]])
    #                else:
    #                    results[-1].extend(['NA'])
    #        results = genomics.sort_(results, idx=5, reverse_=True)
    #        results.insert(0, ['#peak_ID','gene', 'chr','start','end','width','distance','overlap_with_RefSeq_gene'])
    #        genomics.write_file(results, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Assigned_genes/all_peaks_2.5kb/more/'+epi+'_all_peaks_assigned.txt')

    ### STATISTICS FOR READS
    ### CALCULATES FOR EACH CELL TYPE
    #pathway = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Assigned_genes/all_peaks_2.5kb/'
    #genes = set()
    #count_table = {}
    #width_table = {}
    #epigenomes = set()
    #genes = set()
    #for group in tissue_groups:
    #    for epi in tissue_groups[group]:
    #        epigenomes.add(epi)
    #        temp = genomics.read_file1(pathway+epi+'_all_peaks_assigned.txt')
    #        for item in temp:
    #            if item[1] not in count_table:
    #                count_table[item[1]] = {}
    #            if item[1] not in width_table:
    #                width_table[item[1]] = {}
    #            if epi not in count_table[item[1]]:
    #                count_table[item[1]][epi] = 0
    #            if epi not in width_table[item[1]]:
    #                width_table[item[1]][epi] = []
    #            width_table[item[1]][epi].append(float(item[2]))
    #            count_table[item[1]][epi] += 1
    #            if item[1] not in genes:
    #                genes.add(item[1])
    #for gene in genes:
    #    for epi in epigenomes:
    #        if epi not in count_table[gene]:
    #            count_table[gene][epi] = 0
    #        if epi not in width_table[gene]:
    #            width_table[gene][epi] = [0]
    #for gene in genes:
    #    for epi in epigenomes:
    #        width_table[gene][epi] = np.max(width_table[gene][epi])

    #genomics.write_table1(count_table, pathway+'Peak_count_table.txt')
    #genomics.write_table1(width_table, pathway+'Max.width_table.txt')

    ### CONVERT ENSEMBLE IDS TO GENE SYMBOLS (57epigenomes.RPKM)
    #convert_table = conversion_table('/Users/woojunshim/Research/Data/Ensembl_gene_symbols_conversion_.txt', from_idx=1, to_idx=2)
    #pathway = '/Users/woojunshim/Research/Data/'
    #results = {}
    #input_ = read_table1(pathway+'57epigenomes.RPKM.txt')
    #for gene in input_:
    #    if gene in convert_table:
    #        name = convert_table[gene]
    #        results[name] = input_[gene]
    #genomics.write_table1(results, pathway+'57epigenomes.RPKM.symbols.txt')



    ### REVISTING LAST YEAR'S ANALYSIS (DIFFERENTIALLY EXPRESSED 150 TFS) IN SELECTD 46 CELL TYPES FROM ROADMAP
    ### SLIDING FET, BEST P-VALUES & POSITIONS
    #data_pathway = '/Users/woojunshim/Nathan/Results/57_epigenomes/'
    #marks = ['H3K4me3','H3K9me3','H3K27me3','H3K36me3']
    #deg_list = genomics.read_file1('/Users/woojunshim/Research/Data/highly_expressed_genes/DEG_list_top150_.txt')
    #epigenomes = []
    #for item in deg_list:
    #    epigenomes.append(item[0])
    #for mark in marks:
    #    print
    #    print 'Processing.. ', mark
    #    pvalues = []
    #    positions = []
    #    pvalues.append(['#cell_type', 'Widest', 'Sum_of_peaks'])
    #    positions.append(['#cell_type', 'Widest', 'Sum_of_peaks'])
    #    for epi in epigenomes:
    #        print epi
    #        deg_list_ = []
    #        for item in deg_list:
    #            if item[0] == epi:
    #                for no in range(1, len(item)):
    #                    deg_list_.append(item[no])
    #        data_benayoun = open(data_pathway+epi+'-'+mark+'.broadPeak/'+epi+'-'+mark+'.broadPeak_Benayoun.txt', 'r')
    #        input_benayoun = []
    #        temp = set()
    #        for line in data_benayoun:
    #            line = line.replace(' ', '_')
    #            line = line.strip().split()
    #            if not line[0].startswith('feature'):
    #                if len(line) > 5:
    #                    if line[1] not in temp:
    #                        input_benayoun.append([line[1],int(line[-1])-int(line[-2])])
    #                        temp.add(line[1])
    #        input_benayoun = genomics.sort_(input_benayoun, idx=1, reverse_=True)
    #        benayoun = []
    #        for item in input_benayoun:
    #            benayoun.append(item[0])
    #        data_our = open(data_pathway+epi+'-'+mark+'.broadPeak/'+epi+'-'+mark+'.broadPeak_our_method.txt', 'r')
    #        input_our = []
    #        for line in data_our:
    #            line = line.replace(' ', '_')
    #            line = line.strip().split()
    #            if not line[0].startswith('feature'):
    #                if len(line) > 4:
    #                    if line[1] not in temp:
    #                        input_our.append([line[3], int(line[1])])
    #        input_our = genomics.sort_(input_our, idx=1, reverse_=True)
    #        our = []
    #        for item in input_our:
    #            our.append(item[0])
    #        temp1 = sliding_fet(benayoun, set(deg_list_), output_='p-value')
    #        temp2 = sliding_fet(our, set(deg_list_), output_='p-value')
    #        pvalues.append([epi, min(temp1), min(temp2)])
    #        positions.append([epi, (1-(float(temp1.index(min(temp1))+1)/len(temp1)))*100, (1-(float(temp2.index(min(temp2))+1)/len(temp2)))*100])
    #    genomics.write_file(pvalues, data_pathway + mark + '_' + 'best_pvalues.txt')
    #    genomics.write_file(positions, data_pathway + mark + '_' + 'best_positions_percentile.txt')



    ### CREATE RANK TABLES
    #input_ = genomics.read_file('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/summary_results_pdf_dominant_2.5kb_standard.txt_1.0', [0,4], rowname='1')
    #input__ = read_table1('/Users/woojunshim/Research/Data/57epigenomes.RPKM.txt', threshold_=1.0)
    #convert_table = conversion_table('/Users/woojunshim/Research/Data/Ensembl_gene_symbols_conversion_.txt', from_idx=1, to_idx=2)
    #input_ = transpose_table1(input__, as_list_=True)
    #table_ = create_rank_table(input_, gene_idx=0, value_idx=1, rank_position=False)
    #table_ = {}
    #table_['colnames'] = table['colnames']
    #for item in table:
    #    if item in convert_table:
    #        name = convert_table[item]
    #        table_[name] = table[item]
    #genomics.write_table(table_, '/Users/woojunshim/Research/Data/highly_expressed_genes/Rank_table_H3K4me3_.txt')

    ### WILCOXON RANK SUM TEST COMPARING BETWEEN H3K4ME3 AND RPKM (CARDIAC REGULATORS) in 'E095'
    #regulators = genomics.read_file1('/Users/woojunshim/Research/Data/cardiac_regulators.txt')
    #h3k4me3 = read_table1('/Users/woojunshim/Research/Data/highly_expressed_genes/Rank_table_H3K4me3.txt', numerical=False, threshold_=False)
    #rpkm = read_table1('/Users/woojunshim/Research/Data/highly_expressed_genes/Rank_table_RPKM.txt', numerical=False, threshold_=True)
    #h3k4me3_list = []
    #rpkm_list = []
    #for item in regulators:
    #    gene = item[0]
    #    if gene in h3k4me3:
    #        if ('E095' in h3k4me3[gene]) and (h3k4me3[gene]['E095'] != 'NA'):
    #            h3k4me3_list.append(float(h3k4me3[gene]['E095']))
    #    if gene in rpkm:
    #        if ('E095' in rpkm[gene]) and (rpkm[gene]['E095'] != 'NA'):
    #            rpkm_list.append(float(rpkm[gene]['E095']))
    #s, pvalue = scipy.stats.ranksums(h3k4me3_list, rpkm_list)
    #print s
    #print pvalue

    ### COUNT NUMBERS OF EXPRESSED TFS (COMPARING FILTERING VS BOTTOM-UP METHODS)
    #deg_list = genomics.read_file1('/Users/woojunshim/Research/Data/highly_expressed_genes/DEG_list_expressed.txt')
    #data_ = genomics.read_file('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/summary_results_pdf_dominant_2.5kb_standard.txt_1.0',[0,4,-1], rowname='1')

    #results = []
    #results_positions = []
    #results.append(['#cell_type','filtering','bottom_up'])
    #results_positions.append(['#cell_type', 'filtering', 'bottom_up'])
    #epigenomes = []
    #ratio_ = False   # Convert to odd ratios?
    #density1 = []
    #density2 = []
    #genes = []
    #for item in deg_list:
    #    epigenomes.append(item[0])
    #for epi in epigenomes:
    #    pvalues = []
    #    temp = data_[epi]

    #    for no in range(len(temp)):
    #        temp[no][1] = float(temp[no][1])
    #    temp = genomics.sort_(temp, idx=1, reverse_=True)  # sort by DS
    #    input_genes1 = []
    #    input_genes2 = []
    #    no_genes = 0
    #    ref_genes = []
    #    all_genes = []
    #    for item in temp:
    #        all_genes.append(item[0])
    #    for item in deg_list:
    #        if item[0] == epi:
    #            for m in range(1, len(item)):
    #                ref_genes.append(item[m])
    #    overall_ratio = float(len(genomics.intersection(ref_genes, all_genes))) / float(len(temp))
    #    temp = genomics.sort_(temp, idx=-1, reverse_=True, numerical=False)  # sort by dynamics
    #    for item in temp:
    #        if item[-1] == 'True':
    #            input_genes1.append(item[0])
    #            no_genes += 1
    #    temp = genomics.sort_(temp, idx=1, reverse_=True)
    #    for no in range(no_genes):
    #        input_genes2.append(temp[no][0])
    #    if ratio_== True:
    #        a1 = (float(len(genomics.intersection(input_genes1, ref_genes))) / float(len(input_genes1))) / overall_ratio
    #        a2 = (float(len(genomics.intersection(input_genes2, ref_genes))) / float(len(input_genes2))) / overall_ratio
    #    else:
    #        a1 = len(genomics.intersection(input_genes1, ref_genes))
    #        a2 = len(genomics.intersection(input_genes2, ref_genes))
    #    p1 = sliding_fet(input_genes1, set(ref_genes))
    #    p2 = sliding_fet(input_genes2, set(ref_genes))
    #    pvalues.append(p1)
    #    pvalues.append(p2)
    #    results.append([epi, a1, a2])
        #genomics.write_file(pvalues,'/Users/woojunshim/Research/Data/highly_expressed_genes/Sliding_FET_expressed_TFs_'+epi+'.txt')
    #    d2, background_ = density_analysis(input_genes2, ref_genes)
    #    d1, background__ = density_analysis(input_genes1, ref_genes, background_ratio_=background_)
    #    density1.append([epi])
    #    density2.append([epi])
    #    for item in d1:
    #        density1[-1].extend([item])
    #    for item in d2:
    #        density2[-1].extend([item])
    #    genes1_2 = genomics.intersection(input_genes1, input_genes2)
    #    genes1_ref = genomics.intersection(input_genes1, ref_genes)
    #    genes2_ref = genomics.intersection(input_genes2, ref_genes)
    #    genes1_2_ref = genomics.intersection(genes1_ref, genes2_ref)
    #    input_genes1.insert(0, 'genes1')
    #    input_genes2.insert(0, 'genes2')
    #    genes1_2.insert(0, 'genes1_2')
    #    genes1_ref_exclusive = []
    #    genes2_ref_exclusive = []
    #    genes1_ref_ = set(genes1_ref)
    #    genes2_ref_ = set(genes2_ref)
    #    genes1_2_ref_ = set(genes1_2_ref)
    #    for item in genes1_ref_:
    #        if item not in genes1_2_ref_:
    #            genes1_ref_exclusive.append(item)
    #    for item in genes2_ref_:
    #        if item not in genes1_2_ref_:
    #            genes2_ref_exclusive.append(item)
    #    genes1_ref_exclusive.insert(0, 'genes1_ref_exclusive')
    #    genes2_ref_exclusive.insert(0, 'genes2_ref_exclusive')
    #    genes1_ref.insert(0, 'genes1_ref')
    #    genes2_ref.insert(0, 'genes2_ref')
    #    genes1_2_ref.insert(0, 'genes1_2_ref')
    #    genes.append([epi])
    #    genes.append(input_genes1)
    #    genes.append(input_genes2)
    #    genes.append(genes1_2)
    #    genes.append(genes1_ref)
    #    genes.append(genes2_ref)
    #    genes.append(genes1_2_ref)
    #    genes.append(genes1_ref_exclusive)
    #    genes.append(genes2_ref_exclusive)

    #genomics.write_file(density1, '/Users/woojunshim/Research/Data/highly_expressed_genes/Density_analysis_filtering_.txt')
    #genomics.write_file(density2, '/Users/woojunshim/Research/Data/highly_expressed_genes/Density_analysis_bottom_up_.txt')
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/highly_expressed_genes/Expressed_TFs_counts.txt')
    #genomics.write_file(genes, '/Users/woojunshim/Research/Data/highly_expressed_genes/Intersection_genes.txt')

    ### CAREATE A TABLE FILE FOR FILTERED GENES (ones in bottom-up list exclusively) (FROM 'Intersection_genes.txt')
    #deg_list = genomics.read_file1('/Users/woojunshim/Research/Data/highly_expressed_genes/DEG_list_expressed.txt')
    #epigenomes = []
    #table = {}
    #for item in deg_list:
    #    epigenomes.append(item[0])
    #table['colnames'] = epigenomes
    #data_table_ = open('/Users/woojunshim/Research/Data/highly_expressed_genes/Intersection_genes.txt', 'r')
    #data_ = {}
    #all_genes = set()

    #for line in data_table_:
    #    line = line.strip().split()
    #    if line[0] in epigenomes:
    #        data_[line[0]] = {}
    #        epi = line[0]
    #    else:
    #        data_[epi][line[0]] = set()
    #        for no in range(1, len(line)):
    #            data_[epi][line[0]].add(line[no])
    #            if line[0] == 'genes1_ref_exclusive':
    #                if line[no] not in all_genes:
    #                    all_genes.add(line[no])
    #for gene in all_genes:
    #    table[gene] = []
    #    cnt = 0
    #    for epi in epigenomes:
    #        if gene not in data_[epi]['genes1_ref_exclusive']:
    #            table[gene].append(0)
    #        else:
    #            table[gene].append(1)
    #            cnt += 1
    #    table[gene].append(cnt)
    #table['colnames'].append('Total')
    #genomics.write_table(table, '/Users/woojunshim/Research/Data/highly_expressed_genes/Saved_genes_table.txt')



    ### CREATE A COMBINED FILE FOR THE TOP FET P-VALUES (OR THE BEST RANK POSITIONS) FOR ALL 46 CELL TYPES
    #deg_list = genomics.read_file1('/Users/woojunshim/Research/Data/highly_expressed_genes/DEG_list_expressed.txt')
    #results = []
    #results_positions = []
    #results.append(['#cell_type','filtering','bottom_up'])
    #results_positions.append(['#cell_type', 'filtering', 'bottom_up'])
    #epigenomes = []
    #for item in deg_list:
    #    epigenomes.append(item[0])
    #for epi in epigenomes:
    #    file_ = open('/Users/woojunshim/Research/Data/highly_expressed_genes/'+epi+'_sliding_fet_expressed.txt', 'r')
    #    results.append([epi])
    #    results_positions.append([epi])
    #    for line in file_:
    #        line = line.strip().split()
    #        best_ = 1.0
    #        best_position = 0
    #        for no in range(len(line)):
    #            item = line[no]
    #            if float(item) < best_:
    #                best_ = float(item)
    #                best_position = no+1
    #        results[-1].extend([best_])
    #        results_positions[-1].extend([best_position])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/highly_expressed_genes/best_p-values_top30.txt')
    #genomics.write_file(results_positions, '/Users/woojunshim/Research/Data/highly_expressed_genes/best_positions_expressed.txt')

    ### CALCULATE FET P-VALUES AT 95TH PERCENTILE RANK
    #deg_list = genomics.read_file1('/Users/woojunshim/Research/Data/highly_expressed_genes/DEG_list_top150_.txt')
    #input_data = genomics.read_file('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/summary_results_pdf_dominant_2.5kb_standard.txt_1.0', [0,2,4,-1], rowname='1')
    #cut_off = 0.05  #95th percentile
    #results = []
    #results.append(['#cell_type','filtering','bottom_up_removal'])
    #epigenomes = []
    #for item in deg_list:
    #    epigenomes.append(item[0])
    #for epi in epigenomes:
    #    for no in range(len(input_data[epi])):
    #        input_data[epi][no][2] = float(input_data[epi][no][2])
    #    deg_list_ = []
    #    for no in range(len(deg_list)):
    #        if deg_list[no][0] == epi:
    #            deg_list_ = deg_list[no]
    #    temp = input_data[epi]
    #    temp = genomics.sort_(temp, idx=2, reverse_=True)
    #    cut_off_no = int(round(len(temp)*cut_off))
    #    temp1_ = genomics.sort_(temp, idx=-1, reverse_=True)
    #    temp1 = []
    #    temp2 = []
    #    cnt = 0
    #    for no in range(cut_off_no):
    #        if temp[no][-1] == 'True':
    #            cnt += 1
    #        temp2.append(temp[no][0])
    #    for no in range(cnt):
    #        temp1.append(temp1_[no][0])
    #    new_cut_off = float(cnt)/len(temp1_)
    #    p1 = point_fet(temp1, deg_list_, cut_off_=new_cut_off, output_='odd')
    #    p2 = point_fet(temp2, deg_list_, cut_off_=0.05, output_='odd')
    #    results.append([epi, p1, p2])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/highly_expressed_genes/fet_at_95th.txt')


    ### TAKE ONLY mRNA GENES
    #results = []
    #input_data = genomics.read_file1('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/summary_results_dominant_1.0_broadpeak.txt')
    #for item in input_data:
    #    if item[0] in mrna:
    #        results.append(item)
    #results.insert(0, ['#'])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/summary_results_dominant_1.0_broadpeak_mrna.txt')



    ### CALCULATE DENSITY OF DEGS IN BINS

    
    #marks = ['H3K27me3','H3K4me1','H3K9me3','H3K36me3','H3K4me3']
    #marks = ['H3K27ac']
    #refs = ['DEG_TF_list','All_expressed_TF','DEG_genes_list']
    #for mark in marks:
    #    for ref in refs:
    #        results = []
            #input_data = genomics.read_file('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/summary_results_dominant_1.0_broadpeak_mrna.txt',[0, 2, 4], rowname='1')
            #input__ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K4me3/All_widths_H3K4me3.txt')
    #        input__ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/'+mark+'_widths.txt')
            #input__ = read_table1('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.txt', threshold_=1.0)
            #input__ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/combined_table.txt')
    #        input_data = transpose_table1(input__, as_list_=True)
    #        deg_list = genomics.read_file1('/Users/woojunshim/Research/Data/highly_expressed_genes/DEG/new/'+ref+'.txt')
    #        epigenomes = []
    #        for item in deg_list:
    #            epigenomes.append(item[0])
    #        cell_types = get_colnames(input__)
    #        epigenomes = genomics.intersection(epigenomes, cell_types)
    #        for epi in epigenomes:
    #            temp = input_data[epi]
    #            for no in range(len(temp)):
    #                temp[no][1] = float(temp[no][1])   # 1 for RPKM, 2 for DS
    #            temp = genomics.sort_(temp, idx=1, reverse_=True)  # 1 for RPKM, 2 for DS
    #            temp_ = []
    #            for no in range(len(temp)):
    #                temp_.append(temp[no][0])  # [ ] needed when using transpose_table1, (but not needed if using transpose_table)
                #temp__ = convert_id(temp_, '/Users/woojunshim/Research/Data/Ensembl_gene_symbols_conversion_.txt', col_idx1=1, col_idx2=2)  # for expression data
    #            temp__= temp_# for H3K4me3 data
    #            for no in range(len(deg_list)):
    #                if deg_list[no][0] == epi:
    #                    deg_list_ = deg_list[no][1:]
    #            rr, background = density_analysis(temp__, deg_list_, accumulative_=True)
    #            rr.insert(0,epi)
    #            results.append(rr)
    #        genomics.write_file(results, '/Users/woojunshim/Research/Data/highly_expressed_genes/DEG/new/density_ratio_'+ref+'_'+mark+'_a.txt')

    ### CLACULATE ENRICHMENT SCORES FOR ALL HMS FOR TOP X% GENES 
    #results = []
    #input_data = genomics.read_file('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/summary_results_dominant_1.0_broadpeak_mrna.txt',[0, 2, 4], rowname='1')
    #input__ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K4me3/All_widths_H3K4me3.txt')
    #input__ = read_table1('/Users/woojunshim/Research/Data/46epigenomes.RPKM.symbols.txt', threshold_=1.0)
    #input__ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/combined_table.txt')
    #input__ = read_table1('/Users/woojunshim/Research/Data/broadPeaks/H3K27me3_widths.txt')
    #input_data = transpose_table1(input__, as_list_=True)
    #types = [['TF','DEG_TF_list.txt'],['DEG','DEG_genes_list.txt'],['All_TF','All_expressed_TF.txt']]
    #for no in range(len(types)):
    #    n1 = types[no][1]
    #    n0 = types[no][0]
    #    deg_list = genomics.read_file1('/Users/woojunshim/Research/Data/highly_expressed_genes/DEG/new/'+n1)
    #    epigenomes = []
    #    for item in deg_list:
    #        epigenomes.append(item[0])
    #    for epi in epigenomes:
    #        temp = input_data[epi]
    #        for no in range(len(temp)):
    #            temp[no][1] = float(temp[no][1])   # 1 for RPKM, 2 for DS
    #        temp = genomics.sort_(temp, idx=1, reverse_=True)  # 1 for RPKM, 2 for DS
    #        temp_ = []
    #        for no in range(len(temp)):
    #            temp_.append(temp[no][0])  # [ ] needed when using transpose_table1, (but not needed if using transpose_table)
    #        temp__ = convert_id(temp_, '/Users/woojunshim/Research/Data/Ensembl_gene_symbols_conversion_.txt', col_idx1=1, col_idx2=2)  # for expression data
    #        temp__= temp_# for H3K4me3 data
    #        for no in range(len(deg_list)):
    #            if deg_list[no][0] == epi:
    #                deg_list_ = deg_list[no][1:]
    #        rr, background = density_analysis(temp__, deg_list_, accumulative_=False)
    #        rr.insert(0,epi)
    #        results.append(rr)
    #    genomics.write_file(results, '/Users/woojunshim/Research/Data/highly_expressed_genes/DEG/new/density_ratio_'+n0+'_h3k27me3.txt')



    #check_dynamic_ranges(data_pathway1 + 'summary_results_pdf_dominant_2.5kb_standard.txt',
    #                     data_pathway1 + 'summary_results_pdf_dominant_2.5kb_standard.txt_1.0',
    #                     cut_off_file=data_pathway1 + 'combined_cut_off_list_1.0.txt', col_idx=4, gene_idx=0,
    #                     convert=False)


    ### CALCULATE FILTERING SPECIFICITY METRICS
    #table = transpose_table('/Users/woojunshim/Research/Data/highly_expressed_genes/Highly_expressed_TFs.txt')
    #table_ = transpose_table('/Users/woojunshim/Research/Data/57epigenomes.RPKM.txt')
    #input_data = genomics.read_file('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/summary_results_pdf_dominant_2.5kb_standard.txt_1.0', [0,2,4,-1], rowname='1')
    #tf_list_ = genomics.read_file1('/Users/woojunshim/Research/Data/TF/TF_combined_ENSG.txt')
    #tf_list = []
    #for item in tf_list_:
    #    tf_list.append(item[0])
    #for epi in input_data:
    #    for no in range(len(input_data[epi])):
    #        input_data[epi][no][2] = float(input_data[epi][no][2])
    #top_nos = [30,50,100,1000]
    #top_nos = [30]
    #fet_ = False   # Whether to calculate FET with a sliding point
    #fet = {}
    #top_deg = []
    #combined = [[],[],[],[]]
    #simple_removal = False  # Whether the analysis is to be done for the simple bottom-up removal
    #for top_n in range(len(top_nos)):
    #    results = {}
    #    results['colnames'] = ['non-member-ratio(a)', 'member-ratio(b)', 'a/b']
    #    top_no = top_nos[top_n]
    #    for epi in table:
    #        if epi != 'colnames':
    #            input_list = table[epi]
    #            input_list = genomics.sort_(input_list, idx=1,reverse_=False)
    #            input_list_ = []
    #            if top_no =='expressed':
    #                input_list = table_[epi]
    #                input_list = genomics.sort_(input_list, idx=1, reverse_=True)
    #                input_list_ = []
    #                cnt = 0
    #                for i in range(len(input_list)):
    #                    item = input_list[i]
    #                    if float(item[1]) >= 1.0:
    #                        input_list_.append(input_list[i][0])
    #                input_list1 = genomics.intersection(input_list_, tf_list)
    #                input_list_ = input_list1
    #            else:
    #               for i in range(top_no): # top highly expressed TFs
    #                    input_list_.append(input_list[i][0])
    #            genomics.write_file(input_list_, 'temp.txt')
    #            input_list__ = convert_id('temp.txt', '/Users/woojunshim/Research/Data/Ensembl_gene_symbols_conversion_.txt', col_idx1=1, col_idx2=2)
    #            temp = input_data[epi]
    #            temp = genomics.sort_(temp, idx=2, reverse_=True)
    #            a,b,c,d,e,f = filtering_ratios(temp, input_list__, gene_idx=0, dynamic_idx=-1)

    #            if simple_removal==True:  # True if you want to do the analysis on the simple bottom-up removal
    #                cnt = 0
    #                for no in range(len(temp)):
    #                    item = temp[no]
    #                    if item[-1] == 'True':
    #                        cnt += 1
    #                for no in range(cnt):
    #                    temp[no].extend(['True'])  # 'True' meaning it's within the list (after simple bottom-up removal)
    #                for no in range(cnt, len(temp)):
    #                    temp[no].extend(['False'])
    #                a, b, c, d, e, f = filtering_ratios(temp, input_list__, gene_idx=0, dynamic_idx=-1)

    #            input_list__.insert(0,epi)
    #            top_deg.append(input_list__)

                        
                #results[epi]=[float(f[3]), float(f[2]), float(f[3])/float(f[2])]  # change to [a,b,c] for filtering specificity

            #combined[top_n].extend([c])

     #           if fet_==True:
     #               fet[epi] = [[],[]]
     #               fet[epi][0] = sliding_fet(f[0], set(input_list__))
     #               fet[epi][1] = sliding_fet(f[1], set(input_list__))

        #genomics.write_table(results, '/Users/woojunshim/Research/Data/highly_expressed_genes/selection_specificity_top'+str(top_no)+'.txt')
    #for epi in fet:
    #    genomics.write_file(fet[epi], '/Users/woojunshim/Research/Data/highly_expressed_genes/'+epi+'_sliding_fet_expressed.txt')
    #genomics.write_file(top_deg, '/Users/woojunshim/Research/Data/highly_expressed_genes/DEG_list_top30.txt')




    ### CONVERT GENE SYMBOLS TO ENSEMBL IDS or vice versa
    #results = convert_id('/Users/woojunshim/Research/Data/highly_expressed_genes/E095_ranked.txt', '/Users/woojunshim/Research/Data/Ensembl_gene_symbols_conversion.txt', col_idx1=0, col_idx2=1)
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/highly_expressed_genes/E095_ranked_symbols.txt')


    ### ADD GENOMIC COORDINATES TO A FILE (e.g. summary_results_pdf_dominant_2.5kb_standard_1.5.txt)
    #results = add_coordinates(data_pathway1+'summary_results_pdf_dominant_2.5kb_standard_1.5.txt', epi_idx=1)
    #genomics.write_file(results, data_pathway1+'summary_results_pdf_dominant_2.5kb_standard_1.5_combined.txt')

    ### OVERLAP WITH FANTOM5 CAGE-PEAK FILE
    #for group in tissue_groups:
    #    for epi in ['E058']:
    #        results = overlap_fantom('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Assigned_genes/all_peaks_2.5kb/more/'+epi+'_all_peaks_assigned.txt','/Users/woojunshim/Research/Data/FANTOM5_CAGE_peaks.txt', distance=0, gene_idx=1, coordinates=[2,3,4])
    #        genomics.write_file(results, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Assigned_genes/all_peaks_2.5kb/more/'+epi+'_all_peaks_assigned_.txt')

    ### WILCOXON RANK SUM TEST FOR NORMALISED CAGE PEAK COUNTS PER 1KPBS (BETWEEN BROADEST PEAKS VS SMALLER PEAKS)
    ### WILCOXON RANK SUM TEST FOR DISTANCE TO REFSEQ TSS
    #results1 = [['#cell_type','stat','p-value(Wilcoxon)']]
    #results2 = [['#cell_type', 'stat', 'p-value(Wilcoxon)']]
    #for group in tissue_groups:
    #    for epi in tissue_groups[group]:
    #        temp = genomics.read_file1('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Assigned_genes/all_peaks_2.5kb/more/'+epi+'_all_peaks_assigned_.txt')
    #        a1= []
    #        a2= []
    #        b1= []
    #        b2= []
    #        genes = set()
    #        for item in temp:
    #            if item[1] not in genes:
    #                genes.add(item[1])
    #                a1.append(float(item[-2]))
    #                b1.append(float(item[-5]))
    #            else:
    #                a2.append(float(item[-2]))
    #                b2.append(float(item[-5]))
    #        s1, p1 = stat.ranksum(a1,a2)
    #        s2, p2 = stat.ranksum(b1,b2)
    #        results1.append([epi, s1, p1])
    #        results2.append([epi, s2, p2])

    #genomics.write_file(results1, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Assigned_genes/all_peaks_2.5kb/more/Wilcoxon_normalised_FANTOM_peaks_per_1kb_broadest_vs_smaller_peaks.txt')
    #genomics.write_file(results2, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Assigned_genes/all_peaks_2.5kb/more/Wilcoxon_distance_to_RefSeqTSS_broadest_vs_smaller_peaks.txt')


    ### CALCULATE OVERLAP PROPORTIONS OF DOMINANT PEAKS
    #peaks = {}
    #tf_ = genomics.read_file1('/Users/woojunshim/Research/Data/TF/TF_combined.txt')
    #tf_list = set()
    #epigenomes = []
    #for group in tissue_groups:
    #    for epi in tissue_groups[group]:
    #        epigenomes.append(epi)
    #for item in tf_:
    #    tf_list.add(item[0])
    #for group in tissue_groups:
    #    for epi in tissue_groups[group]:
    #        genes = set()
    #        peaks[epi] = {}
    #        temp = genomics.read_file1('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Assigned_genes/all_peaks_2.5kb/more/'+epi+'_all_peaks_assigned_.txt')
    #        for item in temp:
    #            if item[1] not in genes:
    #                genes.add(item[1])
    #                if item[1] not in peaks[epi]:
    #                    peaks[epi][item[1]] = [item[2], item[3], item[4]]
    #for group in tissue_groups:
    #    for epi in tissue_groups[group]:
    #        print epi
    #        genes = set()
    #        temp = genomics.read_file1('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Assigned_genes/all_peaks_2.5kb/more/' + epi + '_all_peaks_assigned_.txt')
    #        for no in range(len(temp)):
    #            cnt = 0
    #            overlap = 0
    #            gene = temp[no][1]
    #            len_gene = (float(temp[no][4]) - float(temp[no][3])) / 1000
    #            for epi_ in epigenomes:
    #                if epi != epi_:
    #                    coordinate1 = [temp[no][2], int(temp[no][3]), int(temp[no][4])]
    #                    if gene in peaks[epi_]:
    #                        coordinate2 = [peaks[epi_][gene][0], int(peaks[epi_][gene][1]), int(peaks[epi_][gene][2])]
    #                        if check_overlap(coordinate1, coordinate2):
    #                            overlap += 1
    #                        cnt += 1
    #            if cnt != 0:
    #                temp[no].extend([(float(overlap)/float(cnt))/len_gene])
    #            else:
    #                temp[no].extend(['NA'])
    #            if gene not in genes:
    #                temp[no].extend(['True'])
    #                genes.add(gene)
    #            else:
    #                temp[no].extend(['False'])
    #        temp.insert(0, ['#peak_ID','gene','chr','start','end','width','distance	overlap_with_RefSeq_gene','CAGE_peak_counts','Normalised_CAGE_peak_counts_per_1kbs','CAGE_peak_counts(ratio)','Overlap_prop(per_1kb)','Dominant_peak'])
    #        genomics.write_file(temp, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Assigned_genes/all_peaks_2.5kb/more/' + epi + '_all_peaks_assigned__.txt')

    ### CALCULATE WILCOX RANK SUM TEST (NORMALISED OVERLAP PROPORTIONS & VARIANCE WITHIN THE DOMINANT PEAKS)
    #results1 = [['#cell_type','stat','normalised_overlap_proportions(compare_dominant_vs_other_peaks)']]
    #results2 = [['#cell_type','variance(dominant_peaks)','variance(smaller_peaks)']]
    #for group in tissue_groups:
    #    for epi in tissue_groups[group]:
    #        a= []
    #        b= []
    #        temp = genomics.read_file1('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Assigned_genes/all_peaks_2.5kb/more/' + epi + '_all_peaks_assigned__.txt')
    #        for item in temp:
    #            if item[-2] != 'NA':
    #                if item[-1] == 'True':
    #                    a.append(float(item[-2]))
    #                else:
    #                    b.append(float(item[-2]))
    #        s, p = stat.ranksum(a,b)
    #        results1.append([epi, s, p])
    #        a= []
    #        b= []
    #        temp = genomics.read_file1('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Assigned_genes/all_peaks_2.5kb/more/' + epi + '_all_peaks_assigned__.txt')
   #        for item in temp:
   #             if item[-1] == 'True':
   #                 a.append(float(item[5]))
    #            else:
    #                b.append(float(item[5]))

     #       results2.append([epi, np.var(a), np.var(b)])
    #genomics.write_file(results1, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Assigned_genes/all_peaks_2.5kb/more/overlap_with_FANTOM5_peaks.txt')
    #genomics.write_file(results2, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Assigned_genes/all_peaks_2.5kb/more/variance_table.txt')











    ### CHECK INTERSECTIONS BETWEEN DEG AND GENES WITH HIGH H3K4ME3 WIDTHS
    #file_ = {}
    #file__ = open(data_pathway1+'summary_results_pdf_dominant_2.5kb_standard.txt_', 'r')
    #for line in file__:
    #    line = line.strip().split()
    #    if not line[0].startswith('#'):
    #        if line[1] not in file_:
    #            file_[line[1]] = []
    #        file_[line[1]].append([line[0], float(line[4]), line[10]])
    #degs=get_DEG('/Users/woojunshim/Research/Data/56_epigenomes_empirical.txt')
    #temp = []
    #for epi in degs:
    #    for item in degs[epi]:
    #        temp.append([epi, item])
    #genomics.write_file(temp, data_pathway1+'Sig_highly_expressed_genes.txt')
    #intersection_ = get_intersection(file_, degs, no_genes=100, dynamic_filter=True)
    #temp = []
    #for epi in intersection_:
    #    temp.append([epi, str(intersection_[epi])])
    #genomics.write_file(temp, data_pathway1+'100_genes_vs_HEGs.txt' )

    ### EXTRACT A SPECIFIC EPIGENOME FROM 'summary_...txt' file
    #epi = 'E083'
    #input_ = genomics.read_file(data_pathway1+'summary_results_pdf_dominant_2.5kb_standard.txt_1.2',[0,1,2,3,4,8,9,10])
    #output_ = genomics.find_entry(input_, feature=epi)
    #genomics.write_file(output_, data_pathway1+epi+'_summary_1.2.txt')

    ### ADD HIGH DYNAMIC TAGS
    #check_dynamic_ranges(data_pathway1+'summary_results_pdf_dominant_2.5kb_standard.txt', data_pathway1+'summary_results_pdf_dominant_2.5kb_standard.txt_1.5', cut_off_file=data_pathway1+'combined_cut_off_list_1.5.txt', col_idx=4, gene_idx=0, convert=False)

    ### REMOVE NCNRA GENES AND COMBINE 'broad_tf_background.txt' & 'broadpeak_nontf_background.txt' INTO ONE FILE
    #input_ = open('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/broadpeak_combined_enrichment_table.txt', 'r')
    #header = []
    #results = []
    #for line in input_:
    #    line = line.strip().split()
    #    if line[0].startwith('E0'):
    #        for m in line:
    #            header.append(m)
    #    else:
    #        if line[0] in mrna:

    ### CONVERT FISHER'S EXACT TEST (TISSUE TYPES) INTO NORMALISED -LOG10(P-VALUE) (RANGING FROM 0 TO 1 FOR EACH GENE)
    #file_ = read_table1('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/broadpeak_tissue_enrichment_pvalues_.txt', del_colnames=True)
    #for gene in file_:
    #    for tissue in file_[gene]:
    #        if float(file_[gene][tissue]) == float(1.0):
    #            file_[gene][tissue] = 0.0
    #        else:
    #            file_[gene][tissue] = -np.log10(float(file_[gene][tissue]))
    #for gene in file_:
    #    sum_ = 0.0
    #    for m in file_[gene]:
    #        sum_ += float(file_[gene][m])
    #    if sum_ != 0.0:   # remove genes with p-values of 0 for all tissue types
    #        for m in file_[gene]:
    #            file_[gene][m] = float(file_[gene][m]) / sum_
    #genomics.write_table1(file_, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/broadpeak_tissue_enrichment_evidence_score.txt')



    ### FISHER'S EXACT TEST FOR GENES ACROSS TISSUE TYPES
    #pathway = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/'
    #tf_enrichment_table = enrichment_analysis(input_file=pathway+'gene_entropy_tissue_counts.txt', background_file=pathway+'gene_entropy_tissue_counts_background.txt', output_='p-value',binary_output=False)
    #non_tf_enrichment_table = enrichment_analysis(input_file=pathway + 'non_tf_dynamics_range_table_GROUP_counts.txt',background_file=pathway + 'non_tf_dynamics_range_table_GROUP_background_counts.txt',output_='p-value', binary_output=False)
    #genomics.write_table(tf_enrichment_table, pathway+'gene_entropy_enrichment_pvalues_.txt')
    #genomics.write_table(non_tf_enrichment_table, pathway+'non_tf_tissue_enrichment_table_pvalues.txt')


    ### DEFINE THE NON-LINEAR (DYNAMIC) RANGE
    #define(threshold_=2.0, file_='/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/summary_results_dominant_1.0_broadpeak_mrna_.txt', output_='/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/new_broadpeak__')

    ### CONVERT 'Paige_K4Me3_day..txt' to a standard BED format
    #pathway = '/Users/woojunshim/Nathan/Results/'
    #days = ['day5', 'day9', 'day14']
    #for day in days:
    #    results = create_bed(pathway+'Paige_K4me3_'+day+'/'+'Paige_K4me3_'+day+'_Benayoun.txt', chr_idx=-3, start_idx=-2, end_idx=-1, id_idx=0)
    #    genomics.write_file(results, pathway+'Paige_K4me3_'+day+'/'+'Paige_K4me3_'+day+'_Benayoun.bed')


    ### RUN ANALYSIS (WITH FILTERING SPECIFICITY)
    #pathway_='/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Analysis_results/Tsankov/'
    #files = ['Assigned_genes_dMS__.txt']
    #exp_ = genomics.read_file1('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Analysis_results/Tsankov/expression_FPKM_dMS.txt')
    #exp_ = genomics.sort_(exp_, idx=1, reverse_=True, numerical=True)
    #tf_list_ = genomics.read_file1('/Users/woojunshim/Research/Data/TF/TF_combined.txt')
    #top_no = 30
    #exp = []
    #tf_list = []
    #cnt = 0

    #for item in tf_list_:
    #    tf_list.append(item[0])
    #for item in exp_:
    #    if str(item[0]) != '-':
    #        if str(item[0]) in tf_list:
    #            exp.append(item[0])
    #            cnt += 1
    #    if cnt == top_no:
    #        break

    #cardiac_genes = exp
    #cardiac_genes_ = genomics.read_file1('/Users/woojunshim/Research/Data/cardiac_tf.txt')
    #cardiac_genes = []
    #results = []
    #fet = []
    #for item in cardiac_genes_:
    #    if not item[0].startswith('#'):
    #        cardiac_genes.append(item[0])

    #for file in files:
    #    temp = genomics.read_file(pathway_+file, [1,2,-1])
    #    for no in range(len(temp)):
    #        temp[no][1] = float(temp[no][1])
    #    temp = genomics.sort_(temp, idx=1, reverse_=True)
    #    a, b, c, d, e, f = filtering_ratios(temp, cardiac_genes, gene_idx=0, dynamic_idx=-1)
    #    results.append([file, a, b, c])
    #    fet = [[],[]]
    #    fet[0] = sliding_fet(f[0], set(cardiac_genes))
    #    fet[1] = sliding_fet(f[1], set(cardiac_genes))
    #    genomics.write_file(results, pathway_+file+'_filtering.txt')
    #    genomics.write_file(fet, pathway_+file+'_fet.txt')
    #    print file
    #    print 'filtering:',len(d)
    #    print 'bottom-up:',len(e)




    ### FIND A INTRA-THRESHOLD AND FILTER OUT
    #results = find_intra_threshold(
    #        '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Analysis_results/Test1/E095-H3K4me3.gappedPeak.bed___.txt',
    #        col_idx=2, threshold_=1.5)
    #results = genomics.sort_(results, idx=2, reverse_=True)
    #genomics.write_file(results,
    #                        '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Analysis_results/Test1/E095_summary_1.0_filtered.txt')

    ### CHECK DYNAMIC RANGE
    #pathway_ = '/Users/woojunshim/Research/Data/Paige/1/'
    #files = ['h3k4me3_day0','h3k4me3_day2','h3k4me3_day5','h3k4me3_day9','h3k4me3_day14']
    #for file in files:
    #    check_dynamic_ranges(pathway_+file+'_assigned.txt', pathway_+file+'_assigned_.txt','/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/combined_broadpeak_cut_off_list.txt', col_idx=2, gene_idx=1, convert=False)

    ### CREATE A TABLE (AVERAGE DS OF GENES IN EACH TISSUE GROUP)
    #input_ = genomics.read_file('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/summary_results_dominant_1.0_broadpeak.txt', [1,4], rowname='0')
    #results=[]
    #del tissue_groups['Other']
    #epigenomes = []
    #epigenomes_ = set()
    #for epi in tissue_groups:
    #    if len(tissue_groups) > 1:
    #        epigenomes.append(epi)
    #epigenomes_ = set(epigenomes)
    #for gene in input_:
    #    for item in input_[gene]:
    #        if item[0] in epigenomes_:

    ### CREATE BACKGROUND COUNT TABLE
    #data_ = open('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/summary_results_dominant_1.0_broadpeak.txt', 'r')
    #results={}
    #for line in data_:
    #    line = line.strip().split()
    #    if not line[0].startswith('#'):
    #        if line[0] not in results:
    #            results[line[0]] = set()
    #        results[line[0]].add(line[1])
    #output_ = {}
    #for item in results:
    #    output_[item] = {}
    #    for epi in epigenomes:
    #        if epi in results[item]:
    #            output_[item][epi] = 1
    #        else:
    #            output_[item][epi] = 0
    #genomics.write_table1(output_, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/broadpeak_combined_background_counts.txt')


    ### CREATE FOREGROUND COUNT TABLE
    #data_ = open('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/summary_results_dominant_1.0_broadpeak_mrna_.txt', 'r')
    #cut_off_ = genomics.read_file('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/combined_broadpeak_cut_off_list__.txt', [1], rowname='0')
    #results={}
    #for line in data_:
    #   line = line.strip().split()
    #   if not line[0].startswith('#'):
    #       if line[0] not in results:
    #           results[line[0]] = set()
    #       if line[0] in cut_off_:
    #           if float(line[4]) > float(cut_off_[line[0]][0][0]):
    #               results[line[0]].add(line[1])
    #output_ = {}
    #for item in results:
    #   output_[item] = {}
    #   for epi in epigenomes:
    #       if epi in results[item]:
    #           output_[item][epi] = 1
    #       else:
    #           output_[item][epi] = 0
    #genomics.write_table1(output_, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/broadpeak_combined_foreground_counts_all.txt')

    ### MERGE COUNTS INTO TISSUE GROUPS
    #pp_ = genomics.read_file1('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/top5_genes_h3k4me3.txt')
    #pp = set()
    #for line in pp_:
    #    pp.add(line[0])
    #data_ = open('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/gene_entropy_table_z_.txt', 'r')
    #input_ = {}
    #epigenomes = []
    #for line in data_:
    #    line = line.strip().split()
    #    if line[0].startswith('E0'):
    #        for epi in line:
    #            epigenomes.append(epi)
    #    else:
    #        if (line[0] not in input_) and (line[0] in pp):
    #            input_[line[0]] = []
    #        if line[0] in pp:
    #            for no in range(1, len(line)):
    #                epi = epigenomes[no-1]
    #                if int(line[no]) == 1:
    #                    input_[line[0]].append(epi)
    #group_counting(input_, tissue_groups_, 'gene_entropy_tissue_counts.txt', proportion=False)

    ### EXTRACT FPKM VALUES
    #exp_data = extract_info('nature14233-s1.txt', gene_id_idx=4, exp_idx=7)
    #exp_data.insert(0,['#gene_ID','FPKM'])
    #genomics.write_file(exp_data, input_pathway+'expression_FPKM_dMS.txt')

    ### COUNT TF CHIP-SEQ
    #main1('Assigned_genes_dMS.txt', ['GSM1505631_Eomes_111212_mesendo.bed.peak.txt','GSM1505784_T_111212_mesendo.bed.peak.txt','GSM1505726_Pou5f1_111212_mesendo.bed.peak.txt','GSM1505624_Ctcf_111512_mesendo.bed.peak.txt'],['Eomes','T','Pou5f1','CTCF'])

    ### SUMMARISE THE TF ENRICHMENT IN BINS
    #results_ = []
    #for i in range(7, 11):  # i= column numbers of TF counts
    #    results_.append(chip_enrichment('results.txt', i, 635, sort_by=2, binary=False, normalise=True))
    #genomics.write_file(results_, input_pathway+'enrichment_counts_normalised_H3K4me3.txt')

    ### ADD FPKM VALUES TO 'results.txt'
    #new_results = add_column('results.txt', 'expression_FPKM_dMS.txt', id_idx=1, insert_head='FPKM', insert_position=6)
    #genomics.write_file(new_results, input_pathway+'results.txt')

    ### EXTRACT A LIST OF GENES WITH THEIR PROMOTER REGIONS MARKED BY A GIVEN TF CHIP-SEQ BINDING EVENTS
    ### AN STEP FOR GO FUNCTIONAL ANALYSIS
    #data__ = open(input_pathway+'results.txt', 'r')
    #data_ = []
    #for line in data__:
    #    line = line.strip().split()
    #    if not line[0].startswith('#'):
    #        data_.append(line)

    #tf_idx = 10  # Column index number where a TF of interest is recorded in data_
    #top = 100   # Number of genes to extract
    #tf_name = 'CTCF'  # Name of TF

    #for no in range(len(data_)):
    #    data_[no][2] = int(data_[no][2])
    #    data_[no][6] = float(data_[no][6])

    #data_ = genomics.sort_(data_, idx=2, reverse_=True)   # Sort by 2=H3K4me3 or 6=FPKM
    #filtered = num_filter_list(data_, col_idx=tf_idx, min_= 0.0)

    #total_genes = []
    #selected_genes = []
    #cnt = 0
    #for item in filtered:
    #    if int(item[tf_idx]) > 0.0:
    #        total_genes.append([item[1]])
    #    if cnt < top:
    #    if cnt < top:define
    #        if int(item[tf_idx]) > 0.0:
    #            selected_genes.append([item[1]])
    #            cnt += 1
    #genomics.write_file(selected_genes, input_pathway + 'functional_analysis/' + tf_name + '_selected_H3K4me3.txt')
    #genomics.write_file(total_genes, input_pathway + 'functional_analysis/' + tf_name +'_all_genes.txt')

    ### EXTRACT GO ANALYSIS RESULTS (TAKING ONLY COLUMNS 0,1 AND -1)
    #files = ['E029','E083']
    #methods = ['average','dominant','sum']
    #columns = [0,1,9,-1]
    #column_names = ['Category','Term','Fold','FDR']
    #input_pathway = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Assigned_genes/all_peaks_2.5kb/GO/'

    #for file in files:
    #    for method in methods:
    #        input_file = input_pathway+'GO_'+file+'_mrna_top5%_'+method+'.txt'
    #        input__ = open(input_file, 'r')
    #        input_ = []
    #        output_ = []
    #        for line in input__:
    #            line = line.replace(' ', '_')
    #            line = line.strip().split()
    #            if not line[0].startswith('Category'):
    #                output_.append([])
    #                for col in columns:
    #                    output_[-1].extend([line[col]])
    #        for no in range(len(output_)):
    #            item = output_[no]
    #            temp = item[1].split('~')
    #            if len(temp) > 1:
    #                output_[no][1] = temp[1]+'('+temp[0]+')'
    #        output_.insert(0, column_names)
    #        genomics.write_file(output_, input_pathway+'GO_'+file+'_mrna_top5%_'+method+'_short.txt')

    ### CALCULATE INTER-CELL TYPE P-VALUE
    #inter_cell_type_analysis('Assigned_genes_dMS.txt', 2, 'summary_results_pdf_dominant_2.5kb_standard_percentile.txt', 4)

    ### PROCESSING TF DATA FILES AND EXTRACT COLUMNS AND MERGING INTO A FILE
    #genomics.replace('/Users/woojunshim/Research/Data/TF/TF_uniprot.txt', '/Users/woojunshim/Research/Data/TF/TF_uniprot_.txt', ' ', '_')
    #input_ = genomics.read_file('/Users/woojunshim/Research/Data/TF/TF_uniprot_.txt', [4])
    #results = []
    #for item in input_:
    #    temp = item[0]
    #    temp = temp.split('_')
    #    results.append(temp[0])
    #results.insert(0, '#UniProt_Human_TF')
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/TF/TF_uniprot_short.txt')

    #input_ = genomics.read_file('/Users/woojunshim/Research/Data/TF/Homo_sapiens_transcription_factors_gene_list.txt', [0])
    #genomics.write_file(input_, '/Users/woojunshim/Research/Data/TF/TF_animalTFBD_short.txt')

    # MERGING
    #input1 = genomics.read_file('/Users/woojunshim/Research/Data/TF/TF_uniprot_short.txt',[0])
    #input2 = genomics.read_file('/Users/woojunshim/Research/Data/TF/TF_animalTFDB_short.txt',[0])
    #input3 = genomics.read_file('/Users/woojunshim/Research/Data/TF/TF_DBD_short.txt',[0])
    #results = set()
    #results_ = []
    #for item in input1:
    #    item = item[0]
    #    if item not in results:
    #        results.add(item)
    #for item in input2:
    #    item = item[0]
    #    if item not in results:
    #        results.add(item)
    #for item in input3:
    #    item = item[0]
    #    if item not in results:
    #        results.add(item)
    #for item in results:
    #    results_.append(item)
    #results_.insert(0, '#TF_combined')
    #genomics.write_file(results_, '/Users/woojunshim/Research/Data/TF/TF_combined.txt')

    ### CHECK IF A GIVEN PEAK PASSES THE THRESHOLD (BROAD PEAK)
    ### ADDS A COLUMN TO THE FILE
    #input_ = genomics.read_file1('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/summary_results_dominant_1.0_broadpeak_mrna.txt')
    #pp = []
    #threshold_ = genomics.read_file('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/combined_broadpeak_cut_off_list_.txt', [1], rowname='0')
    #for no in range(len(input_)):
    #    item  = input_[no][0]
    #    if item in threshold_:
    #        thre_ = float(threshold_[item][0][0])
    #        if thre_ != float(999999):
    #            input_[no].extend([float(input_[no][4])-thre_])
    #            pp.append(input_[no])
    #genomics.write_file(pp, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/summary_results_dominant_1.0_broadpeak_mrna_.txt')

    ### CALCULATE EMPIRICAL P-VALUES ON THE H3K4ME3 WIDTH CHANGE
    #input_ = genomics.read_file('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/summary_results_dominant_1.0_broadpeak_mrna_.txt', [0,2,4,-1], rowname='1')
    #for epi in input_:
    #    results = []
    #    temp_ = input_[epi]
    #    temp = []
    #    for item in temp_:
    #        if (item[-1]!='True') and (item[-1]!='False'):
    #            temp.append(item)
    #    for no in range(len(temp)):
    #        temp[no][-1] = float(temp[no][-1])
    #    temp = genomics.sort_(temp, idx=-1, reverse_=True)
    #    input_list = []
    #    for item in temp:
    #        input_list.append(float(item[-1]))
    #    pvalues = population_analysis(input_list, output_='empirical')
    #    for no in range(len(input_list)):
    #        temp[no].extend([pvalues[no]])
    #    temp.insert(0, ['#gene','peak','width/sd','difference_from_threshold','p-value(empirical)'])
    #    genomics.write_file(temp, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/new_ds/'+epi+'_new_ds.txt')

    ### REMOVE ONES WITH 999999 VALUES IN 'COMBINED_BROADPEAK_CUT_OFF_LIST_.TXT'
    #results = [['#gene','cut_off_threshold']]
    #input_ = genomics.read_file1('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/combined_broadpeak_cut_off_list_.txt')
    #for item in input_:
    #    if float(item[1]) != float(999999):
    #        results.append(item)
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/combined_broadpeak_cut_off_list__.txt')


    ### CALCULATE SUMS OF DS CHANGE FOR ALL GENES ACROSS CELL TYPES
    #results = [['#cell_type','sum_of_DS_change_for_all_genes/no_genes']]
    #ref_ = genomics.read_file('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/combined_broadpeak_cut_off_list__.txt', [1], rowname='0')
    #for epi in epigenomes:
    #    temp = genomics.read_file1('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/new_ds/'+epi+'_new_ds.txt')
    #    sum_ = 0.0
    #    cnt = 0
    #    for item in temp:
    #        if item[0] in ref_:
    #            sum_ += float(item[3])
    #            cnt += 1
    #    results.append([epi, sum_/cnt])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/new_ds/sum_ds_change.txt')


    ### SLIDING FET FOR BROAD PEAKS
    #input_ = genomics.read_file('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/summary_results_dominant_1.0_broadpeak_mrna_.txt', [0,4,-1], rowname='1')
    #top_genes = 'top150'
    #deg_list_ = genomics.read_file1('/Users/woojunshim/Research/Data/highly_expressed_genes/DEG_list_'+top_genes+'.txt')
    #results1 = [['#cell_type','filtering','simple_extraction']]  # for bet p-values
    #results2 = [['#cell_type','filtering','simple_extraction']]  # for best positions
    #cell_types = []
    #output_1 = []
    #output_2 = []
    #for item in deg_list_:
    #    cell_types.append(item[0])

    #for epi in cell_types:
    #    print epi
    #    ref_genes = []
    #    for item in deg_list_:
    #        if item[0] == epi:
    #            for m in range(1, len(item)):
    #                ref_genes.append(item[m])
    #    print len(ref_genes)
    #    temp = input_[epi]
    #    input_list = []
    #    no_genes = 0
    #    for no in range(len(temp)):
    #        temp[no][1] = float(temp[no][1])
    #        if temp[no][-1] == 'True':
    #            no_genes += 1
    #    temp = genomics.sort_(temp, idx=1, reverse_=True)
    #    for n in range(no_genes):
    #        input_list.append(temp[n][0])
    #    fet2 = sliding_fet(input_list, ref_genes, convert_to_percentile=True)
    #    input_list = []
    #    for n in range(len(temp)):
    #        if temp[n][-1] == 'True':
    #            input_list.append(temp[n][0])
    #    fet1 = sliding_fet(input_list, ref_genes, convert_to_percentile=True)
    #    print len(input_list)
    #    print len(fet1)
    #    print len(fet2)


    #    results1.append([epi, min(fet1), min(fet2)])
    #    results2.append([epi, fet1.index(min(fet1))+1, fet2.index(min(fet2))+1])
    #    genomics.write_file([fet1, fet2], '/Users/woojunshim/Research/Data/highly_expressed_genes/broadpeak/'+top_genes+'/'+epi+'_performance_fet_'+top_genes+'_broadpeak_percentile.txt')
    #    fet1.insert(0,epi)
    #    fet2.insert(0,epi)
    #    output_1.append(fet1)
    #    output_2.append(fet2)
    #genomics.write_file(results1, '/Users/woojunshim/Research/Data/highly_expressed_genes/broadpeak/'+top_genes+'/'+'best_pvalues_'+top_genes+'_broadpeak.txt')
    #genomics.write_file(results2, '/Users/woojunshim/Research/Data/highly_expressed_genes/broadpeak/'+top_genes+'/'+'best_positions_'+top_genes+'_broadpeak.txt')
    #genomics.write_file(output_1, '/Users/woojunshim/Research/Data/highly_expressed_genes/broadpeak/'+top_genes+'/'+'fet_filtering_percentile.txt')
    #genomics.write_file(output_2, '/Users/woojunshim/Research/Data/highly_expressed_genes/broadpeak/' + top_genes + '/' + 'fet_extraction_percentile.txt')

    ### FILTERING SPECIFICITY (BROAD PEAKS)
    #input_ = genomics.read_file('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/summary_results_dominant_1.0_broadpeak_mrna_.txt', [0,4,-1], rowname='1')
    #results = [['top_30','top_150','all_expressed']]
    #tops = ['top30','top150','expressed']
    #cell_list = []
    #ii = open('/Users/woojunshim/Research/Data/highly_expressed_genes/filtering_specificity_combined.txt', 'r')
    #for line in ii:
    #    line = line.strip().split()
    #    if line[0].startswith('E'):
    #        cell_list.append(line[0])
    #for epi in cell_list:
    #    results.append([epi])
    #    temp = input_[epi]
    #    for no in range(len(temp)):
    #        temp[no][1] = float(temp[no][1])
    #    temp = genomics.sort_(temp, idx=1, reverse_=True)

    #    for top in tops:
    #        deg_list_ = genomics.read_file1('/Users/woojunshim/Research/Data/highly_expressed_genes/DEG_list_' + top + '.txt')

    #        ref_genes = []
    #        for item in deg_list_:
    #            if item[0] == epi:
    #                for m in range(1, len(item)):
    #                    ref_genes.append(item[m])

    #        a,b,c,d,e,f = filtering_ratios(temp, ref_genes, gene_idx=0, dynamic_idx=-1)
    #        results[-1].extend([c])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/highly_expressed_genes/broadpeak/filtering_specificity_broadpeak.txt' )

    ### RESCUE PLAN FOR GENES WITH NO DS THRESHOLD
    ### WE INTERPOLATED INITIALLY USING CUBIC FIT WITH SMOOTHING 2, BUT 344 GENES WERE WITHOUT DS THRESHOLD
    #ref_ = genomics.read_file1('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/new_broadpeak__tf_cut_off_list.txt')
    #genes = set()
    #for no in range(len(ref_)):
    #    item = ref_[no]
    #    if float(item[1]) > 9999:
    #        genes.add(item[0])
    #input_ = genomics.read_file('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/summary_results_dominant_1.0_broadpeak.txt', [4], rowname='0')
    #results = [['#gene','DS_threshold']]
    #for gene in genes:
    #    temp = input_[gene]
    #    for no in range(len(temp)):
    #        temp[no][0] = float(temp[no][0])
    #    temp = genomics.sort_(temp, idx=0, reverse_=False)
    #    input_data = []
    #    for no in range(len(temp)):
    #        input_data.append([no+1, temp[no][0]])
    #    slope_1 = calculate_slope(input_data[0], input_data[-1], abs_=True)
    #    result_, cut_off = find_dynamic_range(input_data, interpolate_=False, output_cutoff=True, range_mark=0.5, threshold=2.0*slope_1)
    #    results.append([gene, cut_off])
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/rescued_genes_cut_off_list_2.0.txt')

    ### REPLACE 999999 VALUES WITH RESCURED DS THRESHOLD VALUES
    #ori_ = genomics.read_file1('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/new_broadpeak__tf_cut_off_list.txt')
    #new_ = genomics.read_file('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/rescued_genes_cut_off_list_2.0.txt', [1], rowname='0')
    #for no in range(len(ori_)):
    #    item = ori_[no]
    #    if float(item[1]) > 99999:
    #        ori_[no][1] = new_[item[0]][0][0]
    #ori_.insert(0, ['#gene','cut_off(DS)'])
    #genomics.write_file(ori_, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/combined_broadpeak_cut_off_list_2.0.txt')

    ### ** NEW ANALYSIS USING CLUSTERING OF GENES **
    #file_ = genomics.read_file('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/summary_results_dominant_1.0_broadpeak_mrna_.txt',[0,4], rowname='1')
    ### 1. IDENTIFY INTRA-CELLULAR THRESHOLD POSITION
    #results = []
    #for epi in epigenomes:
    #    print epi
    #    temp = file_[epi]
    #    for no in range(len(temp)):
    #        temp[no][1] = float(temp[no][1])
    #    temp = genomics.sort_(temp, idx=1, reverse_=False)
    #    input_list = []
    #    for no in range(len(temp)):
    #        input_list.append([no+1, temp[no][1]])
    #    overall_threshold = calculate_slope(input_list[0], input_list[-1], abs_=True)
    #    a,b = find_dynamic_range(input_list, threshold=1*overall_threshold, interpolate_=True, range_mark=0.99, output_cutoff=True)
    #    position = len(input_list) - int(a[0][0])  # First point (x-point) where the slope exceeds the threshold
    #    results.append([epi, position])
    #genomics.write_file(results,'/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/hclust/Roadmap_cutoff_positions.txt' )

    ### 2. CALCULATE CONDITIONAL PROBABILITIES (P(A<t1 | b<t2) where A,B are cell types amd t is a threshold)
    ### REQUIRES FILES = E**_clusters.txt
    #pathway = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/hclust/FET/clusters/'
    #t1 = 1.0
    #t2 = 1.0
    #results = {}
    #data_ = {}
    #groups = []
    #marg = {}
    #for epi in epigenomes:
    #    data_[epi] = {}
    #    file_ = genomics.read_file1(pathway+epi+'_clusters.txt')
    #    for item in file_:
    #        if item[3] !='FET':  # 1 for p-value, 2 for the odds-ratio
    #            if item[1] not in groups:
    #                if item[1]!='purple':
    #                    groups.append(item[1])
    #            if item[1] not in marg:
    #                marg[item[1]] = []
    #            if float(item[3]) > t2:
    #                marg[item[1]].append(1.0)
    #            else:
    #                marg[item[1]].append(0.0)
    #for item in marg:
    #    marg[item] = sum(marg[item]) / len(marg[item])
    #for group in groups:
    #    results[group] = {}
    #    for group_ in groups:
    #        results[group][group_] = []  # 1 yes, 0 no, results[A][B] --> probability of A given B
    #for epi in epigenomes:
    #    for group in groups:
    #        data_[epi][group] = 1
    #for epi in epigenomes:
    #    file_ = genomics.read_file1(pathway+epi+'_clusters.txt')
    #    for item in file_:
    #        if item[1] != 'FET':
    #            data_[epi][item[1]] = float(item[3])
    #for group in groups:
    #    for group_ in groups:
    #        for epi in epigenomes:
    #            if group==group_:
    #                results[group][group_].append(1.0)
    #            else:
    #                if (group_ in data_[epi]) and (group in data_[epi]):
    #                    if (float(data_[epi][group_]) > t2) and (float(data_[epi][group]) > t1): #'purple' group is not enriched in any cell types, so the conditional probability can't be established

    #                        results[group][group_].append(1.0)
    #                    else:
    #                        results[group][group_].append(0.0)
    #for group in groups:
    #    for group_ in groups:
    #        if group != group_:
    #            results[group][group_] = (sum(results[group][group_]) / len(results[group][group_])) / marg[group_]
    #        else:
    #            results[group][group_] = marg[group]
    #genomics.write_table1(results, pathway+'cluster_conditional_probabilities_odds_ratio_.txt')
    #genomics.write_file(marg, pathway+'cluster_marginal_probabilities.txt')

    ### 3. PERFORM THE ANALYSIS (THIS INCLUDES THE WHOLE PROCESS, ONCE THE GENE ASSIGNMENT IS COMPLETE)
    #pathway='/Users/woojunshim/Research/Data/Paige/1/'
    #pathway='/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/new_ds/'
    #filename='h3k4me3_day14_assigned_.txt'
    #filename='E034_new_ds.txt'
    #filenames = ['day0','day2','day5','day9','day14']
    #for filename in filenames:
    #    cluster_analysis(pathway+'h3k4me3_'+filename+'_assigned_.txt', '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/hclust/gene_clusters.txt', output_file=pathway+filename+'_results.txt', threshold_=1.0, input_gene_idx=1, input_value_idx=2, ref_gene_idx=1, ref_cluster_idx=2, plot_=False, cond_output_=pathway+filename+'_cond_prob.txt', threshold__=0.05, autoselection=True)


    #### 4. EXTRACT ODDS RATIOS FOR ALL ROADMAP DATASET
    #pathway = '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/hclust/FET/clusters/'
    #results = {}
    #groups = []
    #for epi in epigenomes:
    #    results[epi] = {}
    #    file_ = genomics.read_file1(pathway+epi+'_clusters.txt')
    #    for item in file_:
    #        if item[1] not in groups:
    #            groups.append(item[1])
    #for epi in epigenomes:
    #    for group in groups:
    #        results[epi][group] = 0.0
    #for epi in epigenomes:
    #    file_ = genomics.read_file1(pathway + epi + '_clusters.txt')
    #    for item in file_:
    #        results[epi][item[1]] = item[3]
    #genomics.write_table1(results, pathway+'Roadmap_odds_ratios.txt')

    ### 5. CALCULATE DIFFERENCE BETWEEN CONDITIONAL PROBABILITIES AND MARGINAL PROBABILITIES
    #pathway='/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/hclust/FET/clusters/'
    #results = independence_test(pathway+'cluster_conditional_probabilities_odds_ratio.txt', pathway+'cluster_probability.txt', cluster_idx=0, value_idx=1, threshold_=0.05)
    #results.insert(0,['#cluster','independece_score','up-regulated_by','down-regulated_by','not_affected_by'])
    #genomics.write_file(results, pathway+'cluster_independence_table.txt')

    ### 6. GENE-LEVEL ANALYSIS
    ### FIRST CALCULATE MARGINAL PROBABILITIES FOR ALL GENES ACROSS THE 111 EPIGENOMES
    #results = marginal_prob('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/gene_entropy_table_z_.txt')
    #genomics.write_file(results, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/genes_marginal_prob_entropy.txt')

    ### SECOND CALCULATE CONDITIONAL PROBABILITIES FOR ALL POSSIBLE PAIRS
    #table = read_table1('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/gene_entropy_table_z_.txt', del_colnames=True)
    #table = genomics.transpose(table)
    #results = conditional_prob1(table)
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/genes_conditional_prob_short_entropy.txt')

    ### THRID CALCULATE CONDITIONAL PROBABILITY - MARGINAL PROBABILITY FOR ALL GENES
    #cond = read_table1('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/genes_conditional_prob_short_entropy.txt', del_colnames=True)
    #marg = genomics.read_file('/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/genes_marginal_prob_entropy.txt', [1], rowname='0')
    #results = {}
    #for gene in cond:
    #    if gene not in results:
    #        results[gene] = {}
    #    for gene_ in cond:
    #        results[gene][gene_] = 0
    #for gene in cond:
    #    print gene
    #    pop = []
    #    marg_p = float(marg[gene][0][0])
    #    for item in cond[gene]:
    #        if item == gene:
    #            continue
    #        else:
    #            diff_ = float(cond[gene][item]) - marg_p
    #        results[gene][item] = diff_
    #        pop.append(diff_)
    #    mean_ = np.mean(pop)
    #    sd_ = np.std(pop)
    #    for item in results[gene]:
    #        z_ = stat.z_score(results[gene][item], mean_=mean_, sd_=sd_)
    #        p_ = stat.p_value(z_)
    #        results[gene][item] = p_
    #genomics.write_table1(results, '/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/entropy/dependence_p_value_entropy.txt')

    ### 7. ANALYSIS ONLY
    #pathway='/Users/woojunshim/Research/Data/Paige/1/'
    #pathway='/Users/woojunshim/Research/Data/Gapped_peaks/H3K4me3/Background_models/new_ds/'
    #filename='h3k4me3_day14_assigned_.txt'
    #analysis(pathway+filename, threshold_=1.0, input_gene_idx=1, input_value_idx=2, threshold__=0.05, cond_output_=None)










